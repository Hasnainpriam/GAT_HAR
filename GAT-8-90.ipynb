{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f288f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0017ca5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class\n",
       "0                0  2.660984 -9.653030  0.470237      1\n",
       "1                1  2.223091 -9.432167  2.223091      1\n",
       "2                2  2.098372 -9.481953  0.926070      1\n",
       "3                3  2.716461 -9.739352  0.912008      1\n",
       "4                4  2.288388 -9.371498  0.910390      1\n",
       "...            ...       ...       ...       ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21\n",
       "155403      155403  8.680778  4.261679 -0.159214     21\n",
       "155404      155404  8.756194  4.168306 -0.144251     21\n",
       "155405      155405  8.662222  4.219781 -0.183755     21\n",
       "155406      155406  8.738238  4.180277 -0.201711     21\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('no-outlier.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c51b238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0                0  2.660984 -9.653030  0.470237      1      0\n",
       "1                1  2.223091 -9.432167  2.223091      1      0\n",
       "2                2  2.098372 -9.481953  0.926070      1      0\n",
       "3                3  2.716461 -9.739352  0.912008      1      0\n",
       "4                4  2.288388 -9.371498  0.910390      1      0\n",
       "...            ...       ...       ...       ...    ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403      155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404      155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405      155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406      155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = LabelEncoder()\n",
    "data['label'] = label.fit_transform(data['Class'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c6752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "fig=sns.boxplot(data=data.iloc[0:8000,1:4],whis=[0, 100])\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777795b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0       2.660984 -9.653030  0.470237      1      0\n",
       "1       2.223091 -9.432167  2.223091      1      0\n",
       "2       2.098372 -9.481953  0.926070      1      0\n",
       "3       2.716461 -9.739352  0.912008      1      0\n",
       "4       2.288388 -9.371498  0.910390      1      0\n",
       "...          ...       ...       ...    ...    ...\n",
       "155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = data.drop('Unnamed: 0', axis=1)  \n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cce5ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bcdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn[['Acc_X', 'Acc_Y', 'Acc_Z']]\n",
    "y = dfn['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346d3bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985481</td>\n",
       "      <td>-0.807007</td>\n",
       "      <td>-0.491449</td>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865844</td>\n",
       "      <td>-0.763546</td>\n",
       "      <td>-0.059973</td>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.773343</td>\n",
       "      <td>-0.379243</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000638</td>\n",
       "      <td>-0.823993</td>\n",
       "      <td>-0.382704</td>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883684</td>\n",
       "      <td>-0.751608</td>\n",
       "      <td>-0.383103</td>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acc_X     Acc_Y     Acc_Z       mag  label\n",
       "0  0.985481 -0.807007 -0.491449  1.365267      0\n",
       "1  0.865844 -0.763546 -0.059973  1.155978      0\n",
       "2  0.831769 -0.773343 -0.379243  1.197382      0\n",
       "3  1.000638 -0.823993 -0.382704  1.351556      0\n",
       "4  0.883684 -0.751608 -0.383103  1.221712      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = ['Acc_X', 'Acc_Y', 'Acc_Z'])\n",
    "scaled_X['mag'] = np.sqrt(scaled_X['Acc_X'] ** 2 + scaled_X['Acc_Y'] ** 2 + scaled_X['Acc_Z'] ** 2)\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f2b34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>3.329777</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>3.326341</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>3.331364</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>3.318731</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>3.331576</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mag  label\n",
       "0       1.365267      0\n",
       "1       1.155978      0\n",
       "2       1.197382      0\n",
       "3       1.351556      0\n",
       "4       1.221712      0\n",
       "...          ...    ...\n",
       "155402  3.329777     20\n",
       "155403  3.326341     20\n",
       "155404  3.331364     20\n",
       "155405  3.318731     20\n",
       "155406  3.331576     20\n",
       "\n",
       "[155407 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X = scaled_X.drop(['Acc_X', 'Acc_Y', 'Acc_Z'], axis=1)\n",
    "\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d53643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1152f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer Nitro 5\\AppData\\Local\\Temp\\ipykernel_10688\\1805871090.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n"
     ]
    }
   ],
   "source": [
    "Fs = 20\n",
    "frame_size = Fs * 20\n",
    "hop_size = Fs * 1\n",
    "frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(scaled_X) - frame_size, hop_size):\n",
    "    x = scaled_X['mag'].values[i: i + frame_size]\n",
    "    label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n",
    "    frames.append([x])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194a32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.asarray(frames).reshape(-1, frame_size)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42c64bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESHAPE SHAPE:  (7751, 400)\n",
      "LABELS:  (7751,)\n",
      "LABELS:  0\n",
      "LABELS:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"RESHAPE SHAPE: \",frames.shape)\n",
    "print(\"LABELS: \",labels.shape)\n",
    "print(\"LABELS: \",labels[0])\n",
    "print(\"LABELS: \",labels[487])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669b01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=frames\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcde6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=123, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85780267",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files=[x_train, y_train]\n",
    "subject_files=[x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e386eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def print(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad998893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class LoadDataset_from_numpy(Dataset):\n",
    "    def __init__(self, np_data):\n",
    "        super(LoadDataset_from_numpy, self).__init__()\n",
    "        X_train = np_data[0]\n",
    "        y_train = np_data[1]\n",
    "        self.len = X_train.shape[0]\n",
    "        self.x_data = torch.from_numpy(X_train).float()\n",
    "        self.y_data = torch.from_numpy(y_train).long()\n",
    "        self.x_data = self.x_data.view(self.x_data.size()[0], 1, self.x_data.size()[1])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def data_generator_np(training_files, subject_files, batch_size):\n",
    "    train_dataset = LoadDataset_from_numpy(training_files)\n",
    "    test_dataset = LoadDataset_from_numpy(subject_files)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               drop_last=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              drop_last=True,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf2b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = data_generator_np(training_files, subject_files, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91118e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "\n",
    "\"\"\"\n",
    "2.1  Signal Segments Representation\n",
    "\n",
    "Signal Segment Definition: class SignalSegmentDefinition(nn.Module)\n",
    "Signal Segment Representation: class SignalSegmentRepresentation(nn.Module)\n",
    "\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.1 Global Node Attention: class GNA(nn.Module):\n",
    "\n",
    "***\n",
    "(1) Signal Segment Definition -> (2) Signal Segment Representation -> (3) Global Node Attention\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SignalSegmentDefinition(nn.Module):\n",
    "    \"\"\"\n",
    "   (1) Signal Segment Definition\n",
    "\n",
    "    input size: B, 1, 1, L\n",
    "    output size: B, K, 1, D\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = f.unfold(x, kernel_size=self.kernel_size, stride=self.stride)  # overlapping sliding window\n",
    "        b = b.permute(0, 2, 1)\n",
    "        b = b.unsqueeze(-2)\n",
    "        return b\n",
    "\n",
    "\n",
    "class SignalSegmentRepresentation(nn.Module):\n",
    "    \"\"\"\n",
    "    (2) Signal Segment Representation\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    segment_num: number of the signal segments\n",
    "\n",
    "    input size:  B, 1, 1, L\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, segment_size, overlapping_rate, segment_num):\n",
    "        super(SignalSegmentRepresentation, self).__init__()\n",
    "        self.overlapping = int(segment_size - segment_size * overlapping_rate)\n",
    "        self.segment = SignalSegmentDefinition((1, segment_size), self.overlapping)\n",
    "        self.segment2vec = SignalSegment2Vec(30)\n",
    "        self.gna = GNA(segment_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        signal_segments = []\n",
    "        x = self.segment(x)\n",
    "        x = x.squeeze()\n",
    "        \"share the SignalSegment2Vec Encoder\"\n",
    "        for idx in range(x.size()[1]):\n",
    "            data = x[:, idx, :]\n",
    "            data = data.unsqueeze(1)\n",
    "            out = self.segment2vec(data)\n",
    "            out = out.view(x.size()[0], 1, -1)\n",
    "            signal_segments.append(out)\n",
    "        signal_segments = torch.cat(signal_segments, dim=1)\n",
    "        signal_segments = signal_segments .unsqueeze(2)\n",
    "        \"global node attention\"\n",
    "        signal_segments = self.gna(signal_segments).permute(0, 2, 1, 3)\n",
    "        return signal_segments\n",
    "\n",
    "\n",
    "class GNA(nn.Module):\n",
    "    \"\"\"\n",
    "    (3) Global Node Attention\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "\n",
    "    input size: B, K, 1, C\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(GNA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SignalSegment2Vec(nn.Module):\n",
    "    \"\"\"\n",
    "    SignalSegment2Vec Encoder module in Signal Segment Representation\n",
    "\n",
    "    input size:  B, K, 1, D\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, afr_reduced_cnn_size):\n",
    "        super(SignalSegment2Vec, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=49, stride=6, bias=False, padding=int(49//2)),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool1d(kernel_size=7, stride=4, padding=int(7//2)),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv1d(128, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=3, stride=4, padding=int(3//2)),\n",
    "        )\n",
    "\n",
    "        self.inplanes = 128\n",
    "        self.AFR = self._make_layer(ResBasicBlock, afr_reduced_cnn_size, 1)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.AFR(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"Residual Squeeze-and-Excitation(SE) Block\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class ResBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=4):\n",
    "        super(ResBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.GELU()\n",
    "        self.conv2 = nn.Conv1d(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.reslayer = ResLayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.reslayer(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0938c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.2 Graph-based Self Attention\n",
    "\n",
    "graph attention: class Attention(nn.Module)\n",
    "convolution-based multi-head attention: class Block(nn.Module)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention (see Eq.4)\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "    input size:  B, M, K, C\n",
    "    output size: B, M, K, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((None, 1)),\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, K, _ = x.size()\n",
    "        adj = self.pearson(x)  # adjacency matrix\n",
    "        x_ = self._prepare_attentional_mechanism_input(x)\n",
    "        e = self.attn(x_)\n",
    "        e = e.permute(0, 2, 1, 3).contiguous()\n",
    "        e = e.view(B, M, K, K)\n",
    "        zero_vec_adj = -9e15 * torch.ones_like(adj)\n",
    "        attention = torch.where(adj > 0, e, zero_vec_adj)\n",
    "        attention = f.softmax(attention, dim=-1)\n",
    "        x = torch.matmul(attention, x)\n",
    "        return x, adj\n",
    "\n",
    "    def h_matmul(self, x):\n",
    "        N = x.size()[-2]\n",
    "        x_repeated_in_chunks = x.repeat_interleave(N, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, N, 1)\n",
    "        result = torch.mul(x_repeated_in_chunks, x_repeated_alternating)\n",
    "        return result\n",
    "\n",
    "    def pearson(self, x):\n",
    "        \"Pearson Correlation\"\n",
    "        centered_h = x - x.mean(dim=-1, keepdim=True)\n",
    "        covariance = self.h_matmul(centered_h).sum(dim=-1, keepdim=True)\n",
    "        bessel_corrected_covariance = torch.div(covariance, (x.shape[-1] - 1))\n",
    "        std_h = x.std(dim=-1, keepdim=True)\n",
    "        p = torch.div(bessel_corrected_covariance, (self.h_matmul(std_h)))\n",
    "        p = p.view(x.size()[0], x.size()[1], x.size()[2], -1)\n",
    "        return p\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, x):\n",
    "        \"concatenation operation (see Eq.4) with positional encoding\"\n",
    "        B, _, K, _ = x.size()\n",
    "        x_repeated_in_chunks = x.repeat_interleave(K, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, K, 1)\n",
    "\n",
    "        \"positional encoding\"\n",
    "        pos = 2 * torch.ones_like(x_repeated_alternating)\n",
    "        one_vec = torch.ones_like(x_repeated_alternating)\n",
    "        x_repeated_in_chunks.eq(x_repeated_alternating)\n",
    "        pos = torch.where(x_repeated_in_chunks.eq(x_repeated_alternating) > 0, one_vec, pos)\n",
    "        x_repeated_alternating = pos * x_repeated_alternating\n",
    "\n",
    "        all_combinations_matrix = torch.cat([x_repeated_in_chunks, x_repeated_alternating], dim=-1)\n",
    "        all_combinations_matrix = all_combinations_matrix.permute(0, 2, 1, 3)\n",
    "        return all_combinations_matrix\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention (see Fig.2)\n",
    "\n",
    "    input arg:\n",
    "    node_size: number of the signal segments\n",
    "    input_size: Q in Fig. 2\n",
    "    multi_heads: number of heads\n",
    "\n",
    "    input size: B, J, K, C    J=1 when H=1\n",
    "    output size: B, M'', K, C''\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_size, input_size, kernel_size, stride, multi_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        expand = 1\n",
    "\n",
    "        padding = kernel_size//2\n",
    "        self.mid_channels_ = (multi_heads - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "        self.multi_head = nn.Sequential(\n",
    "            nn.Conv2d(input_size, multi_heads, 1, bias=False),\n",
    "            nn.Conv2d(multi_heads, multi_heads, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                      groups=node_size, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.attn = Attention(node_size * node_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Conv2d(self.mid_channels_, self.mid_channels_ * 4, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.mid_channels_ * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.mid_channels_ * 4, multi_heads * expand, 1, bias=False),\n",
    "            nn.BatchNorm2d(multi_heads)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.AdaptiveAvgPool2d((1, None))\n",
    "        )\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(multi_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x.permute(0, 2, 1, 3)                 # B, J, K, C -> B, K, J, C\n",
    "        \"Dense layers\"\n",
    "        out = self.multi_head(x)                    # B, J, K, C -> B, M, K, C, where M is the number of heads\n",
    "        out, adj = self.attn(out)\n",
    "        self.adj = adj                              # for visualization\n",
    "        out = f.gelu(self.norm(out))\n",
    "        out = out.permute(0, 2, 1, 3)               # B, M, K, C -> B, K, M, C\n",
    "        \"Attention Layers\"\n",
    "        out = self.feature_extraction(out)          # B, K, M, C -> B, K, M', C'\n",
    "        out = out.permute(0, 2, 1, 3)               # B, K, M', C' -> B, M', K, C'\n",
    "        out = self.feed_forward(out)                # B, M', K, C' -> B, M'', K, C''\n",
    "        shortcut = self.shortcut(res)               # B, K, J, C -> B, 1, K, C''\n",
    "        shortcut = shortcut.permute(0, 2, 1, 3)\n",
    "        out += shortcut                             # (B, M'', K, C'') + (B, 1, K, C'') -> (B, M'', K, C'') Broadcast\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f43a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b51c7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRAPHSENSOR(nn.Module):\n",
    "    \"\"\"\n",
    "    GRAPHSENSOR main()\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    in_channels: number of the signal segments\n",
    "    class_num: class number\n",
    "\n",
    "    input size: B, 1, L\n",
    "    output size: B, class_num\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_size, overlapping_rate, in_channels, class_num):\n",
    "        super(GRAPHSENSOR, self).__init__()\n",
    "        self.segment_size = segment_size\n",
    "        self.signal_segments = SignalSegmentRepresentation(segment_size, overlapping_rate, in_channels)\n",
    "        \"\"\"\n",
    "        The encoder is composed of a stack of H=4 identical layers\n",
    "        Multi-head number: 16 -> 32 -> 64 -> 128\n",
    "        \"\"\"\n",
    "        self.attn = nn.Sequential(\n",
    "            Block(in_channels, 1,   5, 2, 16),\n",
    "            Block(in_channels, 16,  5, 2, 32),\n",
    "            Block(in_channels, 32,  5, 1, 64),\n",
    "            Block(in_channels, 64,  5, 1, 128),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 128, 512, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(1024, class_num, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.signal_segments(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.flatten(1)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37e5c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "768d83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRAPHSENSOR(segment_size=80, overlapping_rate=0.5, in_channels=9, class_num=21).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2162450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,561,768 trainable parameter\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2613a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() >= 1:\n",
    "        print(\"num GPUs: \", torch.cuda.device_count())\n",
    "        model = nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe534d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4100232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b781d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001, amsgrad=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a427e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5e994bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch == 10:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6d8fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be844ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "        return correct * 100 / len(target)\n",
    "\n",
    "\n",
    "def f1_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "    return f1_score(pred.cpu().numpy(), target.data.cpu().numpy(), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee104cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_interval):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score', ':.4e')\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        acc = accuracy_(output, target)\n",
    "        f1 = f1_(output, target) * 100\n",
    "        accuracy.update(acc, data.size(0))\n",
    "        f1_score.update(f1, data.size(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'accuracy {accuracy.val:.3f} ({accuracy.avg:.3f})\\t'\n",
    "                  'f1_score {f1_score.val:.3f} ({f1_score.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), loss=losses, accuracy=accuracy, f1_score=f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb34657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score ', ':.4e')\n",
    "    progress = ProgressMeter(len(val_loader), losses, accuracy, f1_score,\n",
    "                             prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            acc = accuracy_(output, target)\n",
    "            f1 = f1_(output, target) * 100\n",
    "            accuracy.update(acc, data.size(0))\n",
    "            f1_score.update(f1, data.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # TODO: this should also be done with the ProgressMeter\n",
    "        print(' Test: accuracy {accuracy.avg:.3f} f1_score {f1_score.avg:.3f}'\n",
    "              .format(accuracy=accuracy, f1_score=f1_score))\n",
    "\n",
    "        return accuracy.avg, f1_score.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9a32067",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44493805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch NO: 0\n",
      "Epoch: [0][0/96]\tLoss 3.0849 (3.0849)\taccuracy 4.688 (4.688)\tf1_score 3.175 (3.175)\n",
      "Epoch: [0][5/96]\tLoss 2.4247 (2.7036)\taccuracy 23.438 (16.927)\tf1_score 12.619 (10.090)\n",
      "Epoch: [0][10/96]\tLoss 2.1902 (2.5239)\taccuracy 26.562 (20.881)\tf1_score 17.551 (12.856)\n",
      "Epoch: [0][15/96]\tLoss 2.2417 (2.4127)\taccuracy 25.000 (23.047)\tf1_score 19.792 (14.849)\n",
      "Epoch: [0][20/96]\tLoss 1.9106 (2.3767)\taccuracy 28.125 (23.289)\tf1_score 19.552 (15.845)\n",
      "Epoch: [0][25/96]\tLoss 2.2586 (2.3414)\taccuracy 26.562 (23.438)\tf1_score 24.329 (16.571)\n",
      "Epoch: [0][30/96]\tLoss 1.7626 (2.2711)\taccuracy 43.750 (25.101)\tf1_score 38.194 (17.998)\n",
      "Epoch: [0][35/96]\tLoss 1.8084 (2.2129)\taccuracy 37.500 (26.476)\tf1_score 29.622 (18.839)\n",
      "Epoch: [0][40/96]\tLoss 1.6712 (2.1553)\taccuracy 29.688 (27.553)\tf1_score 24.073 (19.893)\n",
      "Epoch: [0][45/96]\tLoss 1.8584 (2.1241)\taccuracy 32.812 (28.057)\tf1_score 23.020 (20.435)\n",
      "Epoch: [0][50/96]\tLoss 1.8815 (2.0925)\taccuracy 18.750 (28.462)\tf1_score 14.218 (20.999)\n",
      "Epoch: [0][55/96]\tLoss 1.6443 (2.0521)\taccuracy 35.938 (29.492)\tf1_score 28.278 (22.051)\n",
      "Epoch: [0][60/96]\tLoss 1.7354 (2.0261)\taccuracy 25.000 (29.816)\tf1_score 19.141 (22.469)\n",
      "Epoch: [0][65/96]\tLoss 1.7188 (2.0095)\taccuracy 32.812 (30.043)\tf1_score 26.355 (22.761)\n",
      "Epoch: [0][70/96]\tLoss 1.6645 (1.9875)\taccuracy 43.750 (30.304)\tf1_score 30.888 (23.046)\n",
      "Epoch: [0][75/96]\tLoss 1.6611 (1.9644)\taccuracy 39.062 (30.736)\tf1_score 32.048 (23.635)\n",
      "Epoch: [0][80/96]\tLoss 1.4480 (1.9351)\taccuracy 45.312 (31.501)\tf1_score 40.355 (24.603)\n",
      "Epoch: [0][85/96]\tLoss 1.5363 (1.9173)\taccuracy 39.062 (32.068)\tf1_score 27.713 (24.974)\n",
      "Epoch: [0][90/96]\tLoss 1.6566 (1.8971)\taccuracy 37.500 (32.503)\tf1_score 32.315 (25.429)\n",
      "Epoch: [0][95/96]\tLoss 1.5263 (1.8769)\taccuracy 42.188 (32.894)\tf1_score 34.999 (25.822)\n",
      " Test: accuracy 38.802 f1_score 30.805\n",
      "Saving..\n",
      "Training time:  32.37069869041443 Hour:  0 Minute:  0 Second:  32 Test best accuracy: 38.802083333333336  Test best f1 score: 30.80521709222137\n",
      "\n",
      "Start of epoch NO: 1\n",
      "Epoch: [1][0/96]\tLoss 1.3044 (1.3044)\taccuracy 56.250 (56.250)\tf1_score 46.871 (46.871)\n",
      "Epoch: [1][5/96]\tLoss 1.3226 (1.4754)\taccuracy 45.312 (41.667)\tf1_score 41.635 (34.867)\n",
      "Epoch: [1][10/96]\tLoss 1.3395 (1.4522)\taccuracy 48.438 (41.903)\tf1_score 43.181 (35.293)\n",
      "Epoch: [1][15/96]\tLoss 1.5957 (1.4921)\taccuracy 43.750 (41.797)\tf1_score 34.230 (34.472)\n",
      "Epoch: [1][20/96]\tLoss 1.6044 (1.5047)\taccuracy 35.938 (40.923)\tf1_score 31.461 (33.547)\n",
      "Epoch: [1][25/96]\tLoss 1.4527 (1.4849)\taccuracy 46.875 (42.488)\tf1_score 43.691 (34.948)\n",
      "Epoch: [1][30/96]\tLoss 1.3563 (1.4669)\taccuracy 48.438 (42.843)\tf1_score 41.619 (35.115)\n",
      "Epoch: [1][35/96]\tLoss 1.6730 (1.4567)\taccuracy 39.062 (43.142)\tf1_score 39.237 (35.802)\n",
      "Epoch: [1][40/96]\tLoss 1.5175 (1.4476)\taccuracy 31.250 (43.407)\tf1_score 24.657 (36.536)\n",
      "Epoch: [1][45/96]\tLoss 1.3525 (1.4432)\taccuracy 43.750 (43.784)\tf1_score 37.923 (36.751)\n",
      "Epoch: [1][50/96]\tLoss 1.3011 (1.4384)\taccuracy 50.000 (44.577)\tf1_score 38.909 (37.202)\n",
      "Epoch: [1][55/96]\tLoss 1.4169 (1.4305)\taccuracy 35.938 (44.531)\tf1_score 31.195 (37.128)\n",
      "Epoch: [1][60/96]\tLoss 1.2758 (1.4226)\taccuracy 46.875 (44.749)\tf1_score 35.513 (37.377)\n",
      "Epoch: [1][65/96]\tLoss 1.8427 (1.4273)\taccuracy 39.062 (44.673)\tf1_score 32.193 (37.526)\n",
      "Epoch: [1][70/96]\tLoss 1.6863 (1.4401)\taccuracy 42.188 (44.740)\tf1_score 36.576 (37.529)\n",
      "Epoch: [1][75/96]\tLoss 1.2884 (1.4287)\taccuracy 51.562 (45.148)\tf1_score 46.856 (37.951)\n",
      "Epoch: [1][80/96]\tLoss 1.3401 (1.4280)\taccuracy 43.750 (45.100)\tf1_score 40.882 (37.933)\n",
      "Epoch: [1][85/96]\tLoss 1.3603 (1.4290)\taccuracy 37.500 (45.022)\tf1_score 38.155 (37.977)\n",
      "Epoch: [1][90/96]\tLoss 1.4505 (1.4391)\taccuracy 45.312 (44.317)\tf1_score 34.104 (37.373)\n",
      "Epoch: [1][95/96]\tLoss 1.3736 (1.4318)\taccuracy 50.000 (44.482)\tf1_score 49.624 (37.567)\n",
      " Test: accuracy 45.573 f1_score 38.427\n",
      "Saving..\n",
      "Training time:  47.59470725059509 Hour:  0 Minute:  0 Second:  47 Test best accuracy: 45.572916666666664  Test best f1 score: 38.426962720041466\n",
      "\n",
      "Start of epoch NO: 2\n",
      "Epoch: [2][0/96]\tLoss 1.2313 (1.2313)\taccuracy 48.438 (48.438)\tf1_score 39.409 (39.409)\n",
      "Epoch: [2][5/96]\tLoss 1.4284 (1.3826)\taccuracy 50.000 (48.177)\tf1_score 43.133 (39.566)\n",
      "Epoch: [2][10/96]\tLoss 1.0665 (1.3156)\taccuracy 65.625 (51.847)\tf1_score 59.045 (43.252)\n",
      "Epoch: [2][15/96]\tLoss 1.7197 (1.3635)\taccuracy 46.875 (50.977)\tf1_score 29.628 (42.090)\n",
      "Epoch: [2][20/96]\tLoss 1.3685 (1.4092)\taccuracy 48.438 (47.619)\tf1_score 36.833 (39.593)\n",
      "Epoch: [2][25/96]\tLoss 1.3691 (1.3886)\taccuracy 51.562 (47.716)\tf1_score 43.629 (40.242)\n",
      "Epoch: [2][30/96]\tLoss 1.2609 (1.3800)\taccuracy 54.688 (48.387)\tf1_score 44.948 (40.800)\n",
      "Epoch: [2][35/96]\tLoss 1.5504 (1.3779)\taccuracy 43.750 (47.873)\tf1_score 31.749 (40.256)\n",
      "Epoch: [2][40/96]\tLoss 1.2547 (1.3591)\taccuracy 48.438 (48.514)\tf1_score 42.537 (40.854)\n",
      "Epoch: [2][45/96]\tLoss 1.4274 (1.3562)\taccuracy 37.500 (48.370)\tf1_score 34.315 (40.834)\n",
      "Epoch: [2][50/96]\tLoss 1.2696 (1.3544)\taccuracy 48.438 (48.499)\tf1_score 45.069 (41.035)\n",
      "Epoch: [2][55/96]\tLoss 1.2589 (1.3588)\taccuracy 43.750 (48.438)\tf1_score 37.069 (40.909)\n",
      "Epoch: [2][60/96]\tLoss 1.3232 (1.3524)\taccuracy 51.562 (48.617)\tf1_score 46.437 (41.009)\n",
      "Epoch: [2][65/96]\tLoss 1.6532 (1.3612)\taccuracy 39.062 (48.390)\tf1_score 34.141 (40.744)\n",
      "Epoch: [2][70/96]\tLoss 1.4720 (1.3620)\taccuracy 43.750 (48.019)\tf1_score 37.829 (40.439)\n",
      "Epoch: [2][75/96]\tLoss 1.2807 (1.3696)\taccuracy 45.312 (47.574)\tf1_score 40.992 (40.153)\n",
      "Epoch: [2][80/96]\tLoss 1.1375 (1.3608)\taccuracy 48.438 (47.801)\tf1_score 44.601 (40.447)\n",
      "Epoch: [2][85/96]\tLoss 1.2696 (1.3596)\taccuracy 50.000 (47.620)\tf1_score 41.270 (40.378)\n",
      "Epoch: [2][90/96]\tLoss 1.1941 (1.3458)\taccuracy 53.125 (48.180)\tf1_score 45.952 (40.921)\n",
      "Epoch: [2][95/96]\tLoss 1.1211 (1.3374)\taccuracy 48.438 (48.324)\tf1_score 45.617 (41.180)\n",
      " Test: accuracy 54.297 f1_score 47.849\n",
      "Saving..\n",
      "Training time:  62.594269037246704 Hour:  0 Minute:  1 Second:  2 Test best accuracy: 54.296875  Test best f1 score: 47.84855416099427\n",
      "\n",
      "Start of epoch NO: 3\n",
      "Epoch: [3][0/96]\tLoss 1.1365 (1.1365)\taccuracy 56.250 (56.250)\tf1_score 46.447 (46.447)\n",
      "Epoch: [3][5/96]\tLoss 0.8866 (1.0453)\taccuracy 68.750 (60.938)\tf1_score 52.368 (53.030)\n",
      "Epoch: [3][10/96]\tLoss 1.1439 (1.1560)\taccuracy 53.125 (55.256)\tf1_score 44.542 (48.300)\n",
      "Epoch: [3][15/96]\tLoss 1.0468 (1.1494)\taccuracy 62.500 (55.469)\tf1_score 56.668 (47.898)\n",
      "Epoch: [3][20/96]\tLoss 1.2119 (1.1806)\taccuracy 46.875 (53.646)\tf1_score 39.341 (46.126)\n",
      "Epoch: [3][25/96]\tLoss 1.1093 (1.1735)\taccuracy 50.000 (53.305)\tf1_score 41.857 (46.302)\n",
      "Epoch: [3][30/96]\tLoss 1.0859 (1.1696)\taccuracy 51.562 (53.679)\tf1_score 39.377 (47.028)\n",
      "Epoch: [3][35/96]\tLoss 1.1075 (1.1685)\taccuracy 59.375 (53.776)\tf1_score 51.671 (47.275)\n",
      "Epoch: [3][40/96]\tLoss 1.2631 (1.1782)\taccuracy 48.438 (53.239)\tf1_score 44.668 (47.226)\n",
      "Epoch: [3][45/96]\tLoss 1.1546 (1.1717)\taccuracy 56.250 (53.499)\tf1_score 48.672 (47.447)\n",
      "Epoch: [3][50/96]\tLoss 1.0100 (1.1687)\taccuracy 57.812 (53.339)\tf1_score 44.841 (47.053)\n",
      "Epoch: [3][55/96]\tLoss 0.9154 (1.1590)\taccuracy 62.500 (53.739)\tf1_score 59.769 (47.384)\n",
      "Epoch: [3][60/96]\tLoss 1.0512 (1.1459)\taccuracy 64.062 (54.355)\tf1_score 58.715 (47.774)\n",
      "Epoch: [3][65/96]\tLoss 1.7032 (1.1513)\taccuracy 29.688 (54.190)\tf1_score 26.520 (47.518)\n",
      "Epoch: [3][70/96]\tLoss 1.1616 (1.1470)\taccuracy 56.250 (54.577)\tf1_score 52.721 (47.955)\n",
      "Epoch: [3][75/96]\tLoss 1.0434 (1.1388)\taccuracy 53.125 (54.975)\tf1_score 43.680 (48.344)\n",
      "Epoch: [3][80/96]\tLoss 0.9181 (1.1370)\taccuracy 60.938 (55.112)\tf1_score 50.133 (48.336)\n",
      "Epoch: [3][85/96]\tLoss 1.0443 (1.1390)\taccuracy 57.812 (54.942)\tf1_score 45.748 (48.159)\n",
      "Epoch: [3][90/96]\tLoss 1.3135 (1.1357)\taccuracy 43.750 (54.842)\tf1_score 40.272 (48.236)\n",
      "Epoch: [3][95/96]\tLoss 0.8426 (1.1347)\taccuracy 65.625 (54.899)\tf1_score 60.117 (48.356)\n",
      " Test: accuracy 62.826 f1_score 56.690\n",
      "Saving..\n",
      "Training time:  77.8098692893982 Hour:  0 Minute:  1 Second:  17 Test best accuracy: 62.825520833333336  Test best f1 score: 56.68967917844015\n",
      "\n",
      "Start of epoch NO: 4\n",
      "Epoch: [4][0/96]\tLoss 1.1402 (1.1402)\taccuracy 50.000 (50.000)\tf1_score 46.929 (46.929)\n",
      "Epoch: [4][5/96]\tLoss 0.9812 (0.9678)\taccuracy 59.375 (60.938)\tf1_score 49.373 (54.284)\n",
      "Epoch: [4][10/96]\tLoss 0.9878 (1.0245)\taccuracy 56.250 (57.812)\tf1_score 51.054 (51.260)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][15/96]\tLoss 1.0985 (1.0644)\taccuracy 51.562 (56.641)\tf1_score 45.837 (51.688)\n",
      "Epoch: [4][20/96]\tLoss 1.1822 (1.0556)\taccuracy 56.250 (57.589)\tf1_score 44.683 (52.269)\n",
      "Epoch: [4][25/96]\tLoss 1.2528 (1.0504)\taccuracy 50.000 (58.353)\tf1_score 42.250 (52.484)\n",
      "Epoch: [4][30/96]\tLoss 1.9309 (1.0629)\taccuracy 37.500 (58.216)\tf1_score 34.344 (52.280)\n",
      "Epoch: [4][35/96]\tLoss 0.9779 (1.0557)\taccuracy 57.812 (58.247)\tf1_score 51.489 (52.387)\n",
      "Epoch: [4][40/96]\tLoss 0.9549 (1.0563)\taccuracy 62.500 (57.927)\tf1_score 59.729 (51.901)\n",
      "Epoch: [4][45/96]\tLoss 1.2848 (1.0704)\taccuracy 48.438 (57.575)\tf1_score 43.864 (51.408)\n",
      "Epoch: [4][50/96]\tLoss 0.8429 (1.0719)\taccuracy 70.312 (57.966)\tf1_score 67.027 (51.526)\n",
      "Epoch: [4][55/96]\tLoss 0.9267 (1.0794)\taccuracy 64.062 (57.729)\tf1_score 57.050 (51.110)\n",
      "Epoch: [4][60/96]\tLoss 1.1436 (1.0895)\taccuracy 50.000 (57.198)\tf1_score 47.841 (50.775)\n",
      "Epoch: [4][65/96]\tLoss 0.9183 (1.0766)\taccuracy 70.312 (57.836)\tf1_score 66.017 (51.426)\n",
      "Epoch: [4][70/96]\tLoss 0.8235 (1.0704)\taccuracy 67.188 (58.121)\tf1_score 67.018 (51.684)\n",
      "Epoch: [4][75/96]\tLoss 1.2211 (1.0575)\taccuracy 53.125 (58.532)\tf1_score 42.987 (52.102)\n",
      "Epoch: [4][80/96]\tLoss 1.0491 (1.0533)\taccuracy 59.375 (58.738)\tf1_score 50.705 (52.350)\n",
      "Epoch: [4][85/96]\tLoss 0.9898 (1.0475)\taccuracy 59.375 (58.939)\tf1_score 60.917 (52.663)\n",
      "Epoch: [4][90/96]\tLoss 1.0470 (1.0440)\taccuracy 60.938 (59.169)\tf1_score 55.713 (53.003)\n",
      "Epoch: [4][95/96]\tLoss 0.9285 (1.0331)\taccuracy 57.812 (59.554)\tf1_score 53.238 (53.548)\n",
      " Test: accuracy 65.495 f1_score 60.904\n",
      "Saving..\n",
      "Training time:  92.9582736492157 Hour:  0 Minute:  1 Second:  32 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 5\n",
      "Epoch: [5][0/96]\tLoss 1.0179 (1.0179)\taccuracy 59.375 (59.375)\tf1_score 47.650 (47.650)\n",
      "Epoch: [5][5/96]\tLoss 0.9486 (1.1223)\taccuracy 62.500 (57.812)\tf1_score 54.790 (50.187)\n",
      "Epoch: [5][10/96]\tLoss 0.8072 (1.0108)\taccuracy 62.500 (61.790)\tf1_score 56.982 (54.797)\n",
      "Epoch: [5][15/96]\tLoss 0.8991 (0.9601)\taccuracy 64.062 (63.379)\tf1_score 60.064 (57.384)\n",
      "Epoch: [5][20/96]\tLoss 0.9357 (0.9399)\taccuracy 62.500 (63.914)\tf1_score 53.727 (57.740)\n",
      "Epoch: [5][25/96]\tLoss 0.9027 (0.9332)\taccuracy 70.312 (64.423)\tf1_score 62.857 (57.873)\n",
      "Epoch: [5][30/96]\tLoss 0.7475 (0.9433)\taccuracy 79.688 (64.113)\tf1_score 68.170 (57.221)\n",
      "Epoch: [5][35/96]\tLoss 0.8093 (0.9428)\taccuracy 67.188 (63.889)\tf1_score 57.980 (56.919)\n",
      "Epoch: [5][40/96]\tLoss 1.0030 (0.9519)\taccuracy 59.375 (62.919)\tf1_score 56.334 (56.339)\n",
      "Epoch: [5][45/96]\tLoss 0.8247 (0.9467)\taccuracy 75.000 (63.145)\tf1_score 71.691 (56.869)\n",
      "Epoch: [5][50/96]\tLoss 1.0315 (0.9452)\taccuracy 57.812 (63.021)\tf1_score 57.794 (57.017)\n",
      "Epoch: [5][55/96]\tLoss 0.8775 (0.9399)\taccuracy 60.938 (63.225)\tf1_score 54.849 (57.099)\n",
      "Epoch: [5][60/96]\tLoss 0.8310 (0.9350)\taccuracy 68.750 (63.422)\tf1_score 58.021 (57.169)\n",
      "Epoch: [5][65/96]\tLoss 0.6919 (0.9298)\taccuracy 70.312 (63.636)\tf1_score 62.254 (57.363)\n",
      "Epoch: [5][70/96]\tLoss 0.8189 (0.9263)\taccuracy 73.438 (63.776)\tf1_score 70.057 (57.585)\n",
      "Epoch: [5][75/96]\tLoss 0.7268 (0.9217)\taccuracy 78.125 (64.042)\tf1_score 77.326 (57.928)\n",
      "Epoch: [5][80/96]\tLoss 1.0698 (0.9223)\taccuracy 56.250 (63.985)\tf1_score 45.590 (58.021)\n",
      "Epoch: [5][85/96]\tLoss 1.0147 (0.9243)\taccuracy 54.688 (63.844)\tf1_score 51.260 (57.722)\n",
      "Epoch: [5][90/96]\tLoss 1.1214 (0.9318)\taccuracy 50.000 (63.530)\tf1_score 42.735 (57.481)\n",
      "Epoch: [5][95/96]\tLoss 0.8272 (0.9322)\taccuracy 70.312 (63.379)\tf1_score 65.073 (57.351)\n",
      " Test: accuracy 51.562 f1_score 43.771\n",
      "Training time:  108.29247832298279 Hour:  0 Minute:  1 Second:  48 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 6\n",
      "Epoch: [6][0/96]\tLoss 1.1798 (1.1798)\taccuracy 59.375 (59.375)\tf1_score 54.981 (54.981)\n",
      "Epoch: [6][5/96]\tLoss 0.8468 (1.0126)\taccuracy 68.750 (61.458)\tf1_score 62.129 (55.188)\n",
      "Epoch: [6][10/96]\tLoss 0.8653 (0.9602)\taccuracy 67.188 (64.062)\tf1_score 57.576 (58.413)\n",
      "Epoch: [6][15/96]\tLoss 0.7050 (0.9351)\taccuracy 75.000 (63.965)\tf1_score 73.445 (58.540)\n",
      "Epoch: [6][20/96]\tLoss 0.8715 (0.9186)\taccuracy 70.312 (64.881)\tf1_score 69.646 (59.910)\n",
      "Epoch: [6][25/96]\tLoss 0.8429 (0.9045)\taccuracy 70.312 (65.445)\tf1_score 63.393 (60.173)\n",
      "Epoch: [6][30/96]\tLoss 0.9622 (0.8896)\taccuracy 60.938 (65.927)\tf1_score 64.671 (60.698)\n",
      "Epoch: [6][35/96]\tLoss 0.6121 (0.8743)\taccuracy 76.562 (66.276)\tf1_score 68.834 (60.995)\n",
      "Epoch: [6][40/96]\tLoss 0.9780 (0.8752)\taccuracy 57.812 (65.968)\tf1_score 47.192 (60.386)\n",
      "Epoch: [6][45/96]\tLoss 0.9015 (0.8602)\taccuracy 57.812 (66.338)\tf1_score 46.948 (60.450)\n",
      "Epoch: [6][50/96]\tLoss 0.7792 (0.8572)\taccuracy 65.625 (66.513)\tf1_score 62.887 (60.902)\n",
      "Epoch: [6][55/96]\tLoss 0.7657 (0.8488)\taccuracy 71.875 (66.825)\tf1_score 70.085 (61.477)\n",
      "Epoch: [6][60/96]\tLoss 0.7407 (0.8409)\taccuracy 71.875 (66.931)\tf1_score 67.782 (61.689)\n",
      "Epoch: [6][65/96]\tLoss 0.8091 (0.8381)\taccuracy 62.500 (66.927)\tf1_score 53.605 (61.465)\n",
      "Epoch: [6][70/96]\tLoss 0.7781 (0.8379)\taccuracy 71.875 (67.033)\tf1_score 69.766 (61.687)\n",
      "Epoch: [6][75/96]\tLoss 1.3605 (0.8533)\taccuracy 53.125 (66.530)\tf1_score 47.731 (61.203)\n",
      "Epoch: [6][80/96]\tLoss 1.8129 (0.8699)\taccuracy 48.438 (66.107)\tf1_score 46.725 (60.888)\n",
      "Epoch: [6][85/96]\tLoss 0.8739 (0.8697)\taccuracy 65.625 (66.188)\tf1_score 59.350 (60.983)\n",
      "Epoch: [6][90/96]\tLoss 0.9198 (0.8742)\taccuracy 57.812 (66.020)\tf1_score 46.508 (60.795)\n",
      "Epoch: [6][95/96]\tLoss 0.7626 (0.8683)\taccuracy 65.625 (66.260)\tf1_score 60.327 (61.077)\n",
      " Test: accuracy 63.932 f1_score 57.098\n",
      "Training time:  123.56446051597595 Hour:  0 Minute:  2 Second:  3 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 7\n",
      "Epoch: [7][0/96]\tLoss 0.6253 (0.6253)\taccuracy 79.688 (79.688)\tf1_score 78.647 (78.647)\n",
      "Epoch: [7][5/96]\tLoss 0.9068 (0.7863)\taccuracy 59.375 (67.448)\tf1_score 54.014 (59.910)\n",
      "Epoch: [7][10/96]\tLoss 0.7038 (0.8154)\taccuracy 75.000 (67.188)\tf1_score 61.809 (59.339)\n",
      "Epoch: [7][15/96]\tLoss 0.8010 (0.8210)\taccuracy 62.500 (65.820)\tf1_score 58.957 (58.887)\n",
      "Epoch: [7][20/96]\tLoss 0.8655 (0.8398)\taccuracy 62.500 (65.476)\tf1_score 57.460 (58.769)\n",
      "Epoch: [7][25/96]\tLoss 0.9053 (0.8308)\taccuracy 65.625 (66.526)\tf1_score 56.642 (60.051)\n",
      "Epoch: [7][30/96]\tLoss 0.5723 (0.8136)\taccuracy 84.375 (67.188)\tf1_score 72.574 (60.417)\n",
      "Epoch: [7][35/96]\tLoss 0.5354 (0.8165)\taccuracy 82.812 (67.274)\tf1_score 75.065 (60.442)\n",
      "Epoch: [7][40/96]\tLoss 0.6780 (0.8193)\taccuracy 73.438 (67.264)\tf1_score 66.176 (60.539)\n",
      "Epoch: [7][45/96]\tLoss 0.7628 (0.8316)\taccuracy 67.188 (66.882)\tf1_score 63.108 (60.313)\n",
      "Epoch: [7][50/96]\tLoss 0.6232 (0.8265)\taccuracy 78.125 (67.096)\tf1_score 68.034 (60.462)\n",
      "Epoch: [7][55/96]\tLoss 0.6995 (0.8308)\taccuracy 73.438 (67.104)\tf1_score 70.572 (60.777)\n",
      "Epoch: [7][60/96]\tLoss 0.7402 (0.8243)\taccuracy 70.312 (67.520)\tf1_score 65.259 (61.340)\n",
      "Epoch: [7][65/96]\tLoss 1.0722 (0.8220)\taccuracy 57.812 (67.685)\tf1_score 53.228 (61.612)\n",
      "Epoch: [7][70/96]\tLoss 0.5801 (0.8098)\taccuracy 79.688 (68.288)\tf1_score 74.565 (62.009)\n",
      "Epoch: [7][75/96]\tLoss 0.8127 (0.8157)\taccuracy 62.500 (67.928)\tf1_score 58.751 (61.762)\n",
      "Epoch: [7][80/96]\tLoss 0.7950 (0.8191)\taccuracy 73.438 (67.921)\tf1_score 68.320 (61.762)\n",
      "Epoch: [7][85/96]\tLoss 0.7885 (0.8268)\taccuracy 70.312 (67.605)\tf1_score 56.981 (61.502)\n",
      "Epoch: [7][90/96]\tLoss 0.8714 (0.8247)\taccuracy 65.625 (67.823)\tf1_score 62.114 (61.715)\n",
      "Epoch: [7][95/96]\tLoss 0.7170 (0.8230)\taccuracy 68.750 (67.855)\tf1_score 63.297 (61.743)\n",
      " Test: accuracy 62.240 f1_score 55.441\n",
      "Training time:  138.81571626663208 Hour:  0 Minute:  2 Second:  18 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 8\n",
      "Epoch: [8][0/96]\tLoss 1.0508 (1.0508)\taccuracy 60.938 (60.938)\tf1_score 55.304 (55.304)\n",
      "Epoch: [8][5/96]\tLoss 1.3910 (0.8870)\taccuracy 48.438 (67.969)\tf1_score 43.388 (61.109)\n",
      "Epoch: [8][10/96]\tLoss 0.7650 (0.8347)\taccuracy 73.438 (69.318)\tf1_score 64.690 (62.906)\n",
      "Epoch: [8][15/96]\tLoss 1.0785 (0.9210)\taccuracy 67.188 (68.652)\tf1_score 62.472 (62.100)\n",
      "Epoch: [8][20/96]\tLoss 0.7765 (0.8944)\taccuracy 71.875 (68.155)\tf1_score 57.394 (61.322)\n",
      "Epoch: [8][25/96]\tLoss 0.7178 (0.8680)\taccuracy 73.438 (69.111)\tf1_score 68.212 (62.127)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][30/96]\tLoss 0.7093 (0.8691)\taccuracy 64.062 (68.599)\tf1_score 60.778 (61.912)\n",
      "Epoch: [8][35/96]\tLoss 0.9815 (0.8595)\taccuracy 64.062 (68.576)\tf1_score 54.015 (61.674)\n",
      "Epoch: [8][40/96]\tLoss 1.0160 (0.8669)\taccuracy 59.375 (67.873)\tf1_score 46.531 (60.866)\n",
      "Epoch: [8][45/96]\tLoss 0.7296 (0.8627)\taccuracy 71.875 (67.969)\tf1_score 69.467 (61.470)\n",
      "Epoch: [8][50/96]\tLoss 0.8227 (0.8679)\taccuracy 68.750 (67.800)\tf1_score 68.547 (61.316)\n",
      "Epoch: [8][55/96]\tLoss 1.0377 (0.8603)\taccuracy 57.812 (68.025)\tf1_score 55.406 (61.899)\n",
      "Epoch: [8][60/96]\tLoss 0.7808 (0.8599)\taccuracy 71.875 (68.084)\tf1_score 64.614 (62.066)\n",
      "Epoch: [8][65/96]\tLoss 1.0242 (0.8623)\taccuracy 57.812 (67.874)\tf1_score 50.654 (61.864)\n",
      "Epoch: [8][70/96]\tLoss 0.8325 (0.8670)\taccuracy 68.750 (67.672)\tf1_score 67.567 (61.692)\n",
      "Epoch: [8][75/96]\tLoss 0.6483 (0.8549)\taccuracy 76.562 (67.969)\tf1_score 71.234 (61.851)\n",
      "Epoch: [8][80/96]\tLoss 0.8181 (0.8523)\taccuracy 68.750 (67.998)\tf1_score 68.433 (62.047)\n",
      "Epoch: [8][85/96]\tLoss 0.7744 (0.8455)\taccuracy 76.562 (68.296)\tf1_score 72.303 (62.335)\n",
      "Epoch: [8][90/96]\tLoss 0.7637 (0.8463)\taccuracy 60.938 (68.012)\tf1_score 58.590 (62.230)\n",
      "Epoch: [8][95/96]\tLoss 0.6332 (0.8385)\taccuracy 71.875 (68.229)\tf1_score 62.014 (62.527)\n",
      " Test: accuracy 57.422 f1_score 51.600\n",
      "Training time:  154.1041088104248 Hour:  0 Minute:  2 Second:  34 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 9\n",
      "Epoch: [9][0/96]\tLoss 0.7641 (0.7641)\taccuracy 71.875 (71.875)\tf1_score 68.175 (68.175)\n",
      "Epoch: [9][5/96]\tLoss 0.7059 (0.7249)\taccuracy 78.125 (71.094)\tf1_score 72.989 (68.185)\n",
      "Epoch: [9][10/96]\tLoss 0.6058 (0.6961)\taccuracy 71.875 (71.591)\tf1_score 69.172 (67.283)\n",
      "Epoch: [9][15/96]\tLoss 0.5727 (0.6683)\taccuracy 79.688 (73.145)\tf1_score 72.283 (67.930)\n",
      "Epoch: [9][20/96]\tLoss 0.9284 (0.6865)\taccuracy 60.938 (72.173)\tf1_score 59.174 (67.178)\n",
      "Epoch: [9][25/96]\tLoss 0.9460 (0.7167)\taccuracy 62.500 (71.815)\tf1_score 56.607 (66.288)\n",
      "Epoch: [9][30/96]\tLoss 0.6599 (0.7086)\taccuracy 67.188 (72.026)\tf1_score 61.775 (66.647)\n",
      "Epoch: [9][35/96]\tLoss 0.5752 (0.7133)\taccuracy 76.562 (71.658)\tf1_score 71.056 (66.408)\n",
      "Epoch: [9][40/96]\tLoss 0.6801 (0.7037)\taccuracy 73.438 (72.332)\tf1_score 60.654 (67.043)\n",
      "Epoch: [9][45/96]\tLoss 0.7808 (0.7038)\taccuracy 71.875 (72.690)\tf1_score 67.785 (67.268)\n",
      "Epoch: [9][50/96]\tLoss 0.7369 (0.7050)\taccuracy 67.188 (72.672)\tf1_score 70.043 (67.665)\n",
      "Epoch: [9][55/96]\tLoss 0.5507 (0.6990)\taccuracy 79.688 (73.158)\tf1_score 78.679 (68.175)\n",
      "Epoch: [9][60/96]\tLoss 0.7893 (0.7053)\taccuracy 70.312 (73.053)\tf1_score 64.448 (68.211)\n",
      "Epoch: [9][65/96]\tLoss 0.8207 (0.7137)\taccuracy 64.062 (72.562)\tf1_score 56.577 (67.465)\n",
      "Epoch: [9][70/96]\tLoss 0.6393 (0.7089)\taccuracy 73.438 (72.777)\tf1_score 69.775 (67.737)\n",
      "Epoch: [9][75/96]\tLoss 1.4322 (0.7242)\taccuracy 48.438 (72.368)\tf1_score 40.058 (67.158)\n",
      "Epoch: [9][80/96]\tLoss 0.8132 (0.7236)\taccuracy 67.188 (72.434)\tf1_score 69.093 (67.378)\n",
      "Epoch: [9][85/96]\tLoss 0.6406 (0.7247)\taccuracy 70.312 (72.329)\tf1_score 62.042 (67.310)\n",
      "Epoch: [9][90/96]\tLoss 0.8076 (0.7187)\taccuracy 60.938 (72.510)\tf1_score 54.956 (67.593)\n",
      "Epoch: [9][95/96]\tLoss 0.5844 (0.7227)\taccuracy 76.562 (72.331)\tf1_score 74.334 (67.504)\n",
      " Test: accuracy 42.122 f1_score 36.398\n",
      "Training time:  169.46969747543335 Hour:  0 Minute:  2 Second:  49 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 10\n",
      "Epoch: [10][0/96]\tLoss 0.8225 (0.8225)\taccuracy 71.875 (71.875)\tf1_score 67.230 (67.230)\n",
      "Epoch: [10][5/96]\tLoss 0.5863 (0.6686)\taccuracy 78.125 (74.740)\tf1_score 78.162 (69.099)\n",
      "Epoch: [10][10/96]\tLoss 0.7956 (0.7013)\taccuracy 71.875 (72.727)\tf1_score 66.410 (68.044)\n",
      "Epoch: [10][15/96]\tLoss 0.6759 (0.7375)\taccuracy 75.000 (71.289)\tf1_score 72.711 (66.747)\n",
      "Epoch: [10][20/96]\tLoss 0.5035 (0.7203)\taccuracy 82.812 (72.247)\tf1_score 77.434 (68.169)\n",
      "Epoch: [10][25/96]\tLoss 0.4250 (0.7111)\taccuracy 82.812 (72.175)\tf1_score 75.363 (67.853)\n",
      "Epoch: [10][30/96]\tLoss 1.0625 (0.7245)\taccuracy 57.812 (71.673)\tf1_score 56.149 (67.696)\n",
      "Epoch: [10][35/96]\tLoss 0.5483 (0.7299)\taccuracy 75.000 (71.094)\tf1_score 72.045 (66.569)\n",
      "Epoch: [10][40/96]\tLoss 0.9154 (0.7180)\taccuracy 67.188 (71.875)\tf1_score 60.969 (66.736)\n",
      "Epoch: [10][45/96]\tLoss 0.7026 (0.7227)\taccuracy 68.750 (71.637)\tf1_score 66.917 (66.560)\n",
      "Epoch: [10][50/96]\tLoss 0.5994 (0.7234)\taccuracy 76.562 (71.630)\tf1_score 74.325 (66.495)\n",
      "Epoch: [10][55/96]\tLoss 0.8314 (0.7167)\taccuracy 68.750 (71.931)\tf1_score 59.491 (66.558)\n",
      "Epoch: [10][60/96]\tLoss 0.9635 (0.7174)\taccuracy 59.375 (71.747)\tf1_score 56.421 (66.572)\n",
      "Epoch: [10][65/96]\tLoss 0.5964 (0.7186)\taccuracy 78.125 (71.922)\tf1_score 70.541 (66.898)\n",
      "Epoch: [10][70/96]\tLoss 0.7905 (0.7200)\taccuracy 71.875 (71.963)\tf1_score 62.623 (66.883)\n",
      "Epoch: [10][75/96]\tLoss 0.4639 (0.7093)\taccuracy 84.375 (72.512)\tf1_score 80.976 (67.439)\n",
      "Epoch: [10][80/96]\tLoss 0.7328 (0.7070)\taccuracy 71.875 (72.550)\tf1_score 66.058 (67.513)\n",
      "Epoch: [10][85/96]\tLoss 0.7586 (0.7079)\taccuracy 68.750 (72.511)\tf1_score 67.001 (67.569)\n",
      "Epoch: [10][90/96]\tLoss 0.7685 (0.7067)\taccuracy 64.062 (72.390)\tf1_score 65.692 (67.360)\n",
      "Epoch: [10][95/96]\tLoss 0.7353 (0.7051)\taccuracy 70.312 (72.363)\tf1_score 64.238 (67.421)\n",
      " Test: accuracy 65.495 f1_score 61.669\n",
      "Training time:  184.8705382347107 Hour:  0 Minute:  3 Second:  4 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 11\n",
      "Epoch: [11][0/96]\tLoss 0.5645 (0.5645)\taccuracy 75.000 (75.000)\tf1_score 73.666 (73.666)\n",
      "Epoch: [11][5/96]\tLoss 0.5887 (0.6027)\taccuracy 84.375 (79.427)\tf1_score 81.627 (74.904)\n",
      "Epoch: [11][10/96]\tLoss 0.5537 (0.5941)\taccuracy 78.125 (79.261)\tf1_score 66.752 (73.445)\n",
      "Epoch: [11][15/96]\tLoss 1.2614 (0.6667)\taccuracy 57.812 (75.781)\tf1_score 56.429 (70.477)\n",
      "Epoch: [11][20/96]\tLoss 0.6969 (0.6410)\taccuracy 73.438 (76.488)\tf1_score 68.348 (71.571)\n",
      "Epoch: [11][25/96]\tLoss 0.7284 (0.6580)\taccuracy 73.438 (75.661)\tf1_score 71.648 (71.582)\n",
      "Epoch: [11][30/96]\tLoss 0.4301 (0.6417)\taccuracy 84.375 (76.310)\tf1_score 82.440 (72.302)\n",
      "Epoch: [11][35/96]\tLoss 0.5421 (0.6591)\taccuracy 78.125 (75.217)\tf1_score 75.269 (71.284)\n",
      "Epoch: [11][40/96]\tLoss 0.4374 (0.6654)\taccuracy 85.938 (74.771)\tf1_score 79.507 (71.008)\n",
      "Epoch: [11][45/96]\tLoss 0.4923 (0.6716)\taccuracy 85.938 (74.762)\tf1_score 86.641 (71.046)\n",
      "Epoch: [11][50/96]\tLoss 0.6938 (0.6923)\taccuracy 73.438 (74.173)\tf1_score 71.833 (70.605)\n",
      "Epoch: [11][55/96]\tLoss 0.5642 (0.6884)\taccuracy 79.688 (74.386)\tf1_score 74.917 (70.589)\n",
      "Epoch: [11][60/96]\tLoss 0.6342 (0.6939)\taccuracy 73.438 (73.899)\tf1_score 70.033 (70.255)\n",
      "Epoch: [11][65/96]\tLoss 0.6878 (0.6942)\taccuracy 76.562 (73.982)\tf1_score 76.465 (70.362)\n",
      "Epoch: [11][70/96]\tLoss 0.7204 (0.6948)\taccuracy 68.750 (73.856)\tf1_score 56.938 (70.023)\n",
      "Epoch: [11][75/96]\tLoss 0.5802 (0.6996)\taccuracy 76.562 (73.684)\tf1_score 66.373 (69.752)\n",
      "Epoch: [11][80/96]\tLoss 0.8018 (0.6976)\taccuracy 67.188 (73.669)\tf1_score 62.193 (69.768)\n",
      "Epoch: [11][85/96]\tLoss 0.9784 (0.7009)\taccuracy 67.188 (73.474)\tf1_score 58.409 (69.538)\n",
      "Epoch: [11][90/96]\tLoss 0.7468 (0.6979)\taccuracy 71.875 (73.523)\tf1_score 71.408 (69.454)\n",
      "Epoch: [11][95/96]\tLoss 0.6754 (0.6999)\taccuracy 75.000 (73.584)\tf1_score 70.382 (69.470)\n",
      " Test: accuracy 61.784 f1_score 57.506\n",
      "Training time:  200.38256168365479 Hour:  0 Minute:  3 Second:  20 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 12\n",
      "Epoch: [12][0/96]\tLoss 0.6438 (0.6438)\taccuracy 75.000 (75.000)\tf1_score 69.646 (69.646)\n",
      "Epoch: [12][5/96]\tLoss 0.4384 (0.6285)\taccuracy 85.938 (77.344)\tf1_score 81.032 (73.295)\n",
      "Epoch: [12][10/96]\tLoss 0.6168 (0.6080)\taccuracy 76.562 (78.125)\tf1_score 65.378 (72.018)\n",
      "Epoch: [12][15/96]\tLoss 0.8953 (0.6353)\taccuracy 62.500 (75.586)\tf1_score 61.207 (69.681)\n",
      "Epoch: [12][20/96]\tLoss 0.6408 (0.6304)\taccuracy 73.438 (76.190)\tf1_score 67.307 (70.006)\n",
      "Epoch: [12][25/96]\tLoss 0.7946 (0.6475)\taccuracy 73.438 (75.541)\tf1_score 68.985 (70.027)\n",
      "Epoch: [12][30/96]\tLoss 0.9848 (0.6660)\taccuracy 64.062 (74.698)\tf1_score 58.355 (69.416)\n",
      "Epoch: [12][35/96]\tLoss 0.5165 (0.6636)\taccuracy 78.125 (74.740)\tf1_score 73.101 (70.295)\n",
      "Epoch: [12][40/96]\tLoss 0.6155 (0.6533)\taccuracy 75.000 (75.076)\tf1_score 72.908 (70.724)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][45/96]\tLoss 0.4824 (0.6428)\taccuracy 87.500 (75.815)\tf1_score 85.250 (71.450)\n",
      "Epoch: [12][50/96]\tLoss 0.5663 (0.6388)\taccuracy 73.438 (75.858)\tf1_score 63.749 (71.250)\n",
      "Epoch: [12][55/96]\tLoss 0.7038 (0.6343)\taccuracy 73.438 (75.921)\tf1_score 63.871 (71.071)\n",
      "Epoch: [12][60/96]\tLoss 0.5852 (0.6345)\taccuracy 82.812 (76.101)\tf1_score 80.813 (71.515)\n",
      "Epoch: [12][65/96]\tLoss 0.5080 (0.6254)\taccuracy 79.688 (76.349)\tf1_score 78.810 (71.867)\n",
      "Epoch: [12][70/96]\tLoss 0.5844 (0.6264)\taccuracy 78.125 (76.166)\tf1_score 73.611 (71.744)\n",
      "Epoch: [12][75/96]\tLoss 0.9441 (0.6235)\taccuracy 62.500 (76.172)\tf1_score 59.498 (71.726)\n",
      "Epoch: [12][80/96]\tLoss 0.9482 (0.6229)\taccuracy 62.500 (76.119)\tf1_score 62.589 (71.689)\n",
      "Epoch: [12][85/96]\tLoss 0.6273 (0.6189)\taccuracy 78.125 (76.108)\tf1_score 73.870 (71.827)\n",
      "Epoch: [12][90/96]\tLoss 0.6637 (0.6234)\taccuracy 73.438 (75.996)\tf1_score 63.016 (71.692)\n",
      "Epoch: [12][95/96]\tLoss 0.6040 (0.6229)\taccuracy 78.125 (76.042)\tf1_score 72.688 (71.661)\n",
      " Test: accuracy 65.169 f1_score 60.140\n",
      "Training time:  215.93398714065552 Hour:  0 Minute:  3 Second:  35 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 13\n",
      "Epoch: [13][0/96]\tLoss 0.5978 (0.5978)\taccuracy 73.438 (73.438)\tf1_score 69.562 (69.562)\n",
      "Epoch: [13][5/96]\tLoss 0.4718 (0.5679)\taccuracy 84.375 (78.125)\tf1_score 82.476 (73.694)\n",
      "Epoch: [13][10/96]\tLoss 0.4245 (0.5698)\taccuracy 87.500 (78.125)\tf1_score 86.577 (74.165)\n",
      "Epoch: [13][15/96]\tLoss 0.9767 (0.5864)\taccuracy 71.875 (78.027)\tf1_score 67.116 (74.221)\n",
      "Epoch: [13][20/96]\tLoss 0.5672 (0.6036)\taccuracy 76.562 (76.786)\tf1_score 74.926 (73.527)\n",
      "Epoch: [13][25/96]\tLoss 0.8704 (0.6194)\taccuracy 68.750 (76.562)\tf1_score 67.711 (73.407)\n",
      "Epoch: [13][30/96]\tLoss 0.5164 (0.6323)\taccuracy 81.250 (76.008)\tf1_score 75.219 (72.650)\n",
      "Epoch: [13][35/96]\tLoss 0.7598 (0.6449)\taccuracy 65.625 (75.651)\tf1_score 63.770 (72.117)\n",
      "Epoch: [13][40/96]\tLoss 0.5106 (0.6496)\taccuracy 81.250 (75.648)\tf1_score 78.640 (72.095)\n",
      "Epoch: [13][45/96]\tLoss 0.6229 (0.6457)\taccuracy 75.000 (75.985)\tf1_score 77.069 (72.302)\n",
      "Epoch: [13][50/96]\tLoss 0.6843 (0.6471)\taccuracy 76.562 (75.827)\tf1_score 70.601 (72.160)\n",
      "Epoch: [13][55/96]\tLoss 0.5706 (0.6573)\taccuracy 75.000 (75.586)\tf1_score 66.940 (71.852)\n",
      "Epoch: [13][60/96]\tLoss 0.8359 (0.6581)\taccuracy 68.750 (75.717)\tf1_score 61.464 (71.801)\n",
      "Epoch: [13][65/96]\tLoss 0.9635 (0.6660)\taccuracy 62.500 (75.379)\tf1_score 56.805 (71.473)\n",
      "Epoch: [13][70/96]\tLoss 0.7013 (0.6622)\taccuracy 75.000 (75.440)\tf1_score 67.767 (71.411)\n",
      "Epoch: [13][75/96]\tLoss 0.5221 (0.6586)\taccuracy 82.812 (75.555)\tf1_score 81.056 (71.584)\n",
      "Epoch: [13][80/96]\tLoss 1.1816 (0.6632)\taccuracy 56.250 (75.367)\tf1_score 47.415 (71.312)\n",
      "Epoch: [13][85/96]\tLoss 0.5894 (0.6584)\taccuracy 79.688 (75.600)\tf1_score 77.915 (71.525)\n",
      "Epoch: [13][90/96]\tLoss 0.5967 (0.6602)\taccuracy 71.875 (75.429)\tf1_score 65.652 (71.287)\n",
      "Epoch: [13][95/96]\tLoss 0.4379 (0.6669)\taccuracy 84.375 (75.130)\tf1_score 79.858 (70.845)\n",
      " Test: accuracy 57.292 f1_score 50.756\n",
      "Training time:  233.73164892196655 Hour:  0 Minute:  3 Second:  53 Test best accuracy: 65.49479166666667  Test best f1 score: 60.904198149733844\n",
      "\n",
      "Start of epoch NO: 14\n",
      "Epoch: [14][0/96]\tLoss 0.4328 (0.4328)\taccuracy 87.500 (87.500)\tf1_score 82.589 (82.589)\n",
      "Epoch: [14][5/96]\tLoss 0.6282 (0.5607)\taccuracy 70.312 (78.385)\tf1_score 67.451 (73.854)\n",
      "Epoch: [14][10/96]\tLoss 0.5546 (0.5524)\taccuracy 84.375 (79.261)\tf1_score 81.478 (75.324)\n",
      "Epoch: [14][15/96]\tLoss 0.4595 (0.5705)\taccuracy 81.250 (78.906)\tf1_score 81.387 (75.541)\n",
      "Epoch: [14][20/96]\tLoss 0.4860 (0.5702)\taccuracy 75.000 (78.274)\tf1_score 71.290 (75.377)\n",
      "Epoch: [14][25/96]\tLoss 0.5356 (0.5584)\taccuracy 81.250 (78.726)\tf1_score 78.957 (75.717)\n",
      "Epoch: [14][30/96]\tLoss 0.5864 (0.5497)\taccuracy 76.562 (79.284)\tf1_score 72.776 (75.835)\n",
      "Epoch: [14][35/96]\tLoss 0.4881 (0.5476)\taccuracy 85.938 (79.123)\tf1_score 73.074 (75.215)\n",
      "Epoch: [14][40/96]\tLoss 0.6248 (0.5540)\taccuracy 71.875 (78.887)\tf1_score 67.463 (75.174)\n",
      "Epoch: [14][45/96]\tLoss 1.0269 (0.5864)\taccuracy 62.500 (77.649)\tf1_score 64.782 (74.219)\n",
      "Epoch: [14][50/96]\tLoss 0.5402 (0.6004)\taccuracy 79.688 (77.298)\tf1_score 74.365 (73.700)\n",
      "Epoch: [14][55/96]\tLoss 0.4104 (0.6015)\taccuracy 84.375 (77.204)\tf1_score 82.302 (73.745)\n",
      "Epoch: [14][60/96]\tLoss 0.7515 (0.6110)\taccuracy 75.000 (77.203)\tf1_score 69.048 (73.556)\n",
      "Epoch: [14][65/96]\tLoss 0.5470 (0.6124)\taccuracy 84.375 (77.296)\tf1_score 81.973 (73.647)\n",
      "Epoch: [14][70/96]\tLoss 0.5485 (0.6121)\taccuracy 79.688 (77.355)\tf1_score 79.928 (73.893)\n",
      "Epoch: [14][75/96]\tLoss 0.7046 (0.6139)\taccuracy 65.625 (77.241)\tf1_score 67.424 (73.806)\n",
      "Epoch: [14][80/96]\tLoss 0.7152 (0.6191)\taccuracy 79.688 (77.045)\tf1_score 75.684 (73.600)\n",
      "Epoch: [14][85/96]\tLoss 0.4143 (0.6206)\taccuracy 81.250 (76.962)\tf1_score 78.250 (73.415)\n",
      "Epoch: [14][90/96]\tLoss 0.4943 (0.6138)\taccuracy 81.250 (77.301)\tf1_score 80.075 (73.716)\n",
      "Epoch: [14][95/96]\tLoss 0.4606 (0.6101)\taccuracy 79.688 (77.425)\tf1_score 73.519 (73.820)\n",
      " Test: accuracy 75.065 f1_score 71.419\n",
      "Saving..\n",
      "Training time:  249.28031826019287 Hour:  0 Minute:  4 Second:  9 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 15\n",
      "Epoch: [15][0/96]\tLoss 0.6392 (0.6392)\taccuracy 78.125 (78.125)\tf1_score 79.676 (79.676)\n",
      "Epoch: [15][5/96]\tLoss 0.9973 (0.6344)\taccuracy 64.062 (76.823)\tf1_score 61.745 (72.483)\n",
      "Epoch: [15][10/96]\tLoss 0.5843 (0.5936)\taccuracy 76.562 (77.983)\tf1_score 72.517 (74.036)\n",
      "Epoch: [15][15/96]\tLoss 0.3182 (0.5654)\taccuracy 90.625 (79.004)\tf1_score 78.944 (74.848)\n",
      "Epoch: [15][20/96]\tLoss 0.3836 (0.5486)\taccuracy 87.500 (79.762)\tf1_score 85.491 (76.253)\n",
      "Epoch: [15][25/96]\tLoss 0.4912 (0.5425)\taccuracy 76.562 (79.688)\tf1_score 76.294 (75.980)\n",
      "Epoch: [15][30/96]\tLoss 0.5643 (0.5481)\taccuracy 84.375 (79.788)\tf1_score 78.696 (76.394)\n",
      "Epoch: [15][35/96]\tLoss 0.4626 (0.5320)\taccuracy 85.938 (80.469)\tf1_score 82.389 (77.042)\n",
      "Epoch: [15][40/96]\tLoss 0.4820 (0.5217)\taccuracy 81.250 (80.831)\tf1_score 75.289 (77.335)\n",
      "Epoch: [15][45/96]\tLoss 0.7152 (0.5256)\taccuracy 79.688 (80.944)\tf1_score 69.129 (77.364)\n",
      "Epoch: [15][50/96]\tLoss 0.4858 (0.5221)\taccuracy 81.250 (80.944)\tf1_score 81.190 (77.523)\n",
      "Epoch: [15][55/96]\tLoss 0.6533 (0.5241)\taccuracy 73.438 (80.664)\tf1_score 70.628 (77.196)\n",
      "Epoch: [15][60/96]\tLoss 0.3512 (0.5193)\taccuracy 93.750 (80.789)\tf1_score 93.732 (77.341)\n",
      "Epoch: [15][65/96]\tLoss 0.5631 (0.5274)\taccuracy 78.125 (80.611)\tf1_score 70.381 (76.966)\n",
      "Epoch: [15][70/96]\tLoss 0.8006 (0.5358)\taccuracy 60.938 (80.084)\tf1_score 57.061 (76.458)\n",
      "Epoch: [15][75/96]\tLoss 1.0531 (0.5430)\taccuracy 57.812 (79.523)\tf1_score 55.090 (75.955)\n",
      "Epoch: [15][80/96]\tLoss 0.6215 (0.5436)\taccuracy 76.562 (79.572)\tf1_score 66.040 (75.898)\n",
      "Epoch: [15][85/96]\tLoss 0.6490 (0.5470)\taccuracy 73.438 (79.488)\tf1_score 65.873 (75.655)\n",
      "Epoch: [15][90/96]\tLoss 0.4309 (0.5450)\taccuracy 81.250 (79.533)\tf1_score 77.789 (75.598)\n",
      "Epoch: [15][95/96]\tLoss 0.3904 (0.5406)\taccuracy 82.812 (79.574)\tf1_score 79.184 (75.698)\n",
      " Test: accuracy 69.531 f1_score 64.519\n",
      "Training time:  264.884968996048 Hour:  0 Minute:  4 Second:  24 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 16\n",
      "Epoch: [16][0/96]\tLoss 0.3750 (0.3750)\taccuracy 84.375 (84.375)\tf1_score 80.728 (80.728)\n",
      "Epoch: [16][5/96]\tLoss 0.5943 (0.4616)\taccuracy 79.688 (81.771)\tf1_score 73.715 (78.719)\n",
      "Epoch: [16][10/96]\tLoss 0.5679 (0.5145)\taccuracy 71.875 (79.972)\tf1_score 65.760 (76.683)\n",
      "Epoch: [16][15/96]\tLoss 0.4862 (0.5104)\taccuracy 79.688 (79.883)\tf1_score 79.909 (76.656)\n",
      "Epoch: [16][20/96]\tLoss 0.4701 (0.5236)\taccuracy 79.688 (79.762)\tf1_score 73.666 (76.128)\n",
      "Epoch: [16][25/96]\tLoss 0.6811 (0.5227)\taccuracy 71.875 (79.808)\tf1_score 72.918 (76.278)\n",
      "Epoch: [16][30/96]\tLoss 0.4469 (0.5137)\taccuracy 89.062 (80.393)\tf1_score 86.190 (76.681)\n",
      "Epoch: [16][35/96]\tLoss 0.7079 (0.5112)\taccuracy 70.312 (80.252)\tf1_score 58.107 (76.497)\n",
      "Epoch: [16][40/96]\tLoss 0.5211 (0.5046)\taccuracy 84.375 (80.602)\tf1_score 81.361 (76.882)\n",
      "Epoch: [16][45/96]\tLoss 0.4388 (0.4998)\taccuracy 84.375 (80.673)\tf1_score 81.362 (77.004)\n",
      "Epoch: [16][50/96]\tLoss 0.6652 (0.4946)\taccuracy 73.438 (80.729)\tf1_score 73.047 (76.826)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16][55/96]\tLoss 0.6702 (0.5013)\taccuracy 73.438 (80.469)\tf1_score 63.569 (76.361)\n",
      "Epoch: [16][60/96]\tLoss 0.4308 (0.4983)\taccuracy 81.250 (80.661)\tf1_score 77.764 (76.328)\n",
      "Epoch: [16][65/96]\tLoss 1.1824 (0.5100)\taccuracy 57.812 (80.161)\tf1_score 51.345 (75.820)\n",
      "Epoch: [16][70/96]\tLoss 0.5420 (0.5113)\taccuracy 84.375 (80.260)\tf1_score 80.097 (76.160)\n",
      "Epoch: [16][75/96]\tLoss 0.8332 (0.5226)\taccuracy 65.625 (79.831)\tf1_score 64.083 (75.818)\n",
      "Epoch: [16][80/96]\tLoss 0.4712 (0.5212)\taccuracy 89.062 (80.093)\tf1_score 85.024 (76.212)\n",
      "Epoch: [16][85/96]\tLoss 0.5204 (0.5231)\taccuracy 82.812 (80.033)\tf1_score 82.921 (76.123)\n",
      "Epoch: [16][90/96]\tLoss 0.9205 (0.5237)\taccuracy 68.750 (79.997)\tf1_score 60.559 (75.970)\n",
      "Epoch: [16][95/96]\tLoss 0.4836 (0.5266)\taccuracy 78.125 (79.753)\tf1_score 70.352 (75.616)\n",
      " Test: accuracy 74.805 f1_score 70.664\n",
      "Training time:  280.3595004081726 Hour:  0 Minute:  4 Second:  40 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 17\n",
      "Epoch: [17][0/96]\tLoss 0.5608 (0.5608)\taccuracy 81.250 (81.250)\tf1_score 81.861 (81.861)\n",
      "Epoch: [17][5/96]\tLoss 0.4859 (0.4792)\taccuracy 84.375 (82.292)\tf1_score 80.906 (80.343)\n",
      "Epoch: [17][10/96]\tLoss 0.5265 (0.4826)\taccuracy 81.250 (82.102)\tf1_score 82.198 (80.236)\n",
      "Epoch: [17][15/96]\tLoss 0.3644 (0.4685)\taccuracy 85.938 (82.129)\tf1_score 82.171 (80.128)\n",
      "Epoch: [17][20/96]\tLoss 0.5761 (0.4877)\taccuracy 68.750 (80.283)\tf1_score 67.228 (78.035)\n",
      "Epoch: [17][25/96]\tLoss 0.5039 (0.4916)\taccuracy 81.250 (79.988)\tf1_score 80.008 (77.651)\n",
      "Epoch: [17][30/96]\tLoss 0.5375 (0.4972)\taccuracy 79.688 (79.940)\tf1_score 79.083 (77.525)\n",
      "Epoch: [17][35/96]\tLoss 0.3175 (0.4848)\taccuracy 89.062 (80.512)\tf1_score 82.808 (78.011)\n",
      "Epoch: [17][40/96]\tLoss 0.4472 (0.4845)\taccuracy 81.250 (80.869)\tf1_score 81.088 (78.393)\n",
      "Epoch: [17][45/96]\tLoss 0.3815 (0.5025)\taccuracy 84.375 (80.639)\tf1_score 81.672 (77.862)\n",
      "Epoch: [17][50/96]\tLoss 0.5710 (0.5097)\taccuracy 79.688 (80.423)\tf1_score 82.137 (77.498)\n",
      "Epoch: [17][55/96]\tLoss 0.3651 (0.5029)\taccuracy 90.625 (80.776)\tf1_score 89.516 (77.808)\n",
      "Epoch: [17][60/96]\tLoss 0.5434 (0.5086)\taccuracy 78.125 (80.763)\tf1_score 68.738 (77.468)\n",
      "Epoch: [17][65/96]\tLoss 0.3917 (0.5032)\taccuracy 84.375 (80.966)\tf1_score 67.723 (77.384)\n",
      "Epoch: [17][70/96]\tLoss 0.4178 (0.5056)\taccuracy 84.375 (80.876)\tf1_score 82.007 (77.251)\n",
      "Epoch: [17][75/96]\tLoss 0.6117 (0.5056)\taccuracy 78.125 (80.757)\tf1_score 77.826 (77.346)\n",
      "Epoch: [17][80/96]\tLoss 0.4432 (0.5029)\taccuracy 82.812 (80.845)\tf1_score 78.565 (77.384)\n",
      "Epoch: [17][85/96]\tLoss 0.5149 (0.5060)\taccuracy 81.250 (80.778)\tf1_score 75.797 (77.254)\n",
      "Epoch: [17][90/96]\tLoss 0.5117 (0.5031)\taccuracy 84.375 (80.975)\tf1_score 84.388 (77.597)\n",
      "Epoch: [17][95/96]\tLoss 0.5951 (0.5067)\taccuracy 84.375 (80.859)\tf1_score 79.596 (77.565)\n",
      " Test: accuracy 39.323 f1_score 34.405\n",
      "Training time:  295.8426868915558 Hour:  0 Minute:  4 Second:  55 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 18\n",
      "Epoch: [18][0/96]\tLoss 0.4083 (0.4083)\taccuracy 84.375 (84.375)\tf1_score 83.005 (83.005)\n",
      "Epoch: [18][5/96]\tLoss 0.4684 (0.5386)\taccuracy 78.125 (76.823)\tf1_score 77.748 (76.489)\n",
      "Epoch: [18][10/96]\tLoss 0.4441 (0.4753)\taccuracy 84.375 (81.250)\tf1_score 80.719 (80.167)\n",
      "Epoch: [18][15/96]\tLoss 0.5532 (0.4969)\taccuracy 76.562 (79.883)\tf1_score 74.991 (78.120)\n",
      "Epoch: [18][20/96]\tLoss 1.0438 (0.5617)\taccuracy 70.312 (78.646)\tf1_score 63.993 (76.273)\n",
      "Epoch: [18][25/96]\tLoss 0.5833 (0.5535)\taccuracy 75.000 (78.486)\tf1_score 65.452 (75.521)\n",
      "Epoch: [18][30/96]\tLoss 0.3563 (0.5454)\taccuracy 89.062 (79.032)\tf1_score 86.855 (75.473)\n",
      "Epoch: [18][35/96]\tLoss 0.6109 (0.5406)\taccuracy 71.875 (79.123)\tf1_score 75.012 (76.028)\n",
      "Epoch: [18][40/96]\tLoss 0.3513 (0.5258)\taccuracy 89.062 (79.916)\tf1_score 85.573 (76.640)\n",
      "Epoch: [18][45/96]\tLoss 0.3430 (0.5208)\taccuracy 87.500 (80.129)\tf1_score 82.790 (76.819)\n",
      "Epoch: [18][50/96]\tLoss 0.3669 (0.5156)\taccuracy 85.938 (80.423)\tf1_score 84.801 (77.258)\n",
      "Epoch: [18][55/96]\tLoss 0.4136 (0.5108)\taccuracy 84.375 (80.552)\tf1_score 79.659 (77.444)\n",
      "Epoch: [18][60/96]\tLoss 0.6019 (0.5063)\taccuracy 70.312 (80.635)\tf1_score 73.832 (77.495)\n",
      "Epoch: [18][65/96]\tLoss 0.3979 (0.5029)\taccuracy 87.500 (80.895)\tf1_score 83.571 (77.869)\n",
      "Epoch: [18][70/96]\tLoss 0.3266 (0.4959)\taccuracy 89.062 (81.074)\tf1_score 88.196 (78.234)\n",
      "Epoch: [18][75/96]\tLoss 0.4281 (0.4898)\taccuracy 82.812 (81.291)\tf1_score 79.821 (78.456)\n",
      "Epoch: [18][80/96]\tLoss 0.4483 (0.4876)\taccuracy 75.000 (81.404)\tf1_score 67.298 (78.558)\n",
      "Epoch: [18][85/96]\tLoss 0.4546 (0.4870)\taccuracy 79.688 (81.468)\tf1_score 76.372 (78.431)\n",
      "Epoch: [18][90/96]\tLoss 0.3264 (0.4866)\taccuracy 85.938 (81.456)\tf1_score 78.571 (78.332)\n",
      "Epoch: [18][95/96]\tLoss 0.4031 (0.4886)\taccuracy 79.688 (81.380)\tf1_score 77.632 (78.286)\n",
      " Test: accuracy 23.177 f1_score 15.546\n",
      "Training time:  311.3400454521179 Hour:  0 Minute:  5 Second:  11 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 19\n",
      "Epoch: [19][0/96]\tLoss 0.4369 (0.4369)\taccuracy 78.125 (78.125)\tf1_score 75.290 (75.290)\n",
      "Epoch: [19][5/96]\tLoss 0.3724 (0.4921)\taccuracy 89.062 (79.948)\tf1_score 82.746 (75.157)\n",
      "Epoch: [19][10/96]\tLoss 0.5580 (0.5062)\taccuracy 76.562 (79.688)\tf1_score 74.823 (74.738)\n",
      "Epoch: [19][15/96]\tLoss 0.4734 (0.4799)\taccuracy 81.250 (81.152)\tf1_score 71.440 (75.689)\n",
      "Epoch: [19][20/96]\tLoss 0.5079 (0.4780)\taccuracy 78.125 (81.324)\tf1_score 72.831 (76.434)\n",
      "Epoch: [19][25/96]\tLoss 0.4752 (0.4819)\taccuracy 75.000 (80.950)\tf1_score 72.407 (76.558)\n",
      "Epoch: [19][30/96]\tLoss 0.5748 (0.4789)\taccuracy 76.562 (81.200)\tf1_score 71.236 (76.812)\n",
      "Epoch: [19][35/96]\tLoss 0.7379 (0.4813)\taccuracy 71.875 (81.337)\tf1_score 66.486 (77.264)\n",
      "Epoch: [19][40/96]\tLoss 0.3425 (0.4685)\taccuracy 89.062 (81.936)\tf1_score 89.409 (78.245)\n",
      "Epoch: [19][45/96]\tLoss 0.6777 (0.4661)\taccuracy 79.688 (82.167)\tf1_score 77.619 (78.723)\n",
      "Epoch: [19][50/96]\tLoss 0.3673 (0.4697)\taccuracy 84.375 (81.924)\tf1_score 81.547 (78.469)\n",
      "Epoch: [19][55/96]\tLoss 0.1910 (0.4710)\taccuracy 93.750 (81.696)\tf1_score 85.113 (78.279)\n",
      "Epoch: [19][60/96]\tLoss 0.4729 (0.4770)\taccuracy 79.688 (81.557)\tf1_score 74.222 (78.039)\n",
      "Epoch: [19][65/96]\tLoss 0.5810 (0.4807)\taccuracy 75.000 (81.439)\tf1_score 71.363 (77.956)\n",
      "Epoch: [19][70/96]\tLoss 0.3256 (0.4813)\taccuracy 89.062 (81.404)\tf1_score 88.473 (78.076)\n",
      "Epoch: [19][75/96]\tLoss 0.3410 (0.4806)\taccuracy 85.938 (81.353)\tf1_score 81.420 (77.943)\n",
      "Epoch: [19][80/96]\tLoss 0.5111 (0.4848)\taccuracy 85.938 (81.231)\tf1_score 84.788 (77.810)\n",
      "Epoch: [19][85/96]\tLoss 0.5439 (0.4838)\taccuracy 85.938 (81.359)\tf1_score 82.968 (77.940)\n",
      "Epoch: [19][90/96]\tLoss 0.7026 (0.4867)\taccuracy 82.812 (81.336)\tf1_score 76.366 (77.975)\n",
      "Epoch: [19][95/96]\tLoss 0.3265 (0.4905)\taccuracy 87.500 (81.201)\tf1_score 86.955 (77.916)\n",
      " Test: accuracy 74.414 f1_score 69.466\n",
      "Training time:  326.90556263923645 Hour:  0 Minute:  5 Second:  26 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 20\n",
      "Epoch: [20][0/96]\tLoss 0.3411 (0.3411)\taccuracy 85.938 (85.938)\tf1_score 76.417 (76.417)\n",
      "Epoch: [20][5/96]\tLoss 0.3000 (0.4021)\taccuracy 87.500 (84.115)\tf1_score 85.159 (80.279)\n",
      "Epoch: [20][10/96]\tLoss 0.4277 (0.4655)\taccuracy 79.688 (80.824)\tf1_score 79.746 (78.501)\n",
      "Epoch: [20][15/96]\tLoss 0.3717 (0.4581)\taccuracy 84.375 (81.445)\tf1_score 76.849 (78.756)\n",
      "Epoch: [20][20/96]\tLoss 0.5994 (0.4680)\taccuracy 78.125 (81.250)\tf1_score 72.587 (78.312)\n",
      "Epoch: [20][25/96]\tLoss 0.5496 (0.4739)\taccuracy 82.812 (81.190)\tf1_score 77.758 (78.167)\n",
      "Epoch: [20][30/96]\tLoss 0.2994 (0.4666)\taccuracy 89.062 (81.754)\tf1_score 86.327 (78.772)\n",
      "Epoch: [20][35/96]\tLoss 0.3351 (0.4619)\taccuracy 85.938 (82.248)\tf1_score 80.425 (79.101)\n",
      "Epoch: [20][40/96]\tLoss 0.4676 (0.4597)\taccuracy 79.688 (82.241)\tf1_score 76.136 (79.003)\n",
      "Epoch: [20][45/96]\tLoss 0.4250 (0.4571)\taccuracy 82.812 (82.167)\tf1_score 77.720 (79.067)\n",
      "Epoch: [20][50/96]\tLoss 0.3229 (0.4580)\taccuracy 89.062 (82.230)\tf1_score 77.534 (79.134)\n",
      "Epoch: [20][55/96]\tLoss 0.7458 (0.4610)\taccuracy 73.438 (82.115)\tf1_score 69.596 (78.905)\n",
      "Epoch: [20][60/96]\tLoss 0.3870 (0.4557)\taccuracy 84.375 (82.300)\tf1_score 78.526 (79.080)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20][65/96]\tLoss 0.3605 (0.4491)\taccuracy 89.062 (82.552)\tf1_score 88.032 (79.370)\n",
      "Epoch: [20][70/96]\tLoss 0.4830 (0.4502)\taccuracy 79.688 (82.482)\tf1_score 74.204 (79.107)\n",
      "Epoch: [20][75/96]\tLoss 0.3592 (0.4498)\taccuracy 82.812 (82.360)\tf1_score 84.707 (79.140)\n",
      "Epoch: [20][80/96]\tLoss 0.5977 (0.4469)\taccuracy 75.000 (82.504)\tf1_score 67.569 (79.187)\n",
      "Epoch: [20][85/96]\tLoss 0.3954 (0.4468)\taccuracy 87.500 (82.395)\tf1_score 87.274 (79.022)\n",
      "Epoch: [20][90/96]\tLoss 0.7910 (0.4499)\taccuracy 75.000 (82.435)\tf1_score 74.726 (79.101)\n",
      "Epoch: [20][95/96]\tLoss 0.4706 (0.4589)\taccuracy 81.250 (82.145)\tf1_score 75.726 (78.653)\n",
      " Test: accuracy 45.247 f1_score 37.561\n",
      "Training time:  342.45727276802063 Hour:  0 Minute:  5 Second:  42 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 21\n",
      "Epoch: [21][0/96]\tLoss 0.5687 (0.5687)\taccuracy 76.562 (76.562)\tf1_score 73.949 (73.949)\n",
      "Epoch: [21][5/96]\tLoss 0.3730 (0.5250)\taccuracy 90.625 (81.771)\tf1_score 88.968 (78.914)\n",
      "Epoch: [21][10/96]\tLoss 0.7345 (0.5599)\taccuracy 73.438 (81.108)\tf1_score 71.077 (78.657)\n",
      "Epoch: [21][15/96]\tLoss 0.3479 (0.5186)\taccuracy 85.938 (81.934)\tf1_score 81.751 (79.025)\n",
      "Epoch: [21][20/96]\tLoss 0.6651 (0.5263)\taccuracy 67.188 (81.176)\tf1_score 68.147 (78.641)\n",
      "Epoch: [21][25/96]\tLoss 0.4495 (0.5117)\taccuracy 82.812 (81.550)\tf1_score 73.235 (78.619)\n",
      "Epoch: [21][30/96]\tLoss 0.4230 (0.4966)\taccuracy 81.250 (81.905)\tf1_score 76.999 (78.944)\n",
      "Epoch: [21][35/96]\tLoss 0.3444 (0.4858)\taccuracy 87.500 (81.988)\tf1_score 79.295 (78.461)\n",
      "Epoch: [21][40/96]\tLoss 0.5458 (0.4872)\taccuracy 78.125 (81.707)\tf1_score 79.702 (78.187)\n",
      "Epoch: [21][45/96]\tLoss 0.4678 (0.4839)\taccuracy 75.000 (81.658)\tf1_score 74.331 (78.010)\n",
      "Epoch: [21][50/96]\tLoss 0.4957 (0.4834)\taccuracy 82.812 (81.495)\tf1_score 74.355 (77.924)\n",
      "Epoch: [21][55/96]\tLoss 0.2651 (0.4698)\taccuracy 89.062 (82.059)\tf1_score 86.807 (78.452)\n",
      "Epoch: [21][60/96]\tLoss 0.9751 (0.4742)\taccuracy 60.938 (81.788)\tf1_score 60.952 (78.421)\n",
      "Epoch: [21][65/96]\tLoss 0.3379 (0.4714)\taccuracy 87.500 (81.700)\tf1_score 88.758 (78.365)\n",
      "Epoch: [21][70/96]\tLoss 0.4384 (0.4701)\taccuracy 79.688 (81.734)\tf1_score 74.717 (78.258)\n",
      "Epoch: [21][75/96]\tLoss 0.3232 (0.4684)\taccuracy 84.375 (81.661)\tf1_score 82.525 (78.183)\n",
      "Epoch: [21][80/96]\tLoss 0.4220 (0.4616)\taccuracy 85.938 (81.983)\tf1_score 75.703 (78.399)\n",
      "Epoch: [21][85/96]\tLoss 0.6696 (0.4646)\taccuracy 73.438 (81.904)\tf1_score 69.694 (78.245)\n",
      "Epoch: [21][90/96]\tLoss 0.7009 (0.4665)\taccuracy 71.875 (81.885)\tf1_score 61.349 (78.135)\n",
      "Epoch: [21][95/96]\tLoss 0.3093 (0.4649)\taccuracy 89.062 (81.836)\tf1_score 87.942 (78.036)\n",
      " Test: accuracy 44.792 f1_score 36.655\n",
      "Training time:  357.9921164512634 Hour:  0 Minute:  5 Second:  57 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 22\n",
      "Epoch: [22][0/96]\tLoss 0.3397 (0.3397)\taccuracy 89.062 (89.062)\tf1_score 82.631 (82.631)\n",
      "Epoch: [22][5/96]\tLoss 0.4371 (0.3843)\taccuracy 82.812 (84.896)\tf1_score 78.811 (80.314)\n",
      "Epoch: [22][10/96]\tLoss 0.5325 (0.4055)\taccuracy 81.250 (83.239)\tf1_score 74.887 (78.533)\n",
      "Epoch: [22][15/96]\tLoss 0.4494 (0.4510)\taccuracy 81.250 (81.934)\tf1_score 82.260 (78.375)\n",
      "Epoch: [22][20/96]\tLoss 0.4041 (0.4413)\taccuracy 85.938 (82.366)\tf1_score 84.768 (78.764)\n",
      "Epoch: [22][25/96]\tLoss 0.3758 (0.4390)\taccuracy 81.250 (82.512)\tf1_score 70.648 (78.839)\n",
      "Epoch: [22][30/96]\tLoss 0.3643 (0.4333)\taccuracy 85.938 (82.762)\tf1_score 87.643 (79.263)\n",
      "Epoch: [22][35/96]\tLoss 0.4320 (0.4273)\taccuracy 81.250 (83.290)\tf1_score 76.260 (79.365)\n",
      "Epoch: [22][40/96]\tLoss 0.4495 (0.4353)\taccuracy 89.062 (83.232)\tf1_score 90.363 (79.518)\n",
      "Epoch: [22][45/96]\tLoss 0.5443 (0.4409)\taccuracy 75.000 (82.846)\tf1_score 68.661 (78.978)\n",
      "Epoch: [22][50/96]\tLoss 0.4604 (0.4458)\taccuracy 82.812 (82.659)\tf1_score 75.977 (78.606)\n",
      "Epoch: [22][55/96]\tLoss 0.3225 (0.4446)\taccuracy 89.062 (82.645)\tf1_score 82.251 (78.486)\n",
      "Epoch: [22][60/96]\tLoss 0.4232 (0.4549)\taccuracy 79.688 (82.249)\tf1_score 76.054 (78.243)\n",
      "Epoch: [22][65/96]\tLoss 0.4180 (0.4574)\taccuracy 89.062 (82.268)\tf1_score 86.935 (78.349)\n",
      "Epoch: [22][70/96]\tLoss 0.6090 (0.4539)\taccuracy 81.250 (82.504)\tf1_score 74.206 (78.691)\n",
      "Epoch: [22][75/96]\tLoss 0.6457 (0.4550)\taccuracy 78.125 (82.463)\tf1_score 71.538 (78.590)\n",
      "Epoch: [22][80/96]\tLoss 0.4122 (0.4542)\taccuracy 81.250 (82.620)\tf1_score 74.299 (78.668)\n",
      "Epoch: [22][85/96]\tLoss 0.5801 (0.4552)\taccuracy 81.250 (82.594)\tf1_score 67.033 (78.602)\n",
      "Epoch: [22][90/96]\tLoss 0.4840 (0.4529)\taccuracy 82.812 (82.709)\tf1_score 78.534 (78.753)\n",
      "Epoch: [22][95/96]\tLoss 0.4686 (0.4485)\taccuracy 81.250 (82.894)\tf1_score 82.851 (79.003)\n",
      " Test: accuracy 65.885 f1_score 61.255\n",
      "Training time:  373.5438208580017 Hour:  0 Minute:  6 Second:  13 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 23\n",
      "Epoch: [23][0/96]\tLoss 0.5459 (0.5459)\taccuracy 79.688 (79.688)\tf1_score 77.566 (77.566)\n",
      "Epoch: [23][5/96]\tLoss 0.4482 (0.4521)\taccuracy 81.250 (83.073)\tf1_score 79.635 (80.700)\n",
      "Epoch: [23][10/96]\tLoss 0.5261 (0.4768)\taccuracy 81.250 (82.386)\tf1_score 75.151 (78.491)\n",
      "Epoch: [23][15/96]\tLoss 0.3518 (0.4571)\taccuracy 87.500 (83.008)\tf1_score 87.027 (79.429)\n",
      "Epoch: [23][20/96]\tLoss 0.3941 (0.4363)\taccuracy 84.375 (83.557)\tf1_score 82.432 (79.467)\n",
      "Epoch: [23][25/96]\tLoss 0.5418 (0.4353)\taccuracy 79.688 (83.233)\tf1_score 72.194 (78.984)\n",
      "Epoch: [23][30/96]\tLoss 0.4423 (0.4219)\taccuracy 79.688 (83.720)\tf1_score 78.730 (79.658)\n",
      "Epoch: [23][35/96]\tLoss 0.3227 (0.4154)\taccuracy 89.062 (83.898)\tf1_score 86.155 (79.462)\n",
      "Epoch: [23][40/96]\tLoss 0.3238 (0.4106)\taccuracy 87.500 (84.070)\tf1_score 83.871 (79.579)\n",
      "Epoch: [23][45/96]\tLoss 0.4699 (0.4050)\taccuracy 81.250 (84.205)\tf1_score 74.898 (80.121)\n",
      "Epoch: [23][50/96]\tLoss 0.2847 (0.4066)\taccuracy 89.062 (84.191)\tf1_score 79.642 (79.981)\n",
      "Epoch: [23][55/96]\tLoss 0.2045 (0.4043)\taccuracy 92.188 (84.542)\tf1_score 87.988 (80.495)\n",
      "Epoch: [23][60/96]\tLoss 0.3620 (0.4062)\taccuracy 87.500 (84.477)\tf1_score 89.459 (80.295)\n",
      "Epoch: [23][65/96]\tLoss 0.4295 (0.4068)\taccuracy 79.688 (84.328)\tf1_score 78.909 (80.292)\n",
      "Epoch: [23][70/96]\tLoss 0.3911 (0.4075)\taccuracy 84.375 (84.309)\tf1_score 81.442 (80.221)\n",
      "Epoch: [23][75/96]\tLoss 0.4012 (0.4139)\taccuracy 84.375 (84.087)\tf1_score 82.051 (79.926)\n",
      "Epoch: [23][80/96]\tLoss 0.3494 (0.4145)\taccuracy 82.812 (83.951)\tf1_score 81.702 (79.826)\n",
      "Epoch: [23][85/96]\tLoss 0.4554 (0.4229)\taccuracy 78.125 (83.703)\tf1_score 78.694 (79.655)\n",
      "Epoch: [23][90/96]\tLoss 0.5654 (0.4221)\taccuracy 82.812 (83.791)\tf1_score 75.740 (79.809)\n",
      "Epoch: [23][95/96]\tLoss 0.3413 (0.4184)\taccuracy 92.188 (84.049)\tf1_score 88.977 (80.184)\n",
      " Test: accuracy 66.341 f1_score 60.045\n",
      "Training time:  389.11737751960754 Hour:  0 Minute:  6 Second:  29 Test best accuracy: 75.06510416666667  Test best f1 score: 71.41857580463517\n",
      "\n",
      "Start of epoch NO: 24\n",
      "Epoch: [24][0/96]\tLoss 0.4939 (0.4939)\taccuracy 84.375 (84.375)\tf1_score 84.863 (84.863)\n",
      "Epoch: [24][5/96]\tLoss 0.5685 (0.5602)\taccuracy 82.812 (80.208)\tf1_score 75.998 (78.117)\n",
      "Epoch: [24][10/96]\tLoss 0.3234 (0.4959)\taccuracy 87.500 (81.818)\tf1_score 85.503 (79.568)\n",
      "Epoch: [24][15/96]\tLoss 0.3837 (0.4815)\taccuracy 85.938 (82.715)\tf1_score 82.997 (79.891)\n",
      "Epoch: [24][20/96]\tLoss 0.5412 (0.4640)\taccuracy 78.125 (82.812)\tf1_score 75.958 (79.728)\n",
      "Epoch: [24][25/96]\tLoss 0.4697 (0.4537)\taccuracy 78.125 (82.993)\tf1_score 77.156 (79.642)\n",
      "Epoch: [24][30/96]\tLoss 0.2962 (0.4606)\taccuracy 92.188 (82.560)\tf1_score 90.119 (79.520)\n",
      "Epoch: [24][35/96]\tLoss 0.4441 (0.4729)\taccuracy 85.938 (82.552)\tf1_score 79.643 (79.273)\n",
      "Epoch: [24][40/96]\tLoss 0.3903 (0.4661)\taccuracy 85.938 (82.812)\tf1_score 77.952 (79.041)\n",
      "Epoch: [24][45/96]\tLoss 0.6796 (0.4602)\taccuracy 71.875 (82.812)\tf1_score 69.410 (78.927)\n",
      "Epoch: [24][50/96]\tLoss 0.4151 (0.4511)\taccuracy 81.250 (83.088)\tf1_score 77.196 (79.161)\n",
      "Epoch: [24][55/96]\tLoss 0.3717 (0.4494)\taccuracy 84.375 (82.840)\tf1_score 84.031 (78.771)\n",
      "Epoch: [24][60/96]\tLoss 0.4309 (0.4487)\taccuracy 81.250 (82.941)\tf1_score 77.382 (79.132)\n",
      "Epoch: [24][65/96]\tLoss 0.5019 (0.4534)\taccuracy 76.562 (82.599)\tf1_score 73.033 (78.721)\n",
      "Epoch: [24][70/96]\tLoss 0.6189 (0.4611)\taccuracy 76.562 (82.394)\tf1_score 64.438 (78.464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24][75/96]\tLoss 0.6012 (0.4589)\taccuracy 75.000 (82.422)\tf1_score 70.741 (78.577)\n",
      "Epoch: [24][80/96]\tLoss 0.4006 (0.4569)\taccuracy 85.938 (82.600)\tf1_score 78.902 (78.810)\n",
      "Epoch: [24][85/96]\tLoss 0.4604 (0.4553)\taccuracy 82.812 (82.740)\tf1_score 79.347 (78.965)\n",
      "Epoch: [24][90/96]\tLoss 0.4717 (0.4515)\taccuracy 81.250 (82.744)\tf1_score 78.912 (78.873)\n",
      "Epoch: [24][95/96]\tLoss 0.3445 (0.4489)\taccuracy 89.062 (82.926)\tf1_score 89.027 (79.081)\n",
      " Test: accuracy 76.302 f1_score 73.822\n",
      "Saving..\n",
      "Training time:  404.7873523235321 Hour:  0 Minute:  6 Second:  44 Test best accuracy: 76.30208333333333  Test best f1 score: 73.8224647575875\n",
      "\n",
      "Start of epoch NO: 25\n",
      "Epoch: [25][0/96]\tLoss 0.6698 (0.6698)\taccuracy 81.250 (81.250)\tf1_score 75.629 (75.629)\n",
      "Epoch: [25][5/96]\tLoss 0.4100 (0.3982)\taccuracy 82.812 (85.677)\tf1_score 74.237 (81.557)\n",
      "Epoch: [25][10/96]\tLoss 0.2582 (0.3925)\taccuracy 85.938 (85.653)\tf1_score 76.846 (81.128)\n",
      "Epoch: [25][15/96]\tLoss 0.5342 (0.3947)\taccuracy 84.375 (85.254)\tf1_score 78.759 (81.492)\n",
      "Epoch: [25][20/96]\tLoss 0.2792 (0.3924)\taccuracy 85.938 (84.673)\tf1_score 80.367 (81.084)\n",
      "Epoch: [25][25/96]\tLoss 0.2990 (0.3945)\taccuracy 89.062 (84.315)\tf1_score 86.470 (81.138)\n",
      "Epoch: [25][30/96]\tLoss 0.3111 (0.3953)\taccuracy 85.938 (84.325)\tf1_score 80.884 (81.215)\n",
      "Epoch: [25][35/96]\tLoss 0.2526 (0.3900)\taccuracy 90.625 (84.635)\tf1_score 85.915 (81.521)\n",
      "Epoch: [25][40/96]\tLoss 0.3537 (0.3854)\taccuracy 89.062 (84.985)\tf1_score 84.253 (81.819)\n",
      "Epoch: [25][45/96]\tLoss 0.3475 (0.3867)\taccuracy 84.375 (84.477)\tf1_score 83.369 (81.197)\n",
      "Epoch: [25][50/96]\tLoss 0.3436 (0.3891)\taccuracy 84.375 (84.375)\tf1_score 83.029 (80.999)\n",
      "Epoch: [25][55/96]\tLoss 0.2172 (0.3978)\taccuracy 92.188 (84.180)\tf1_score 91.440 (80.917)\n",
      "Epoch: [25][60/96]\tLoss 0.5881 (0.4038)\taccuracy 78.125 (84.093)\tf1_score 72.539 (81.019)\n",
      "Epoch: [25][65/96]\tLoss 0.2470 (0.4045)\taccuracy 93.750 (84.233)\tf1_score 89.140 (81.122)\n",
      "Epoch: [25][70/96]\tLoss 0.4035 (0.4060)\taccuracy 82.812 (84.133)\tf1_score 76.931 (80.997)\n",
      "Epoch: [25][75/96]\tLoss 0.6944 (0.4095)\taccuracy 68.750 (83.984)\tf1_score 75.035 (81.020)\n",
      "Epoch: [25][80/96]\tLoss 0.4632 (0.4083)\taccuracy 79.688 (83.989)\tf1_score 80.196 (80.998)\n",
      "Epoch: [25][85/96]\tLoss 0.2592 (0.4052)\taccuracy 92.188 (84.193)\tf1_score 85.775 (81.117)\n",
      "Epoch: [25][90/96]\tLoss 0.3209 (0.3981)\taccuracy 87.500 (84.444)\tf1_score 87.048 (81.522)\n",
      "Epoch: [25][95/96]\tLoss 0.5544 (0.3984)\taccuracy 81.250 (84.408)\tf1_score 78.191 (81.426)\n",
      " Test: accuracy 84.701 f1_score 82.284\n",
      "Saving..\n",
      "Training time:  420.7601146697998 Hour:  0 Minute:  7 Second:  0 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 26\n",
      "Epoch: [26][0/96]\tLoss 0.4235 (0.4235)\taccuracy 82.812 (82.812)\tf1_score 82.145 (82.145)\n",
      "Epoch: [26][5/96]\tLoss 0.3342 (0.3601)\taccuracy 87.500 (86.719)\tf1_score 72.052 (81.681)\n",
      "Epoch: [26][10/96]\tLoss 0.4225 (0.4102)\taccuracy 81.250 (83.807)\tf1_score 82.537 (80.499)\n",
      "Epoch: [26][15/96]\tLoss 0.2621 (0.4037)\taccuracy 90.625 (84.180)\tf1_score 89.953 (81.195)\n",
      "Epoch: [26][20/96]\tLoss 0.3477 (0.3951)\taccuracy 82.812 (84.003)\tf1_score 81.857 (80.648)\n",
      "Epoch: [26][25/96]\tLoss 0.2067 (0.3878)\taccuracy 90.625 (84.315)\tf1_score 81.134 (80.845)\n",
      "Epoch: [26][30/96]\tLoss 0.3305 (0.3890)\taccuracy 85.938 (84.274)\tf1_score 85.613 (81.136)\n",
      "Epoch: [26][35/96]\tLoss 0.2582 (0.3825)\taccuracy 90.625 (84.635)\tf1_score 84.558 (81.402)\n",
      "Epoch: [26][40/96]\tLoss 0.2102 (0.3645)\taccuracy 92.188 (85.442)\tf1_score 92.540 (82.239)\n",
      "Epoch: [26][45/96]\tLoss 0.2842 (0.3570)\taccuracy 89.062 (85.666)\tf1_score 78.000 (82.389)\n",
      "Epoch: [26][50/96]\tLoss 0.4565 (0.3675)\taccuracy 81.250 (85.355)\tf1_score 70.706 (81.982)\n",
      "Epoch: [26][55/96]\tLoss 0.3669 (0.3634)\taccuracy 84.375 (85.631)\tf1_score 84.472 (82.345)\n",
      "Epoch: [26][60/96]\tLoss 0.9561 (0.3833)\taccuracy 68.750 (84.734)\tf1_score 66.462 (81.726)\n",
      "Epoch: [26][65/96]\tLoss 0.5248 (0.3873)\taccuracy 79.688 (84.541)\tf1_score 71.791 (81.323)\n",
      "Epoch: [26][70/96]\tLoss 0.3609 (0.3837)\taccuracy 82.812 (84.727)\tf1_score 80.208 (81.300)\n",
      "Epoch: [26][75/96]\tLoss 0.3125 (0.3869)\taccuracy 92.188 (84.725)\tf1_score 91.585 (81.258)\n",
      "Epoch: [26][80/96]\tLoss 0.5936 (0.3906)\taccuracy 75.000 (84.471)\tf1_score 64.578 (80.877)\n",
      "Epoch: [26][85/96]\tLoss 0.4007 (0.3948)\taccuracy 85.938 (84.211)\tf1_score 82.607 (80.729)\n",
      "Epoch: [26][90/96]\tLoss 0.6881 (0.4014)\taccuracy 71.875 (84.014)\tf1_score 69.440 (80.592)\n",
      "Epoch: [26][95/96]\tLoss 0.6618 (0.4091)\taccuracy 76.562 (83.757)\tf1_score 64.623 (80.207)\n",
      " Test: accuracy 59.570 f1_score 52.543\n",
      "Training time:  436.5368847846985 Hour:  0 Minute:  7 Second:  16 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 27\n",
      "Epoch: [27][0/96]\tLoss 0.9263 (0.9263)\taccuracy 65.625 (65.625)\tf1_score 55.902 (55.902)\n",
      "Epoch: [27][5/96]\tLoss 0.4044 (0.4769)\taccuracy 82.812 (81.771)\tf1_score 78.921 (78.761)\n",
      "Epoch: [27][10/96]\tLoss 0.5120 (0.5009)\taccuracy 78.125 (80.398)\tf1_score 80.968 (78.469)\n",
      "Epoch: [27][15/96]\tLoss 0.5136 (0.4688)\taccuracy 78.125 (81.250)\tf1_score 71.468 (78.345)\n",
      "Epoch: [27][20/96]\tLoss 0.3463 (0.4644)\taccuracy 85.938 (81.548)\tf1_score 85.861 (78.459)\n",
      "Epoch: [27][25/96]\tLoss 0.3523 (0.4370)\taccuracy 87.500 (82.873)\tf1_score 82.665 (80.051)\n",
      "Epoch: [27][30/96]\tLoss 0.5959 (0.4372)\taccuracy 75.000 (82.964)\tf1_score 69.419 (80.088)\n",
      "Epoch: [27][35/96]\tLoss 0.3512 (0.4171)\taccuracy 87.500 (83.854)\tf1_score 86.540 (81.113)\n",
      "Epoch: [27][40/96]\tLoss 0.3234 (0.4051)\taccuracy 87.500 (84.261)\tf1_score 86.651 (81.498)\n",
      "Epoch: [27][45/96]\tLoss 0.4469 (0.4092)\taccuracy 82.812 (83.933)\tf1_score 82.752 (81.270)\n",
      "Epoch: [27][50/96]\tLoss 0.3645 (0.4152)\taccuracy 87.500 (83.609)\tf1_score 84.755 (80.855)\n",
      "Epoch: [27][55/96]\tLoss 0.3756 (0.4156)\taccuracy 84.375 (83.677)\tf1_score 79.158 (80.911)\n",
      "Epoch: [27][60/96]\tLoss 0.3884 (0.4132)\taccuracy 82.812 (83.786)\tf1_score 75.775 (80.827)\n",
      "Epoch: [27][65/96]\tLoss 0.4766 (0.4200)\taccuracy 85.938 (83.499)\tf1_score 80.101 (80.481)\n",
      "Epoch: [27][70/96]\tLoss 0.3085 (0.4180)\taccuracy 87.500 (83.495)\tf1_score 81.807 (80.466)\n",
      "Epoch: [27][75/96]\tLoss 0.4990 (0.4162)\taccuracy 81.250 (83.614)\tf1_score 82.711 (80.635)\n",
      "Epoch: [27][80/96]\tLoss 0.5099 (0.4208)\taccuracy 75.000 (83.353)\tf1_score 67.278 (80.289)\n",
      "Epoch: [27][85/96]\tLoss 0.6052 (0.4205)\taccuracy 76.562 (83.412)\tf1_score 76.640 (80.425)\n",
      "Epoch: [27][90/96]\tLoss 0.4022 (0.4189)\taccuracy 82.812 (83.431)\tf1_score 84.070 (80.291)\n",
      "Epoch: [27][95/96]\tLoss 0.9057 (0.4256)\taccuracy 70.312 (83.203)\tf1_score 64.911 (80.154)\n",
      " Test: accuracy 44.401 f1_score 38.976\n",
      "Training time:  452.15518522262573 Hour:  0 Minute:  7 Second:  32 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 28\n",
      "Epoch: [28][0/96]\tLoss 0.3303 (0.3303)\taccuracy 85.938 (85.938)\tf1_score 83.974 (83.974)\n",
      "Epoch: [28][5/96]\tLoss 0.4454 (0.3986)\taccuracy 82.812 (84.115)\tf1_score 74.894 (80.580)\n",
      "Epoch: [28][10/96]\tLoss 0.4688 (0.3929)\taccuracy 82.812 (83.949)\tf1_score 79.173 (81.614)\n",
      "Epoch: [28][15/96]\tLoss 0.7253 (0.4140)\taccuracy 75.000 (83.008)\tf1_score 67.532 (80.552)\n",
      "Epoch: [28][20/96]\tLoss 0.5372 (0.3996)\taccuracy 79.688 (83.631)\tf1_score 77.895 (81.169)\n",
      "Epoch: [28][25/96]\tLoss 0.8119 (0.3996)\taccuracy 76.562 (84.255)\tf1_score 72.859 (81.885)\n",
      "Epoch: [28][30/96]\tLoss 0.5113 (0.4105)\taccuracy 82.812 (84.173)\tf1_score 83.581 (81.870)\n",
      "Epoch: [28][35/96]\tLoss 0.2283 (0.4105)\taccuracy 95.312 (84.332)\tf1_score 95.862 (81.737)\n",
      "Epoch: [28][40/96]\tLoss 0.3261 (0.4201)\taccuracy 89.062 (84.070)\tf1_score 83.738 (81.449)\n",
      "Epoch: [28][45/96]\tLoss 0.2782 (0.4168)\taccuracy 87.500 (84.069)\tf1_score 80.724 (81.351)\n",
      "Epoch: [28][50/96]\tLoss 0.3588 (0.4149)\taccuracy 87.500 (84.069)\tf1_score 76.277 (81.051)\n",
      "Epoch: [28][55/96]\tLoss 0.3114 (0.4154)\taccuracy 85.938 (83.984)\tf1_score 85.000 (80.964)\n",
      "Epoch: [28][60/96]\tLoss 0.4259 (0.4092)\taccuracy 84.375 (84.273)\tf1_score 80.619 (81.327)\n",
      "Epoch: [28][65/96]\tLoss 0.4721 (0.4049)\taccuracy 78.125 (84.304)\tf1_score 72.262 (81.165)\n",
      "Epoch: [28][70/96]\tLoss 0.5040 (0.4030)\taccuracy 79.688 (84.419)\tf1_score 79.769 (81.371)\n",
      "Epoch: [28][75/96]\tLoss 0.2971 (0.4019)\taccuracy 90.625 (84.560)\tf1_score 90.990 (81.561)\n",
      "Epoch: [28][80/96]\tLoss 0.6202 (0.4011)\taccuracy 79.688 (84.877)\tf1_score 79.071 (81.899)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28][85/96]\tLoss 0.3554 (0.3991)\taccuracy 78.125 (84.793)\tf1_score 71.313 (81.768)\n",
      "Epoch: [28][90/96]\tLoss 0.3269 (0.3944)\taccuracy 89.062 (85.010)\tf1_score 84.832 (81.981)\n",
      "Epoch: [28][95/96]\tLoss 0.3680 (0.3967)\taccuracy 82.812 (84.880)\tf1_score 81.262 (81.869)\n",
      " Test: accuracy 80.469 f1_score 77.410\n",
      "Training time:  467.790301322937 Hour:  0 Minute:  7 Second:  47 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 29\n",
      "Epoch: [29][0/96]\tLoss 0.4682 (0.4682)\taccuracy 79.688 (79.688)\tf1_score 75.199 (75.199)\n",
      "Epoch: [29][5/96]\tLoss 0.2747 (0.3685)\taccuracy 87.500 (84.896)\tf1_score 87.245 (82.196)\n",
      "Epoch: [29][10/96]\tLoss 0.3374 (0.3415)\taccuracy 84.375 (85.511)\tf1_score 83.278 (82.477)\n",
      "Epoch: [29][15/96]\tLoss 0.2841 (0.3283)\taccuracy 89.062 (86.230)\tf1_score 84.033 (83.241)\n",
      "Epoch: [29][20/96]\tLoss 0.1930 (0.3198)\taccuracy 92.188 (86.682)\tf1_score 86.823 (83.837)\n",
      "Epoch: [29][25/96]\tLoss 0.4607 (0.3255)\taccuracy 81.250 (87.200)\tf1_score 78.089 (84.501)\n",
      "Epoch: [29][30/96]\tLoss 0.3043 (0.3256)\taccuracy 89.062 (87.500)\tf1_score 84.460 (84.742)\n",
      "Epoch: [29][35/96]\tLoss 0.3819 (0.3236)\taccuracy 84.375 (87.500)\tf1_score 82.392 (84.679)\n",
      "Epoch: [29][40/96]\tLoss 0.4110 (0.3244)\taccuracy 82.812 (87.500)\tf1_score 75.352 (84.558)\n",
      "Epoch: [29][45/96]\tLoss 0.3716 (0.3308)\taccuracy 87.500 (87.364)\tf1_score 73.042 (84.192)\n",
      "Epoch: [29][50/96]\tLoss 0.1739 (0.3243)\taccuracy 93.750 (87.623)\tf1_score 89.760 (84.532)\n",
      "Epoch: [29][55/96]\tLoss 0.4304 (0.3310)\taccuracy 81.250 (87.249)\tf1_score 75.187 (84.022)\n",
      "Epoch: [29][60/96]\tLoss 0.3320 (0.3344)\taccuracy 84.375 (87.167)\tf1_score 84.966 (83.934)\n",
      "Epoch: [29][65/96]\tLoss 0.3416 (0.3355)\taccuracy 84.375 (87.027)\tf1_score 84.200 (83.939)\n",
      "Epoch: [29][70/96]\tLoss 0.5702 (0.3397)\taccuracy 73.438 (86.664)\tf1_score 71.817 (83.660)\n",
      "Epoch: [29][75/96]\tLoss 0.4234 (0.3418)\taccuracy 85.938 (86.554)\tf1_score 81.317 (83.639)\n",
      "Epoch: [29][80/96]\tLoss 0.3451 (0.3437)\taccuracy 84.375 (86.285)\tf1_score 81.556 (83.321)\n",
      "Epoch: [29][85/96]\tLoss 0.2245 (0.3424)\taccuracy 93.750 (86.283)\tf1_score 92.880 (83.357)\n",
      "Epoch: [29][90/96]\tLoss 0.3821 (0.3446)\taccuracy 82.812 (86.144)\tf1_score 82.775 (83.190)\n",
      "Epoch: [29][95/96]\tLoss 0.2268 (0.3419)\taccuracy 90.625 (86.230)\tf1_score 89.738 (83.263)\n",
      " Test: accuracy 65.560 f1_score 60.231\n",
      "Training time:  483.50682616233826 Hour:  0 Minute:  8 Second:  3 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 30\n",
      "Epoch: [30][0/96]\tLoss 0.4321 (0.4321)\taccuracy 84.375 (84.375)\tf1_score 78.444 (78.444)\n",
      "Epoch: [30][5/96]\tLoss 0.2576 (0.3375)\taccuracy 89.062 (86.458)\tf1_score 83.728 (83.604)\n",
      "Epoch: [30][10/96]\tLoss 0.3361 (0.3709)\taccuracy 90.625 (85.369)\tf1_score 89.422 (82.792)\n",
      "Epoch: [30][15/96]\tLoss 0.3508 (0.3508)\taccuracy 82.812 (86.523)\tf1_score 82.492 (84.090)\n",
      "Epoch: [30][20/96]\tLoss 0.4203 (0.3464)\taccuracy 81.250 (86.533)\tf1_score 82.881 (84.536)\n",
      "Epoch: [30][25/96]\tLoss 0.2845 (0.3449)\taccuracy 85.938 (86.599)\tf1_score 83.889 (84.680)\n",
      "Epoch: [30][30/96]\tLoss 0.7064 (0.3473)\taccuracy 73.438 (86.492)\tf1_score 75.063 (84.588)\n",
      "Epoch: [30][35/96]\tLoss 0.2280 (0.3494)\taccuracy 93.750 (86.372)\tf1_score 89.404 (84.433)\n",
      "Epoch: [30][40/96]\tLoss 0.3092 (0.3527)\taccuracy 87.500 (86.319)\tf1_score 87.454 (84.252)\n",
      "Epoch: [30][45/96]\tLoss 0.5145 (0.3551)\taccuracy 70.312 (85.971)\tf1_score 69.325 (83.849)\n",
      "Epoch: [30][50/96]\tLoss 0.2946 (0.3475)\taccuracy 89.062 (86.428)\tf1_score 84.860 (84.315)\n",
      "Epoch: [30][55/96]\tLoss 0.5050 (0.3566)\taccuracy 84.375 (86.217)\tf1_score 79.344 (84.004)\n",
      "Epoch: [30][60/96]\tLoss 0.3175 (0.3606)\taccuracy 89.062 (86.014)\tf1_score 90.606 (83.754)\n",
      "Epoch: [30][65/96]\tLoss 0.3341 (0.3605)\taccuracy 89.062 (86.032)\tf1_score 83.795 (83.641)\n",
      "Epoch: [30][70/96]\tLoss 0.2879 (0.3628)\taccuracy 93.750 (86.004)\tf1_score 91.754 (83.500)\n",
      "Epoch: [30][75/96]\tLoss 0.4562 (0.3654)\taccuracy 78.125 (85.896)\tf1_score 76.524 (83.410)\n",
      "Epoch: [30][80/96]\tLoss 0.2303 (0.3650)\taccuracy 89.062 (85.899)\tf1_score 82.834 (83.382)\n",
      "Epoch: [30][85/96]\tLoss 0.2522 (0.3612)\taccuracy 87.500 (85.938)\tf1_score 81.689 (83.348)\n",
      "Epoch: [30][90/96]\tLoss 0.3535 (0.3595)\taccuracy 89.062 (86.041)\tf1_score 79.531 (83.402)\n",
      "Epoch: [30][95/96]\tLoss 0.3973 (0.3650)\taccuracy 84.375 (85.889)\tf1_score 82.778 (83.239)\n",
      " Test: accuracy 66.536 f1_score 60.730\n",
      "Training time:  499.15175795555115 Hour:  0 Minute:  8 Second:  19 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 31\n",
      "Epoch: [31][0/96]\tLoss 0.2750 (0.2750)\taccuracy 89.062 (89.062)\tf1_score 89.307 (89.307)\n",
      "Epoch: [31][5/96]\tLoss 0.3269 (0.3208)\taccuracy 84.375 (86.979)\tf1_score 80.869 (84.579)\n",
      "Epoch: [31][10/96]\tLoss 0.5116 (0.3427)\taccuracy 75.000 (85.085)\tf1_score 78.231 (82.540)\n",
      "Epoch: [31][15/96]\tLoss 0.2323 (0.3291)\taccuracy 90.625 (86.133)\tf1_score 87.283 (83.231)\n",
      "Epoch: [31][20/96]\tLoss 0.2219 (0.3350)\taccuracy 90.625 (85.863)\tf1_score 84.970 (82.126)\n",
      "Epoch: [31][25/96]\tLoss 0.3640 (0.3381)\taccuracy 79.688 (85.517)\tf1_score 77.249 (81.441)\n",
      "Epoch: [31][30/96]\tLoss 0.4256 (0.3356)\taccuracy 85.938 (85.736)\tf1_score 78.946 (81.933)\n",
      "Epoch: [31][35/96]\tLoss 0.3860 (0.3498)\taccuracy 85.938 (85.243)\tf1_score 89.145 (81.809)\n",
      "Epoch: [31][40/96]\tLoss 0.4202 (0.3524)\taccuracy 79.688 (85.290)\tf1_score 68.904 (81.890)\n",
      "Epoch: [31][45/96]\tLoss 0.3617 (0.3515)\taccuracy 84.375 (85.224)\tf1_score 86.971 (82.202)\n",
      "Epoch: [31][50/96]\tLoss 0.4045 (0.3496)\taccuracy 84.375 (85.355)\tf1_score 76.098 (82.337)\n",
      "Epoch: [31][55/96]\tLoss 0.4922 (0.3501)\taccuracy 81.250 (85.547)\tf1_score 76.010 (82.449)\n",
      "Epoch: [31][60/96]\tLoss 0.4070 (0.3482)\taccuracy 82.812 (85.605)\tf1_score 81.536 (82.473)\n",
      "Epoch: [31][65/96]\tLoss 0.3143 (0.3655)\taccuracy 89.062 (85.346)\tf1_score 84.981 (82.387)\n",
      "Epoch: [31][70/96]\tLoss 0.2730 (0.3650)\taccuracy 87.500 (85.453)\tf1_score 84.104 (82.496)\n",
      "Epoch: [31][75/96]\tLoss 0.4195 (0.3668)\taccuracy 84.375 (85.382)\tf1_score 82.071 (82.385)\n",
      "Epoch: [31][80/96]\tLoss 0.2480 (0.3636)\taccuracy 95.312 (85.610)\tf1_score 94.082 (82.638)\n",
      "Epoch: [31][85/96]\tLoss 0.6040 (0.3692)\taccuracy 76.562 (85.483)\tf1_score 73.440 (82.362)\n",
      "Epoch: [31][90/96]\tLoss 0.5453 (0.3712)\taccuracy 79.688 (85.440)\tf1_score 79.339 (82.424)\n",
      "Epoch: [31][95/96]\tLoss 0.3514 (0.3739)\taccuracy 82.812 (85.335)\tf1_score 77.398 (82.286)\n",
      " Test: accuracy 78.711 f1_score 74.437\n",
      "Training time:  514.7714145183563 Hour:  0 Minute:  8 Second:  34 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 32\n",
      "Epoch: [32][0/96]\tLoss 0.3148 (0.3148)\taccuracy 87.500 (87.500)\tf1_score 84.411 (84.411)\n",
      "Epoch: [32][5/96]\tLoss 0.3814 (0.3905)\taccuracy 89.062 (86.458)\tf1_score 82.438 (80.673)\n",
      "Epoch: [32][10/96]\tLoss 0.5314 (0.3967)\taccuracy 76.562 (85.511)\tf1_score 72.207 (81.126)\n",
      "Epoch: [32][15/96]\tLoss 0.2959 (0.4029)\taccuracy 85.938 (84.863)\tf1_score 81.048 (80.797)\n",
      "Epoch: [32][20/96]\tLoss 0.3693 (0.4072)\taccuracy 89.062 (84.747)\tf1_score 89.782 (80.758)\n",
      "Epoch: [32][25/96]\tLoss 0.4167 (0.4050)\taccuracy 79.688 (84.315)\tf1_score 70.011 (80.580)\n",
      "Epoch: [32][30/96]\tLoss 0.3917 (0.3976)\taccuracy 84.375 (84.325)\tf1_score 76.321 (80.682)\n",
      "Epoch: [32][35/96]\tLoss 0.2614 (0.3876)\taccuracy 89.062 (84.679)\tf1_score 89.206 (81.426)\n",
      "Epoch: [32][40/96]\tLoss 0.2404 (0.3879)\taccuracy 92.188 (84.947)\tf1_score 92.396 (81.962)\n",
      "Epoch: [32][45/96]\tLoss 0.3336 (0.4015)\taccuracy 87.500 (84.613)\tf1_score 85.869 (81.766)\n",
      "Epoch: [32][50/96]\tLoss 0.3085 (0.3987)\taccuracy 89.062 (84.559)\tf1_score 84.099 (81.633)\n",
      "Epoch: [32][55/96]\tLoss 0.6768 (0.4045)\taccuracy 79.688 (84.598)\tf1_score 71.045 (81.446)\n",
      "Epoch: [32][60/96]\tLoss 0.3596 (0.4113)\taccuracy 87.500 (84.477)\tf1_score 82.061 (81.220)\n",
      "Epoch: [32][65/96]\tLoss 0.5194 (0.4084)\taccuracy 84.375 (84.588)\tf1_score 82.643 (81.496)\n",
      "Epoch: [32][70/96]\tLoss 0.4556 (0.4039)\taccuracy 78.125 (84.749)\tf1_score 75.643 (81.707)\n",
      "Epoch: [32][75/96]\tLoss 0.4166 (0.3990)\taccuracy 84.375 (84.951)\tf1_score 80.786 (81.951)\n",
      "Epoch: [32][80/96]\tLoss 0.2809 (0.3900)\taccuracy 92.188 (85.378)\tf1_score 87.052 (82.264)\n",
      "Epoch: [32][85/96]\tLoss 0.3454 (0.3860)\taccuracy 85.938 (85.501)\tf1_score 83.865 (82.517)\n",
      "Epoch: [32][90/96]\tLoss 0.2866 (0.3815)\taccuracy 90.625 (85.663)\tf1_score 91.823 (82.755)\n",
      "Epoch: [32][95/96]\tLoss 0.4480 (0.3827)\taccuracy 79.688 (85.465)\tf1_score 80.048 (82.719)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test: accuracy 70.898 f1_score 67.476\n",
      "Training time:  530.440648317337 Hour:  0 Minute:  8 Second:  50 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 33\n",
      "Epoch: [33][0/96]\tLoss 0.3158 (0.3158)\taccuracy 82.812 (82.812)\tf1_score 82.465 (82.465)\n",
      "Epoch: [33][5/96]\tLoss 0.2673 (0.3596)\taccuracy 90.625 (84.896)\tf1_score 90.000 (84.680)\n",
      "Epoch: [33][10/96]\tLoss 0.4831 (0.3695)\taccuracy 76.562 (83.949)\tf1_score 76.277 (83.245)\n",
      "Epoch: [33][15/96]\tLoss 0.2863 (0.3759)\taccuracy 92.188 (84.375)\tf1_score 91.274 (82.790)\n",
      "Epoch: [33][20/96]\tLoss 0.6176 (0.3674)\taccuracy 81.250 (85.193)\tf1_score 76.485 (83.285)\n",
      "Epoch: [33][25/96]\tLoss 0.2026 (0.3521)\taccuracy 93.750 (85.757)\tf1_score 91.952 (83.567)\n",
      "Epoch: [33][30/96]\tLoss 0.2382 (0.3372)\taccuracy 92.188 (86.492)\tf1_score 92.184 (84.332)\n",
      "Epoch: [33][35/96]\tLoss 0.3505 (0.3355)\taccuracy 84.375 (86.892)\tf1_score 83.175 (84.540)\n",
      "Epoch: [33][40/96]\tLoss 0.2496 (0.3336)\taccuracy 90.625 (86.966)\tf1_score 86.489 (84.756)\n",
      "Epoch: [33][45/96]\tLoss 0.2414 (0.3294)\taccuracy 90.625 (86.923)\tf1_score 85.178 (84.553)\n",
      "Epoch: [33][50/96]\tLoss 0.5019 (0.3327)\taccuracy 87.500 (86.979)\tf1_score 86.730 (84.722)\n",
      "Epoch: [33][55/96]\tLoss 0.3382 (0.3265)\taccuracy 84.375 (87.193)\tf1_score 74.981 (84.807)\n",
      "Epoch: [33][60/96]\tLoss 0.4133 (0.3263)\taccuracy 87.500 (87.295)\tf1_score 88.329 (84.764)\n",
      "Epoch: [33][65/96]\tLoss 0.1585 (0.3207)\taccuracy 95.312 (87.500)\tf1_score 86.349 (84.865)\n",
      "Epoch: [33][70/96]\tLoss 0.4589 (0.3244)\taccuracy 81.250 (87.324)\tf1_score 82.155 (84.625)\n",
      "Epoch: [33][75/96]\tLoss 0.4264 (0.3242)\taccuracy 82.812 (87.274)\tf1_score 80.775 (84.528)\n",
      "Epoch: [33][80/96]\tLoss 0.3734 (0.3270)\taccuracy 81.250 (87.114)\tf1_score 82.348 (84.393)\n",
      "Epoch: [33][85/96]\tLoss 0.4246 (0.3299)\taccuracy 84.375 (87.009)\tf1_score 84.467 (84.264)\n",
      "Epoch: [33][90/96]\tLoss 0.4012 (0.3344)\taccuracy 79.688 (86.848)\tf1_score 81.075 (84.128)\n",
      "Epoch: [33][95/96]\tLoss 0.5359 (0.3425)\taccuracy 78.125 (86.458)\tf1_score 75.569 (83.698)\n",
      " Test: accuracy 54.883 f1_score 46.568\n",
      "Training time:  546.0763046741486 Hour:  0 Minute:  9 Second:  6 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 34\n",
      "Epoch: [34][0/96]\tLoss 0.2365 (0.2365)\taccuracy 93.750 (93.750)\tf1_score 92.643 (92.643)\n",
      "Epoch: [34][5/96]\tLoss 0.5112 (0.3963)\taccuracy 84.375 (85.417)\tf1_score 68.220 (81.563)\n",
      "Epoch: [34][10/96]\tLoss 0.6249 (0.3926)\taccuracy 75.000 (85.085)\tf1_score 70.550 (81.005)\n",
      "Epoch: [34][15/96]\tLoss 0.3385 (0.3600)\taccuracy 84.375 (86.035)\tf1_score 73.430 (81.470)\n",
      "Epoch: [34][20/96]\tLoss 0.2928 (0.3556)\taccuracy 89.062 (86.086)\tf1_score 87.632 (81.765)\n",
      "Epoch: [34][25/96]\tLoss 0.3361 (0.3548)\taccuracy 87.500 (85.998)\tf1_score 85.976 (82.127)\n",
      "Epoch: [34][30/96]\tLoss 0.3949 (0.3506)\taccuracy 85.938 (86.240)\tf1_score 79.998 (82.337)\n",
      "Epoch: [34][35/96]\tLoss 0.3427 (0.3458)\taccuracy 81.250 (86.285)\tf1_score 77.430 (82.841)\n",
      "Epoch: [34][40/96]\tLoss 0.2860 (0.3369)\taccuracy 90.625 (86.662)\tf1_score 89.647 (83.295)\n",
      "Epoch: [34][45/96]\tLoss 0.2549 (0.3278)\taccuracy 87.500 (86.957)\tf1_score 80.361 (83.479)\n",
      "Epoch: [34][50/96]\tLoss 0.2886 (0.3248)\taccuracy 87.500 (87.224)\tf1_score 82.336 (83.816)\n",
      "Epoch: [34][55/96]\tLoss 0.3352 (0.3333)\taccuracy 85.938 (86.830)\tf1_score 85.486 (83.763)\n",
      "Epoch: [34][60/96]\tLoss 0.2421 (0.3278)\taccuracy 90.625 (86.936)\tf1_score 89.560 (83.760)\n",
      "Epoch: [34][65/96]\tLoss 0.2892 (0.3350)\taccuracy 84.375 (86.600)\tf1_score 76.353 (83.339)\n",
      "Epoch: [34][70/96]\tLoss 0.3979 (0.3395)\taccuracy 85.938 (86.554)\tf1_score 83.672 (83.256)\n",
      "Epoch: [34][75/96]\tLoss 0.2258 (0.3356)\taccuracy 90.625 (86.739)\tf1_score 87.111 (83.608)\n",
      "Epoch: [34][80/96]\tLoss 0.1929 (0.3327)\taccuracy 93.750 (86.941)\tf1_score 92.334 (83.983)\n",
      "Epoch: [34][85/96]\tLoss 0.4243 (0.3468)\taccuracy 79.688 (86.555)\tf1_score 77.211 (83.560)\n",
      "Epoch: [34][90/96]\tLoss 0.1943 (0.3472)\taccuracy 90.625 (86.590)\tf1_score 86.500 (83.598)\n",
      "Epoch: [34][95/96]\tLoss 0.4395 (0.3488)\taccuracy 82.812 (86.491)\tf1_score 78.057 (83.520)\n",
      " Test: accuracy 70.182 f1_score 63.137\n",
      "Training time:  561.8856554031372 Hour:  0 Minute:  9 Second:  21 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 35\n",
      "Epoch: [35][0/96]\tLoss 0.3085 (0.3085)\taccuracy 89.062 (89.062)\tf1_score 87.793 (87.793)\n",
      "Epoch: [35][5/96]\tLoss 0.4286 (0.3700)\taccuracy 82.812 (85.677)\tf1_score 77.863 (81.758)\n",
      "Epoch: [35][10/96]\tLoss 0.2231 (0.3528)\taccuracy 95.312 (87.216)\tf1_score 95.190 (83.505)\n",
      "Epoch: [35][15/96]\tLoss 0.3126 (0.3452)\taccuracy 89.062 (86.621)\tf1_score 82.326 (83.090)\n",
      "Epoch: [35][20/96]\tLoss 0.4828 (0.3758)\taccuracy 85.938 (85.789)\tf1_score 86.962 (82.229)\n",
      "Epoch: [35][25/96]\tLoss 0.3926 (0.3715)\taccuracy 85.938 (85.938)\tf1_score 85.394 (82.389)\n",
      "Epoch: [35][30/96]\tLoss 0.3062 (0.3667)\taccuracy 85.938 (86.190)\tf1_score 83.450 (82.605)\n",
      "Epoch: [35][35/96]\tLoss 0.4434 (0.3622)\taccuracy 81.250 (86.285)\tf1_score 77.009 (82.553)\n",
      "Epoch: [35][40/96]\tLoss 0.4774 (0.3590)\taccuracy 84.375 (86.509)\tf1_score 81.683 (82.844)\n",
      "Epoch: [35][45/96]\tLoss 0.4794 (0.3617)\taccuracy 82.812 (86.311)\tf1_score 78.155 (82.523)\n",
      "Epoch: [35][50/96]\tLoss 0.3682 (0.3551)\taccuracy 84.375 (86.642)\tf1_score 87.849 (83.213)\n",
      "Epoch: [35][55/96]\tLoss 0.4122 (0.3575)\taccuracy 79.688 (86.412)\tf1_score 69.597 (82.963)\n",
      "Epoch: [35][60/96]\tLoss 0.3940 (0.3566)\taccuracy 84.375 (86.501)\tf1_score 81.120 (83.192)\n",
      "Epoch: [35][65/96]\tLoss 0.2021 (0.3520)\taccuracy 92.188 (86.600)\tf1_score 91.930 (83.411)\n",
      "Epoch: [35][70/96]\tLoss 0.2627 (0.3475)\taccuracy 90.625 (86.818)\tf1_score 87.081 (83.611)\n",
      "Epoch: [35][75/96]\tLoss 0.2025 (0.3442)\taccuracy 90.625 (86.822)\tf1_score 90.365 (83.580)\n",
      "Epoch: [35][80/96]\tLoss 0.4020 (0.3478)\taccuracy 82.812 (86.593)\tf1_score 76.708 (83.324)\n",
      "Epoch: [35][85/96]\tLoss 0.3271 (0.3457)\taccuracy 85.938 (86.592)\tf1_score 86.405 (83.309)\n",
      "Epoch: [35][90/96]\tLoss 0.4086 (0.3474)\taccuracy 79.688 (86.435)\tf1_score 82.245 (83.109)\n",
      "Epoch: [35][95/96]\tLoss 0.3086 (0.3474)\taccuracy 90.625 (86.507)\tf1_score 90.837 (83.124)\n",
      " Test: accuracy 74.089 f1_score 70.119\n",
      "Training time:  577.6098310947418 Hour:  0 Minute:  9 Second:  37 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 36\n",
      "Epoch: [36][0/96]\tLoss 0.3893 (0.3893)\taccuracy 81.250 (81.250)\tf1_score 73.345 (73.345)\n",
      "Epoch: [36][5/96]\tLoss 0.2788 (0.3010)\taccuracy 90.625 (87.500)\tf1_score 90.924 (83.218)\n",
      "Epoch: [36][10/96]\tLoss 0.2864 (0.3138)\taccuracy 87.500 (86.648)\tf1_score 84.617 (83.207)\n",
      "Epoch: [36][15/96]\tLoss 0.3421 (0.3152)\taccuracy 85.938 (86.816)\tf1_score 83.399 (83.214)\n",
      "Epoch: [36][20/96]\tLoss 0.2961 (0.3340)\taccuracy 89.062 (86.756)\tf1_score 88.996 (83.604)\n",
      "Epoch: [36][25/96]\tLoss 0.3005 (0.3268)\taccuracy 90.625 (87.380)\tf1_score 82.670 (83.664)\n",
      "Epoch: [36][30/96]\tLoss 0.1890 (0.3129)\taccuracy 95.312 (88.206)\tf1_score 94.233 (84.627)\n",
      "Epoch: [36][35/96]\tLoss 0.1515 (0.3014)\taccuracy 93.750 (88.845)\tf1_score 93.810 (85.242)\n",
      "Epoch: [36][40/96]\tLoss 0.2441 (0.2961)\taccuracy 90.625 (88.872)\tf1_score 80.554 (85.515)\n",
      "Epoch: [36][45/96]\tLoss 0.3341 (0.2854)\taccuracy 90.625 (89.368)\tf1_score 89.762 (86.058)\n",
      "Epoch: [36][50/96]\tLoss 0.3473 (0.2871)\taccuracy 85.938 (89.216)\tf1_score 74.817 (85.866)\n",
      "Epoch: [36][55/96]\tLoss 0.2289 (0.2853)\taccuracy 90.625 (89.286)\tf1_score 91.263 (86.022)\n",
      "Epoch: [36][60/96]\tLoss 0.2903 (0.2866)\taccuracy 85.938 (89.139)\tf1_score 87.577 (86.166)\n",
      "Epoch: [36][65/96]\tLoss 0.2802 (0.2874)\taccuracy 89.062 (89.086)\tf1_score 88.321 (86.219)\n",
      "Epoch: [36][70/96]\tLoss 0.2545 (0.2850)\taccuracy 89.062 (89.217)\tf1_score 86.955 (86.458)\n",
      "Epoch: [36][75/96]\tLoss 0.2710 (0.2819)\taccuracy 87.500 (89.227)\tf1_score 84.670 (86.311)\n",
      "Epoch: [36][80/96]\tLoss 0.3663 (0.2849)\taccuracy 84.375 (89.024)\tf1_score 85.758 (86.265)\n",
      "Epoch: [36][85/96]\tLoss 0.4664 (0.2867)\taccuracy 81.250 (88.953)\tf1_score 76.497 (86.234)\n",
      "Epoch: [36][90/96]\tLoss 0.4298 (0.2885)\taccuracy 81.250 (88.822)\tf1_score 79.041 (85.951)\n",
      "Epoch: [36][95/96]\tLoss 0.2595 (0.2883)\taccuracy 90.625 (88.802)\tf1_score 87.672 (85.925)\n",
      " Test: accuracy 79.883 f1_score 77.265\n",
      "Training time:  593.3311376571655 Hour:  0 Minute:  9 Second:  53 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 37\n",
      "Epoch: [37][0/96]\tLoss 0.2059 (0.2059)\taccuracy 92.188 (92.188)\tf1_score 86.799 (86.799)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37][5/96]\tLoss 0.2155 (0.3273)\taccuracy 90.625 (85.417)\tf1_score 90.079 (81.894)\n",
      "Epoch: [37][10/96]\tLoss 0.3762 (0.3217)\taccuracy 82.812 (86.364)\tf1_score 81.100 (83.300)\n",
      "Epoch: [37][15/96]\tLoss 0.2395 (0.2890)\taccuracy 90.625 (88.379)\tf1_score 90.646 (85.720)\n",
      "Epoch: [37][20/96]\tLoss 0.3997 (0.2917)\taccuracy 85.938 (88.616)\tf1_score 83.216 (85.820)\n",
      "Epoch: [37][25/96]\tLoss 0.2451 (0.3012)\taccuracy 90.625 (88.702)\tf1_score 91.861 (86.050)\n",
      "Epoch: [37][30/96]\tLoss 0.2900 (0.3007)\taccuracy 92.188 (88.609)\tf1_score 90.702 (85.712)\n",
      "Epoch: [37][35/96]\tLoss 0.1772 (0.2903)\taccuracy 93.750 (89.062)\tf1_score 92.248 (86.187)\n",
      "Epoch: [37][40/96]\tLoss 0.5245 (0.2986)\taccuracy 76.562 (88.415)\tf1_score 77.450 (85.617)\n",
      "Epoch: [37][45/96]\tLoss 0.3148 (0.3004)\taccuracy 85.938 (88.383)\tf1_score 77.644 (85.329)\n",
      "Epoch: [37][50/96]\tLoss 0.5489 (0.3203)\taccuracy 82.812 (87.653)\tf1_score 77.453 (84.606)\n",
      "Epoch: [37][55/96]\tLoss 0.7670 (0.3315)\taccuracy 78.125 (87.360)\tf1_score 76.128 (84.421)\n",
      "Epoch: [37][60/96]\tLoss 0.3811 (0.3374)\taccuracy 85.938 (87.141)\tf1_score 84.964 (84.178)\n",
      "Epoch: [37][65/96]\tLoss 0.8321 (0.3445)\taccuracy 65.625 (86.766)\tf1_score 66.222 (83.828)\n",
      "Epoch: [37][70/96]\tLoss 0.4040 (0.3559)\taccuracy 84.375 (86.312)\tf1_score 85.537 (83.556)\n",
      "Epoch: [37][75/96]\tLoss 0.6132 (0.3683)\taccuracy 81.250 (85.938)\tf1_score 69.476 (83.038)\n",
      "Epoch: [37][80/96]\tLoss 0.4382 (0.3674)\taccuracy 81.250 (85.860)\tf1_score 80.783 (83.079)\n",
      "Epoch: [37][85/96]\tLoss 0.3318 (0.3670)\taccuracy 84.375 (85.810)\tf1_score 84.762 (83.177)\n",
      "Epoch: [37][90/96]\tLoss 0.2902 (0.3650)\taccuracy 85.938 (85.886)\tf1_score 86.667 (83.348)\n",
      "Epoch: [37][95/96]\tLoss 0.2280 (0.3655)\taccuracy 90.625 (85.889)\tf1_score 88.156 (83.336)\n",
      " Test: accuracy 49.023 f1_score 43.466\n",
      "Training time:  608.9653489589691 Hour:  0 Minute:  10 Second:  8 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 38\n",
      "Epoch: [38][0/96]\tLoss 0.4955 (0.4955)\taccuracy 78.125 (78.125)\tf1_score 76.362 (76.362)\n",
      "Epoch: [38][5/96]\tLoss 0.4177 (0.3343)\taccuracy 82.812 (86.198)\tf1_score 77.298 (81.342)\n",
      "Epoch: [38][10/96]\tLoss 0.4403 (0.3776)\taccuracy 82.812 (85.227)\tf1_score 86.194 (81.480)\n",
      "Epoch: [38][15/96]\tLoss 0.3479 (0.3777)\taccuracy 85.938 (85.547)\tf1_score 83.243 (81.218)\n",
      "Epoch: [38][20/96]\tLoss 0.1552 (0.3711)\taccuracy 96.875 (85.640)\tf1_score 95.979 (81.878)\n",
      "Epoch: [38][25/96]\tLoss 0.3305 (0.3652)\taccuracy 87.500 (85.757)\tf1_score 82.698 (82.212)\n",
      "Epoch: [38][30/96]\tLoss 0.3519 (0.3523)\taccuracy 90.625 (86.341)\tf1_score 90.293 (82.556)\n",
      "Epoch: [38][35/96]\tLoss 0.3208 (0.3484)\taccuracy 89.062 (86.545)\tf1_score 85.072 (82.980)\n",
      "Epoch: [38][40/96]\tLoss 0.5236 (0.3605)\taccuracy 87.500 (86.319)\tf1_score 83.080 (82.575)\n",
      "Epoch: [38][45/96]\tLoss 0.4146 (0.3590)\taccuracy 78.125 (86.073)\tf1_score 79.501 (82.460)\n",
      "Epoch: [38][50/96]\tLoss 0.4664 (0.3597)\taccuracy 82.812 (86.121)\tf1_score 81.435 (82.517)\n",
      "Epoch: [38][55/96]\tLoss 0.3960 (0.3562)\taccuracy 84.375 (86.300)\tf1_score 82.440 (82.984)\n",
      "Epoch: [38][60/96]\tLoss 0.2382 (0.3496)\taccuracy 90.625 (86.629)\tf1_score 88.401 (83.455)\n",
      "Epoch: [38][65/96]\tLoss 0.3562 (0.3474)\taccuracy 84.375 (86.648)\tf1_score 80.837 (83.552)\n",
      "Epoch: [38][70/96]\tLoss 0.4047 (0.3563)\taccuracy 84.375 (86.378)\tf1_score 85.926 (83.217)\n",
      "Epoch: [38][75/96]\tLoss 0.3362 (0.3588)\taccuracy 87.500 (86.205)\tf1_score 82.214 (83.028)\n",
      "Epoch: [38][80/96]\tLoss 0.3715 (0.3614)\taccuracy 89.062 (86.092)\tf1_score 91.340 (83.056)\n",
      "Epoch: [38][85/96]\tLoss 0.2653 (0.3601)\taccuracy 90.625 (86.265)\tf1_score 89.676 (83.301)\n",
      "Epoch: [38][90/96]\tLoss 0.3311 (0.3607)\taccuracy 87.500 (86.229)\tf1_score 74.116 (83.098)\n",
      "Epoch: [38][95/96]\tLoss 0.2521 (0.3617)\taccuracy 93.750 (86.133)\tf1_score 93.995 (83.095)\n",
      " Test: accuracy 68.490 f1_score 60.760\n",
      "Training time:  624.632331609726 Hour:  0 Minute:  10 Second:  24 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 39\n",
      "Epoch: [39][0/96]\tLoss 0.3440 (0.3440)\taccuracy 84.375 (84.375)\tf1_score 82.013 (82.013)\n",
      "Epoch: [39][5/96]\tLoss 0.4007 (0.3660)\taccuracy 84.375 (85.677)\tf1_score 77.717 (81.598)\n",
      "Epoch: [39][10/96]\tLoss 0.3873 (0.3672)\taccuracy 89.062 (86.222)\tf1_score 92.250 (83.807)\n",
      "Epoch: [39][15/96]\tLoss 0.3692 (0.3606)\taccuracy 89.062 (86.035)\tf1_score 81.179 (83.550)\n",
      "Epoch: [39][20/96]\tLoss 0.4171 (0.3548)\taccuracy 81.250 (86.384)\tf1_score 80.138 (83.875)\n",
      "Epoch: [39][25/96]\tLoss 0.2238 (0.3340)\taccuracy 90.625 (87.079)\tf1_score 91.383 (84.539)\n",
      "Epoch: [39][30/96]\tLoss 0.2319 (0.3274)\taccuracy 90.625 (87.349)\tf1_score 91.165 (84.857)\n",
      "Epoch: [39][35/96]\tLoss 0.3097 (0.3176)\taccuracy 89.062 (87.804)\tf1_score 85.411 (85.443)\n",
      "Epoch: [39][40/96]\tLoss 0.2942 (0.3153)\taccuracy 90.625 (88.110)\tf1_score 86.897 (85.561)\n",
      "Epoch: [39][45/96]\tLoss 0.1451 (0.3081)\taccuracy 93.750 (88.349)\tf1_score 93.058 (85.898)\n",
      "Epoch: [39][50/96]\tLoss 0.1930 (0.3028)\taccuracy 92.188 (88.480)\tf1_score 89.825 (86.106)\n",
      "Epoch: [39][55/96]\tLoss 0.3198 (0.3035)\taccuracy 85.938 (88.532)\tf1_score 86.787 (86.076)\n",
      "Epoch: [39][60/96]\tLoss 0.3112 (0.2999)\taccuracy 84.375 (88.627)\tf1_score 80.493 (86.041)\n",
      "Epoch: [39][65/96]\tLoss 0.2754 (0.2949)\taccuracy 92.188 (88.849)\tf1_score 92.595 (86.344)\n",
      "Epoch: [39][70/96]\tLoss 0.2022 (0.2880)\taccuracy 95.312 (89.151)\tf1_score 94.186 (86.699)\n",
      "Epoch: [39][75/96]\tLoss 0.2044 (0.2903)\taccuracy 90.625 (89.124)\tf1_score 89.800 (86.662)\n",
      "Epoch: [39][80/96]\tLoss 0.2284 (0.2910)\taccuracy 92.188 (89.062)\tf1_score 93.039 (86.635)\n",
      "Epoch: [39][85/96]\tLoss 0.3036 (0.2906)\taccuracy 89.062 (89.044)\tf1_score 83.853 (86.608)\n",
      "Epoch: [39][90/96]\tLoss 0.3438 (0.2946)\taccuracy 85.938 (88.788)\tf1_score 89.244 (86.429)\n",
      "Epoch: [39][95/96]\tLoss 0.4787 (0.2971)\taccuracy 78.125 (88.672)\tf1_score 78.695 (86.358)\n",
      " Test: accuracy 69.922 f1_score 65.505\n",
      "Training time:  640.3636600971222 Hour:  0 Minute:  10 Second:  40 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 40\n",
      "Epoch: [40][0/96]\tLoss 0.2068 (0.2068)\taccuracy 92.188 (92.188)\tf1_score 91.949 (91.949)\n",
      "Epoch: [40][5/96]\tLoss 0.1527 (0.3174)\taccuracy 93.750 (88.542)\tf1_score 93.707 (87.375)\n",
      "Epoch: [40][10/96]\tLoss 0.3813 (0.3352)\taccuracy 84.375 (87.500)\tf1_score 76.732 (85.125)\n",
      "Epoch: [40][15/96]\tLoss 0.4331 (0.3478)\taccuracy 79.688 (86.426)\tf1_score 79.862 (84.146)\n",
      "Epoch: [40][20/96]\tLoss 0.4400 (0.3521)\taccuracy 78.125 (85.863)\tf1_score 73.537 (83.497)\n",
      "Epoch: [40][25/96]\tLoss 0.1904 (0.3309)\taccuracy 93.750 (86.779)\tf1_score 90.333 (84.484)\n",
      "Epoch: [40][30/96]\tLoss 0.3686 (0.3295)\taccuracy 84.375 (86.895)\tf1_score 81.556 (84.579)\n",
      "Epoch: [40][35/96]\tLoss 0.3083 (0.3342)\taccuracy 85.938 (86.762)\tf1_score 82.353 (84.256)\n",
      "Epoch: [40][40/96]\tLoss 0.4582 (0.3310)\taccuracy 81.250 (86.890)\tf1_score 83.333 (84.414)\n",
      "Epoch: [40][45/96]\tLoss 0.4410 (0.3278)\taccuracy 82.812 (86.957)\tf1_score 83.746 (84.634)\n",
      "Epoch: [40][50/96]\tLoss 0.2282 (0.3168)\taccuracy 89.062 (87.439)\tf1_score 84.571 (85.207)\n",
      "Epoch: [40][55/96]\tLoss 0.1614 (0.3115)\taccuracy 95.312 (87.612)\tf1_score 91.937 (85.254)\n",
      "Epoch: [40][60/96]\tLoss 0.5151 (0.3169)\taccuracy 81.250 (87.372)\tf1_score 72.045 (84.744)\n",
      "Epoch: [40][65/96]\tLoss 0.2693 (0.3152)\taccuracy 90.625 (87.547)\tf1_score 82.810 (84.809)\n",
      "Epoch: [40][70/96]\tLoss 0.2190 (0.3105)\taccuracy 90.625 (87.852)\tf1_score 87.687 (85.227)\n",
      "Epoch: [40][75/96]\tLoss 0.2428 (0.3066)\taccuracy 92.188 (87.952)\tf1_score 92.351 (85.426)\n",
      "Epoch: [40][80/96]\tLoss 0.2253 (0.3099)\taccuracy 90.625 (87.905)\tf1_score 87.283 (85.380)\n",
      "Epoch: [40][85/96]\tLoss 0.2836 (0.3135)\taccuracy 90.625 (87.754)\tf1_score 89.783 (85.230)\n",
      "Epoch: [40][90/96]\tLoss 0.1867 (0.3132)\taccuracy 95.312 (87.843)\tf1_score 95.083 (85.366)\n",
      "Epoch: [40][95/96]\tLoss 0.3306 (0.3128)\taccuracy 89.062 (87.891)\tf1_score 87.454 (85.494)\n",
      " Test: accuracy 60.482 f1_score 55.347\n",
      "Training time:  656.1170992851257 Hour:  0 Minute:  10 Second:  56 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 41\n",
      "Epoch: [41][0/96]\tLoss 0.3588 (0.3588)\taccuracy 85.938 (85.938)\tf1_score 86.282 (86.282)\n",
      "Epoch: [41][5/96]\tLoss 0.2073 (0.2834)\taccuracy 92.188 (90.104)\tf1_score 89.392 (86.815)\n",
      "Epoch: [41][10/96]\tLoss 0.5759 (0.3122)\taccuracy 78.125 (88.494)\tf1_score 75.177 (85.769)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41][15/96]\tLoss 0.3048 (0.2970)\taccuracy 85.938 (88.965)\tf1_score 84.804 (86.569)\n",
      "Epoch: [41][20/96]\tLoss 0.1671 (0.2775)\taccuracy 95.312 (89.658)\tf1_score 95.914 (87.459)\n",
      "Epoch: [41][25/96]\tLoss 0.3392 (0.2799)\taccuracy 87.500 (89.483)\tf1_score 88.810 (87.440)\n",
      "Epoch: [41][30/96]\tLoss 0.4378 (0.2810)\taccuracy 79.688 (89.365)\tf1_score 71.440 (86.909)\n",
      "Epoch: [41][35/96]\tLoss 0.3661 (0.2846)\taccuracy 90.625 (89.366)\tf1_score 90.356 (87.198)\n",
      "Epoch: [41][40/96]\tLoss 0.2007 (0.2896)\taccuracy 92.188 (89.291)\tf1_score 94.041 (87.457)\n",
      "Epoch: [41][45/96]\tLoss 0.1550 (0.2812)\taccuracy 96.875 (89.708)\tf1_score 91.451 (87.767)\n",
      "Epoch: [41][50/96]\tLoss 0.3887 (0.2882)\taccuracy 85.938 (89.308)\tf1_score 88.085 (87.406)\n",
      "Epoch: [41][55/96]\tLoss 0.3955 (0.2866)\taccuracy 79.688 (89.258)\tf1_score 76.468 (87.232)\n",
      "Epoch: [41][60/96]\tLoss 0.1897 (0.2900)\taccuracy 87.500 (89.088)\tf1_score 84.283 (86.849)\n",
      "Epoch: [41][65/96]\tLoss 0.4111 (0.2887)\taccuracy 85.938 (89.205)\tf1_score 76.835 (86.959)\n",
      "Epoch: [41][70/96]\tLoss 0.3638 (0.2887)\taccuracy 85.938 (89.107)\tf1_score 85.876 (86.848)\n",
      "Epoch: [41][75/96]\tLoss 0.3457 (0.2931)\taccuracy 87.500 (88.898)\tf1_score 87.397 (86.624)\n",
      "Epoch: [41][80/96]\tLoss 0.4104 (0.2927)\taccuracy 81.250 (88.908)\tf1_score 73.577 (86.632)\n",
      "Epoch: [41][85/96]\tLoss 0.3496 (0.2945)\taccuracy 85.938 (88.735)\tf1_score 83.473 (86.467)\n",
      "Epoch: [41][90/96]\tLoss 0.4924 (0.3009)\taccuracy 85.938 (88.462)\tf1_score 80.667 (86.084)\n",
      "Epoch: [41][95/96]\tLoss 0.3633 (0.3001)\taccuracy 84.375 (88.460)\tf1_score 72.336 (85.979)\n",
      " Test: accuracy 71.159 f1_score 65.472\n",
      "Training time:  671.9262194633484 Hour:  0 Minute:  11 Second:  11 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 42\n",
      "Epoch: [42][0/96]\tLoss 0.4330 (0.4330)\taccuracy 85.938 (85.938)\tf1_score 83.494 (83.494)\n",
      "Epoch: [42][5/96]\tLoss 0.1584 (0.2939)\taccuracy 93.750 (88.802)\tf1_score 94.210 (86.934)\n",
      "Epoch: [42][10/96]\tLoss 0.3877 (0.3155)\taccuracy 89.062 (88.636)\tf1_score 90.965 (87.589)\n",
      "Epoch: [42][15/96]\tLoss 0.2191 (0.2856)\taccuracy 92.188 (89.648)\tf1_score 91.056 (88.666)\n",
      "Epoch: [42][20/96]\tLoss 0.2633 (0.2896)\taccuracy 90.625 (89.211)\tf1_score 86.851 (88.020)\n",
      "Epoch: [42][25/96]\tLoss 0.6251 (0.3020)\taccuracy 76.562 (88.401)\tf1_score 72.360 (86.838)\n",
      "Epoch: [42][30/96]\tLoss 0.4362 (0.2946)\taccuracy 84.375 (88.609)\tf1_score 79.014 (86.995)\n",
      "Epoch: [42][35/96]\tLoss 0.2868 (0.2983)\taccuracy 85.938 (88.108)\tf1_score 82.756 (86.325)\n",
      "Epoch: [42][40/96]\tLoss 0.1295 (0.2926)\taccuracy 93.750 (88.377)\tf1_score 92.971 (86.543)\n",
      "Epoch: [42][45/96]\tLoss 0.2014 (0.2926)\taccuracy 95.312 (88.383)\tf1_score 89.998 (86.379)\n",
      "Epoch: [42][50/96]\tLoss 0.1975 (0.2832)\taccuracy 93.750 (88.848)\tf1_score 89.841 (86.662)\n",
      "Epoch: [42][55/96]\tLoss 0.5148 (0.2885)\taccuracy 84.375 (88.867)\tf1_score 80.223 (86.607)\n",
      "Epoch: [42][60/96]\tLoss 0.4194 (0.2870)\taccuracy 82.812 (88.986)\tf1_score 78.615 (86.843)\n",
      "Epoch: [42][65/96]\tLoss 0.4478 (0.2911)\taccuracy 76.562 (88.920)\tf1_score 71.816 (86.667)\n",
      "Epoch: [42][70/96]\tLoss 0.2201 (0.2894)\taccuracy 90.625 (88.952)\tf1_score 89.365 (86.686)\n",
      "Epoch: [42][75/96]\tLoss 0.1546 (0.2867)\taccuracy 93.750 (89.104)\tf1_score 92.275 (86.835)\n",
      "Epoch: [42][80/96]\tLoss 0.3636 (0.2878)\taccuracy 87.500 (89.062)\tf1_score 89.202 (86.969)\n",
      "Epoch: [42][85/96]\tLoss 0.2753 (0.2894)\taccuracy 87.500 (88.863)\tf1_score 87.141 (86.782)\n",
      "Epoch: [42][90/96]\tLoss 0.2567 (0.2905)\taccuracy 93.750 (88.908)\tf1_score 89.571 (86.820)\n",
      "Epoch: [42][95/96]\tLoss 0.1911 (0.2890)\taccuracy 93.750 (88.981)\tf1_score 86.833 (86.716)\n",
      " Test: accuracy 74.740 f1_score 70.762\n",
      "Training time:  687.6513779163361 Hour:  0 Minute:  11 Second:  27 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 43\n",
      "Epoch: [43][0/96]\tLoss 0.4108 (0.4108)\taccuracy 82.812 (82.812)\tf1_score 83.822 (83.822)\n",
      "Epoch: [43][5/96]\tLoss 0.1670 (0.2645)\taccuracy 92.188 (88.281)\tf1_score 87.574 (86.723)\n",
      "Epoch: [43][10/96]\tLoss 0.1574 (0.2791)\taccuracy 95.312 (88.636)\tf1_score 90.317 (86.645)\n",
      "Epoch: [43][15/96]\tLoss 0.1952 (0.2965)\taccuracy 92.188 (87.988)\tf1_score 92.608 (86.399)\n",
      "Epoch: [43][20/96]\tLoss 0.2158 (0.2718)\taccuracy 89.062 (89.137)\tf1_score 88.450 (87.680)\n",
      "Epoch: [43][25/96]\tLoss 0.2744 (0.2767)\taccuracy 89.062 (88.882)\tf1_score 81.200 (86.982)\n",
      "Epoch: [43][30/96]\tLoss 0.3329 (0.2783)\taccuracy 81.250 (88.407)\tf1_score 79.813 (86.380)\n",
      "Epoch: [43][35/96]\tLoss 0.3948 (0.2783)\taccuracy 82.812 (88.411)\tf1_score 81.986 (86.405)\n",
      "Epoch: [43][40/96]\tLoss 0.2372 (0.2753)\taccuracy 85.938 (88.605)\tf1_score 84.410 (86.786)\n",
      "Epoch: [43][45/96]\tLoss 0.2022 (0.2911)\taccuracy 93.750 (88.179)\tf1_score 93.690 (86.532)\n",
      "Epoch: [43][50/96]\tLoss 0.2253 (0.2957)\taccuracy 87.500 (88.113)\tf1_score 80.930 (86.449)\n",
      "Epoch: [43][55/96]\tLoss 0.2881 (0.2947)\taccuracy 89.062 (88.058)\tf1_score 88.651 (86.555)\n",
      "Epoch: [43][60/96]\tLoss 0.3210 (0.2915)\taccuracy 85.938 (88.192)\tf1_score 87.028 (86.812)\n",
      "Epoch: [43][65/96]\tLoss 0.1794 (0.2874)\taccuracy 92.188 (88.329)\tf1_score 89.240 (86.948)\n",
      "Epoch: [43][70/96]\tLoss 0.3963 (0.2881)\taccuracy 85.938 (88.248)\tf1_score 86.714 (86.849)\n",
      "Epoch: [43][75/96]\tLoss 0.5017 (0.2910)\taccuracy 81.250 (88.076)\tf1_score 81.923 (86.580)\n",
      "Epoch: [43][80/96]\tLoss 0.2975 (0.2930)\taccuracy 89.062 (87.982)\tf1_score 89.302 (86.592)\n",
      "Epoch: [43][85/96]\tLoss 0.3033 (0.2944)\taccuracy 87.500 (87.972)\tf1_score 87.381 (86.481)\n",
      "Epoch: [43][90/96]\tLoss 0.2082 (0.2890)\taccuracy 92.188 (88.255)\tf1_score 88.156 (86.719)\n",
      "Epoch: [43][95/96]\tLoss 0.2696 (0.2857)\taccuracy 92.188 (88.428)\tf1_score 92.812 (86.839)\n",
      " Test: accuracy 80.013 f1_score 76.774\n",
      "Training time:  703.5511558055878 Hour:  0 Minute:  11 Second:  43 Test best accuracy: 84.70052083333333  Test best f1 score: 82.28367410083418\n",
      "\n",
      "Start of epoch NO: 44\n",
      "Epoch: [44][0/96]\tLoss 0.3254 (0.3254)\taccuracy 89.062 (89.062)\tf1_score 85.799 (85.799)\n",
      "Epoch: [44][5/96]\tLoss 0.3150 (0.3019)\taccuracy 90.625 (89.844)\tf1_score 89.087 (86.596)\n",
      "Epoch: [44][10/96]\tLoss 0.2638 (0.2759)\taccuracy 93.750 (90.341)\tf1_score 85.633 (86.691)\n",
      "Epoch: [44][15/96]\tLoss 0.1884 (0.2770)\taccuracy 92.188 (89.941)\tf1_score 92.119 (86.994)\n",
      "Epoch: [44][20/96]\tLoss 0.1657 (0.2653)\taccuracy 95.312 (90.179)\tf1_score 95.714 (87.426)\n",
      "Epoch: [44][25/96]\tLoss 0.4261 (0.2836)\taccuracy 79.688 (89.363)\tf1_score 75.473 (86.520)\n",
      "Epoch: [44][30/96]\tLoss 0.5471 (0.2972)\taccuracy 73.438 (88.407)\tf1_score 72.600 (85.735)\n",
      "Epoch: [44][35/96]\tLoss 0.2339 (0.2941)\taccuracy 90.625 (88.542)\tf1_score 91.077 (86.070)\n",
      "Epoch: [44][40/96]\tLoss 0.2756 (0.2912)\taccuracy 90.625 (88.453)\tf1_score 81.859 (86.088)\n",
      "Epoch: [44][45/96]\tLoss 0.3122 (0.2869)\taccuracy 87.500 (88.689)\tf1_score 84.788 (86.373)\n",
      "Epoch: [44][50/96]\tLoss 0.2739 (0.2830)\taccuracy 85.938 (88.787)\tf1_score 76.542 (86.078)\n",
      "Epoch: [44][55/96]\tLoss 0.3242 (0.2846)\taccuracy 89.062 (88.783)\tf1_score 89.079 (86.200)\n",
      "Epoch: [44][60/96]\tLoss 0.8431 (0.2952)\taccuracy 70.312 (88.576)\tf1_score 69.723 (85.872)\n",
      "Epoch: [44][65/96]\tLoss 0.3267 (0.2991)\taccuracy 89.062 (88.447)\tf1_score 89.570 (85.729)\n",
      "Epoch: [44][70/96]\tLoss 0.3332 (0.3032)\taccuracy 85.938 (88.270)\tf1_score 77.295 (85.519)\n",
      "Epoch: [44][75/96]\tLoss 0.2601 (0.3054)\taccuracy 90.625 (88.240)\tf1_score 93.450 (85.506)\n",
      "Epoch: [44][80/96]\tLoss 0.2172 (0.3043)\taccuracy 93.750 (88.272)\tf1_score 86.984 (85.440)\n",
      "Epoch: [44][85/96]\tLoss 0.2838 (0.3076)\taccuracy 87.500 (88.081)\tf1_score 85.873 (85.184)\n",
      "Epoch: [44][90/96]\tLoss 0.3291 (0.3055)\taccuracy 87.500 (88.152)\tf1_score 86.178 (85.337)\n",
      "Epoch: [44][95/96]\tLoss 0.3856 (0.3037)\taccuracy 84.375 (88.200)\tf1_score 82.784 (85.378)\n",
      " Test: accuracy 88.411 f1_score 85.877\n",
      "Saving..\n",
      "Training time:  719.3246927261353 Hour:  0 Minute:  11 Second:  59 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 45\n",
      "Epoch: [45][0/96]\tLoss 0.2592 (0.2592)\taccuracy 90.625 (90.625)\tf1_score 85.270 (85.270)\n",
      "Epoch: [45][5/96]\tLoss 0.3152 (0.2622)\taccuracy 87.500 (89.844)\tf1_score 82.802 (86.845)\n",
      "Epoch: [45][10/96]\tLoss 0.1592 (0.2808)\taccuracy 93.750 (89.489)\tf1_score 89.197 (86.313)\n",
      "Epoch: [45][15/96]\tLoss 0.2460 (0.2867)\taccuracy 92.188 (89.160)\tf1_score 90.635 (86.737)\n",
      "Epoch: [45][20/96]\tLoss 0.2854 (0.2877)\taccuracy 90.625 (89.360)\tf1_score 82.445 (86.900)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45][25/96]\tLoss 0.2339 (0.2861)\taccuracy 90.625 (89.663)\tf1_score 90.690 (87.686)\n",
      "Epoch: [45][30/96]\tLoss 0.2639 (0.2904)\taccuracy 87.500 (89.214)\tf1_score 84.693 (87.245)\n",
      "Epoch: [45][35/96]\tLoss 0.2261 (0.2822)\taccuracy 89.062 (89.497)\tf1_score 89.424 (87.345)\n",
      "Epoch: [45][40/96]\tLoss 0.3087 (0.2811)\taccuracy 90.625 (89.520)\tf1_score 87.976 (87.377)\n",
      "Epoch: [45][45/96]\tLoss 0.3753 (0.2780)\taccuracy 84.375 (89.640)\tf1_score 80.599 (87.387)\n",
      "Epoch: [45][50/96]\tLoss 0.4235 (0.2834)\taccuracy 85.938 (89.461)\tf1_score 79.669 (86.935)\n",
      "Epoch: [45][55/96]\tLoss 0.3295 (0.2880)\taccuracy 85.938 (89.286)\tf1_score 83.323 (86.688)\n",
      "Epoch: [45][60/96]\tLoss 0.3828 (0.2920)\taccuracy 85.938 (89.037)\tf1_score 83.822 (86.407)\n",
      "Epoch: [45][65/96]\tLoss 0.1888 (0.2988)\taccuracy 92.188 (88.707)\tf1_score 90.313 (86.053)\n",
      "Epoch: [45][70/96]\tLoss 0.2945 (0.3017)\taccuracy 92.188 (88.556)\tf1_score 90.619 (85.959)\n",
      "Epoch: [45][75/96]\tLoss 0.2284 (0.3025)\taccuracy 90.625 (88.487)\tf1_score 89.833 (85.876)\n",
      "Epoch: [45][80/96]\tLoss 0.2196 (0.2987)\taccuracy 89.062 (88.561)\tf1_score 86.246 (85.974)\n",
      "Epoch: [45][85/96]\tLoss 0.3724 (0.3009)\taccuracy 84.375 (88.408)\tf1_score 82.283 (85.914)\n",
      "Epoch: [45][90/96]\tLoss 0.1934 (0.3015)\taccuracy 90.625 (88.376)\tf1_score 88.655 (85.926)\n",
      "Epoch: [45][95/96]\tLoss 0.2608 (0.2998)\taccuracy 89.062 (88.493)\tf1_score 86.765 (85.950)\n",
      " Test: accuracy 76.628 f1_score 71.103\n",
      "Training time:  735.0248734951019 Hour:  0 Minute:  12 Second:  15 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 46\n",
      "Epoch: [46][0/96]\tLoss 0.4481 (0.4481)\taccuracy 82.812 (82.812)\tf1_score 81.204 (81.204)\n",
      "Epoch: [46][5/96]\tLoss 0.1909 (0.3367)\taccuracy 93.750 (87.500)\tf1_score 93.197 (85.309)\n",
      "Epoch: [46][10/96]\tLoss 0.1280 (0.2964)\taccuracy 95.312 (88.494)\tf1_score 96.145 (87.244)\n",
      "Epoch: [46][15/96]\tLoss 0.1096 (0.2772)\taccuracy 96.875 (88.965)\tf1_score 95.397 (87.898)\n",
      "Epoch: [46][20/96]\tLoss 0.1497 (0.2893)\taccuracy 95.312 (88.542)\tf1_score 96.740 (86.686)\n",
      "Epoch: [46][25/96]\tLoss 0.1820 (0.2923)\taccuracy 90.625 (88.341)\tf1_score 87.430 (85.859)\n",
      "Epoch: [46][30/96]\tLoss 0.1736 (0.2880)\taccuracy 93.750 (88.458)\tf1_score 91.571 (86.024)\n",
      "Epoch: [46][35/96]\tLoss 0.1940 (0.2798)\taccuracy 92.188 (88.759)\tf1_score 91.573 (86.536)\n",
      "Epoch: [46][40/96]\tLoss 0.4002 (0.2860)\taccuracy 84.375 (88.529)\tf1_score 84.890 (86.313)\n",
      "Epoch: [46][45/96]\tLoss 0.1773 (0.2786)\taccuracy 90.625 (88.825)\tf1_score 88.367 (86.692)\n",
      "Epoch: [46][50/96]\tLoss 0.3279 (0.2819)\taccuracy 92.188 (88.787)\tf1_score 92.599 (86.663)\n",
      "Epoch: [46][55/96]\tLoss 0.2836 (0.2840)\taccuracy 89.062 (88.700)\tf1_score 83.946 (86.521)\n",
      "Epoch: [46][60/96]\tLoss 0.1664 (0.2835)\taccuracy 93.750 (88.781)\tf1_score 94.655 (86.634)\n",
      "Epoch: [46][65/96]\tLoss 0.4049 (0.2822)\taccuracy 82.812 (88.778)\tf1_score 83.274 (86.758)\n",
      "Epoch: [46][70/96]\tLoss 0.3877 (0.2854)\taccuracy 84.375 (88.710)\tf1_score 81.466 (86.727)\n",
      "Epoch: [46][75/96]\tLoss 0.3000 (0.2937)\taccuracy 89.062 (88.528)\tf1_score 79.743 (86.327)\n",
      "Epoch: [46][80/96]\tLoss 0.2809 (0.2943)\taccuracy 85.938 (88.484)\tf1_score 87.672 (86.254)\n",
      "Epoch: [46][85/96]\tLoss 0.3828 (0.2953)\taccuracy 87.500 (88.354)\tf1_score 82.270 (86.085)\n",
      "Epoch: [46][90/96]\tLoss 0.3099 (0.2958)\taccuracy 87.500 (88.290)\tf1_score 88.396 (86.116)\n",
      "Epoch: [46][95/96]\tLoss 0.4543 (0.2940)\taccuracy 78.125 (88.346)\tf1_score 79.647 (86.259)\n",
      " Test: accuracy 60.352 f1_score 54.575\n",
      "Training time:  750.7642936706543 Hour:  0 Minute:  12 Second:  30 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 47\n",
      "Epoch: [47][0/96]\tLoss 0.3590 (0.3590)\taccuracy 87.500 (87.500)\tf1_score 87.127 (87.127)\n",
      "Epoch: [47][5/96]\tLoss 0.3332 (0.3134)\taccuracy 89.062 (88.021)\tf1_score 88.018 (86.958)\n",
      "Epoch: [47][10/96]\tLoss 0.1149 (0.2702)\taccuracy 95.312 (89.773)\tf1_score 88.139 (87.003)\n",
      "Epoch: [47][15/96]\tLoss 0.2135 (0.2704)\taccuracy 92.188 (89.551)\tf1_score 87.220 (86.220)\n",
      "Epoch: [47][20/96]\tLoss 0.2609 (0.2861)\taccuracy 89.062 (88.839)\tf1_score 86.008 (85.534)\n",
      "Epoch: [47][25/96]\tLoss 0.4064 (0.2764)\taccuracy 81.250 (89.243)\tf1_score 82.944 (86.342)\n",
      "Epoch: [47][30/96]\tLoss 0.2238 (0.2806)\taccuracy 87.500 (88.962)\tf1_score 83.597 (86.308)\n",
      "Epoch: [47][35/96]\tLoss 0.1815 (0.2802)\taccuracy 89.062 (88.628)\tf1_score 90.978 (86.148)\n",
      "Epoch: [47][40/96]\tLoss 0.2859 (0.2806)\taccuracy 87.500 (88.643)\tf1_score 86.746 (86.369)\n",
      "Epoch: [47][45/96]\tLoss 0.2873 (0.2805)\taccuracy 87.500 (88.961)\tf1_score 80.571 (86.686)\n",
      "Epoch: [47][50/96]\tLoss 0.2234 (0.2769)\taccuracy 93.750 (89.216)\tf1_score 89.637 (86.873)\n",
      "Epoch: [47][55/96]\tLoss 0.3245 (0.2791)\taccuracy 84.375 (88.923)\tf1_score 74.638 (86.570)\n",
      "Epoch: [47][60/96]\tLoss 0.1924 (0.2739)\taccuracy 93.750 (89.011)\tf1_score 91.111 (86.750)\n",
      "Epoch: [47][65/96]\tLoss 0.2597 (0.2704)\taccuracy 89.062 (89.205)\tf1_score 84.303 (87.042)\n",
      "Epoch: [47][70/96]\tLoss 0.2756 (0.2703)\taccuracy 87.500 (89.217)\tf1_score 84.702 (87.093)\n",
      "Epoch: [47][75/96]\tLoss 0.1018 (0.2620)\taccuracy 98.438 (89.638)\tf1_score 94.709 (87.376)\n",
      "Epoch: [47][80/96]\tLoss 0.3442 (0.2609)\taccuracy 92.188 (89.776)\tf1_score 92.514 (87.570)\n",
      "Epoch: [47][85/96]\tLoss 0.1654 (0.2570)\taccuracy 92.188 (89.898)\tf1_score 86.726 (87.615)\n",
      "Epoch: [47][90/96]\tLoss 0.2124 (0.2575)\taccuracy 90.625 (89.973)\tf1_score 90.461 (87.805)\n",
      "Epoch: [47][95/96]\tLoss 0.1519 (0.2541)\taccuracy 96.875 (90.104)\tf1_score 97.158 (87.973)\n",
      " Test: accuracy 86.523 f1_score 84.058\n",
      "Training time:  766.4435279369354 Hour:  0 Minute:  12 Second:  46 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 48\n",
      "Epoch: [48][0/96]\tLoss 0.2151 (0.2151)\taccuracy 90.625 (90.625)\tf1_score 87.680 (87.680)\n",
      "Epoch: [48][5/96]\tLoss 0.1801 (0.2431)\taccuracy 93.750 (89.583)\tf1_score 90.036 (87.664)\n",
      "Epoch: [48][10/96]\tLoss 0.2842 (0.2447)\taccuracy 87.500 (90.767)\tf1_score 86.213 (88.642)\n",
      "Epoch: [48][15/96]\tLoss 0.2831 (0.2393)\taccuracy 85.938 (90.527)\tf1_score 87.000 (88.480)\n",
      "Epoch: [48][20/96]\tLoss 0.2689 (0.2455)\taccuracy 90.625 (90.179)\tf1_score 89.165 (88.386)\n",
      "Epoch: [48][25/96]\tLoss 0.2436 (0.2545)\taccuracy 95.312 (90.144)\tf1_score 94.357 (88.130)\n",
      "Epoch: [48][30/96]\tLoss 0.3161 (0.2624)\taccuracy 89.062 (90.171)\tf1_score 87.755 (88.188)\n",
      "Epoch: [48][35/96]\tLoss 0.2758 (0.2632)\taccuracy 85.938 (89.931)\tf1_score 84.098 (87.789)\n",
      "Epoch: [48][40/96]\tLoss 0.1583 (0.2658)\taccuracy 93.750 (89.825)\tf1_score 90.385 (87.803)\n",
      "Epoch: [48][45/96]\tLoss 0.3433 (0.2667)\taccuracy 82.812 (89.640)\tf1_score 82.369 (87.564)\n",
      "Epoch: [48][50/96]\tLoss 0.4018 (0.2696)\taccuracy 87.500 (89.369)\tf1_score 85.984 (87.320)\n",
      "Epoch: [48][55/96]\tLoss 0.3521 (0.2684)\taccuracy 82.812 (89.369)\tf1_score 79.233 (87.341)\n",
      "Epoch: [48][60/96]\tLoss 0.1514 (0.2645)\taccuracy 95.312 (89.524)\tf1_score 93.870 (87.251)\n",
      "Epoch: [48][65/96]\tLoss 0.4349 (0.2675)\taccuracy 84.375 (89.370)\tf1_score 86.937 (86.976)\n",
      "Epoch: [48][70/96]\tLoss 0.2788 (0.2695)\taccuracy 85.938 (89.173)\tf1_score 86.876 (86.954)\n",
      "Epoch: [48][75/96]\tLoss 0.2244 (0.2705)\taccuracy 90.625 (89.124)\tf1_score 91.949 (87.024)\n",
      "Epoch: [48][80/96]\tLoss 0.3874 (0.2743)\taccuracy 84.375 (89.024)\tf1_score 78.789 (86.929)\n",
      "Epoch: [48][85/96]\tLoss 0.2211 (0.2728)\taccuracy 89.062 (89.044)\tf1_score 84.832 (86.816)\n",
      "Epoch: [48][90/96]\tLoss 0.1906 (0.2735)\taccuracy 92.188 (89.011)\tf1_score 88.311 (86.758)\n",
      "Epoch: [48][95/96]\tLoss 0.2894 (0.2755)\taccuracy 89.062 (88.981)\tf1_score 87.702 (86.856)\n",
      " Test: accuracy 78.125 f1_score 74.351\n",
      "Training time:  782.1364550590515 Hour:  0 Minute:  13 Second:  2 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 49\n",
      "Epoch: [49][0/96]\tLoss 0.2507 (0.2507)\taccuracy 85.938 (85.938)\tf1_score 83.857 (83.857)\n",
      "Epoch: [49][5/96]\tLoss 0.2319 (0.2740)\taccuracy 89.062 (86.458)\tf1_score 88.413 (85.778)\n",
      "Epoch: [49][10/96]\tLoss 0.3352 (0.2734)\taccuracy 87.500 (87.926)\tf1_score 82.665 (86.432)\n",
      "Epoch: [49][15/96]\tLoss 0.2001 (0.2568)\taccuracy 90.625 (88.770)\tf1_score 90.310 (87.306)\n",
      "Epoch: [49][20/96]\tLoss 0.2552 (0.2763)\taccuracy 87.500 (88.318)\tf1_score 87.653 (86.754)\n",
      "Epoch: [49][25/96]\tLoss 0.2604 (0.2694)\taccuracy 92.188 (88.822)\tf1_score 92.151 (87.294)\n",
      "Epoch: [49][30/96]\tLoss 0.2222 (0.2617)\taccuracy 93.750 (89.214)\tf1_score 94.900 (87.853)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [49][35/96]\tLoss 0.2368 (0.2654)\taccuracy 89.062 (89.149)\tf1_score 83.672 (87.650)\n",
      "Epoch: [49][40/96]\tLoss 0.1731 (0.2611)\taccuracy 95.312 (89.329)\tf1_score 92.161 (87.648)\n",
      "Epoch: [49][45/96]\tLoss 0.0722 (0.2509)\taccuracy 98.438 (89.640)\tf1_score 94.286 (87.747)\n",
      "Epoch: [49][50/96]\tLoss 0.3113 (0.2527)\taccuracy 89.062 (89.798)\tf1_score 87.041 (88.016)\n",
      "Epoch: [49][55/96]\tLoss 0.1137 (0.2559)\taccuracy 96.875 (89.872)\tf1_score 96.165 (88.062)\n",
      "Epoch: [49][60/96]\tLoss 0.2282 (0.2588)\taccuracy 90.625 (89.703)\tf1_score 86.661 (88.010)\n",
      "Epoch: [49][65/96]\tLoss 0.2419 (0.2545)\taccuracy 90.625 (89.891)\tf1_score 86.111 (88.072)\n",
      "Epoch: [49][70/96]\tLoss 0.2068 (0.2529)\taccuracy 90.625 (89.877)\tf1_score 89.025 (88.055)\n",
      "Epoch: [49][75/96]\tLoss 0.3534 (0.2561)\taccuracy 89.062 (89.803)\tf1_score 84.404 (87.905)\n",
      "Epoch: [49][80/96]\tLoss 0.6064 (0.2612)\taccuracy 79.688 (89.641)\tf1_score 78.329 (87.670)\n",
      "Epoch: [49][85/96]\tLoss 0.2610 (0.2642)\taccuracy 89.062 (89.571)\tf1_score 85.179 (87.490)\n",
      "Epoch: [49][90/96]\tLoss 0.3436 (0.2666)\taccuracy 87.500 (89.560)\tf1_score 81.587 (87.307)\n",
      "Epoch: [49][95/96]\tLoss 0.3373 (0.2760)\taccuracy 84.375 (89.193)\tf1_score 77.150 (86.894)\n",
      " Test: accuracy 70.898 f1_score 66.396\n",
      "Training time:  797.8955354690552 Hour:  0 Minute:  13 Second:  17 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 50\n",
      "Epoch: [50][0/96]\tLoss 0.4280 (0.4280)\taccuracy 82.812 (82.812)\tf1_score 80.351 (80.351)\n",
      "Epoch: [50][5/96]\tLoss 0.2592 (0.4275)\taccuracy 87.500 (85.156)\tf1_score 87.687 (82.823)\n",
      "Epoch: [50][10/96]\tLoss 0.3640 (0.3781)\taccuracy 82.812 (86.506)\tf1_score 82.073 (83.800)\n",
      "Epoch: [50][15/96]\tLoss 0.4915 (0.3506)\taccuracy 76.562 (86.914)\tf1_score 77.403 (84.907)\n",
      "Epoch: [50][20/96]\tLoss 0.2379 (0.3187)\taccuracy 89.062 (88.170)\tf1_score 90.968 (86.282)\n",
      "Epoch: [50][25/96]\tLoss 0.2771 (0.3170)\taccuracy 89.062 (87.800)\tf1_score 87.848 (85.662)\n",
      "Epoch: [50][30/96]\tLoss 0.3934 (0.3125)\taccuracy 84.375 (88.105)\tf1_score 82.869 (86.249)\n",
      "Epoch: [50][35/96]\tLoss 0.6265 (0.3269)\taccuracy 78.125 (87.587)\tf1_score 69.700 (85.173)\n",
      "Epoch: [50][40/96]\tLoss 0.3238 (0.3277)\taccuracy 84.375 (87.576)\tf1_score 81.175 (85.136)\n",
      "Epoch: [50][45/96]\tLoss 0.3907 (0.3302)\taccuracy 82.812 (87.500)\tf1_score 77.812 (84.884)\n",
      "Epoch: [50][50/96]\tLoss 0.3233 (0.3327)\taccuracy 84.375 (87.224)\tf1_score 81.417 (84.838)\n",
      "Epoch: [50][55/96]\tLoss 0.6326 (0.3337)\taccuracy 79.688 (87.360)\tf1_score 79.617 (84.970)\n",
      "Epoch: [50][60/96]\tLoss 0.3309 (0.3294)\taccuracy 84.375 (87.474)\tf1_score 84.658 (84.995)\n",
      "Epoch: [50][65/96]\tLoss 0.2085 (0.3273)\taccuracy 87.500 (87.500)\tf1_score 88.333 (84.857)\n",
      "Epoch: [50][70/96]\tLoss 0.4026 (0.3249)\taccuracy 90.625 (87.566)\tf1_score 85.824 (84.974)\n",
      "Epoch: [50][75/96]\tLoss 0.3931 (0.3223)\taccuracy 82.812 (87.747)\tf1_score 82.333 (85.175)\n",
      "Epoch: [50][80/96]\tLoss 0.1903 (0.3154)\taccuracy 95.312 (87.982)\tf1_score 96.181 (85.403)\n",
      "Epoch: [50][85/96]\tLoss 0.2096 (0.3111)\taccuracy 95.312 (88.263)\tf1_score 95.556 (85.782)\n",
      "Epoch: [50][90/96]\tLoss 0.3507 (0.3083)\taccuracy 82.812 (88.341)\tf1_score 82.670 (85.883)\n",
      "Epoch: [50][95/96]\tLoss 0.3656 (0.3058)\taccuracy 87.500 (88.493)\tf1_score 88.666 (86.118)\n",
      " Test: accuracy 80.990 f1_score 77.344\n",
      "Training time:  813.6159992218018 Hour:  0 Minute:  13 Second:  33 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 51\n",
      "Epoch: [51][0/96]\tLoss 0.1291 (0.1291)\taccuracy 95.312 (95.312)\tf1_score 95.000 (95.000)\n",
      "Epoch: [51][5/96]\tLoss 0.1415 (0.2541)\taccuracy 95.312 (88.021)\tf1_score 94.278 (86.589)\n",
      "Epoch: [51][10/96]\tLoss 0.1644 (0.2631)\taccuracy 93.750 (88.068)\tf1_score 94.476 (86.354)\n",
      "Epoch: [51][15/96]\tLoss 0.2014 (0.2678)\taccuracy 90.625 (88.184)\tf1_score 88.926 (86.337)\n",
      "Epoch: [51][20/96]\tLoss 0.5861 (0.2707)\taccuracy 79.688 (88.839)\tf1_score 78.434 (86.866)\n",
      "Epoch: [51][25/96]\tLoss 0.4517 (0.2650)\taccuracy 87.500 (89.483)\tf1_score 84.584 (87.469)\n",
      "Epoch: [51][30/96]\tLoss 0.2919 (0.2748)\taccuracy 89.062 (89.163)\tf1_score 88.235 (87.125)\n",
      "Epoch: [51][35/96]\tLoss 0.2214 (0.2768)\taccuracy 90.625 (89.106)\tf1_score 84.499 (86.641)\n",
      "Epoch: [51][40/96]\tLoss 0.1384 (0.2677)\taccuracy 96.875 (89.520)\tf1_score 95.778 (86.967)\n",
      "Epoch: [51][45/96]\tLoss 0.2612 (0.2705)\taccuracy 90.625 (89.368)\tf1_score 89.450 (86.924)\n",
      "Epoch: [51][50/96]\tLoss 0.1796 (0.2693)\taccuracy 90.625 (89.400)\tf1_score 85.351 (86.856)\n",
      "Epoch: [51][55/96]\tLoss 0.2730 (0.2664)\taccuracy 90.625 (89.648)\tf1_score 87.438 (87.152)\n",
      "Epoch: [51][60/96]\tLoss 0.1921 (0.2623)\taccuracy 96.875 (89.933)\tf1_score 93.730 (87.502)\n",
      "Epoch: [51][65/96]\tLoss 0.3062 (0.2645)\taccuracy 85.938 (89.773)\tf1_score 85.776 (87.380)\n",
      "Epoch: [51][70/96]\tLoss 0.2633 (0.2650)\taccuracy 89.062 (89.657)\tf1_score 87.392 (87.333)\n",
      "Epoch: [51][75/96]\tLoss 0.2856 (0.2630)\taccuracy 85.938 (89.700)\tf1_score 88.361 (87.463)\n",
      "Epoch: [51][80/96]\tLoss 0.3034 (0.2642)\taccuracy 84.375 (89.468)\tf1_score 80.367 (87.341)\n",
      "Epoch: [51][85/96]\tLoss 0.2956 (0.2664)\taccuracy 90.625 (89.517)\tf1_score 84.321 (87.187)\n",
      "Epoch: [51][90/96]\tLoss 0.4055 (0.2662)\taccuracy 82.812 (89.492)\tf1_score 78.632 (87.135)\n",
      "Epoch: [51][95/96]\tLoss 0.1991 (0.2671)\taccuracy 92.188 (89.518)\tf1_score 87.937 (87.153)\n",
      " Test: accuracy 73.763 f1_score 68.157\n",
      "Training time:  829.3182425498962 Hour:  0 Minute:  13 Second:  49 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 52\n",
      "Epoch: [52][0/96]\tLoss 0.1921 (0.1921)\taccuracy 93.750 (93.750)\tf1_score 92.105 (92.105)\n",
      "Epoch: [52][5/96]\tLoss 0.2197 (0.1923)\taccuracy 92.188 (92.969)\tf1_score 93.134 (91.342)\n",
      "Epoch: [52][10/96]\tLoss 0.2857 (0.1882)\taccuracy 90.625 (93.040)\tf1_score 89.111 (91.379)\n",
      "Epoch: [52][15/96]\tLoss 0.1707 (0.1976)\taccuracy 92.188 (92.578)\tf1_score 89.912 (90.374)\n",
      "Epoch: [52][20/96]\tLoss 0.5479 (0.2255)\taccuracy 81.250 (91.443)\tf1_score 81.230 (89.236)\n",
      "Epoch: [52][25/96]\tLoss 0.3124 (0.2301)\taccuracy 87.500 (91.046)\tf1_score 77.143 (88.767)\n",
      "Epoch: [52][30/96]\tLoss 0.2711 (0.2310)\taccuracy 87.500 (91.179)\tf1_score 80.452 (88.653)\n",
      "Epoch: [52][35/96]\tLoss 0.1953 (0.2419)\taccuracy 93.750 (90.972)\tf1_score 94.709 (88.489)\n",
      "Epoch: [52][40/96]\tLoss 0.2694 (0.2492)\taccuracy 89.062 (90.816)\tf1_score 81.817 (88.210)\n",
      "Epoch: [52][45/96]\tLoss 0.3485 (0.2484)\taccuracy 87.500 (90.931)\tf1_score 85.528 (88.363)\n",
      "Epoch: [52][50/96]\tLoss 0.1809 (0.2485)\taccuracy 92.188 (90.778)\tf1_score 89.227 (88.263)\n",
      "Epoch: [52][55/96]\tLoss 0.2608 (0.2554)\taccuracy 89.062 (90.402)\tf1_score 90.124 (87.817)\n",
      "Epoch: [52][60/96]\tLoss 0.3400 (0.2596)\taccuracy 85.938 (90.138)\tf1_score 87.090 (87.863)\n",
      "Epoch: [52][65/96]\tLoss 0.4383 (0.2626)\taccuracy 82.812 (90.009)\tf1_score 83.691 (87.739)\n",
      "Epoch: [52][70/96]\tLoss 0.2964 (0.2743)\taccuracy 87.500 (89.481)\tf1_score 82.415 (87.143)\n",
      "Epoch: [52][75/96]\tLoss 0.2708 (0.2740)\taccuracy 84.375 (89.453)\tf1_score 82.003 (87.054)\n",
      "Epoch: [52][80/96]\tLoss 0.3179 (0.2731)\taccuracy 92.188 (89.583)\tf1_score 89.667 (87.191)\n",
      "Epoch: [52][85/96]\tLoss 0.3483 (0.2764)\taccuracy 89.062 (89.517)\tf1_score 83.596 (87.048)\n",
      "Epoch: [52][90/96]\tLoss 0.4613 (0.2802)\taccuracy 82.812 (89.354)\tf1_score 76.319 (86.858)\n",
      "Epoch: [52][95/96]\tLoss 0.2198 (0.2792)\taccuracy 90.625 (89.421)\tf1_score 87.120 (86.909)\n",
      " Test: accuracy 76.042 f1_score 70.544\n",
      "Training time:  845.1867074966431 Hour:  0 Minute:  14 Second:  5 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 53\n",
      "Epoch: [53][0/96]\tLoss 0.2039 (0.2039)\taccuracy 92.188 (92.188)\tf1_score 91.472 (91.472)\n",
      "Epoch: [53][5/96]\tLoss 0.2133 (0.2093)\taccuracy 92.188 (91.667)\tf1_score 91.551 (89.760)\n",
      "Epoch: [53][10/96]\tLoss 0.1534 (0.2307)\taccuracy 93.750 (91.051)\tf1_score 86.746 (88.089)\n",
      "Epoch: [53][15/96]\tLoss 0.2120 (0.2566)\taccuracy 92.188 (89.551)\tf1_score 87.441 (86.804)\n",
      "Epoch: [53][20/96]\tLoss 0.1436 (0.2482)\taccuracy 95.312 (89.583)\tf1_score 93.647 (86.756)\n",
      "Epoch: [53][25/96]\tLoss 0.2542 (0.2404)\taccuracy 89.062 (89.964)\tf1_score 90.180 (87.472)\n",
      "Epoch: [53][30/96]\tLoss 0.2176 (0.2524)\taccuracy 90.625 (89.567)\tf1_score 90.429 (87.214)\n",
      "Epoch: [53][35/96]\tLoss 0.1937 (0.2491)\taccuracy 90.625 (89.670)\tf1_score 88.333 (87.056)\n",
      "Epoch: [53][40/96]\tLoss 0.2657 (0.2489)\taccuracy 85.938 (89.672)\tf1_score 79.028 (87.087)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [53][45/96]\tLoss 0.2736 (0.2488)\taccuracy 90.625 (89.844)\tf1_score 92.874 (87.453)\n",
      "Epoch: [53][50/96]\tLoss 0.2700 (0.2486)\taccuracy 89.062 (89.951)\tf1_score 79.265 (87.358)\n",
      "Epoch: [53][55/96]\tLoss 0.2227 (0.2427)\taccuracy 92.188 (90.206)\tf1_score 89.776 (87.713)\n",
      "Epoch: [53][60/96]\tLoss 0.1480 (0.2422)\taccuracy 93.750 (90.446)\tf1_score 94.359 (88.039)\n",
      "Epoch: [53][65/96]\tLoss 0.2840 (0.2464)\taccuracy 89.062 (90.270)\tf1_score 88.340 (87.984)\n",
      "Epoch: [53][70/96]\tLoss 0.1419 (0.2436)\taccuracy 95.312 (90.405)\tf1_score 87.256 (87.828)\n",
      "Epoch: [53][75/96]\tLoss 0.1730 (0.2420)\taccuracy 92.188 (90.502)\tf1_score 90.230 (87.970)\n",
      "Epoch: [53][80/96]\tLoss 0.4605 (0.2454)\taccuracy 84.375 (90.278)\tf1_score 79.501 (87.824)\n",
      "Epoch: [53][85/96]\tLoss 0.4081 (0.2469)\taccuracy 87.500 (90.207)\tf1_score 86.745 (87.837)\n",
      "Epoch: [53][90/96]\tLoss 0.2881 (0.2470)\taccuracy 87.500 (90.247)\tf1_score 87.711 (87.956)\n",
      "Epoch: [53][95/96]\tLoss 0.2511 (0.2469)\taccuracy 92.188 (90.283)\tf1_score 92.880 (88.079)\n",
      " Test: accuracy 82.682 f1_score 80.502\n",
      "Training time:  861.1447641849518 Hour:  0 Minute:  14 Second:  21 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 54\n",
      "Epoch: [54][0/96]\tLoss 0.2635 (0.2635)\taccuracy 87.500 (87.500)\tf1_score 84.317 (84.317)\n",
      "Epoch: [54][5/96]\tLoss 0.3517 (0.3135)\taccuracy 84.375 (87.240)\tf1_score 87.738 (85.035)\n",
      "Epoch: [54][10/96]\tLoss 0.2612 (0.3271)\taccuracy 93.750 (86.364)\tf1_score 93.957 (84.634)\n",
      "Epoch: [54][15/96]\tLoss 0.3605 (0.3175)\taccuracy 85.938 (86.816)\tf1_score 85.674 (85.042)\n",
      "Epoch: [54][20/96]\tLoss 0.2820 (0.3104)\taccuracy 87.500 (87.054)\tf1_score 87.868 (85.660)\n",
      "Epoch: [54][25/96]\tLoss 0.3290 (0.3037)\taccuracy 90.625 (87.620)\tf1_score 88.730 (86.103)\n",
      "Epoch: [54][30/96]\tLoss 0.2404 (0.2975)\taccuracy 90.625 (88.155)\tf1_score 85.644 (86.678)\n",
      "Epoch: [54][35/96]\tLoss 0.3784 (0.2966)\taccuracy 85.938 (88.325)\tf1_score 86.701 (87.055)\n",
      "Epoch: [54][40/96]\tLoss 0.2986 (0.3018)\taccuracy 87.500 (88.262)\tf1_score 87.465 (86.575)\n",
      "Epoch: [54][45/96]\tLoss 0.3488 (0.3106)\taccuracy 84.375 (87.704)\tf1_score 74.214 (85.760)\n",
      "Epoch: [54][50/96]\tLoss 0.2827 (0.3074)\taccuracy 90.625 (88.051)\tf1_score 86.160 (85.864)\n",
      "Epoch: [54][55/96]\tLoss 0.4146 (0.3129)\taccuracy 89.062 (88.002)\tf1_score 85.587 (85.792)\n",
      "Epoch: [54][60/96]\tLoss 0.7164 (0.3222)\taccuracy 70.312 (87.551)\tf1_score 68.050 (85.272)\n",
      "Epoch: [54][65/96]\tLoss 0.3496 (0.3252)\taccuracy 84.375 (87.429)\tf1_score 76.851 (84.822)\n",
      "Epoch: [54][70/96]\tLoss 0.5409 (0.3369)\taccuracy 78.125 (86.906)\tf1_score 73.270 (84.290)\n",
      "Epoch: [54][75/96]\tLoss 0.6195 (0.3484)\taccuracy 79.688 (86.513)\tf1_score 74.942 (83.832)\n",
      "Epoch: [54][80/96]\tLoss 0.6117 (0.3622)\taccuracy 71.875 (86.015)\tf1_score 75.787 (83.543)\n",
      "Epoch: [54][85/96]\tLoss 0.3366 (0.3635)\taccuracy 89.062 (85.919)\tf1_score 88.101 (83.387)\n",
      "Epoch: [54][90/96]\tLoss 0.4484 (0.3651)\taccuracy 87.500 (86.023)\tf1_score 83.086 (83.378)\n",
      "Epoch: [54][95/96]\tLoss 0.2521 (0.3627)\taccuracy 90.625 (86.100)\tf1_score 83.683 (83.380)\n",
      " Test: accuracy 84.635 f1_score 81.981\n",
      "Training time:  876.9576094150543 Hour:  0 Minute:  14 Second:  36 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 55\n",
      "Epoch: [55][0/96]\tLoss 0.6439 (0.6439)\taccuracy 71.875 (71.875)\tf1_score 67.088 (67.088)\n",
      "Epoch: [55][5/96]\tLoss 0.1633 (0.3567)\taccuracy 95.312 (85.677)\tf1_score 90.748 (81.916)\n",
      "Epoch: [55][10/96]\tLoss 0.2984 (0.3353)\taccuracy 92.188 (87.358)\tf1_score 87.462 (84.793)\n",
      "Epoch: [55][15/96]\tLoss 0.4467 (0.3290)\taccuracy 84.375 (87.598)\tf1_score 84.970 (85.264)\n",
      "Epoch: [55][20/96]\tLoss 0.1816 (0.3263)\taccuracy 93.750 (87.872)\tf1_score 88.297 (85.080)\n",
      "Epoch: [55][25/96]\tLoss 0.2052 (0.3130)\taccuracy 92.188 (88.221)\tf1_score 93.388 (85.424)\n",
      "Epoch: [55][30/96]\tLoss 0.2835 (0.3162)\taccuracy 85.938 (87.853)\tf1_score 83.776 (85.343)\n",
      "Epoch: [55][35/96]\tLoss 0.2038 (0.3186)\taccuracy 90.625 (87.891)\tf1_score 81.897 (85.185)\n",
      "Epoch: [55][40/96]\tLoss 0.2409 (0.3098)\taccuracy 90.625 (88.148)\tf1_score 86.857 (85.290)\n",
      "Epoch: [55][45/96]\tLoss 0.1961 (0.3035)\taccuracy 89.062 (88.383)\tf1_score 85.397 (85.537)\n",
      "Epoch: [55][50/96]\tLoss 0.1766 (0.2949)\taccuracy 92.188 (88.756)\tf1_score 86.216 (85.733)\n",
      "Epoch: [55][55/96]\tLoss 0.1912 (0.2915)\taccuracy 93.750 (88.951)\tf1_score 87.625 (86.032)\n",
      "Epoch: [55][60/96]\tLoss 0.2884 (0.2913)\taccuracy 85.938 (88.883)\tf1_score 80.178 (86.094)\n",
      "Epoch: [55][65/96]\tLoss 0.2416 (0.2860)\taccuracy 90.625 (89.110)\tf1_score 85.735 (86.342)\n",
      "Epoch: [55][70/96]\tLoss 0.3672 (0.2879)\taccuracy 84.375 (88.952)\tf1_score 88.401 (86.282)\n",
      "Epoch: [55][75/96]\tLoss 0.1900 (0.2861)\taccuracy 93.750 (88.980)\tf1_score 88.569 (86.316)\n",
      "Epoch: [55][80/96]\tLoss 0.2950 (0.2844)\taccuracy 89.062 (89.005)\tf1_score 87.806 (86.241)\n",
      "Epoch: [55][85/96]\tLoss 0.1602 (0.2821)\taccuracy 92.188 (89.044)\tf1_score 87.857 (86.270)\n",
      "Epoch: [55][90/96]\tLoss 0.1796 (0.2796)\taccuracy 92.188 (89.166)\tf1_score 89.853 (86.420)\n",
      "Epoch: [55][95/96]\tLoss 0.2706 (0.2783)\taccuracy 87.500 (89.128)\tf1_score 88.587 (86.517)\n",
      " Test: accuracy 81.445 f1_score 78.771\n",
      "Training time:  892.7616155147552 Hour:  0 Minute:  14 Second:  52 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 56\n",
      "Epoch: [56][0/96]\tLoss 0.2026 (0.2026)\taccuracy 90.625 (90.625)\tf1_score 88.802 (88.802)\n",
      "Epoch: [56][5/96]\tLoss 0.2666 (0.2557)\taccuracy 90.625 (90.625)\tf1_score 90.978 (88.513)\n",
      "Epoch: [56][10/96]\tLoss 0.1797 (0.2384)\taccuracy 92.188 (90.909)\tf1_score 92.802 (89.498)\n",
      "Epoch: [56][15/96]\tLoss 0.2876 (0.2289)\taccuracy 90.625 (91.113)\tf1_score 80.167 (88.629)\n",
      "Epoch: [56][20/96]\tLoss 0.1311 (0.2379)\taccuracy 96.875 (91.071)\tf1_score 97.932 (88.125)\n",
      "Epoch: [56][25/96]\tLoss 0.1530 (0.2355)\taccuracy 96.875 (91.406)\tf1_score 96.614 (88.413)\n",
      "Epoch: [56][30/96]\tLoss 0.2960 (0.2332)\taccuracy 84.375 (91.381)\tf1_score 84.915 (88.545)\n",
      "Epoch: [56][35/96]\tLoss 0.3192 (0.2399)\taccuracy 85.938 (91.016)\tf1_score 89.431 (88.260)\n",
      "Epoch: [56][40/96]\tLoss 0.2145 (0.2443)\taccuracy 93.750 (90.892)\tf1_score 94.743 (88.474)\n",
      "Epoch: [56][45/96]\tLoss 0.1818 (0.2413)\taccuracy 90.625 (90.965)\tf1_score 90.206 (88.677)\n",
      "Epoch: [56][50/96]\tLoss 0.1537 (0.2452)\taccuracy 95.312 (90.809)\tf1_score 90.265 (88.576)\n",
      "Epoch: [56][55/96]\tLoss 0.1125 (0.2488)\taccuracy 93.750 (90.625)\tf1_score 93.122 (88.221)\n",
      "Epoch: [56][60/96]\tLoss 0.2279 (0.2484)\taccuracy 89.062 (90.574)\tf1_score 81.353 (88.056)\n",
      "Epoch: [56][65/96]\tLoss 0.2704 (0.2527)\taccuracy 92.188 (90.365)\tf1_score 92.220 (87.981)\n",
      "Epoch: [56][70/96]\tLoss 0.2317 (0.2542)\taccuracy 93.750 (90.251)\tf1_score 87.458 (87.963)\n",
      "Epoch: [56][75/96]\tLoss 0.2520 (0.2549)\taccuracy 89.062 (90.070)\tf1_score 89.370 (87.894)\n",
      "Epoch: [56][80/96]\tLoss 0.1833 (0.2539)\taccuracy 92.188 (90.008)\tf1_score 91.679 (87.849)\n",
      "Epoch: [56][85/96]\tLoss 0.2773 (0.2556)\taccuracy 92.188 (89.789)\tf1_score 92.387 (87.697)\n",
      "Epoch: [56][90/96]\tLoss 0.1096 (0.2507)\taccuracy 96.875 (90.007)\tf1_score 91.746 (87.907)\n",
      "Epoch: [56][95/96]\tLoss 0.2956 (0.2521)\taccuracy 85.938 (89.876)\tf1_score 87.445 (87.800)\n",
      " Test: accuracy 76.367 f1_score 72.459\n",
      "Training time:  908.5432760715485 Hour:  0 Minute:  15 Second:  8 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 57\n",
      "Epoch: [57][0/96]\tLoss 0.3308 (0.3308)\taccuracy 89.062 (89.062)\tf1_score 92.607 (92.607)\n",
      "Epoch: [57][5/96]\tLoss 0.2780 (0.2490)\taccuracy 87.500 (91.146)\tf1_score 86.190 (89.413)\n",
      "Epoch: [57][10/96]\tLoss 0.3482 (0.2666)\taccuracy 85.938 (90.483)\tf1_score 79.994 (88.470)\n",
      "Epoch: [57][15/96]\tLoss 0.3892 (0.2717)\taccuracy 87.500 (90.137)\tf1_score 88.311 (88.036)\n",
      "Epoch: [57][20/96]\tLoss 0.1433 (0.2691)\taccuracy 93.750 (89.807)\tf1_score 93.435 (87.383)\n",
      "Epoch: [57][25/96]\tLoss 0.2817 (0.2666)\taccuracy 89.062 (89.663)\tf1_score 85.107 (87.124)\n",
      "Epoch: [57][30/96]\tLoss 0.3141 (0.2654)\taccuracy 84.375 (89.617)\tf1_score 84.793 (87.197)\n",
      "Epoch: [57][35/96]\tLoss 0.2485 (0.2555)\taccuracy 89.062 (89.974)\tf1_score 91.241 (87.770)\n",
      "Epoch: [57][40/96]\tLoss 0.3069 (0.2589)\taccuracy 85.938 (89.863)\tf1_score 86.028 (87.880)\n",
      "Epoch: [57][45/96]\tLoss 0.1898 (0.2507)\taccuracy 92.188 (90.183)\tf1_score 86.954 (88.161)\n",
      "Epoch: [57][50/96]\tLoss 0.2531 (0.2459)\taccuracy 90.625 (90.441)\tf1_score 88.672 (88.527)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [57][55/96]\tLoss 0.2755 (0.2469)\taccuracy 90.625 (90.430)\tf1_score 83.807 (88.331)\n",
      "Epoch: [57][60/96]\tLoss 0.2945 (0.2570)\taccuracy 89.062 (90.061)\tf1_score 90.025 (88.050)\n",
      "Epoch: [57][65/96]\tLoss 0.5054 (0.2624)\taccuracy 81.250 (89.867)\tf1_score 81.138 (87.790)\n",
      "Epoch: [57][70/96]\tLoss 0.3502 (0.2636)\taccuracy 87.500 (89.877)\tf1_score 85.079 (87.637)\n",
      "Epoch: [57][75/96]\tLoss 0.2161 (0.2619)\taccuracy 93.750 (90.029)\tf1_score 91.119 (87.680)\n",
      "Epoch: [57][80/96]\tLoss 0.2336 (0.2596)\taccuracy 90.625 (90.066)\tf1_score 90.369 (87.702)\n",
      "Epoch: [57][85/96]\tLoss 0.2471 (0.2558)\taccuracy 93.750 (90.243)\tf1_score 91.069 (87.928)\n",
      "Epoch: [57][90/96]\tLoss 0.1746 (0.2528)\taccuracy 93.750 (90.350)\tf1_score 93.209 (88.025)\n",
      "Epoch: [57][95/96]\tLoss 0.3601 (0.2516)\taccuracy 87.500 (90.348)\tf1_score 82.381 (87.995)\n",
      " Test: accuracy 77.669 f1_score 73.222\n",
      "Training time:  925.2865269184113 Hour:  0 Minute:  15 Second:  25 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 58\n",
      "Epoch: [58][0/96]\tLoss 0.4682 (0.4682)\taccuracy 84.375 (84.375)\tf1_score 76.755 (76.755)\n",
      "Epoch: [58][5/96]\tLoss 0.3666 (0.2653)\taccuracy 89.062 (91.146)\tf1_score 91.089 (87.742)\n",
      "Epoch: [58][10/96]\tLoss 0.4256 (0.2972)\taccuracy 85.938 (89.773)\tf1_score 83.354 (87.723)\n",
      "Epoch: [58][15/96]\tLoss 0.1834 (0.2874)\taccuracy 92.188 (89.844)\tf1_score 86.165 (87.666)\n",
      "Epoch: [58][20/96]\tLoss 0.2818 (0.3016)\taccuracy 89.062 (89.137)\tf1_score 87.413 (86.990)\n",
      "Epoch: [58][25/96]\tLoss 0.1598 (0.2905)\taccuracy 92.188 (89.423)\tf1_score 91.083 (87.583)\n",
      "Epoch: [58][30/96]\tLoss 0.2295 (0.3036)\taccuracy 90.625 (88.710)\tf1_score 80.905 (86.015)\n",
      "Epoch: [58][35/96]\tLoss 0.2307 (0.2918)\taccuracy 92.188 (89.149)\tf1_score 90.192 (86.659)\n",
      "Epoch: [58][40/96]\tLoss 0.2009 (0.2791)\taccuracy 93.750 (89.634)\tf1_score 86.282 (86.987)\n",
      "Epoch: [58][45/96]\tLoss 0.1927 (0.2782)\taccuracy 92.188 (89.674)\tf1_score 90.536 (87.199)\n",
      "Epoch: [58][50/96]\tLoss 0.2040 (0.2688)\taccuracy 89.062 (89.890)\tf1_score 88.182 (87.495)\n",
      "Epoch: [58][55/96]\tLoss 0.3906 (0.2659)\taccuracy 82.812 (90.039)\tf1_score 88.309 (87.787)\n",
      "Epoch: [58][60/96]\tLoss 0.1969 (0.2633)\taccuracy 92.188 (90.036)\tf1_score 88.020 (87.855)\n",
      "Epoch: [58][65/96]\tLoss 0.2467 (0.2573)\taccuracy 89.062 (90.223)\tf1_score 83.953 (88.106)\n",
      "Epoch: [58][70/96]\tLoss 0.2436 (0.2542)\taccuracy 87.500 (90.251)\tf1_score 88.155 (88.252)\n",
      "Epoch: [58][75/96]\tLoss 0.1982 (0.2541)\taccuracy 90.625 (90.234)\tf1_score 91.047 (88.286)\n",
      "Epoch: [58][80/96]\tLoss 0.1978 (0.2492)\taccuracy 93.750 (90.471)\tf1_score 93.084 (88.499)\n",
      "Epoch: [58][85/96]\tLoss 0.2759 (0.2462)\taccuracy 87.500 (90.552)\tf1_score 87.401 (88.578)\n",
      "Epoch: [58][90/96]\tLoss 0.2549 (0.2445)\taccuracy 89.062 (90.573)\tf1_score 85.272 (88.540)\n",
      "Epoch: [58][95/96]\tLoss 0.1535 (0.2460)\taccuracy 96.875 (90.527)\tf1_score 92.332 (88.300)\n",
      " Test: accuracy 59.049 f1_score 51.962\n",
      "Training time:  941.0390028953552 Hour:  0 Minute:  15 Second:  41 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 59\n",
      "Epoch: [59][0/96]\tLoss 0.2193 (0.2193)\taccuracy 90.625 (90.625)\tf1_score 89.921 (89.921)\n",
      "Epoch: [59][5/96]\tLoss 0.1893 (0.2052)\taccuracy 92.188 (91.667)\tf1_score 86.710 (88.597)\n",
      "Epoch: [59][10/96]\tLoss 0.1414 (0.2403)\taccuracy 95.312 (90.483)\tf1_score 96.224 (89.101)\n",
      "Epoch: [59][15/96]\tLoss 0.1051 (0.2109)\taccuracy 96.875 (91.699)\tf1_score 97.276 (90.465)\n",
      "Epoch: [59][20/96]\tLoss 0.2962 (0.2235)\taccuracy 92.188 (91.369)\tf1_score 85.952 (89.539)\n",
      "Epoch: [59][25/96]\tLoss 0.2093 (0.2153)\taccuracy 90.625 (91.647)\tf1_score 89.714 (90.005)\n",
      "Epoch: [59][30/96]\tLoss 0.1904 (0.2107)\taccuracy 92.188 (91.835)\tf1_score 80.748 (89.895)\n",
      "Epoch: [59][35/96]\tLoss 0.1679 (0.2060)\taccuracy 93.750 (92.014)\tf1_score 91.429 (90.099)\n",
      "Epoch: [59][40/96]\tLoss 0.2246 (0.2048)\taccuracy 90.625 (92.073)\tf1_score 86.961 (89.928)\n",
      "Epoch: [59][45/96]\tLoss 0.1445 (0.2186)\taccuracy 95.312 (91.406)\tf1_score 91.905 (89.251)\n",
      "Epoch: [59][50/96]\tLoss 0.2421 (0.2240)\taccuracy 90.625 (91.176)\tf1_score 91.071 (88.883)\n",
      "Epoch: [59][55/96]\tLoss 0.2230 (0.2245)\taccuracy 90.625 (91.211)\tf1_score 89.667 (89.058)\n",
      "Epoch: [59][60/96]\tLoss 0.2833 (0.2285)\taccuracy 85.938 (90.984)\tf1_score 80.559 (88.740)\n",
      "Epoch: [59][65/96]\tLoss 0.1643 (0.2307)\taccuracy 96.875 (90.862)\tf1_score 96.667 (88.703)\n",
      "Epoch: [59][70/96]\tLoss 0.2065 (0.2305)\taccuracy 93.750 (90.911)\tf1_score 93.815 (88.772)\n",
      "Epoch: [59][75/96]\tLoss 0.4422 (0.2334)\taccuracy 79.688 (90.707)\tf1_score 76.634 (88.503)\n",
      "Epoch: [59][80/96]\tLoss 0.3645 (0.2353)\taccuracy 89.062 (90.683)\tf1_score 92.177 (88.613)\n",
      "Epoch: [59][85/96]\tLoss 0.4178 (0.2416)\taccuracy 79.688 (90.425)\tf1_score 78.435 (88.365)\n",
      "Epoch: [59][90/96]\tLoss 0.3842 (0.2476)\taccuracy 84.375 (90.110)\tf1_score 84.143 (87.961)\n",
      "Epoch: [59][95/96]\tLoss 0.2270 (0.2516)\taccuracy 90.625 (89.827)\tf1_score 89.471 (87.723)\n",
      " Test: accuracy 61.849 f1_score 56.002\n",
      "Training time:  956.7885966300964 Hour:  0 Minute:  15 Second:  56 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 60\n",
      "Epoch: [60][0/96]\tLoss 0.2020 (0.2020)\taccuracy 90.625 (90.625)\tf1_score 89.153 (89.153)\n",
      "Epoch: [60][5/96]\tLoss 0.2746 (0.2860)\taccuracy 89.062 (89.062)\tf1_score 88.740 (86.721)\n",
      "Epoch: [60][10/96]\tLoss 0.1718 (0.2879)\taccuracy 93.750 (89.489)\tf1_score 95.897 (87.694)\n",
      "Epoch: [60][15/96]\tLoss 0.2957 (0.2757)\taccuracy 85.938 (89.648)\tf1_score 80.722 (87.242)\n",
      "Epoch: [60][20/96]\tLoss 0.4318 (0.2755)\taccuracy 89.062 (89.807)\tf1_score 84.794 (87.388)\n",
      "Epoch: [60][25/96]\tLoss 0.1961 (0.2696)\taccuracy 90.625 (89.844)\tf1_score 89.275 (87.175)\n",
      "Epoch: [60][30/96]\tLoss 0.2062 (0.2746)\taccuracy 92.188 (89.970)\tf1_score 90.212 (87.129)\n",
      "Epoch: [60][35/96]\tLoss 0.3962 (0.3014)\taccuracy 82.812 (88.932)\tf1_score 82.814 (86.241)\n",
      "Epoch: [60][40/96]\tLoss 0.2430 (0.2920)\taccuracy 89.062 (89.253)\tf1_score 90.494 (86.784)\n",
      "Epoch: [60][45/96]\tLoss 0.2057 (0.2848)\taccuracy 92.188 (89.504)\tf1_score 92.600 (87.137)\n",
      "Epoch: [60][50/96]\tLoss 0.2336 (0.2829)\taccuracy 90.625 (89.308)\tf1_score 88.076 (87.032)\n",
      "Epoch: [60][55/96]\tLoss 0.3252 (0.2856)\taccuracy 90.625 (89.118)\tf1_score 87.593 (86.771)\n",
      "Epoch: [60][60/96]\tLoss 0.3365 (0.2906)\taccuracy 84.375 (88.858)\tf1_score 85.572 (86.530)\n",
      "Epoch: [60][65/96]\tLoss 0.5920 (0.2959)\taccuracy 75.000 (88.684)\tf1_score 73.288 (86.320)\n",
      "Epoch: [60][70/96]\tLoss 0.3883 (0.3101)\taccuracy 85.938 (88.270)\tf1_score 85.801 (85.886)\n",
      "Epoch: [60][75/96]\tLoss 0.2007 (0.3084)\taccuracy 95.312 (88.405)\tf1_score 90.616 (85.977)\n",
      "Epoch: [60][80/96]\tLoss 0.2847 (0.3083)\taccuracy 87.500 (88.426)\tf1_score 84.974 (85.977)\n",
      "Epoch: [60][85/96]\tLoss 0.3401 (0.3063)\taccuracy 90.625 (88.445)\tf1_score 83.029 (85.964)\n",
      "Epoch: [60][90/96]\tLoss 0.2210 (0.3029)\taccuracy 93.750 (88.616)\tf1_score 94.346 (86.222)\n",
      "Epoch: [60][95/96]\tLoss 0.3243 (0.3050)\taccuracy 85.938 (88.525)\tf1_score 81.784 (86.114)\n",
      " Test: accuracy 83.203 f1_score 78.563\n",
      "Training time:  972.5660226345062 Hour:  0 Minute:  16 Second:  12 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 61\n",
      "Epoch: [61][0/96]\tLoss 0.2818 (0.2818)\taccuracy 82.812 (82.812)\tf1_score 78.148 (78.148)\n",
      "Epoch: [61][5/96]\tLoss 0.2827 (0.2533)\taccuracy 87.500 (88.281)\tf1_score 88.730 (86.792)\n",
      "Epoch: [61][10/96]\tLoss 0.2591 (0.2735)\taccuracy 84.375 (87.642)\tf1_score 80.254 (84.805)\n",
      "Epoch: [61][15/96]\tLoss 0.3719 (0.2670)\taccuracy 85.938 (88.281)\tf1_score 82.424 (85.524)\n",
      "Epoch: [61][20/96]\tLoss 0.1502 (0.2634)\taccuracy 96.875 (89.286)\tf1_score 97.617 (86.374)\n",
      "Epoch: [61][25/96]\tLoss 0.3023 (0.2559)\taccuracy 89.062 (89.663)\tf1_score 90.357 (86.733)\n",
      "Epoch: [61][30/96]\tLoss 0.2181 (0.2589)\taccuracy 92.188 (89.819)\tf1_score 92.897 (87.190)\n",
      "Epoch: [61][35/96]\tLoss 0.1411 (0.2550)\taccuracy 93.750 (89.974)\tf1_score 88.753 (87.328)\n",
      "Epoch: [61][40/96]\tLoss 0.1672 (0.2505)\taccuracy 95.312 (90.282)\tf1_score 96.372 (87.613)\n",
      "Epoch: [61][45/96]\tLoss 0.2918 (0.2480)\taccuracy 89.062 (90.319)\tf1_score 89.314 (87.814)\n",
      "Epoch: [61][50/96]\tLoss 0.1995 (0.2441)\taccuracy 93.750 (90.257)\tf1_score 93.413 (87.813)\n",
      "Epoch: [61][55/96]\tLoss 0.2443 (0.2415)\taccuracy 90.625 (90.402)\tf1_score 85.844 (88.084)\n",
      "Epoch: [61][60/96]\tLoss 0.4485 (0.2451)\taccuracy 82.812 (90.215)\tf1_score 77.148 (87.804)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61][65/96]\tLoss 0.1484 (0.2524)\taccuracy 89.062 (89.986)\tf1_score 86.315 (87.562)\n",
      "Epoch: [61][70/96]\tLoss 0.4532 (0.2535)\taccuracy 82.812 (89.877)\tf1_score 77.162 (87.492)\n",
      "Epoch: [61][75/96]\tLoss 0.2073 (0.2564)\taccuracy 92.188 (89.885)\tf1_score 90.986 (87.622)\n",
      "Epoch: [61][80/96]\tLoss 0.2227 (0.2557)\taccuracy 90.625 (89.950)\tf1_score 88.952 (87.583)\n",
      "Epoch: [61][85/96]\tLoss 0.2453 (0.2563)\taccuracy 90.625 (90.007)\tf1_score 91.349 (87.684)\n",
      "Epoch: [61][90/96]\tLoss 0.2916 (0.2592)\taccuracy 90.625 (89.921)\tf1_score 91.905 (87.693)\n",
      "Epoch: [61][95/96]\tLoss 0.1444 (0.2565)\taccuracy 98.438 (90.072)\tf1_score 98.545 (87.830)\n",
      " Test: accuracy 77.799 f1_score 74.135\n",
      "Training time:  988.9084057807922 Hour:  0 Minute:  16 Second:  28 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 62\n",
      "Epoch: [62][0/96]\tLoss 0.2592 (0.2592)\taccuracy 89.062 (89.062)\tf1_score 87.519 (87.519)\n",
      "Epoch: [62][5/96]\tLoss 0.1985 (0.2238)\taccuracy 92.188 (90.885)\tf1_score 92.314 (89.473)\n",
      "Epoch: [62][10/96]\tLoss 0.0979 (0.2019)\taccuracy 96.875 (91.761)\tf1_score 95.828 (90.236)\n",
      "Epoch: [62][15/96]\tLoss 0.1704 (0.1900)\taccuracy 96.875 (92.578)\tf1_score 96.617 (91.554)\n",
      "Epoch: [62][20/96]\tLoss 0.1348 (0.1916)\taccuracy 93.750 (92.485)\tf1_score 90.071 (91.117)\n",
      "Epoch: [62][25/96]\tLoss 0.2322 (0.1938)\taccuracy 90.625 (92.188)\tf1_score 89.413 (90.751)\n",
      "Epoch: [62][30/96]\tLoss 0.1896 (0.1875)\taccuracy 90.625 (92.339)\tf1_score 90.317 (90.986)\n",
      "Epoch: [62][35/96]\tLoss 0.1519 (0.1876)\taccuracy 93.750 (92.535)\tf1_score 90.079 (91.044)\n",
      "Epoch: [62][40/96]\tLoss 0.1768 (0.1865)\taccuracy 93.750 (92.645)\tf1_score 88.238 (90.937)\n",
      "Epoch: [62][45/96]\tLoss 0.3034 (0.1857)\taccuracy 89.062 (92.833)\tf1_score 90.576 (91.212)\n",
      "Epoch: [62][50/96]\tLoss 0.2580 (0.1918)\taccuracy 89.062 (92.555)\tf1_score 85.710 (90.969)\n",
      "Epoch: [62][55/96]\tLoss 0.3135 (0.1954)\taccuracy 87.500 (92.439)\tf1_score 85.405 (90.866)\n",
      "Epoch: [62][60/96]\tLoss 0.1243 (0.1941)\taccuracy 95.312 (92.495)\tf1_score 95.746 (91.086)\n",
      "Epoch: [62][65/96]\tLoss 0.2688 (0.1931)\taccuracy 85.938 (92.543)\tf1_score 85.604 (91.211)\n",
      "Epoch: [62][70/96]\tLoss 0.2975 (0.1943)\taccuracy 85.938 (92.474)\tf1_score 87.256 (91.150)\n",
      "Epoch: [62][75/96]\tLoss 0.3540 (0.1956)\taccuracy 87.500 (92.331)\tf1_score 83.997 (90.932)\n",
      "Epoch: [62][80/96]\tLoss 0.1782 (0.2000)\taccuracy 92.188 (92.052)\tf1_score 87.653 (90.611)\n",
      "Epoch: [62][85/96]\tLoss 0.3318 (0.2084)\taccuracy 84.375 (91.751)\tf1_score 79.024 (90.351)\n",
      "Epoch: [62][90/96]\tLoss 0.1218 (0.2061)\taccuracy 96.875 (91.861)\tf1_score 93.333 (90.450)\n",
      "Epoch: [62][95/96]\tLoss 0.4455 (0.2133)\taccuracy 81.250 (91.569)\tf1_score 69.052 (90.050)\n",
      " Test: accuracy 73.633 f1_score 71.550\n",
      "Training time:  1004.6926815509796 Hour:  0 Minute:  16 Second:  44 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 63\n",
      "Epoch: [63][0/96]\tLoss 0.1642 (0.1642)\taccuracy 98.438 (98.438)\tf1_score 97.778 (97.778)\n",
      "Epoch: [63][5/96]\tLoss 0.3438 (0.2907)\taccuracy 84.375 (89.844)\tf1_score 83.289 (87.577)\n",
      "Epoch: [63][10/96]\tLoss 0.2495 (0.2771)\taccuracy 87.500 (89.489)\tf1_score 84.743 (85.403)\n",
      "Epoch: [63][15/96]\tLoss 0.1801 (0.2602)\taccuracy 93.750 (90.137)\tf1_score 89.158 (85.931)\n",
      "Epoch: [63][20/96]\tLoss 0.3708 (0.2619)\taccuracy 87.500 (90.179)\tf1_score 78.452 (86.280)\n",
      "Epoch: [63][25/96]\tLoss 0.2911 (0.2552)\taccuracy 87.500 (90.024)\tf1_score 82.177 (86.486)\n",
      "Epoch: [63][30/96]\tLoss 0.2103 (0.2615)\taccuracy 92.188 (89.970)\tf1_score 91.938 (86.783)\n",
      "Epoch: [63][35/96]\tLoss 0.3953 (0.2628)\taccuracy 87.500 (89.887)\tf1_score 86.132 (86.555)\n",
      "Epoch: [63][40/96]\tLoss 0.2627 (0.2667)\taccuracy 89.062 (89.939)\tf1_score 87.794 (86.785)\n",
      "Epoch: [63][45/96]\tLoss 0.3012 (0.2676)\taccuracy 89.062 (89.912)\tf1_score 77.821 (86.653)\n",
      "Epoch: [63][50/96]\tLoss 0.2560 (0.2662)\taccuracy 87.500 (89.920)\tf1_score 86.498 (86.855)\n",
      "Epoch: [63][55/96]\tLoss 0.4540 (0.2666)\taccuracy 81.250 (89.927)\tf1_score 85.420 (87.037)\n",
      "Epoch: [63][60/96]\tLoss 0.2014 (0.2633)\taccuracy 93.750 (90.010)\tf1_score 92.952 (87.122)\n",
      "Epoch: [63][65/96]\tLoss 0.2275 (0.2623)\taccuracy 92.188 (89.962)\tf1_score 91.026 (87.220)\n",
      "Epoch: [63][70/96]\tLoss 0.1292 (0.2577)\taccuracy 96.875 (90.273)\tf1_score 96.138 (87.562)\n",
      "Epoch: [63][75/96]\tLoss 0.2413 (0.2550)\taccuracy 87.500 (90.337)\tf1_score 84.762 (87.551)\n",
      "Epoch: [63][80/96]\tLoss 0.2266 (0.2541)\taccuracy 90.625 (90.316)\tf1_score 90.672 (87.584)\n",
      "Epoch: [63][85/96]\tLoss 0.2382 (0.2550)\taccuracy 90.625 (90.334)\tf1_score 79.734 (87.557)\n",
      "Epoch: [63][90/96]\tLoss 0.3247 (0.2607)\taccuracy 87.500 (90.093)\tf1_score 84.817 (87.336)\n",
      "Epoch: [63][95/96]\tLoss 0.1627 (0.2596)\taccuracy 93.750 (90.169)\tf1_score 94.180 (87.483)\n",
      " Test: accuracy 79.688 f1_score 75.071\n",
      "Training time:  1020.5452599525452 Hour:  0 Minute:  17 Second:  0 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 64\n",
      "Epoch: [64][0/96]\tLoss 0.2609 (0.2609)\taccuracy 90.625 (90.625)\tf1_score 92.418 (92.418)\n",
      "Epoch: [64][5/96]\tLoss 0.2435 (0.2643)\taccuracy 89.062 (89.844)\tf1_score 87.129 (88.966)\n",
      "Epoch: [64][10/96]\tLoss 0.1805 (0.2370)\taccuracy 92.188 (91.335)\tf1_score 92.290 (90.179)\n",
      "Epoch: [64][15/96]\tLoss 0.3506 (0.2320)\taccuracy 89.062 (91.309)\tf1_score 85.828 (89.691)\n",
      "Epoch: [64][20/96]\tLoss 0.2527 (0.2328)\taccuracy 87.500 (91.071)\tf1_score 88.686 (89.338)\n",
      "Epoch: [64][25/96]\tLoss 0.3421 (0.2376)\taccuracy 84.375 (90.986)\tf1_score 76.640 (89.312)\n",
      "Epoch: [64][30/96]\tLoss 0.2249 (0.2455)\taccuracy 90.625 (90.877)\tf1_score 90.637 (89.203)\n",
      "Epoch: [64][35/96]\tLoss 0.1859 (0.2415)\taccuracy 92.188 (90.799)\tf1_score 90.160 (88.878)\n",
      "Epoch: [64][40/96]\tLoss 0.1450 (0.2339)\taccuracy 93.750 (91.159)\tf1_score 90.519 (89.241)\n",
      "Epoch: [64][45/96]\tLoss 0.2984 (0.2274)\taccuracy 84.375 (91.270)\tf1_score 85.742 (89.176)\n",
      "Epoch: [64][50/96]\tLoss 0.2555 (0.2305)\taccuracy 87.500 (91.207)\tf1_score 81.607 (89.089)\n",
      "Epoch: [64][55/96]\tLoss 0.1636 (0.2269)\taccuracy 92.188 (91.406)\tf1_score 89.864 (89.160)\n",
      "Epoch: [64][60/96]\tLoss 0.3094 (0.2240)\taccuracy 85.938 (91.393)\tf1_score 88.675 (89.217)\n",
      "Epoch: [64][65/96]\tLoss 0.1331 (0.2275)\taccuracy 93.750 (91.217)\tf1_score 92.993 (88.961)\n",
      "Epoch: [64][70/96]\tLoss 0.2581 (0.2288)\taccuracy 87.500 (91.131)\tf1_score 89.854 (88.936)\n",
      "Epoch: [64][75/96]\tLoss 0.1710 (0.2296)\taccuracy 92.188 (91.098)\tf1_score 88.175 (88.847)\n",
      "Epoch: [64][80/96]\tLoss 0.3951 (0.2338)\taccuracy 89.062 (90.992)\tf1_score 87.609 (88.815)\n",
      "Epoch: [64][85/96]\tLoss 0.2686 (0.2342)\taccuracy 89.062 (91.007)\tf1_score 89.278 (88.826)\n",
      "Epoch: [64][90/96]\tLoss 0.3283 (0.2354)\taccuracy 82.812 (90.951)\tf1_score 81.693 (88.847)\n",
      "Epoch: [64][95/96]\tLoss 0.3094 (0.2372)\taccuracy 87.500 (90.788)\tf1_score 83.911 (88.662)\n",
      " Test: accuracy 77.344 f1_score 73.936\n",
      "Training time:  1036.279661655426 Hour:  0 Minute:  17 Second:  16 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 65\n",
      "Epoch: [65][0/96]\tLoss 0.1879 (0.1879)\taccuracy 95.312 (95.312)\tf1_score 96.412 (96.412)\n",
      "Epoch: [65][5/96]\tLoss 0.4426 (0.2577)\taccuracy 84.375 (91.146)\tf1_score 82.340 (87.828)\n",
      "Epoch: [65][10/96]\tLoss 0.2069 (0.2406)\taccuracy 90.625 (91.051)\tf1_score 89.019 (87.630)\n",
      "Epoch: [65][15/96]\tLoss 0.2087 (0.2633)\taccuracy 89.062 (90.137)\tf1_score 87.108 (87.475)\n",
      "Epoch: [65][20/96]\tLoss 0.3252 (0.2685)\taccuracy 90.625 (89.881)\tf1_score 85.081 (87.035)\n",
      "Epoch: [65][25/96]\tLoss 0.2501 (0.2665)\taccuracy 95.312 (90.204)\tf1_score 91.338 (87.609)\n",
      "Epoch: [65][30/96]\tLoss 0.2266 (0.2613)\taccuracy 90.625 (90.222)\tf1_score 87.417 (87.432)\n",
      "Epoch: [65][35/96]\tLoss 0.1714 (0.2591)\taccuracy 95.312 (90.408)\tf1_score 95.590 (87.732)\n",
      "Epoch: [65][40/96]\tLoss 0.2710 (0.2546)\taccuracy 87.500 (90.434)\tf1_score 85.944 (87.586)\n",
      "Epoch: [65][45/96]\tLoss 0.2759 (0.2525)\taccuracy 90.625 (90.693)\tf1_score 86.228 (87.909)\n",
      "Epoch: [65][50/96]\tLoss 0.2029 (0.2483)\taccuracy 92.188 (90.717)\tf1_score 88.269 (88.050)\n",
      "Epoch: [65][55/96]\tLoss 0.1095 (0.2415)\taccuracy 95.312 (91.016)\tf1_score 95.063 (88.349)\n",
      "Epoch: [65][60/96]\tLoss 0.1182 (0.2359)\taccuracy 98.438 (91.317)\tf1_score 98.367 (88.805)\n",
      "Epoch: [65][65/96]\tLoss 0.1803 (0.2309)\taccuracy 95.312 (91.383)\tf1_score 93.500 (88.825)\n",
      "Epoch: [65][70/96]\tLoss 0.1478 (0.2290)\taccuracy 95.312 (91.439)\tf1_score 96.230 (89.056)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [65][75/96]\tLoss 0.3159 (0.2290)\taccuracy 85.938 (91.386)\tf1_score 82.623 (89.031)\n",
      "Epoch: [65][80/96]\tLoss 0.3803 (0.2300)\taccuracy 85.938 (91.397)\tf1_score 87.667 (89.179)\n",
      "Epoch: [65][85/96]\tLoss 0.2955 (0.2290)\taccuracy 89.062 (91.388)\tf1_score 87.006 (89.244)\n",
      "Epoch: [65][90/96]\tLoss 0.2372 (0.2263)\taccuracy 90.625 (91.466)\tf1_score 83.144 (89.173)\n",
      "Epoch: [65][95/96]\tLoss 0.1124 (0.2226)\taccuracy 95.312 (91.618)\tf1_score 90.965 (89.348)\n",
      " Test: accuracy 81.966 f1_score 78.554\n",
      "Training time:  1052.012568950653 Hour:  0 Minute:  17 Second:  32 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 66\n",
      "Epoch: [66][0/96]\tLoss 0.4624 (0.4624)\taccuracy 81.250 (81.250)\tf1_score 78.942 (78.942)\n",
      "Epoch: [66][5/96]\tLoss 0.1458 (0.2450)\taccuracy 95.312 (90.885)\tf1_score 92.352 (89.258)\n",
      "Epoch: [66][10/96]\tLoss 0.1559 (0.2395)\taccuracy 90.625 (90.909)\tf1_score 90.401 (89.255)\n",
      "Epoch: [66][15/96]\tLoss 0.4230 (0.2366)\taccuracy 79.688 (90.137)\tf1_score 76.333 (88.052)\n",
      "Epoch: [66][20/96]\tLoss 0.2791 (0.2475)\taccuracy 95.312 (90.476)\tf1_score 96.901 (88.517)\n",
      "Epoch: [66][25/96]\tLoss 0.1330 (0.2447)\taccuracy 95.312 (90.805)\tf1_score 91.970 (88.850)\n",
      "Epoch: [66][30/96]\tLoss 0.2707 (0.2393)\taccuracy 89.062 (91.179)\tf1_score 86.857 (89.411)\n",
      "Epoch: [66][35/96]\tLoss 0.3499 (0.2380)\taccuracy 87.500 (91.146)\tf1_score 84.488 (89.516)\n",
      "Epoch: [66][40/96]\tLoss 0.2898 (0.2335)\taccuracy 89.062 (91.197)\tf1_score 89.229 (89.651)\n",
      "Epoch: [66][45/96]\tLoss 0.1339 (0.2355)\taccuracy 98.438 (91.067)\tf1_score 97.884 (89.579)\n",
      "Epoch: [66][50/96]\tLoss 0.1977 (0.2328)\taccuracy 92.188 (91.238)\tf1_score 89.821 (89.772)\n",
      "Epoch: [66][55/96]\tLoss 0.1662 (0.2416)\taccuracy 93.750 (91.099)\tf1_score 92.963 (89.691)\n",
      "Epoch: [66][60/96]\tLoss 0.5725 (0.2468)\taccuracy 84.375 (91.009)\tf1_score 81.859 (89.410)\n",
      "Epoch: [66][65/96]\tLoss 0.3579 (0.2576)\taccuracy 87.500 (90.649)\tf1_score 89.337 (89.056)\n",
      "Epoch: [66][70/96]\tLoss 0.3105 (0.2578)\taccuracy 93.750 (90.603)\tf1_score 90.652 (89.037)\n",
      "Epoch: [66][75/96]\tLoss 0.2348 (0.2655)\taccuracy 90.625 (90.378)\tf1_score 87.155 (88.508)\n",
      "Epoch: [66][80/96]\tLoss 0.2848 (0.2788)\taccuracy 87.500 (89.988)\tf1_score 84.482 (88.012)\n",
      "Epoch: [66][85/96]\tLoss 0.2698 (0.2807)\taccuracy 87.500 (89.826)\tf1_score 85.107 (87.718)\n",
      "Epoch: [66][90/96]\tLoss 0.2457 (0.2818)\taccuracy 90.625 (89.749)\tf1_score 90.444 (87.600)\n",
      "Epoch: [66][95/96]\tLoss 0.3072 (0.2825)\taccuracy 85.938 (89.632)\tf1_score 88.099 (87.511)\n",
      " Test: accuracy 70.117 f1_score 64.653\n",
      "Training time:  1067.782136440277 Hour:  0 Minute:  17 Second:  47 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 67\n",
      "Epoch: [67][0/96]\tLoss 0.3193 (0.3193)\taccuracy 82.812 (82.812)\tf1_score 83.028 (83.028)\n",
      "Epoch: [67][5/96]\tLoss 0.2427 (0.2634)\taccuracy 85.938 (89.062)\tf1_score 83.555 (87.053)\n",
      "Epoch: [67][10/96]\tLoss 0.3009 (0.2695)\taccuracy 82.812 (87.784)\tf1_score 84.369 (86.261)\n",
      "Epoch: [67][15/96]\tLoss 0.5513 (0.2639)\taccuracy 85.938 (89.551)\tf1_score 82.136 (88.015)\n",
      "Epoch: [67][20/96]\tLoss 0.3112 (0.2598)\taccuracy 87.500 (89.955)\tf1_score 80.173 (87.852)\n",
      "Epoch: [67][25/96]\tLoss 0.2333 (0.2548)\taccuracy 89.062 (89.964)\tf1_score 80.340 (87.704)\n",
      "Epoch: [67][30/96]\tLoss 0.1343 (0.2518)\taccuracy 96.875 (90.323)\tf1_score 96.857 (88.344)\n",
      "Epoch: [67][35/96]\tLoss 0.1785 (0.2472)\taccuracy 92.188 (90.495)\tf1_score 92.804 (88.259)\n",
      "Epoch: [67][40/96]\tLoss 0.1205 (0.2459)\taccuracy 95.312 (90.549)\tf1_score 93.605 (88.447)\n",
      "Epoch: [67][45/96]\tLoss 0.1630 (0.2423)\taccuracy 92.188 (90.659)\tf1_score 93.206 (88.655)\n",
      "Epoch: [67][50/96]\tLoss 0.1610 (0.2371)\taccuracy 93.750 (90.748)\tf1_score 88.119 (88.652)\n",
      "Epoch: [67][55/96]\tLoss 0.2011 (0.2362)\taccuracy 92.188 (90.792)\tf1_score 88.307 (88.652)\n",
      "Epoch: [67][60/96]\tLoss 0.2233 (0.2318)\taccuracy 92.188 (91.060)\tf1_score 87.897 (88.924)\n",
      "Epoch: [67][65/96]\tLoss 0.2194 (0.2311)\taccuracy 90.625 (91.122)\tf1_score 90.423 (88.964)\n",
      "Epoch: [67][70/96]\tLoss 0.3293 (0.2324)\taccuracy 89.062 (91.131)\tf1_score 86.477 (88.993)\n",
      "Epoch: [67][75/96]\tLoss 0.2286 (0.2298)\taccuracy 93.750 (91.262)\tf1_score 91.383 (89.084)\n",
      "Epoch: [67][80/96]\tLoss 0.2821 (0.2287)\taccuracy 84.375 (91.184)\tf1_score 80.994 (89.043)\n",
      "Epoch: [67][85/96]\tLoss 0.2397 (0.2315)\taccuracy 90.625 (91.079)\tf1_score 92.086 (88.989)\n",
      "Epoch: [67][90/96]\tLoss 0.1799 (0.2305)\taccuracy 93.750 (91.123)\tf1_score 89.524 (89.004)\n",
      "Epoch: [67][95/96]\tLoss 0.3344 (0.2331)\taccuracy 87.500 (91.081)\tf1_score 87.412 (88.967)\n",
      " Test: accuracy 88.281 f1_score 85.567\n",
      "Training time:  1083.5038194656372 Hour:  0 Minute:  18 Second:  3 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 68\n",
      "Epoch: [68][0/96]\tLoss 0.2520 (0.2520)\taccuracy 89.062 (89.062)\tf1_score 87.940 (87.940)\n",
      "Epoch: [68][5/96]\tLoss 0.2591 (0.2176)\taccuracy 90.625 (93.229)\tf1_score 87.680 (90.179)\n",
      "Epoch: [68][10/96]\tLoss 0.3150 (0.2392)\taccuracy 87.500 (91.051)\tf1_score 82.147 (88.479)\n",
      "Epoch: [68][15/96]\tLoss 0.3238 (0.2751)\taccuracy 89.062 (89.648)\tf1_score 83.635 (86.925)\n",
      "Epoch: [68][20/96]\tLoss 0.2872 (0.2611)\taccuracy 87.500 (90.327)\tf1_score 86.130 (88.066)\n",
      "Epoch: [68][25/96]\tLoss 0.3093 (0.2692)\taccuracy 87.500 (89.784)\tf1_score 83.524 (87.362)\n",
      "Epoch: [68][30/96]\tLoss 0.2206 (0.2735)\taccuracy 87.500 (89.315)\tf1_score 85.343 (87.033)\n",
      "Epoch: [68][35/96]\tLoss 0.1742 (0.2648)\taccuracy 90.625 (89.497)\tf1_score 91.474 (87.431)\n",
      "Epoch: [68][40/96]\tLoss 0.4418 (0.2688)\taccuracy 85.938 (89.405)\tf1_score 77.177 (87.104)\n",
      "Epoch: [68][45/96]\tLoss 0.1667 (0.2663)\taccuracy 95.312 (89.436)\tf1_score 88.399 (87.214)\n",
      "Epoch: [68][50/96]\tLoss 0.2044 (0.2601)\taccuracy 87.500 (89.491)\tf1_score 86.199 (87.337)\n",
      "Epoch: [68][55/96]\tLoss 0.3120 (0.2589)\taccuracy 87.500 (89.593)\tf1_score 85.488 (87.271)\n",
      "Epoch: [68][60/96]\tLoss 0.1977 (0.2538)\taccuracy 90.625 (89.780)\tf1_score 85.599 (87.576)\n",
      "Epoch: [68][65/96]\tLoss 0.3369 (0.2566)\taccuracy 85.938 (89.820)\tf1_score 76.406 (87.373)\n",
      "Epoch: [68][70/96]\tLoss 0.2596 (0.2547)\taccuracy 92.188 (89.943)\tf1_score 89.500 (87.506)\n",
      "Epoch: [68][75/96]\tLoss 0.1586 (0.2500)\taccuracy 95.312 (90.173)\tf1_score 90.544 (87.654)\n",
      "Epoch: [68][80/96]\tLoss 0.1906 (0.2478)\taccuracy 93.750 (90.297)\tf1_score 95.036 (87.811)\n",
      "Epoch: [68][85/96]\tLoss 0.2174 (0.2479)\taccuracy 87.500 (90.262)\tf1_score 89.000 (87.868)\n",
      "Epoch: [68][90/96]\tLoss 0.2605 (0.2451)\taccuracy 90.625 (90.316)\tf1_score 89.213 (87.989)\n",
      "Epoch: [68][95/96]\tLoss 0.2454 (0.2438)\taccuracy 90.625 (90.397)\tf1_score 88.571 (87.949)\n",
      " Test: accuracy 81.641 f1_score 79.022\n",
      "Training time:  1099.2707002162933 Hour:  0 Minute:  18 Second:  19 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 69\n",
      "Epoch: [69][0/96]\tLoss 0.1373 (0.1373)\taccuracy 95.312 (95.312)\tf1_score 95.797 (95.797)\n",
      "Epoch: [69][5/96]\tLoss 0.1964 (0.1773)\taccuracy 93.750 (93.229)\tf1_score 94.089 (92.762)\n",
      "Epoch: [69][10/96]\tLoss 0.1609 (0.1980)\taccuracy 95.312 (92.614)\tf1_score 91.905 (90.792)\n",
      "Epoch: [69][15/96]\tLoss 0.1551 (0.1858)\taccuracy 95.312 (92.969)\tf1_score 95.556 (91.482)\n",
      "Epoch: [69][20/96]\tLoss 0.2143 (0.1997)\taccuracy 89.062 (92.113)\tf1_score 90.340 (90.815)\n",
      "Epoch: [69][25/96]\tLoss 0.2278 (0.2106)\taccuracy 89.062 (91.587)\tf1_score 85.183 (89.992)\n",
      "Epoch: [69][30/96]\tLoss 0.1958 (0.2025)\taccuracy 89.062 (92.036)\tf1_score 93.417 (90.468)\n",
      "Epoch: [69][35/96]\tLoss 0.2571 (0.1971)\taccuracy 95.312 (92.535)\tf1_score 90.741 (90.912)\n",
      "Epoch: [69][40/96]\tLoss 0.1969 (0.1962)\taccuracy 95.312 (92.492)\tf1_score 93.983 (90.698)\n",
      "Epoch: [69][45/96]\tLoss 0.1922 (0.1947)\taccuracy 90.625 (92.527)\tf1_score 80.823 (90.784)\n",
      "Epoch: [69][50/96]\tLoss 0.1719 (0.1896)\taccuracy 95.312 (92.800)\tf1_score 95.828 (91.101)\n",
      "Epoch: [69][55/96]\tLoss 0.1622 (0.1946)\taccuracy 93.750 (92.634)\tf1_score 88.985 (90.755)\n",
      "Epoch: [69][60/96]\tLoss 0.1535 (0.1976)\taccuracy 92.188 (92.469)\tf1_score 86.621 (90.614)\n",
      "Epoch: [69][65/96]\tLoss 0.2725 (0.1977)\taccuracy 90.625 (92.353)\tf1_score 88.118 (90.457)\n",
      "Epoch: [69][70/96]\tLoss 0.2237 (0.2002)\taccuracy 90.625 (92.386)\tf1_score 89.643 (90.596)\n",
      "Epoch: [69][75/96]\tLoss 0.0714 (0.2007)\taccuracy 98.438 (92.352)\tf1_score 98.000 (90.514)\n",
      "Epoch: [69][80/96]\tLoss 0.3185 (0.2035)\taccuracy 85.938 (92.168)\tf1_score 82.952 (90.394)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][85/96]\tLoss 0.2244 (0.2040)\taccuracy 92.188 (92.115)\tf1_score 91.750 (90.375)\n",
      "Epoch: [69][90/96]\tLoss 0.2274 (0.2061)\taccuracy 90.625 (92.119)\tf1_score 86.893 (90.335)\n",
      "Epoch: [69][95/96]\tLoss 0.2316 (0.2077)\taccuracy 89.062 (92.057)\tf1_score 87.585 (90.315)\n",
      " Test: accuracy 30.859 f1_score 22.541\n",
      "Training time:  1114.9893071651459 Hour:  0 Minute:  18 Second:  34 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 70\n",
      "Epoch: [70][0/96]\tLoss 0.1823 (0.1823)\taccuracy 89.062 (89.062)\tf1_score 86.769 (86.769)\n",
      "Epoch: [70][5/96]\tLoss 0.1730 (0.2281)\taccuracy 92.188 (89.844)\tf1_score 88.683 (86.895)\n",
      "Epoch: [70][10/96]\tLoss 0.1494 (0.2353)\taccuracy 95.312 (90.057)\tf1_score 95.556 (87.999)\n",
      "Epoch: [70][15/96]\tLoss 0.2945 (0.2401)\taccuracy 84.375 (89.746)\tf1_score 75.918 (87.662)\n",
      "Epoch: [70][20/96]\tLoss 0.2367 (0.2332)\taccuracy 89.062 (89.807)\tf1_score 87.857 (87.557)\n",
      "Epoch: [70][25/96]\tLoss 0.2705 (0.2316)\taccuracy 89.062 (89.844)\tf1_score 80.000 (87.565)\n",
      "Epoch: [70][30/96]\tLoss 0.1624 (0.2264)\taccuracy 92.188 (89.970)\tf1_score 90.952 (88.063)\n",
      "Epoch: [70][35/96]\tLoss 0.1172 (0.2192)\taccuracy 96.875 (90.451)\tf1_score 95.905 (88.698)\n",
      "Epoch: [70][40/96]\tLoss 0.1147 (0.2250)\taccuracy 96.875 (90.434)\tf1_score 97.037 (88.753)\n",
      "Epoch: [70][45/96]\tLoss 0.1715 (0.2198)\taccuracy 95.312 (90.727)\tf1_score 95.476 (89.115)\n",
      "Epoch: [70][50/96]\tLoss 0.1632 (0.2173)\taccuracy 92.188 (90.870)\tf1_score 89.928 (89.208)\n",
      "Epoch: [70][55/96]\tLoss 0.3175 (0.2202)\taccuracy 87.500 (90.737)\tf1_score 86.730 (89.033)\n",
      "Epoch: [70][60/96]\tLoss 0.2921 (0.2158)\taccuracy 85.938 (90.984)\tf1_score 85.714 (89.324)\n",
      "Epoch: [70][65/96]\tLoss 0.2846 (0.2154)\taccuracy 89.062 (91.004)\tf1_score 87.246 (89.435)\n",
      "Epoch: [70][70/96]\tLoss 0.1523 (0.2097)\taccuracy 95.312 (91.351)\tf1_score 91.778 (89.797)\n",
      "Epoch: [70][75/96]\tLoss 0.1288 (0.2091)\taccuracy 93.750 (91.386)\tf1_score 90.899 (89.729)\n",
      "Epoch: [70][80/96]\tLoss 0.3368 (0.2125)\taccuracy 87.500 (91.262)\tf1_score 83.839 (89.612)\n",
      "Epoch: [70][85/96]\tLoss 0.2119 (0.2132)\taccuracy 90.625 (91.206)\tf1_score 92.148 (89.411)\n",
      "Epoch: [70][90/96]\tLoss 0.1922 (0.2148)\taccuracy 93.750 (91.174)\tf1_score 93.473 (89.285)\n",
      "Epoch: [70][95/96]\tLoss 0.1254 (0.2157)\taccuracy 96.875 (91.276)\tf1_score 96.111 (89.388)\n",
      " Test: accuracy 80.404 f1_score 77.545\n",
      "Training time:  1130.7547900676727 Hour:  0 Minute:  18 Second:  50 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 71\n",
      "Epoch: [71][0/96]\tLoss 0.0930 (0.0930)\taccuracy 96.875 (96.875)\tf1_score 95.351 (95.351)\n",
      "Epoch: [71][5/96]\tLoss 0.1630 (0.1990)\taccuracy 92.188 (92.708)\tf1_score 90.159 (91.884)\n",
      "Epoch: [71][10/96]\tLoss 0.2438 (0.2071)\taccuracy 87.500 (91.193)\tf1_score 81.992 (88.970)\n",
      "Epoch: [71][15/96]\tLoss 0.2812 (0.2075)\taccuracy 85.938 (90.820)\tf1_score 88.827 (88.729)\n",
      "Epoch: [71][20/96]\tLoss 0.1127 (0.1979)\taccuracy 96.875 (91.443)\tf1_score 96.982 (89.218)\n",
      "Epoch: [71][25/96]\tLoss 0.2650 (0.2039)\taccuracy 87.500 (91.286)\tf1_score 86.522 (88.988)\n",
      "Epoch: [71][30/96]\tLoss 0.1869 (0.2128)\taccuracy 92.188 (90.776)\tf1_score 91.640 (88.589)\n",
      "Epoch: [71][35/96]\tLoss 0.5563 (0.2265)\taccuracy 75.000 (90.451)\tf1_score 69.433 (87.874)\n",
      "Epoch: [71][40/96]\tLoss 0.2822 (0.2415)\taccuracy 87.500 (90.053)\tf1_score 81.882 (87.456)\n",
      "Epoch: [71][45/96]\tLoss 0.1895 (0.2502)\taccuracy 93.750 (90.048)\tf1_score 94.007 (87.507)\n",
      "Epoch: [71][50/96]\tLoss 0.3604 (0.2623)\taccuracy 85.938 (89.461)\tf1_score 79.190 (86.893)\n",
      "Epoch: [71][55/96]\tLoss 0.5079 (0.2666)\taccuracy 85.938 (89.481)\tf1_score 71.172 (86.405)\n",
      "Epoch: [71][60/96]\tLoss 0.1859 (0.2615)\taccuracy 92.188 (89.652)\tf1_score 92.052 (86.583)\n",
      "Epoch: [71][65/96]\tLoss 0.1732 (0.2673)\taccuracy 92.188 (89.441)\tf1_score 89.203 (86.187)\n",
      "Epoch: [71][70/96]\tLoss 0.2472 (0.2627)\taccuracy 85.938 (89.525)\tf1_score 87.841 (86.318)\n",
      "Epoch: [71][75/96]\tLoss 0.2641 (0.2569)\taccuracy 92.188 (89.864)\tf1_score 87.725 (86.740)\n",
      "Epoch: [71][80/96]\tLoss 0.2290 (0.2581)\taccuracy 90.625 (89.796)\tf1_score 87.115 (86.691)\n",
      "Epoch: [71][85/96]\tLoss 0.1433 (0.2572)\taccuracy 96.875 (89.916)\tf1_score 95.556 (86.886)\n",
      "Epoch: [71][90/96]\tLoss 0.2594 (0.2570)\taccuracy 89.062 (89.938)\tf1_score 89.439 (87.060)\n",
      "Epoch: [71][95/96]\tLoss 0.2025 (0.2595)\taccuracy 92.188 (89.909)\tf1_score 92.915 (86.929)\n",
      " Test: accuracy 79.753 f1_score 76.885\n",
      "Training time:  1146.510704278946 Hour:  0 Minute:  19 Second:  6 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 72\n",
      "Epoch: [72][0/96]\tLoss 0.2374 (0.2374)\taccuracy 90.625 (90.625)\tf1_score 80.361 (80.361)\n",
      "Epoch: [72][5/96]\tLoss 0.1600 (0.2198)\taccuracy 96.875 (92.448)\tf1_score 95.498 (89.192)\n",
      "Epoch: [72][10/96]\tLoss 0.2074 (0.2087)\taccuracy 89.062 (92.188)\tf1_score 86.054 (89.990)\n",
      "Epoch: [72][15/96]\tLoss 0.1060 (0.2048)\taccuracy 95.312 (92.090)\tf1_score 91.944 (89.855)\n",
      "Epoch: [72][20/96]\tLoss 0.1502 (0.2149)\taccuracy 93.750 (91.815)\tf1_score 92.389 (90.258)\n",
      "Epoch: [72][25/96]\tLoss 0.1503 (0.2107)\taccuracy 95.312 (92.007)\tf1_score 92.332 (90.247)\n",
      "Epoch: [72][30/96]\tLoss 0.1815 (0.2100)\taccuracy 90.625 (91.986)\tf1_score 92.629 (89.941)\n",
      "Epoch: [72][35/96]\tLoss 0.2553 (0.2074)\taccuracy 90.625 (91.970)\tf1_score 86.460 (89.807)\n",
      "Epoch: [72][40/96]\tLoss 0.1689 (0.2089)\taccuracy 95.312 (91.921)\tf1_score 93.935 (89.691)\n",
      "Epoch: [72][45/96]\tLoss 0.1632 (0.2021)\taccuracy 93.750 (92.120)\tf1_score 93.535 (90.020)\n",
      "Epoch: [72][50/96]\tLoss 0.3312 (0.2029)\taccuracy 87.500 (92.126)\tf1_score 83.063 (89.974)\n",
      "Epoch: [72][55/96]\tLoss 0.3005 (0.2046)\taccuracy 90.625 (92.076)\tf1_score 92.187 (90.017)\n",
      "Epoch: [72][60/96]\tLoss 0.1142 (0.2063)\taccuracy 95.312 (91.983)\tf1_score 92.309 (89.973)\n",
      "Epoch: [72][65/96]\tLoss 0.2438 (0.2074)\taccuracy 85.938 (91.927)\tf1_score 83.935 (89.942)\n",
      "Epoch: [72][70/96]\tLoss 0.2085 (0.2108)\taccuracy 92.188 (91.791)\tf1_score 93.535 (89.863)\n",
      "Epoch: [72][75/96]\tLoss 0.2256 (0.2098)\taccuracy 90.625 (91.838)\tf1_score 85.397 (89.969)\n",
      "Epoch: [72][80/96]\tLoss 0.2146 (0.2100)\taccuracy 90.625 (91.763)\tf1_score 93.461 (89.918)\n",
      "Epoch: [72][85/96]\tLoss 0.2853 (0.2085)\taccuracy 89.062 (91.824)\tf1_score 89.144 (89.932)\n",
      "Epoch: [72][90/96]\tLoss 0.2647 (0.2098)\taccuracy 89.062 (91.724)\tf1_score 89.323 (89.813)\n",
      "Epoch: [72][95/96]\tLoss 0.1187 (0.2084)\taccuracy 96.875 (91.748)\tf1_score 97.571 (89.882)\n",
      " Test: accuracy 73.633 f1_score 68.710\n",
      "Training time:  1162.2966771125793 Hour:  0 Minute:  19 Second:  22 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 73\n",
      "Epoch: [73][0/96]\tLoss 0.2369 (0.2369)\taccuracy 89.062 (89.062)\tf1_score 91.338 (91.338)\n",
      "Epoch: [73][5/96]\tLoss 0.1812 (0.1684)\taccuracy 93.750 (93.229)\tf1_score 91.151 (92.435)\n",
      "Epoch: [73][10/96]\tLoss 0.2488 (0.2051)\taccuracy 87.500 (91.619)\tf1_score 82.507 (90.833)\n",
      "Epoch: [73][15/96]\tLoss 0.2238 (0.1988)\taccuracy 89.062 (91.602)\tf1_score 89.369 (90.215)\n",
      "Epoch: [73][20/96]\tLoss 0.3364 (0.1993)\taccuracy 84.375 (91.741)\tf1_score 81.175 (90.249)\n",
      "Epoch: [73][25/96]\tLoss 0.2334 (0.2001)\taccuracy 90.625 (92.007)\tf1_score 87.018 (90.397)\n",
      "Epoch: [73][30/96]\tLoss 0.1475 (0.1987)\taccuracy 93.750 (91.885)\tf1_score 93.889 (90.395)\n",
      "Epoch: [73][35/96]\tLoss 0.2620 (0.1997)\taccuracy 89.062 (91.884)\tf1_score 87.710 (90.183)\n",
      "Epoch: [73][40/96]\tLoss 0.2314 (0.1993)\taccuracy 93.750 (91.921)\tf1_score 93.288 (90.367)\n",
      "Epoch: [73][45/96]\tLoss 0.1733 (0.1947)\taccuracy 92.188 (92.154)\tf1_score 92.716 (90.411)\n",
      "Epoch: [73][50/96]\tLoss 0.1651 (0.2072)\taccuracy 93.750 (91.789)\tf1_score 92.738 (89.970)\n",
      "Epoch: [73][55/96]\tLoss 0.1393 (0.2056)\taccuracy 96.875 (91.964)\tf1_score 93.060 (90.157)\n",
      "Epoch: [73][60/96]\tLoss 0.1831 (0.2064)\taccuracy 92.188 (91.880)\tf1_score 92.079 (89.978)\n",
      "Epoch: [73][65/96]\tLoss 0.1477 (0.2051)\taccuracy 95.312 (91.903)\tf1_score 91.444 (89.946)\n",
      "Epoch: [73][70/96]\tLoss 0.1590 (0.2060)\taccuracy 96.875 (91.901)\tf1_score 97.158 (89.807)\n",
      "Epoch: [73][75/96]\tLoss 0.2442 (0.2086)\taccuracy 90.625 (91.756)\tf1_score 92.611 (89.758)\n",
      "Epoch: [73][80/96]\tLoss 0.2259 (0.2097)\taccuracy 92.188 (91.686)\tf1_score 93.154 (89.808)\n",
      "Epoch: [73][85/96]\tLoss 0.1870 (0.2097)\taccuracy 95.312 (91.733)\tf1_score 94.180 (89.858)\n",
      "Epoch: [73][90/96]\tLoss 0.2296 (0.2091)\taccuracy 89.062 (91.775)\tf1_score 81.190 (89.789)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [73][95/96]\tLoss 0.1654 (0.2107)\taccuracy 95.312 (91.781)\tf1_score 95.906 (89.850)\n",
      " Test: accuracy 81.445 f1_score 78.722\n",
      "Training time:  1177.9939551353455 Hour:  0 Minute:  19 Second:  37 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 74\n",
      "Epoch: [74][0/96]\tLoss 0.1370 (0.1370)\taccuracy 93.750 (93.750)\tf1_score 90.703 (90.703)\n",
      "Epoch: [74][5/96]\tLoss 0.2683 (0.2050)\taccuracy 92.188 (92.188)\tf1_score 91.831 (89.973)\n",
      "Epoch: [74][10/96]\tLoss 0.1595 (0.1922)\taccuracy 95.312 (93.040)\tf1_score 90.786 (90.687)\n",
      "Epoch: [74][15/96]\tLoss 0.3588 (0.1951)\taccuracy 87.500 (92.871)\tf1_score 80.169 (90.154)\n",
      "Epoch: [74][20/96]\tLoss 0.1838 (0.2043)\taccuracy 90.625 (92.113)\tf1_score 86.286 (89.434)\n",
      "Epoch: [74][25/96]\tLoss 0.1981 (0.2101)\taccuracy 96.875 (92.368)\tf1_score 96.484 (89.891)\n",
      "Epoch: [74][30/96]\tLoss 0.3081 (0.2221)\taccuracy 89.062 (92.137)\tf1_score 87.811 (89.708)\n",
      "Epoch: [74][35/96]\tLoss 0.2729 (0.2159)\taccuracy 90.625 (92.361)\tf1_score 93.952 (90.241)\n",
      "Epoch: [74][40/96]\tLoss 0.1492 (0.2183)\taccuracy 93.750 (92.340)\tf1_score 87.831 (89.894)\n",
      "Epoch: [74][45/96]\tLoss 0.2217 (0.2159)\taccuracy 90.625 (92.323)\tf1_score 86.869 (89.517)\n",
      "Epoch: [74][50/96]\tLoss 0.2460 (0.2151)\taccuracy 90.625 (92.341)\tf1_score 91.630 (89.849)\n",
      "Epoch: [74][55/96]\tLoss 0.1584 (0.2135)\taccuracy 95.312 (92.383)\tf1_score 89.405 (89.919)\n",
      "Epoch: [74][60/96]\tLoss 0.3552 (0.2153)\taccuracy 87.500 (92.264)\tf1_score 85.099 (89.825)\n",
      "Epoch: [74][65/96]\tLoss 0.1282 (0.2151)\taccuracy 96.875 (92.282)\tf1_score 95.735 (89.865)\n",
      "Epoch: [74][70/96]\tLoss 0.1225 (0.2117)\taccuracy 95.312 (92.430)\tf1_score 95.571 (90.187)\n",
      "Epoch: [74][75/96]\tLoss 0.1410 (0.2063)\taccuracy 96.875 (92.681)\tf1_score 92.967 (90.528)\n",
      "Epoch: [74][80/96]\tLoss 0.4265 (0.2069)\taccuracy 82.812 (92.573)\tf1_score 78.349 (90.416)\n",
      "Epoch: [74][85/96]\tLoss 0.2150 (0.2077)\taccuracy 89.062 (92.478)\tf1_score 88.333 (90.324)\n",
      "Epoch: [74][90/96]\tLoss 0.1635 (0.2071)\taccuracy 95.312 (92.479)\tf1_score 93.810 (90.315)\n",
      "Epoch: [74][95/96]\tLoss 0.1455 (0.2074)\taccuracy 93.750 (92.432)\tf1_score 94.635 (90.361)\n",
      " Test: accuracy 60.026 f1_score 54.994\n",
      "Training time:  1193.7535803318024 Hour:  0 Minute:  19 Second:  53 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 75\n",
      "Epoch: [75][0/96]\tLoss 0.3309 (0.3309)\taccuracy 89.062 (89.062)\tf1_score 88.516 (88.516)\n",
      "Epoch: [75][5/96]\tLoss 0.1456 (0.2110)\taccuracy 92.188 (92.188)\tf1_score 91.776 (92.039)\n",
      "Epoch: [75][10/96]\tLoss 0.1915 (0.2023)\taccuracy 92.188 (91.903)\tf1_score 91.693 (91.264)\n",
      "Epoch: [75][15/96]\tLoss 0.1201 (0.2035)\taccuracy 96.875 (91.211)\tf1_score 96.402 (90.573)\n",
      "Epoch: [75][20/96]\tLoss 0.0749 (0.1973)\taccuracy 98.438 (91.667)\tf1_score 97.884 (90.687)\n",
      "Epoch: [75][25/96]\tLoss 0.2653 (0.1940)\taccuracy 92.188 (92.067)\tf1_score 87.567 (90.456)\n",
      "Epoch: [75][30/96]\tLoss 0.1942 (0.1958)\taccuracy 93.750 (92.087)\tf1_score 88.932 (90.441)\n",
      "Epoch: [75][35/96]\tLoss 0.1622 (0.1925)\taccuracy 95.312 (92.318)\tf1_score 92.175 (90.587)\n",
      "Epoch: [75][40/96]\tLoss 0.1134 (0.1850)\taccuracy 95.312 (92.607)\tf1_score 95.986 (91.075)\n",
      "Epoch: [75][45/96]\tLoss 0.2712 (0.1938)\taccuracy 92.188 (92.459)\tf1_score 91.852 (91.099)\n",
      "Epoch: [75][50/96]\tLoss 0.1829 (0.1945)\taccuracy 92.188 (92.463)\tf1_score 89.361 (91.124)\n",
      "Epoch: [75][55/96]\tLoss 0.1361 (0.1959)\taccuracy 96.875 (92.522)\tf1_score 97.460 (91.161)\n",
      "Epoch: [75][60/96]\tLoss 0.3091 (0.1962)\taccuracy 90.625 (92.444)\tf1_score 78.673 (90.908)\n",
      "Epoch: [75][65/96]\tLoss 0.2388 (0.2036)\taccuracy 90.625 (92.330)\tf1_score 84.197 (90.834)\n",
      "Epoch: [75][70/96]\tLoss 0.1942 (0.2043)\taccuracy 92.188 (92.276)\tf1_score 86.235 (90.795)\n",
      "Epoch: [75][75/96]\tLoss 0.5584 (0.2091)\taccuracy 76.562 (92.002)\tf1_score 75.413 (90.446)\n",
      "Epoch: [75][80/96]\tLoss 0.2643 (0.2095)\taccuracy 89.062 (91.995)\tf1_score 85.141 (90.484)\n",
      "Epoch: [75][85/96]\tLoss 0.4161 (0.2124)\taccuracy 85.938 (91.788)\tf1_score 84.332 (90.218)\n",
      "Epoch: [75][90/96]\tLoss 0.1515 (0.2124)\taccuracy 95.312 (91.810)\tf1_score 92.167 (90.226)\n",
      "Epoch: [75][95/96]\tLoss 0.1631 (0.2101)\taccuracy 93.750 (91.927)\tf1_score 92.810 (90.308)\n",
      " Test: accuracy 73.893 f1_score 70.207\n",
      "Training time:  1210.685714006424 Hour:  0 Minute:  20 Second:  10 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 76\n",
      "Epoch: [76][0/96]\tLoss 0.1684 (0.1684)\taccuracy 93.750 (93.750)\tf1_score 91.429 (91.429)\n",
      "Epoch: [76][5/96]\tLoss 0.3435 (0.2268)\taccuracy 84.375 (92.188)\tf1_score 80.134 (89.435)\n",
      "Epoch: [76][10/96]\tLoss 0.0947 (0.2216)\taccuracy 96.875 (92.756)\tf1_score 95.333 (89.953)\n",
      "Epoch: [76][15/96]\tLoss 0.5003 (0.2449)\taccuracy 76.562 (91.699)\tf1_score 73.502 (88.387)\n",
      "Epoch: [76][20/96]\tLoss 0.4345 (0.2448)\taccuracy 89.062 (91.667)\tf1_score 85.833 (88.511)\n",
      "Epoch: [76][25/96]\tLoss 0.1614 (0.2446)\taccuracy 95.312 (91.466)\tf1_score 95.193 (88.633)\n",
      "Epoch: [76][30/96]\tLoss 0.0865 (0.2535)\taccuracy 100.000 (91.431)\tf1_score 100.000 (88.688)\n",
      "Epoch: [76][35/96]\tLoss 0.1845 (0.2447)\taccuracy 93.750 (91.710)\tf1_score 93.702 (89.044)\n",
      "Epoch: [76][40/96]\tLoss 0.2727 (0.2386)\taccuracy 90.625 (91.959)\tf1_score 82.643 (89.347)\n",
      "Epoch: [76][45/96]\tLoss 0.1720 (0.2354)\taccuracy 92.188 (91.950)\tf1_score 93.707 (89.648)\n",
      "Epoch: [76][50/96]\tLoss 0.1979 (0.2335)\taccuracy 90.625 (92.004)\tf1_score 87.043 (89.436)\n",
      "Epoch: [76][55/96]\tLoss 0.3326 (0.2315)\taccuracy 87.500 (92.048)\tf1_score 82.286 (89.536)\n",
      "Epoch: [76][60/96]\tLoss 0.0854 (0.2246)\taccuracy 96.875 (92.341)\tf1_score 96.063 (90.013)\n",
      "Epoch: [76][65/96]\tLoss 0.1632 (0.2241)\taccuracy 90.625 (92.235)\tf1_score 91.154 (89.821)\n",
      "Epoch: [76][70/96]\tLoss 0.1612 (0.2203)\taccuracy 92.188 (92.364)\tf1_score 91.415 (90.142)\n",
      "Epoch: [76][75/96]\tLoss 0.1635 (0.2239)\taccuracy 92.188 (92.044)\tf1_score 91.036 (89.881)\n",
      "Epoch: [76][80/96]\tLoss 0.2411 (0.2218)\taccuracy 95.312 (92.072)\tf1_score 93.278 (89.820)\n",
      "Epoch: [76][85/96]\tLoss 0.1745 (0.2220)\taccuracy 93.750 (91.951)\tf1_score 89.830 (89.593)\n",
      "Epoch: [76][90/96]\tLoss 0.2602 (0.2233)\taccuracy 89.062 (91.827)\tf1_score 87.757 (89.427)\n",
      "Epoch: [76][95/96]\tLoss 0.2395 (0.2247)\taccuracy 89.062 (91.699)\tf1_score 84.417 (89.241)\n",
      " Test: accuracy 76.823 f1_score 71.565\n",
      "Training time:  1226.341296195984 Hour:  0 Minute:  20 Second:  26 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 77\n",
      "Epoch: [77][0/96]\tLoss 0.1237 (0.1237)\taccuracy 96.875 (96.875)\tf1_score 95.556 (95.556)\n",
      "Epoch: [77][5/96]\tLoss 0.2725 (0.2100)\taccuracy 89.062 (91.927)\tf1_score 88.214 (89.687)\n",
      "Epoch: [77][10/96]\tLoss 0.5722 (0.2178)\taccuracy 79.688 (92.045)\tf1_score 71.079 (89.800)\n",
      "Epoch: [77][15/96]\tLoss 0.0483 (0.1904)\taccuracy 98.438 (93.066)\tf1_score 93.651 (90.359)\n",
      "Epoch: [77][20/96]\tLoss 0.4085 (0.2091)\taccuracy 82.812 (91.964)\tf1_score 81.126 (89.146)\n",
      "Epoch: [77][25/96]\tLoss 0.3563 (0.2220)\taccuracy 81.250 (91.526)\tf1_score 74.796 (88.454)\n",
      "Epoch: [77][30/96]\tLoss 0.2707 (0.2252)\taccuracy 89.062 (91.734)\tf1_score 89.159 (88.946)\n",
      "Epoch: [77][35/96]\tLoss 0.1667 (0.2291)\taccuracy 92.188 (91.493)\tf1_score 92.343 (88.738)\n",
      "Epoch: [77][40/96]\tLoss 0.2180 (0.2312)\taccuracy 87.500 (91.349)\tf1_score 84.190 (88.574)\n",
      "Epoch: [77][45/96]\tLoss 0.2103 (0.2271)\taccuracy 90.625 (91.236)\tf1_score 87.410 (88.477)\n",
      "Epoch: [77][50/96]\tLoss 0.1270 (0.2289)\taccuracy 96.875 (91.207)\tf1_score 96.770 (88.588)\n",
      "Epoch: [77][55/96]\tLoss 0.2549 (0.2259)\taccuracy 90.625 (91.350)\tf1_score 86.421 (88.869)\n",
      "Epoch: [77][60/96]\tLoss 0.1639 (0.2219)\taccuracy 96.875 (91.624)\tf1_score 97.831 (89.278)\n",
      "Epoch: [77][65/96]\tLoss 0.1451 (0.2184)\taccuracy 92.188 (91.761)\tf1_score 87.095 (89.458)\n",
      "Epoch: [77][70/96]\tLoss 0.1185 (0.2173)\taccuracy 93.750 (91.703)\tf1_score 85.351 (89.278)\n",
      "Epoch: [77][75/96]\tLoss 0.1500 (0.2139)\taccuracy 93.750 (91.817)\tf1_score 91.083 (89.502)\n",
      "Epoch: [77][80/96]\tLoss 0.3172 (0.2127)\taccuracy 87.500 (91.860)\tf1_score 80.174 (89.491)\n",
      "Epoch: [77][85/96]\tLoss 0.1474 (0.2170)\taccuracy 95.312 (91.733)\tf1_score 94.911 (89.498)\n",
      "Epoch: [77][90/96]\tLoss 0.2146 (0.2179)\taccuracy 89.062 (91.587)\tf1_score 88.549 (89.156)\n",
      "Epoch: [77][95/96]\tLoss 0.4194 (0.2203)\taccuracy 87.500 (91.520)\tf1_score 79.647 (89.004)\n",
      " Test: accuracy 64.062 f1_score 58.776\n",
      "Training time:  1242.0524020195007 Hour:  0 Minute:  20 Second:  42 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 78\n",
      "Epoch: [78][0/96]\tLoss 0.0820 (0.0820)\taccuracy 95.312 (95.312)\tf1_score 94.021 (94.021)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [78][5/96]\tLoss 0.3951 (0.2037)\taccuracy 84.375 (91.406)\tf1_score 84.831 (88.997)\n",
      "Epoch: [78][10/96]\tLoss 0.1543 (0.1828)\taccuracy 96.875 (92.898)\tf1_score 92.593 (90.500)\n",
      "Epoch: [78][15/96]\tLoss 0.3819 (0.2125)\taccuracy 84.375 (91.699)\tf1_score 80.410 (89.678)\n",
      "Epoch: [78][20/96]\tLoss 0.2228 (0.2182)\taccuracy 92.188 (91.518)\tf1_score 90.837 (89.951)\n",
      "Epoch: [78][25/96]\tLoss 0.1060 (0.2192)\taccuracy 95.312 (91.526)\tf1_score 95.556 (89.732)\n",
      "Epoch: [78][30/96]\tLoss 0.2840 (0.2171)\taccuracy 89.062 (91.784)\tf1_score 85.714 (90.199)\n",
      "Epoch: [78][35/96]\tLoss 0.1943 (0.2131)\taccuracy 90.625 (92.057)\tf1_score 88.881 (90.247)\n",
      "Epoch: [78][40/96]\tLoss 0.1902 (0.2060)\taccuracy 93.750 (92.378)\tf1_score 95.543 (90.575)\n",
      "Epoch: [78][45/96]\tLoss 0.1042 (0.1972)\taccuracy 96.875 (92.697)\tf1_score 96.857 (90.914)\n",
      "Epoch: [78][50/96]\tLoss 0.2715 (0.2051)\taccuracy 87.500 (92.310)\tf1_score 86.196 (90.671)\n",
      "Epoch: [78][55/96]\tLoss 0.3870 (0.2117)\taccuracy 79.688 (91.964)\tf1_score 73.844 (90.222)\n",
      "Epoch: [78][60/96]\tLoss 0.3347 (0.2138)\taccuracy 87.500 (91.803)\tf1_score 82.375 (89.856)\n",
      "Epoch: [78][65/96]\tLoss 0.1819 (0.2117)\taccuracy 92.188 (91.903)\tf1_score 91.770 (90.004)\n",
      "Epoch: [78][70/96]\tLoss 0.2937 (0.2119)\taccuracy 90.625 (91.857)\tf1_score 91.776 (90.003)\n",
      "Epoch: [78][75/96]\tLoss 0.1519 (0.2081)\taccuracy 93.750 (91.982)\tf1_score 94.417 (90.053)\n",
      "Epoch: [78][80/96]\tLoss 0.1827 (0.2055)\taccuracy 93.750 (92.110)\tf1_score 91.947 (90.212)\n",
      "Epoch: [78][85/96]\tLoss 0.2617 (0.2053)\taccuracy 90.625 (92.151)\tf1_score 89.287 (90.223)\n",
      "Epoch: [78][90/96]\tLoss 0.3423 (0.2109)\taccuracy 87.500 (91.930)\tf1_score 85.837 (89.959)\n",
      "Epoch: [78][95/96]\tLoss 0.1428 (0.2116)\taccuracy 92.188 (91.797)\tf1_score 88.787 (89.752)\n",
      " Test: accuracy 68.034 f1_score 62.900\n",
      "Training time:  1257.7868735790253 Hour:  0 Minute:  20 Second:  57 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 79\n",
      "Epoch: [79][0/96]\tLoss 0.1456 (0.1456)\taccuracy 95.312 (95.312)\tf1_score 97.179 (97.179)\n",
      "Epoch: [79][5/96]\tLoss 0.2908 (0.2085)\taccuracy 90.625 (91.927)\tf1_score 91.912 (91.784)\n",
      "Epoch: [79][10/96]\tLoss 0.1700 (0.2187)\taccuracy 90.625 (91.619)\tf1_score 89.319 (91.410)\n",
      "Epoch: [79][15/96]\tLoss 0.1738 (0.2136)\taccuracy 93.750 (91.895)\tf1_score 91.224 (91.319)\n",
      "Epoch: [79][20/96]\tLoss 0.2111 (0.2041)\taccuracy 93.750 (92.262)\tf1_score 90.537 (90.824)\n",
      "Epoch: [79][25/96]\tLoss 0.3142 (0.1989)\taccuracy 89.062 (92.368)\tf1_score 79.581 (90.775)\n",
      "Epoch: [79][30/96]\tLoss 0.1769 (0.1940)\taccuracy 93.750 (92.591)\tf1_score 89.791 (90.856)\n",
      "Epoch: [79][35/96]\tLoss 0.1438 (0.1896)\taccuracy 93.750 (92.708)\tf1_score 94.664 (91.135)\n",
      "Epoch: [79][40/96]\tLoss 0.2757 (0.1899)\taccuracy 85.938 (92.645)\tf1_score 83.677 (91.127)\n",
      "Epoch: [79][45/96]\tLoss 0.1727 (0.1872)\taccuracy 93.750 (92.731)\tf1_score 89.221 (91.145)\n",
      "Epoch: [79][50/96]\tLoss 0.3617 (0.1914)\taccuracy 81.250 (92.525)\tf1_score 76.092 (90.923)\n",
      "Epoch: [79][55/96]\tLoss 0.2409 (0.1935)\taccuracy 89.062 (92.411)\tf1_score 87.778 (90.977)\n",
      "Epoch: [79][60/96]\tLoss 0.3042 (0.1934)\taccuracy 84.375 (92.290)\tf1_score 81.557 (90.586)\n",
      "Epoch: [79][65/96]\tLoss 0.1884 (0.1955)\taccuracy 93.750 (92.211)\tf1_score 94.788 (90.526)\n",
      "Epoch: [79][70/96]\tLoss 0.1384 (0.1973)\taccuracy 93.750 (92.143)\tf1_score 91.066 (90.406)\n",
      "Epoch: [79][75/96]\tLoss 0.1503 (0.1962)\taccuracy 92.188 (92.188)\tf1_score 93.379 (90.489)\n",
      "Epoch: [79][80/96]\tLoss 0.2175 (0.1965)\taccuracy 90.625 (92.149)\tf1_score 87.914 (90.325)\n",
      "Epoch: [79][85/96]\tLoss 0.0828 (0.1954)\taccuracy 95.312 (92.115)\tf1_score 94.486 (90.318)\n",
      "Epoch: [79][90/96]\tLoss 0.2290 (0.1941)\taccuracy 92.188 (92.222)\tf1_score 93.057 (90.489)\n",
      "Epoch: [79][95/96]\tLoss 0.2254 (0.1939)\taccuracy 90.625 (92.301)\tf1_score 91.718 (90.558)\n",
      " Test: accuracy 78.971 f1_score 74.113\n",
      "Training time:  1273.5063672065735 Hour:  0 Minute:  21 Second:  13 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 80\n",
      "Epoch: [80][0/96]\tLoss 0.2532 (0.2532)\taccuracy 89.062 (89.062)\tf1_score 81.149 (81.149)\n",
      "Epoch: [80][5/96]\tLoss 0.1359 (0.1918)\taccuracy 93.750 (91.927)\tf1_score 91.605 (89.350)\n",
      "Epoch: [80][10/96]\tLoss 0.2002 (0.1896)\taccuracy 92.188 (92.188)\tf1_score 88.569 (89.584)\n",
      "Epoch: [80][15/96]\tLoss 0.2968 (0.1908)\taccuracy 85.938 (91.992)\tf1_score 84.843 (89.925)\n",
      "Epoch: [80][20/96]\tLoss 0.1128 (0.1857)\taccuracy 95.312 (92.113)\tf1_score 94.687 (90.073)\n",
      "Epoch: [80][25/96]\tLoss 0.3742 (0.1921)\taccuracy 84.375 (92.067)\tf1_score 84.988 (90.181)\n",
      "Epoch: [80][30/96]\tLoss 0.1269 (0.1930)\taccuracy 95.312 (92.188)\tf1_score 95.289 (90.358)\n",
      "Epoch: [80][35/96]\tLoss 0.5521 (0.2001)\taccuracy 78.125 (92.057)\tf1_score 74.946 (90.363)\n",
      "Epoch: [80][40/96]\tLoss 0.1568 (0.1944)\taccuracy 93.750 (92.302)\tf1_score 89.792 (90.672)\n",
      "Epoch: [80][45/96]\tLoss 0.1137 (0.1900)\taccuracy 95.312 (92.459)\tf1_score 95.619 (90.939)\n",
      "Epoch: [80][50/96]\tLoss 0.3567 (0.1940)\taccuracy 92.188 (92.341)\tf1_score 89.177 (90.780)\n",
      "Epoch: [80][55/96]\tLoss 0.1375 (0.1997)\taccuracy 95.312 (92.355)\tf1_score 90.079 (90.645)\n",
      "Epoch: [80][60/96]\tLoss 0.2170 (0.2061)\taccuracy 90.625 (92.034)\tf1_score 89.000 (90.413)\n",
      "Epoch: [80][65/96]\tLoss 0.2964 (0.2102)\taccuracy 90.625 (91.927)\tf1_score 83.369 (90.270)\n",
      "Epoch: [80][70/96]\tLoss 0.2926 (0.2091)\taccuracy 87.500 (91.923)\tf1_score 88.605 (90.354)\n",
      "Epoch: [80][75/96]\tLoss 0.2091 (0.2103)\taccuracy 90.625 (91.653)\tf1_score 87.143 (89.988)\n",
      "Epoch: [80][80/96]\tLoss 0.1347 (0.2095)\taccuracy 93.750 (91.628)\tf1_score 90.738 (89.887)\n",
      "Epoch: [80][85/96]\tLoss 0.2883 (0.2142)\taccuracy 87.500 (91.443)\tf1_score 82.379 (89.682)\n",
      "Epoch: [80][90/96]\tLoss 0.2659 (0.2126)\taccuracy 93.750 (91.604)\tf1_score 88.635 (89.749)\n",
      "Epoch: [80][95/96]\tLoss 0.2191 (0.2150)\taccuracy 90.625 (91.569)\tf1_score 87.128 (89.723)\n",
      " Test: accuracy 84.766 f1_score 82.754\n",
      "Training time:  1289.2326183319092 Hour:  0 Minute:  21 Second:  29 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 81\n",
      "Epoch: [81][0/96]\tLoss 0.1375 (0.1375)\taccuracy 95.312 (95.312)\tf1_score 94.796 (94.796)\n",
      "Epoch: [81][5/96]\tLoss 0.1450 (0.2182)\taccuracy 95.312 (91.927)\tf1_score 96.088 (92.045)\n",
      "Epoch: [81][10/96]\tLoss 0.1361 (0.2089)\taccuracy 93.750 (91.903)\tf1_score 85.861 (90.092)\n",
      "Epoch: [81][15/96]\tLoss 0.0932 (0.1863)\taccuracy 96.875 (92.871)\tf1_score 95.837 (91.193)\n",
      "Epoch: [81][20/96]\tLoss 0.1737 (0.1880)\taccuracy 93.750 (93.155)\tf1_score 92.194 (91.659)\n",
      "Epoch: [81][25/96]\tLoss 0.2125 (0.1860)\taccuracy 92.188 (93.089)\tf1_score 87.634 (91.564)\n",
      "Epoch: [81][30/96]\tLoss 0.1573 (0.1922)\taccuracy 93.750 (92.994)\tf1_score 93.700 (91.277)\n",
      "Epoch: [81][35/96]\tLoss 0.0939 (0.1881)\taccuracy 96.875 (93.056)\tf1_score 94.921 (91.073)\n",
      "Epoch: [81][40/96]\tLoss 0.1601 (0.1914)\taccuracy 93.750 (92.873)\tf1_score 90.561 (91.005)\n",
      "Epoch: [81][45/96]\tLoss 0.1805 (0.1885)\taccuracy 92.188 (92.799)\tf1_score 93.243 (90.905)\n",
      "Epoch: [81][50/96]\tLoss 0.3856 (0.2042)\taccuracy 85.938 (92.279)\tf1_score 72.773 (90.241)\n",
      "Epoch: [81][55/96]\tLoss 0.1769 (0.2013)\taccuracy 93.750 (92.411)\tf1_score 85.342 (90.274)\n",
      "Epoch: [81][60/96]\tLoss 0.2491 (0.2041)\taccuracy 89.062 (92.239)\tf1_score 86.434 (90.240)\n",
      "Epoch: [81][65/96]\tLoss 0.2805 (0.2080)\taccuracy 93.750 (92.022)\tf1_score 94.606 (89.978)\n",
      "Epoch: [81][70/96]\tLoss 0.1312 (0.2069)\taccuracy 95.312 (92.077)\tf1_score 89.524 (90.110)\n",
      "Epoch: [81][75/96]\tLoss 0.3099 (0.2131)\taccuracy 85.938 (91.797)\tf1_score 83.542 (89.736)\n",
      "Epoch: [81][80/96]\tLoss 0.1338 (0.2094)\taccuracy 95.312 (91.937)\tf1_score 90.385 (89.844)\n",
      "Epoch: [81][85/96]\tLoss 0.1117 (0.2109)\taccuracy 96.875 (91.951)\tf1_score 97.158 (89.921)\n",
      "Epoch: [81][90/96]\tLoss 0.1378 (0.2103)\taccuracy 93.750 (91.878)\tf1_score 90.516 (89.919)\n",
      "Epoch: [81][95/96]\tLoss 0.2007 (0.2156)\taccuracy 89.062 (91.650)\tf1_score 84.726 (89.665)\n",
      " Test: accuracy 65.690 f1_score 59.068\n",
      "Training time:  1305.021991968155 Hour:  0 Minute:  21 Second:  45 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 82\n",
      "Epoch: [82][0/96]\tLoss 0.0592 (0.0592)\taccuracy 100.000 (100.000)\tf1_score 100.000 (100.000)\n",
      "Epoch: [82][5/96]\tLoss 0.2047 (0.1460)\taccuracy 92.188 (94.531)\tf1_score 90.272 (93.045)\n",
      "Epoch: [82][10/96]\tLoss 0.1417 (0.1714)\taccuracy 93.750 (93.608)\tf1_score 94.609 (92.187)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [82][15/96]\tLoss 0.2866 (0.1807)\taccuracy 85.938 (92.969)\tf1_score 82.679 (91.900)\n",
      "Epoch: [82][20/96]\tLoss 0.4142 (0.2332)\taccuracy 82.812 (91.592)\tf1_score 84.135 (90.380)\n",
      "Epoch: [82][25/96]\tLoss 0.2731 (0.2388)\taccuracy 90.625 (91.406)\tf1_score 83.938 (90.056)\n",
      "Epoch: [82][30/96]\tLoss 0.1899 (0.2321)\taccuracy 93.750 (91.532)\tf1_score 92.668 (89.739)\n",
      "Epoch: [82][35/96]\tLoss 0.1514 (0.2446)\taccuracy 93.750 (91.189)\tf1_score 92.283 (89.286)\n",
      "Epoch: [82][40/96]\tLoss 0.1336 (0.2475)\taccuracy 93.750 (91.006)\tf1_score 87.143 (88.917)\n",
      "Epoch: [82][45/96]\tLoss 0.0978 (0.2397)\taccuracy 96.875 (91.270)\tf1_score 96.825 (89.364)\n",
      "Epoch: [82][50/96]\tLoss 0.1258 (0.2400)\taccuracy 98.438 (91.299)\tf1_score 97.732 (89.062)\n",
      "Epoch: [82][55/96]\tLoss 0.2398 (0.2364)\taccuracy 89.062 (91.323)\tf1_score 89.724 (89.077)\n",
      "Epoch: [82][60/96]\tLoss 0.1184 (0.2283)\taccuracy 96.875 (91.675)\tf1_score 96.735 (89.612)\n",
      "Epoch: [82][65/96]\tLoss 0.1584 (0.2295)\taccuracy 93.750 (91.525)\tf1_score 91.361 (89.642)\n",
      "Epoch: [82][70/96]\tLoss 0.1854 (0.2268)\taccuracy 92.188 (91.571)\tf1_score 90.739 (89.749)\n",
      "Epoch: [82][75/96]\tLoss 0.1759 (0.2239)\taccuracy 92.188 (91.694)\tf1_score 93.322 (90.021)\n",
      "Epoch: [82][80/96]\tLoss 0.2472 (0.2218)\taccuracy 90.625 (91.763)\tf1_score 92.003 (90.188)\n",
      "Epoch: [82][85/96]\tLoss 0.1928 (0.2189)\taccuracy 93.750 (91.860)\tf1_score 93.545 (90.277)\n",
      "Epoch: [82][90/96]\tLoss 0.1819 (0.2186)\taccuracy 90.625 (91.827)\tf1_score 88.152 (90.248)\n",
      "Epoch: [82][95/96]\tLoss 0.1207 (0.2174)\taccuracy 98.438 (91.878)\tf1_score 94.286 (90.254)\n",
      " Test: accuracy 86.784 f1_score 84.730\n",
      "Training time:  1320.81857919693 Hour:  0 Minute:  22 Second:  0 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 83\n",
      "Epoch: [83][0/96]\tLoss 0.1652 (0.1652)\taccuracy 95.312 (95.312)\tf1_score 94.987 (94.987)\n",
      "Epoch: [83][5/96]\tLoss 0.1531 (0.1816)\taccuracy 95.312 (93.490)\tf1_score 94.793 (92.816)\n",
      "Epoch: [83][10/96]\tLoss 0.1149 (0.1843)\taccuracy 95.312 (93.324)\tf1_score 93.492 (92.458)\n",
      "Epoch: [83][15/96]\tLoss 0.1011 (0.1851)\taccuracy 98.438 (93.750)\tf1_score 97.333 (92.417)\n",
      "Epoch: [83][20/96]\tLoss 0.2213 (0.1900)\taccuracy 89.062 (93.304)\tf1_score 81.066 (91.643)\n",
      "Epoch: [83][25/96]\tLoss 0.2511 (0.1815)\taccuracy 87.500 (93.389)\tf1_score 84.025 (91.608)\n",
      "Epoch: [83][30/96]\tLoss 0.2700 (0.1789)\taccuracy 89.062 (93.397)\tf1_score 86.047 (91.546)\n",
      "Epoch: [83][35/96]\tLoss 0.1674 (0.1791)\taccuracy 92.188 (93.186)\tf1_score 88.549 (91.322)\n",
      "Epoch: [83][40/96]\tLoss 0.0866 (0.1818)\taccuracy 96.875 (93.293)\tf1_score 96.100 (91.454)\n",
      "Epoch: [83][45/96]\tLoss 0.1004 (0.1807)\taccuracy 98.438 (93.240)\tf1_score 97.732 (91.365)\n",
      "Epoch: [83][50/96]\tLoss 0.2803 (0.1814)\taccuracy 90.625 (93.321)\tf1_score 90.748 (91.570)\n",
      "Epoch: [83][55/96]\tLoss 0.1032 (0.1817)\taccuracy 95.312 (93.276)\tf1_score 94.505 (91.697)\n",
      "Epoch: [83][60/96]\tLoss 0.1397 (0.1767)\taccuracy 95.312 (93.443)\tf1_score 96.302 (91.777)\n",
      "Epoch: [83][65/96]\tLoss 0.1309 (0.1775)\taccuracy 96.875 (93.442)\tf1_score 96.558 (91.821)\n",
      "Epoch: [83][70/96]\tLoss 0.4492 (0.1824)\taccuracy 87.500 (93.288)\tf1_score 76.545 (91.498)\n",
      "Epoch: [83][75/96]\tLoss 0.1899 (0.1831)\taccuracy 92.188 (93.257)\tf1_score 85.123 (91.440)\n",
      "Epoch: [83][80/96]\tLoss 0.1200 (0.1817)\taccuracy 96.875 (93.268)\tf1_score 95.828 (91.535)\n",
      "Epoch: [83][85/96]\tLoss 0.1925 (0.1834)\taccuracy 92.188 (93.169)\tf1_score 84.921 (91.325)\n",
      "Epoch: [83][90/96]\tLoss 0.1932 (0.1837)\taccuracy 93.750 (93.149)\tf1_score 90.525 (91.280)\n",
      "Epoch: [83][95/96]\tLoss 0.1936 (0.1845)\taccuracy 93.750 (93.083)\tf1_score 94.484 (91.264)\n",
      " Test: accuracy 62.565 f1_score 55.855\n",
      "Training time:  1336.5761151313782 Hour:  0 Minute:  22 Second:  16 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 84\n",
      "Epoch: [84][0/96]\tLoss 0.4312 (0.4312)\taccuracy 84.375 (84.375)\tf1_score 75.758 (75.758)\n",
      "Epoch: [84][5/96]\tLoss 0.2621 (0.2161)\taccuracy 90.625 (92.708)\tf1_score 84.674 (89.800)\n",
      "Epoch: [84][10/96]\tLoss 0.1667 (0.2073)\taccuracy 93.750 (91.903)\tf1_score 91.701 (90.100)\n",
      "Epoch: [84][15/96]\tLoss 0.1760 (0.1985)\taccuracy 95.312 (92.773)\tf1_score 94.029 (91.242)\n",
      "Epoch: [84][20/96]\tLoss 0.1345 (0.1799)\taccuracy 93.750 (93.304)\tf1_score 90.996 (92.162)\n",
      "Epoch: [84][25/96]\tLoss 0.1916 (0.1852)\taccuracy 90.625 (92.969)\tf1_score 89.395 (91.510)\n",
      "Epoch: [84][30/96]\tLoss 0.0598 (0.1779)\taccuracy 98.438 (93.347)\tf1_score 97.879 (91.876)\n",
      "Epoch: [84][35/96]\tLoss 0.1780 (0.1713)\taccuracy 90.625 (93.490)\tf1_score 90.178 (91.978)\n",
      "Epoch: [84][40/96]\tLoss 0.2845 (0.1777)\taccuracy 90.625 (93.216)\tf1_score 91.738 (91.774)\n",
      "Epoch: [84][45/96]\tLoss 0.1553 (0.1769)\taccuracy 93.750 (93.207)\tf1_score 94.524 (91.735)\n",
      "Epoch: [84][50/96]\tLoss 0.1530 (0.1720)\taccuracy 93.750 (93.352)\tf1_score 91.931 (91.772)\n",
      "Epoch: [84][55/96]\tLoss 0.1623 (0.1744)\taccuracy 92.188 (93.248)\tf1_score 87.292 (91.520)\n",
      "Epoch: [84][60/96]\tLoss 0.1954 (0.1700)\taccuracy 92.188 (93.494)\tf1_score 89.766 (91.714)\n",
      "Epoch: [84][65/96]\tLoss 0.1302 (0.1723)\taccuracy 93.750 (93.324)\tf1_score 93.832 (91.537)\n",
      "Epoch: [84][70/96]\tLoss 0.1624 (0.1722)\taccuracy 93.750 (93.310)\tf1_score 96.083 (91.626)\n",
      "Epoch: [84][75/96]\tLoss 0.1865 (0.1714)\taccuracy 92.188 (93.359)\tf1_score 92.222 (91.769)\n",
      "Epoch: [84][80/96]\tLoss 0.1240 (0.1712)\taccuracy 96.875 (93.422)\tf1_score 98.135 (91.846)\n",
      "Epoch: [84][85/96]\tLoss 0.2477 (0.1757)\taccuracy 92.188 (93.259)\tf1_score 92.018 (91.744)\n",
      "Epoch: [84][90/96]\tLoss 0.2025 (0.1768)\taccuracy 92.188 (93.183)\tf1_score 90.730 (91.680)\n",
      "Epoch: [84][95/96]\tLoss 0.1145 (0.1772)\taccuracy 96.875 (93.311)\tf1_score 97.362 (91.870)\n",
      " Test: accuracy 79.362 f1_score 75.635\n",
      "Training time:  1352.295315027237 Hour:  0 Minute:  22 Second:  32 Test best accuracy: 88.41145833333333  Test best f1 score: 85.87723393638457\n",
      "\n",
      "Start of epoch NO: 85\n",
      "Epoch: [85][0/96]\tLoss 0.1766 (0.1766)\taccuracy 93.750 (93.750)\tf1_score 93.711 (93.711)\n",
      "Epoch: [85][5/96]\tLoss 0.2077 (0.1716)\taccuracy 90.625 (94.271)\tf1_score 91.143 (92.967)\n",
      "Epoch: [85][10/96]\tLoss 0.1939 (0.1717)\taccuracy 92.188 (93.608)\tf1_score 91.053 (92.755)\n",
      "Epoch: [85][15/96]\tLoss 0.1730 (0.1672)\taccuracy 90.625 (93.359)\tf1_score 85.988 (92.196)\n",
      "Epoch: [85][20/96]\tLoss 0.1967 (0.1661)\taccuracy 89.062 (93.304)\tf1_score 88.636 (92.152)\n",
      "Epoch: [85][25/96]\tLoss 0.1830 (0.1645)\taccuracy 92.188 (93.329)\tf1_score 92.005 (92.071)\n",
      "Epoch: [85][30/96]\tLoss 0.1783 (0.1642)\taccuracy 93.750 (93.498)\tf1_score 90.582 (92.093)\n",
      "Epoch: [85][35/96]\tLoss 0.1096 (0.1621)\taccuracy 95.312 (93.663)\tf1_score 93.832 (92.215)\n",
      "Epoch: [85][40/96]\tLoss 0.2041 (0.1686)\taccuracy 92.188 (93.445)\tf1_score 88.492 (91.772)\n",
      "Epoch: [85][45/96]\tLoss 0.1492 (0.1650)\taccuracy 93.750 (93.580)\tf1_score 90.423 (91.862)\n",
      "Epoch: [85][50/96]\tLoss 0.2657 (0.1658)\taccuracy 90.625 (93.566)\tf1_score 92.807 (91.752)\n",
      "Epoch: [85][55/96]\tLoss 0.0969 (0.1637)\taccuracy 96.875 (93.666)\tf1_score 95.905 (91.903)\n",
      "Epoch: [85][60/96]\tLoss 0.3736 (0.1703)\taccuracy 87.500 (93.494)\tf1_score 78.953 (91.754)\n",
      "Epoch: [85][65/96]\tLoss 0.2419 (0.1705)\taccuracy 87.500 (93.466)\tf1_score 84.946 (91.719)\n",
      "Epoch: [85][70/96]\tLoss 0.1115 (0.1681)\taccuracy 96.875 (93.530)\tf1_score 95.712 (91.811)\n",
      "Epoch: [85][75/96]\tLoss 0.2708 (0.1687)\taccuracy 92.188 (93.462)\tf1_score 91.584 (91.836)\n",
      "Epoch: [85][80/96]\tLoss 0.2981 (0.1698)\taccuracy 85.938 (93.403)\tf1_score 88.672 (91.887)\n",
      "Epoch: [85][85/96]\tLoss 0.0678 (0.1648)\taccuracy 96.875 (93.605)\tf1_score 97.175 (92.091)\n",
      "Epoch: [85][90/96]\tLoss 0.0910 (0.1655)\taccuracy 95.312 (93.561)\tf1_score 90.528 (91.950)\n",
      "Epoch: [85][95/96]\tLoss 0.1730 (0.1657)\taccuracy 92.188 (93.555)\tf1_score 95.667 (91.987)\n",
      " Test: accuracy 90.560 f1_score 88.312\n",
      "Saving..\n",
      "Training time:  1367.9996364116669 Hour:  0 Minute:  22 Second:  47 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 86\n",
      "Epoch: [86][0/96]\tLoss 0.2398 (0.2398)\taccuracy 89.062 (89.062)\tf1_score 88.601 (88.601)\n",
      "Epoch: [86][5/96]\tLoss 0.1556 (0.2155)\taccuracy 95.312 (92.188)\tf1_score 91.508 (91.317)\n",
      "Epoch: [86][10/96]\tLoss 0.1210 (0.2074)\taccuracy 95.312 (92.330)\tf1_score 94.392 (91.452)\n",
      "Epoch: [86][15/96]\tLoss 0.0567 (0.1858)\taccuracy 98.438 (93.750)\tf1_score 97.333 (92.930)\n",
      "Epoch: [86][20/96]\tLoss 0.1474 (0.1761)\taccuracy 96.875 (93.824)\tf1_score 92.804 (92.704)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [86][25/96]\tLoss 0.1395 (0.1787)\taccuracy 95.312 (94.111)\tf1_score 95.230 (93.043)\n",
      "Epoch: [86][30/96]\tLoss 0.1730 (0.1767)\taccuracy 89.062 (93.901)\tf1_score 81.293 (92.521)\n",
      "Epoch: [86][35/96]\tLoss 0.1711 (0.1722)\taccuracy 92.188 (94.010)\tf1_score 92.700 (92.629)\n",
      "Epoch: [86][40/96]\tLoss 0.0815 (0.1683)\taccuracy 98.438 (94.093)\tf1_score 99.038 (92.903)\n",
      "Epoch: [86][45/96]\tLoss 0.1347 (0.1725)\taccuracy 95.312 (93.988)\tf1_score 94.921 (92.919)\n",
      "Epoch: [86][50/96]\tLoss 0.0767 (0.1708)\taccuracy 98.438 (94.056)\tf1_score 98.730 (92.904)\n",
      "Epoch: [86][55/96]\tLoss 0.1743 (0.1755)\taccuracy 93.750 (93.694)\tf1_score 93.995 (92.472)\n",
      "Epoch: [86][60/96]\tLoss 0.3004 (0.1805)\taccuracy 89.062 (93.519)\tf1_score 90.576 (92.348)\n",
      "Epoch: [86][65/96]\tLoss 0.4624 (0.1839)\taccuracy 87.500 (93.419)\tf1_score 82.988 (92.185)\n",
      "Epoch: [86][70/96]\tLoss 0.3532 (0.1844)\taccuracy 85.938 (93.376)\tf1_score 84.486 (92.201)\n",
      "Epoch: [86][75/96]\tLoss 0.1057 (0.1830)\taccuracy 96.875 (93.318)\tf1_score 92.266 (92.128)\n",
      "Epoch: [86][80/96]\tLoss 0.1365 (0.1895)\taccuracy 90.625 (93.017)\tf1_score 83.356 (91.753)\n",
      "Epoch: [86][85/96]\tLoss 0.2167 (0.1941)\taccuracy 89.062 (92.842)\tf1_score 88.314 (91.508)\n",
      "Epoch: [86][90/96]\tLoss 0.4710 (0.1982)\taccuracy 84.375 (92.685)\tf1_score 76.736 (91.358)\n",
      "Epoch: [86][95/96]\tLoss 0.1948 (0.2001)\taccuracy 92.188 (92.464)\tf1_score 89.526 (91.094)\n",
      " Test: accuracy 85.872 f1_score 82.417\n",
      "Training time:  1383.7585275173187 Hour:  0 Minute:  23 Second:  3 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 87\n",
      "Epoch: [87][0/96]\tLoss 0.2567 (0.2567)\taccuracy 90.625 (90.625)\tf1_score 84.762 (84.762)\n",
      "Epoch: [87][5/96]\tLoss 0.1259 (0.2115)\taccuracy 95.312 (92.448)\tf1_score 95.395 (88.957)\n",
      "Epoch: [87][10/96]\tLoss 0.2232 (0.2733)\taccuracy 85.938 (90.057)\tf1_score 80.000 (85.871)\n",
      "Epoch: [87][15/96]\tLoss 0.3664 (0.2752)\taccuracy 85.938 (89.551)\tf1_score 85.081 (86.119)\n",
      "Epoch: [87][20/96]\tLoss 0.1903 (0.2599)\taccuracy 92.188 (90.253)\tf1_score 89.119 (87.013)\n",
      "Epoch: [87][25/96]\tLoss 0.3816 (0.2500)\taccuracy 89.062 (90.745)\tf1_score 82.124 (87.318)\n",
      "Epoch: [87][30/96]\tLoss 0.2858 (0.2565)\taccuracy 87.500 (90.071)\tf1_score 81.940 (86.289)\n",
      "Epoch: [87][35/96]\tLoss 0.2051 (0.2618)\taccuracy 93.750 (89.800)\tf1_score 92.171 (86.167)\n",
      "Epoch: [87][40/96]\tLoss 0.1306 (0.2611)\taccuracy 98.438 (90.168)\tf1_score 97.460 (86.794)\n",
      "Epoch: [87][45/96]\tLoss 0.2132 (0.2507)\taccuracy 89.062 (90.557)\tf1_score 88.284 (87.404)\n",
      "Epoch: [87][50/96]\tLoss 0.3772 (0.2515)\taccuracy 82.812 (90.502)\tf1_score 80.728 (87.192)\n",
      "Epoch: [87][55/96]\tLoss 0.1695 (0.2465)\taccuracy 95.312 (90.681)\tf1_score 94.516 (87.486)\n",
      "Epoch: [87][60/96]\tLoss 0.2603 (0.2442)\taccuracy 90.625 (90.830)\tf1_score 88.207 (87.886)\n",
      "Epoch: [87][65/96]\tLoss 0.2296 (0.2416)\taccuracy 89.062 (90.838)\tf1_score 82.625 (88.072)\n",
      "Epoch: [87][70/96]\tLoss 0.1674 (0.2378)\taccuracy 92.188 (90.955)\tf1_score 90.672 (88.214)\n",
      "Epoch: [87][75/96]\tLoss 0.1852 (0.2418)\taccuracy 93.750 (90.851)\tf1_score 91.701 (88.133)\n",
      "Epoch: [87][80/96]\tLoss 0.1338 (0.2432)\taccuracy 98.438 (90.721)\tf1_score 98.367 (88.073)\n",
      "Epoch: [87][85/96]\tLoss 0.1322 (0.2394)\taccuracy 96.875 (90.861)\tf1_score 95.556 (88.336)\n",
      "Epoch: [87][90/96]\tLoss 0.1581 (0.2383)\taccuracy 92.188 (90.831)\tf1_score 92.167 (88.330)\n",
      "Epoch: [87][95/96]\tLoss 0.1645 (0.2384)\taccuracy 95.312 (90.804)\tf1_score 94.726 (88.194)\n",
      " Test: accuracy 80.664 f1_score 75.394\n",
      "Training time:  1399.4672627449036 Hour:  0 Minute:  23 Second:  19 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 88\n",
      "Epoch: [88][0/96]\tLoss 0.1858 (0.1858)\taccuracy 92.188 (92.188)\tf1_score 91.812 (91.812)\n",
      "Epoch: [88][5/96]\tLoss 0.1124 (0.1449)\taccuracy 95.312 (94.271)\tf1_score 90.317 (92.698)\n",
      "Epoch: [88][10/96]\tLoss 0.2173 (0.1974)\taccuracy 93.750 (93.466)\tf1_score 91.610 (91.095)\n",
      "Epoch: [88][15/96]\tLoss 0.1221 (0.1984)\taccuracy 95.312 (92.969)\tf1_score 87.362 (90.890)\n",
      "Epoch: [88][20/96]\tLoss 0.1983 (0.2095)\taccuracy 89.062 (91.964)\tf1_score 84.460 (90.336)\n",
      "Epoch: [88][25/96]\tLoss 0.2362 (0.2171)\taccuracy 87.500 (91.526)\tf1_score 83.161 (89.888)\n",
      "Epoch: [88][30/96]\tLoss 0.1961 (0.2112)\taccuracy 90.625 (91.482)\tf1_score 83.800 (89.618)\n",
      "Epoch: [88][35/96]\tLoss 0.3707 (0.2125)\taccuracy 84.375 (91.319)\tf1_score 80.218 (89.345)\n",
      "Epoch: [88][40/96]\tLoss 0.2329 (0.2111)\taccuracy 85.938 (91.235)\tf1_score 80.537 (89.245)\n",
      "Epoch: [88][45/96]\tLoss 0.2230 (0.2092)\taccuracy 92.188 (91.406)\tf1_score 87.176 (89.287)\n",
      "Epoch: [88][50/96]\tLoss 0.1262 (0.2075)\taccuracy 96.875 (91.575)\tf1_score 97.007 (89.493)\n",
      "Epoch: [88][55/96]\tLoss 0.3115 (0.2051)\taccuracy 84.375 (91.685)\tf1_score 80.040 (89.438)\n",
      "Epoch: [88][60/96]\tLoss 0.1415 (0.2042)\taccuracy 93.750 (91.726)\tf1_score 94.229 (89.571)\n",
      "Epoch: [88][65/96]\tLoss 0.1978 (0.2050)\taccuracy 92.188 (91.761)\tf1_score 88.877 (89.430)\n",
      "Epoch: [88][70/96]\tLoss 0.3120 (0.2033)\taccuracy 85.938 (91.879)\tf1_score 82.083 (89.583)\n",
      "Epoch: [88][75/96]\tLoss 0.2560 (0.2044)\taccuracy 89.062 (91.797)\tf1_score 86.961 (89.488)\n",
      "Epoch: [88][80/96]\tLoss 0.1123 (0.2012)\taccuracy 95.312 (91.956)\tf1_score 93.730 (89.744)\n",
      "Epoch: [88][85/96]\tLoss 0.1224 (0.1987)\taccuracy 95.312 (92.097)\tf1_score 94.248 (89.778)\n",
      "Epoch: [88][90/96]\tLoss 0.1839 (0.1977)\taccuracy 93.750 (92.136)\tf1_score 91.534 (89.947)\n",
      "Epoch: [88][95/96]\tLoss 0.1863 (0.1963)\taccuracy 95.312 (92.220)\tf1_score 94.312 (90.053)\n",
      " Test: accuracy 75.065 f1_score 70.870\n",
      "Training time:  1415.2405667304993 Hour:  0 Minute:  23 Second:  35 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 89\n",
      "Epoch: [89][0/96]\tLoss 0.0948 (0.0948)\taccuracy 96.875 (96.875)\tf1_score 95.905 (95.905)\n",
      "Epoch: [89][5/96]\tLoss 0.1501 (0.1195)\taccuracy 92.188 (95.833)\tf1_score 93.055 (95.744)\n",
      "Epoch: [89][10/96]\tLoss 0.3529 (0.1395)\taccuracy 84.375 (94.744)\tf1_score 78.511 (94.042)\n",
      "Epoch: [89][15/96]\tLoss 0.1605 (0.1722)\taccuracy 95.312 (93.750)\tf1_score 95.705 (92.676)\n",
      "Epoch: [89][20/96]\tLoss 0.3428 (0.1921)\taccuracy 89.062 (92.708)\tf1_score 83.333 (91.443)\n",
      "Epoch: [89][25/96]\tLoss 0.1067 (0.1892)\taccuracy 98.438 (92.909)\tf1_score 98.615 (91.575)\n",
      "Epoch: [89][30/96]\tLoss 0.2463 (0.1902)\taccuracy 90.625 (92.843)\tf1_score 80.348 (90.852)\n",
      "Epoch: [89][35/96]\tLoss 0.0584 (0.1821)\taccuracy 98.438 (93.012)\tf1_score 98.571 (90.941)\n",
      "Epoch: [89][40/96]\tLoss 0.2229 (0.1825)\taccuracy 92.188 (93.026)\tf1_score 88.148 (91.011)\n",
      "Epoch: [89][45/96]\tLoss 0.0972 (0.1802)\taccuracy 98.438 (93.037)\tf1_score 96.667 (91.076)\n",
      "Epoch: [89][50/96]\tLoss 0.1843 (0.1818)\taccuracy 95.312 (93.168)\tf1_score 90.490 (91.141)\n",
      "Epoch: [89][55/96]\tLoss 0.0724 (0.1790)\taccuracy 98.438 (93.220)\tf1_score 97.879 (91.164)\n",
      "Epoch: [89][60/96]\tLoss 0.0481 (0.1763)\taccuracy 100.000 (93.391)\tf1_score 100.000 (91.438)\n",
      "Epoch: [89][65/96]\tLoss 0.1652 (0.1746)\taccuracy 92.188 (93.395)\tf1_score 91.334 (91.525)\n",
      "Epoch: [89][70/96]\tLoss 0.2454 (0.1734)\taccuracy 89.062 (93.508)\tf1_score 87.339 (91.631)\n",
      "Epoch: [89][75/96]\tLoss 0.1118 (0.1720)\taccuracy 96.875 (93.668)\tf1_score 96.063 (91.792)\n",
      "Epoch: [89][80/96]\tLoss 0.1963 (0.1719)\taccuracy 93.750 (93.711)\tf1_score 89.831 (91.810)\n",
      "Epoch: [89][85/96]\tLoss 0.2542 (0.1741)\taccuracy 87.500 (93.586)\tf1_score 88.542 (91.661)\n",
      "Epoch: [89][90/96]\tLoss 0.1567 (0.1785)\taccuracy 95.312 (93.304)\tf1_score 86.349 (91.342)\n",
      "Epoch: [89][95/96]\tLoss 0.1785 (0.1775)\taccuracy 92.188 (93.294)\tf1_score 93.175 (91.397)\n",
      " Test: accuracy 70.508 f1_score 65.646\n",
      "Training time:  1432.3871619701385 Hour:  0 Minute:  23 Second:  52 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 90\n",
      "Epoch: [90][0/96]\tLoss 0.2140 (0.2140)\taccuracy 92.188 (92.188)\tf1_score 89.646 (89.646)\n",
      "Epoch: [90][5/96]\tLoss 0.1752 (0.1576)\taccuracy 92.188 (94.010)\tf1_score 91.234 (92.961)\n",
      "Epoch: [90][10/96]\tLoss 0.2357 (0.1442)\taccuracy 90.625 (94.602)\tf1_score 81.905 (92.951)\n",
      "Epoch: [90][15/96]\tLoss 0.1281 (0.1544)\taccuracy 92.188 (93.555)\tf1_score 91.825 (92.118)\n",
      "Epoch: [90][20/96]\tLoss 0.1568 (0.1522)\taccuracy 96.875 (94.048)\tf1_score 97.424 (92.819)\n",
      "Epoch: [90][25/96]\tLoss 0.3377 (0.1660)\taccuracy 84.375 (93.510)\tf1_score 82.925 (92.204)\n",
      "Epoch: [90][30/96]\tLoss 0.2507 (0.1658)\taccuracy 90.625 (93.448)\tf1_score 86.082 (91.861)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [90][35/96]\tLoss 0.1481 (0.1592)\taccuracy 95.312 (93.837)\tf1_score 96.143 (92.165)\n",
      "Epoch: [90][40/96]\tLoss 0.1106 (0.1570)\taccuracy 98.438 (93.864)\tf1_score 94.286 (91.982)\n",
      "Epoch: [90][45/96]\tLoss 0.2229 (0.1592)\taccuracy 89.062 (93.648)\tf1_score 91.580 (91.861)\n",
      "Epoch: [90][50/96]\tLoss 0.1015 (0.1559)\taccuracy 95.312 (93.750)\tf1_score 96.026 (92.028)\n",
      "Epoch: [90][55/96]\tLoss 0.1883 (0.1611)\taccuracy 92.188 (93.555)\tf1_score 91.429 (91.934)\n",
      "Epoch: [90][60/96]\tLoss 0.1826 (0.1642)\taccuracy 93.750 (93.417)\tf1_score 86.118 (91.713)\n",
      "Epoch: [90][65/96]\tLoss 0.1577 (0.1662)\taccuracy 95.312 (93.277)\tf1_score 95.731 (91.730)\n",
      "Epoch: [90][70/96]\tLoss 0.1666 (0.1659)\taccuracy 93.750 (93.310)\tf1_score 93.517 (91.819)\n",
      "Epoch: [90][75/96]\tLoss 0.2659 (0.1669)\taccuracy 89.062 (93.257)\tf1_score 85.173 (91.792)\n",
      "Epoch: [90][80/96]\tLoss 0.3636 (0.1796)\taccuracy 84.375 (93.036)\tf1_score 81.015 (91.546)\n",
      "Epoch: [90][85/96]\tLoss 0.4823 (0.1879)\taccuracy 81.250 (92.733)\tf1_score 76.856 (91.197)\n",
      "Epoch: [90][90/96]\tLoss 0.7388 (0.2036)\taccuracy 73.438 (92.170)\tf1_score 70.734 (90.488)\n",
      "Epoch: [90][95/96]\tLoss 0.3899 (0.2203)\taccuracy 82.812 (91.797)\tf1_score 84.018 (90.024)\n",
      " Test: accuracy 38.346 f1_score 30.083\n",
      "Training time:  1448.2129418849945 Hour:  0 Minute:  24 Second:  8 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 91\n",
      "Epoch: [91][0/96]\tLoss 0.5104 (0.5104)\taccuracy 79.688 (79.688)\tf1_score 74.909 (74.909)\n",
      "Epoch: [91][5/96]\tLoss 0.2466 (0.4020)\taccuracy 89.062 (83.854)\tf1_score 89.928 (81.049)\n",
      "Epoch: [91][10/96]\tLoss 0.5806 (0.3924)\taccuracy 68.750 (83.523)\tf1_score 65.983 (80.600)\n",
      "Epoch: [91][15/96]\tLoss 0.4116 (0.3915)\taccuracy 84.375 (83.789)\tf1_score 81.537 (81.191)\n",
      "Epoch: [91][20/96]\tLoss 0.2597 (0.3652)\taccuracy 87.500 (85.193)\tf1_score 86.096 (82.348)\n",
      "Epoch: [91][25/96]\tLoss 0.2875 (0.3522)\taccuracy 85.938 (85.577)\tf1_score 84.253 (82.321)\n",
      "Epoch: [91][30/96]\tLoss 0.3606 (0.3483)\taccuracy 81.250 (85.534)\tf1_score 79.974 (82.300)\n",
      "Epoch: [91][35/96]\tLoss 0.3924 (0.3443)\taccuracy 89.062 (85.894)\tf1_score 85.970 (82.814)\n",
      "Epoch: [91][40/96]\tLoss 0.3661 (0.3354)\taccuracy 85.938 (86.357)\tf1_score 85.675 (83.379)\n",
      "Epoch: [91][45/96]\tLoss 0.2560 (0.3408)\taccuracy 90.625 (86.243)\tf1_score 87.303 (83.114)\n",
      "Epoch: [91][50/96]\tLoss 0.2248 (0.3305)\taccuracy 90.625 (86.765)\tf1_score 87.289 (83.545)\n",
      "Epoch: [91][55/96]\tLoss 0.1010 (0.3192)\taccuracy 96.875 (87.333)\tf1_score 96.674 (84.115)\n",
      "Epoch: [91][60/96]\tLoss 0.2138 (0.3165)\taccuracy 90.625 (87.372)\tf1_score 83.999 (84.181)\n",
      "Epoch: [91][65/96]\tLoss 0.1877 (0.3128)\taccuracy 92.188 (87.595)\tf1_score 91.000 (84.416)\n",
      "Epoch: [91][70/96]\tLoss 0.2322 (0.3110)\taccuracy 90.625 (87.632)\tf1_score 90.493 (84.406)\n",
      "Epoch: [91][75/96]\tLoss 0.1262 (0.3059)\taccuracy 93.750 (87.850)\tf1_score 92.619 (84.878)\n",
      "Epoch: [91][80/96]\tLoss 0.1822 (0.2994)\taccuracy 92.188 (88.059)\tf1_score 90.905 (85.174)\n",
      "Epoch: [91][85/96]\tLoss 0.3567 (0.2956)\taccuracy 87.500 (88.209)\tf1_score 83.220 (85.222)\n",
      "Epoch: [91][90/96]\tLoss 0.2820 (0.2932)\taccuracy 87.500 (88.341)\tf1_score 88.673 (85.454)\n",
      "Epoch: [91][95/96]\tLoss 0.3079 (0.2903)\taccuracy 89.062 (88.493)\tf1_score 91.951 (85.619)\n",
      " Test: accuracy 79.557 f1_score 75.594\n",
      "Training time:  1463.9558625221252 Hour:  0 Minute:  24 Second:  23 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 92\n",
      "Epoch: [92][0/96]\tLoss 0.2231 (0.2231)\taccuracy 90.625 (90.625)\tf1_score 86.670 (86.670)\n",
      "Epoch: [92][5/96]\tLoss 0.1844 (0.2658)\taccuracy 93.750 (89.844)\tf1_score 91.383 (86.345)\n",
      "Epoch: [92][10/96]\tLoss 0.1530 (0.2411)\taccuracy 96.875 (91.051)\tf1_score 93.420 (88.641)\n",
      "Epoch: [92][15/96]\tLoss 0.1705 (0.2507)\taccuracy 93.750 (90.625)\tf1_score 91.746 (87.737)\n",
      "Epoch: [92][20/96]\tLoss 0.1748 (0.2394)\taccuracy 93.750 (91.220)\tf1_score 88.016 (88.651)\n",
      "Epoch: [92][25/96]\tLoss 0.2764 (0.2307)\taccuracy 87.500 (91.466)\tf1_score 85.361 (88.991)\n",
      "Epoch: [92][30/96]\tLoss 0.1390 (0.2417)\taccuracy 95.312 (91.129)\tf1_score 95.258 (88.758)\n",
      "Epoch: [92][35/96]\tLoss 0.4259 (0.2464)\taccuracy 79.688 (90.755)\tf1_score 76.240 (88.363)\n",
      "Epoch: [92][40/96]\tLoss 0.1733 (0.2418)\taccuracy 90.625 (90.930)\tf1_score 88.707 (88.683)\n",
      "Epoch: [92][45/96]\tLoss 0.1815 (0.2387)\taccuracy 93.750 (90.999)\tf1_score 85.861 (88.385)\n",
      "Epoch: [92][50/96]\tLoss 0.2696 (0.2328)\taccuracy 92.188 (91.146)\tf1_score 92.672 (88.652)\n",
      "Epoch: [92][55/96]\tLoss 0.1834 (0.2304)\taccuracy 90.625 (91.211)\tf1_score 88.543 (88.687)\n",
      "Epoch: [92][60/96]\tLoss 0.7973 (0.2381)\taccuracy 75.000 (90.804)\tf1_score 68.331 (88.225)\n",
      "Epoch: [92][65/96]\tLoss 0.2932 (0.2400)\taccuracy 85.938 (90.743)\tf1_score 83.364 (88.099)\n",
      "Epoch: [92][70/96]\tLoss 0.2408 (0.2378)\taccuracy 90.625 (90.823)\tf1_score 90.885 (88.362)\n",
      "Epoch: [92][75/96]\tLoss 0.1154 (0.2323)\taccuracy 93.750 (90.954)\tf1_score 95.017 (88.522)\n",
      "Epoch: [92][80/96]\tLoss 0.3373 (0.2325)\taccuracy 90.625 (90.934)\tf1_score 88.867 (88.528)\n",
      "Epoch: [92][85/96]\tLoss 0.2525 (0.2351)\taccuracy 87.500 (90.825)\tf1_score 87.173 (88.374)\n",
      "Epoch: [92][90/96]\tLoss 0.1779 (0.2343)\taccuracy 90.625 (90.831)\tf1_score 88.228 (88.387)\n",
      "Epoch: [92][95/96]\tLoss 0.2526 (0.2320)\taccuracy 87.500 (90.951)\tf1_score 78.119 (88.324)\n",
      " Test: accuracy 71.159 f1_score 64.616\n",
      "Training time:  1479.6173129081726 Hour:  0 Minute:  24 Second:  39 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 93\n",
      "Epoch: [93][0/96]\tLoss 0.1902 (0.1902)\taccuracy 92.188 (92.188)\tf1_score 89.683 (89.683)\n",
      "Epoch: [93][5/96]\tLoss 0.1967 (0.2033)\taccuracy 90.625 (92.188)\tf1_score 91.222 (90.246)\n",
      "Epoch: [93][10/96]\tLoss 0.1546 (0.1792)\taccuracy 92.188 (93.182)\tf1_score 87.333 (90.686)\n",
      "Epoch: [93][15/96]\tLoss 0.2197 (0.1883)\taccuracy 92.188 (93.164)\tf1_score 88.357 (90.609)\n",
      "Epoch: [93][20/96]\tLoss 0.4310 (0.2094)\taccuracy 90.625 (92.411)\tf1_score 82.667 (89.903)\n",
      "Epoch: [93][25/96]\tLoss 0.3133 (0.2127)\taccuracy 89.062 (92.248)\tf1_score 87.769 (89.939)\n",
      "Epoch: [93][30/96]\tLoss 0.2040 (0.2045)\taccuracy 92.188 (92.339)\tf1_score 89.709 (90.231)\n",
      "Epoch: [93][35/96]\tLoss 0.2448 (0.2031)\taccuracy 89.062 (92.057)\tf1_score 86.032 (89.779)\n",
      "Epoch: [93][40/96]\tLoss 0.1159 (0.1967)\taccuracy 95.312 (92.454)\tf1_score 95.060 (90.258)\n",
      "Epoch: [93][45/96]\tLoss 0.1000 (0.1963)\taccuracy 96.875 (92.527)\tf1_score 96.770 (90.268)\n",
      "Epoch: [93][50/96]\tLoss 0.2089 (0.1980)\taccuracy 90.625 (92.494)\tf1_score 91.226 (90.169)\n",
      "Epoch: [93][55/96]\tLoss 0.2261 (0.1982)\taccuracy 92.188 (92.467)\tf1_score 94.053 (90.219)\n",
      "Epoch: [93][60/96]\tLoss 0.1297 (0.1941)\taccuracy 95.312 (92.597)\tf1_score 94.512 (90.393)\n",
      "Epoch: [93][65/96]\tLoss 0.1875 (0.1942)\taccuracy 93.750 (92.614)\tf1_score 93.711 (90.398)\n",
      "Epoch: [93][70/96]\tLoss 0.2044 (0.1950)\taccuracy 95.312 (92.584)\tf1_score 87.730 (90.362)\n",
      "Epoch: [93][75/96]\tLoss 0.1657 (0.1903)\taccuracy 92.188 (92.784)\tf1_score 90.323 (90.649)\n",
      "Epoch: [93][80/96]\tLoss 0.3202 (0.1972)\taccuracy 87.500 (92.747)\tf1_score 89.274 (90.647)\n",
      "Epoch: [93][85/96]\tLoss 0.3336 (0.2028)\taccuracy 89.062 (92.533)\tf1_score 86.138 (90.457)\n",
      "Epoch: [93][90/96]\tLoss 0.0959 (0.2020)\taccuracy 93.750 (92.428)\tf1_score 87.719 (90.289)\n",
      "Epoch: [93][95/96]\tLoss 0.1226 (0.2068)\taccuracy 95.312 (92.285)\tf1_score 93.333 (90.163)\n",
      " Test: accuracy 83.008 f1_score 79.700\n",
      "Training time:  1495.3503201007843 Hour:  0 Minute:  24 Second:  55 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 94\n",
      "Epoch: [94][0/96]\tLoss 0.4669 (0.4669)\taccuracy 78.125 (78.125)\tf1_score 78.180 (78.180)\n",
      "Epoch: [94][5/96]\tLoss 0.1867 (0.2514)\taccuracy 92.188 (89.844)\tf1_score 90.457 (88.311)\n",
      "Epoch: [94][10/96]\tLoss 0.2054 (0.2243)\taccuracy 92.188 (91.051)\tf1_score 89.937 (89.548)\n",
      "Epoch: [94][15/96]\tLoss 0.1919 (0.2171)\taccuracy 93.750 (91.309)\tf1_score 86.621 (89.180)\n",
      "Epoch: [94][20/96]\tLoss 0.1309 (0.2101)\taccuracy 98.438 (92.262)\tf1_score 97.980 (90.090)\n",
      "Epoch: [94][25/96]\tLoss 0.2838 (0.2290)\taccuracy 84.375 (91.166)\tf1_score 82.107 (89.335)\n",
      "Epoch: [94][30/96]\tLoss 0.2371 (0.2263)\taccuracy 84.375 (90.978)\tf1_score 87.858 (89.482)\n",
      "Epoch: [94][35/96]\tLoss 0.1048 (0.2300)\taccuracy 95.312 (90.972)\tf1_score 92.687 (89.476)\n",
      "Epoch: [94][40/96]\tLoss 0.3071 (0.2285)\taccuracy 87.500 (90.968)\tf1_score 87.642 (89.278)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][45/96]\tLoss 0.2824 (0.2277)\taccuracy 90.625 (91.304)\tf1_score 92.607 (89.802)\n",
      "Epoch: [94][50/96]\tLoss 0.1377 (0.2276)\taccuracy 95.312 (91.452)\tf1_score 95.440 (89.754)\n",
      "Epoch: [94][55/96]\tLoss 0.1974 (0.2273)\taccuracy 93.750 (91.378)\tf1_score 93.036 (89.571)\n",
      "Epoch: [94][60/96]\tLoss 0.3017 (0.2273)\taccuracy 90.625 (91.368)\tf1_score 90.941 (89.651)\n",
      "Epoch: [94][65/96]\tLoss 0.1160 (0.2261)\taccuracy 96.875 (91.383)\tf1_score 92.169 (89.653)\n",
      "Epoch: [94][70/96]\tLoss 0.0883 (0.2215)\taccuracy 98.438 (91.549)\tf1_score 97.333 (89.943)\n",
      "Epoch: [94][75/96]\tLoss 0.1103 (0.2184)\taccuracy 96.875 (91.715)\tf1_score 97.175 (90.188)\n",
      "Epoch: [94][80/96]\tLoss 0.2208 (0.2149)\taccuracy 93.750 (91.917)\tf1_score 90.000 (90.348)\n",
      "Epoch: [94][85/96]\tLoss 0.1219 (0.2155)\taccuracy 95.312 (91.897)\tf1_score 95.317 (90.283)\n",
      "Epoch: [94][90/96]\tLoss 0.2072 (0.2182)\taccuracy 90.625 (91.793)\tf1_score 86.599 (90.178)\n",
      "Epoch: [94][95/96]\tLoss 0.1597 (0.2148)\taccuracy 96.875 (91.976)\tf1_score 96.561 (90.385)\n",
      " Test: accuracy 82.357 f1_score 78.945\n",
      "Training time:  1511.0890264511108 Hour:  0 Minute:  25 Second:  11 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 95\n",
      "Epoch: [95][0/96]\tLoss 0.1991 (0.1991)\taccuracy 93.750 (93.750)\tf1_score 89.786 (89.786)\n",
      "Epoch: [95][5/96]\tLoss 0.2179 (0.2161)\taccuracy 89.062 (91.667)\tf1_score 85.312 (88.567)\n",
      "Epoch: [95][10/96]\tLoss 0.2750 (0.2320)\taccuracy 89.062 (91.193)\tf1_score 86.528 (88.442)\n",
      "Epoch: [95][15/96]\tLoss 0.2044 (0.2068)\taccuracy 92.188 (92.480)\tf1_score 92.921 (90.189)\n",
      "Epoch: [95][20/96]\tLoss 0.1921 (0.2199)\taccuracy 93.750 (91.964)\tf1_score 89.762 (89.868)\n",
      "Epoch: [95][25/96]\tLoss 0.1818 (0.2275)\taccuracy 92.188 (91.526)\tf1_score 88.333 (89.768)\n",
      "Epoch: [95][30/96]\tLoss 0.2005 (0.2216)\taccuracy 93.750 (91.583)\tf1_score 95.306 (89.868)\n",
      "Epoch: [95][35/96]\tLoss 0.1336 (0.2150)\taccuracy 96.875 (91.884)\tf1_score 95.029 (90.271)\n",
      "Epoch: [95][40/96]\tLoss 0.1485 (0.2167)\taccuracy 92.188 (91.692)\tf1_score 88.519 (89.831)\n",
      "Epoch: [95][45/96]\tLoss 0.1408 (0.2124)\taccuracy 95.312 (91.848)\tf1_score 95.580 (89.869)\n",
      "Epoch: [95][50/96]\tLoss 0.1002 (0.2042)\taccuracy 98.438 (92.218)\tf1_score 98.887 (90.294)\n",
      "Epoch: [95][55/96]\tLoss 0.1632 (0.1965)\taccuracy 92.188 (92.411)\tf1_score 87.732 (90.441)\n",
      "Epoch: [95][60/96]\tLoss 0.2591 (0.1932)\taccuracy 84.375 (92.469)\tf1_score 81.933 (90.454)\n",
      "Epoch: [95][65/96]\tLoss 0.2056 (0.1929)\taccuracy 89.062 (92.590)\tf1_score 83.504 (90.447)\n",
      "Epoch: [95][70/96]\tLoss 0.1821 (0.1904)\taccuracy 90.625 (92.650)\tf1_score 89.832 (90.577)\n",
      "Epoch: [95][75/96]\tLoss 0.2811 (0.1901)\taccuracy 82.812 (92.516)\tf1_score 83.641 (90.411)\n",
      "Epoch: [95][80/96]\tLoss 0.1727 (0.1919)\taccuracy 93.750 (92.419)\tf1_score 94.397 (90.438)\n",
      "Epoch: [95][85/96]\tLoss 0.0998 (0.1902)\taccuracy 95.312 (92.460)\tf1_score 87.333 (90.425)\n",
      "Epoch: [95][90/96]\tLoss 0.2577 (0.1909)\taccuracy 89.062 (92.445)\tf1_score 87.304 (90.358)\n",
      "Epoch: [95][95/96]\tLoss 0.2194 (0.1906)\taccuracy 90.625 (92.448)\tf1_score 83.127 (90.295)\n",
      " Test: accuracy 88.542 f1_score 85.645\n",
      "Training time:  1526.8286128044128 Hour:  0 Minute:  25 Second:  26 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 96\n",
      "Epoch: [96][0/96]\tLoss 0.2261 (0.2261)\taccuracy 92.188 (92.188)\tf1_score 93.193 (93.193)\n",
      "Epoch: [96][5/96]\tLoss 0.1765 (0.1554)\taccuracy 92.188 (94.010)\tf1_score 91.000 (93.120)\n",
      "Epoch: [96][10/96]\tLoss 0.1900 (0.1589)\taccuracy 90.625 (93.608)\tf1_score 88.949 (92.252)\n",
      "Epoch: [96][15/96]\tLoss 0.1758 (0.1614)\taccuracy 92.188 (93.750)\tf1_score 91.767 (92.309)\n",
      "Epoch: [96][20/96]\tLoss 0.1261 (0.1574)\taccuracy 93.750 (93.973)\tf1_score 93.397 (92.649)\n",
      "Epoch: [96][25/96]\tLoss 0.2805 (0.1615)\taccuracy 85.938 (93.570)\tf1_score 85.386 (92.668)\n",
      "Epoch: [96][30/96]\tLoss 0.2075 (0.1602)\taccuracy 92.188 (93.548)\tf1_score 91.611 (92.548)\n",
      "Epoch: [96][35/96]\tLoss 0.2190 (0.1670)\taccuracy 92.188 (93.186)\tf1_score 91.903 (92.125)\n",
      "Epoch: [96][40/96]\tLoss 0.2068 (0.1754)\taccuracy 90.625 (92.759)\tf1_score 86.349 (91.659)\n",
      "Epoch: [96][45/96]\tLoss 0.1846 (0.1776)\taccuracy 95.312 (92.731)\tf1_score 94.564 (91.420)\n",
      "Epoch: [96][50/96]\tLoss 0.1453 (0.1780)\taccuracy 92.188 (92.770)\tf1_score 91.505 (91.224)\n",
      "Epoch: [96][55/96]\tLoss 0.2094 (0.1775)\taccuracy 87.500 (92.690)\tf1_score 85.659 (91.253)\n",
      "Epoch: [96][60/96]\tLoss 0.1393 (0.1743)\taccuracy 93.750 (92.956)\tf1_score 90.369 (91.509)\n",
      "Epoch: [96][65/96]\tLoss 0.1901 (0.1746)\taccuracy 92.188 (92.969)\tf1_score 90.837 (91.578)\n",
      "Epoch: [96][70/96]\tLoss 0.1735 (0.1758)\taccuracy 92.188 (92.936)\tf1_score 89.717 (91.393)\n",
      "Epoch: [96][75/96]\tLoss 0.1591 (0.1782)\taccuracy 92.188 (92.825)\tf1_score 91.927 (91.281)\n",
      "Epoch: [96][80/96]\tLoss 0.1158 (0.1766)\taccuracy 96.875 (92.940)\tf1_score 96.778 (91.369)\n",
      "Epoch: [96][85/96]\tLoss 0.1270 (0.1774)\taccuracy 93.750 (92.969)\tf1_score 91.604 (91.441)\n",
      "Epoch: [96][90/96]\tLoss 0.1483 (0.1751)\taccuracy 95.312 (93.115)\tf1_score 95.797 (91.624)\n",
      "Epoch: [96][95/96]\tLoss 0.2767 (0.1757)\taccuracy 87.500 (93.083)\tf1_score 87.521 (91.636)\n",
      " Test: accuracy 82.812 f1_score 79.083\n",
      "Training time:  1542.55117726326 Hour:  0 Minute:  25 Second:  42 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 97\n",
      "Epoch: [97][0/96]\tLoss 0.1364 (0.1364)\taccuracy 96.875 (96.875)\tf1_score 96.859 (96.859)\n",
      "Epoch: [97][5/96]\tLoss 0.2473 (0.1903)\taccuracy 90.625 (94.010)\tf1_score 89.470 (92.202)\n",
      "Epoch: [97][10/96]\tLoss 0.1152 (0.1496)\taccuracy 95.312 (94.886)\tf1_score 94.952 (94.058)\n",
      "Epoch: [97][15/96]\tLoss 0.2416 (0.1604)\taccuracy 92.188 (94.141)\tf1_score 83.411 (92.489)\n",
      "Epoch: [97][20/96]\tLoss 0.1389 (0.1752)\taccuracy 95.312 (93.304)\tf1_score 95.862 (92.189)\n",
      "Epoch: [97][25/96]\tLoss 0.1893 (0.1706)\taccuracy 89.062 (93.389)\tf1_score 84.123 (92.037)\n",
      "Epoch: [97][30/96]\tLoss 0.1105 (0.1748)\taccuracy 93.750 (93.347)\tf1_score 92.957 (91.757)\n",
      "Epoch: [97][35/96]\tLoss 0.1386 (0.1762)\taccuracy 95.312 (93.359)\tf1_score 90.525 (91.542)\n",
      "Epoch: [97][40/96]\tLoss 0.2749 (0.1792)\taccuracy 84.375 (92.988)\tf1_score 83.704 (91.279)\n",
      "Epoch: [97][45/96]\tLoss 0.1782 (0.1781)\taccuracy 93.750 (93.037)\tf1_score 91.744 (91.519)\n",
      "Epoch: [97][50/96]\tLoss 0.4471 (0.1815)\taccuracy 87.500 (93.045)\tf1_score 85.004 (91.435)\n",
      "Epoch: [97][55/96]\tLoss 0.1427 (0.1818)\taccuracy 95.312 (93.025)\tf1_score 89.119 (91.379)\n",
      "Epoch: [97][60/96]\tLoss 0.1577 (0.1835)\taccuracy 92.188 (92.982)\tf1_score 93.000 (91.185)\n",
      "Epoch: [97][65/96]\tLoss 0.1616 (0.1864)\taccuracy 92.188 (92.898)\tf1_score 90.970 (91.009)\n",
      "Epoch: [97][70/96]\tLoss 0.4230 (0.1883)\taccuracy 82.812 (92.804)\tf1_score 78.069 (90.803)\n",
      "Epoch: [97][75/96]\tLoss 0.1885 (0.1857)\taccuracy 92.188 (92.969)\tf1_score 91.712 (90.898)\n",
      "Epoch: [97][80/96]\tLoss 0.1654 (0.1819)\taccuracy 93.750 (93.094)\tf1_score 92.563 (90.993)\n",
      "Epoch: [97][85/96]\tLoss 0.1385 (0.1832)\taccuracy 95.312 (93.078)\tf1_score 93.651 (90.990)\n",
      "Epoch: [97][90/96]\tLoss 0.1028 (0.1825)\taccuracy 96.875 (93.115)\tf1_score 97.561 (91.135)\n",
      "Epoch: [97][95/96]\tLoss 0.2029 (0.1818)\taccuracy 92.188 (93.132)\tf1_score 90.952 (91.181)\n",
      " Test: accuracy 66.992 f1_score 59.496\n",
      "Training time:  1558.4183855056763 Hour:  0 Minute:  25 Second:  58 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 98\n",
      "Epoch: [98][0/96]\tLoss 0.1336 (0.1336)\taccuracy 95.312 (95.312)\tf1_score 94.516 (94.516)\n",
      "Epoch: [98][5/96]\tLoss 0.2784 (0.2203)\taccuracy 87.500 (90.365)\tf1_score 86.073 (89.597)\n",
      "Epoch: [98][10/96]\tLoss 0.3034 (0.2097)\taccuracy 92.188 (91.619)\tf1_score 86.576 (89.458)\n",
      "Epoch: [98][15/96]\tLoss 0.2469 (0.2026)\taccuracy 89.062 (91.699)\tf1_score 90.497 (89.948)\n",
      "Epoch: [98][20/96]\tLoss 0.0409 (0.1870)\taccuracy 100.000 (92.485)\tf1_score 100.000 (90.741)\n",
      "Epoch: [98][25/96]\tLoss 0.2211 (0.1969)\taccuracy 87.500 (92.368)\tf1_score 83.364 (90.430)\n",
      "Epoch: [98][30/96]\tLoss 0.1299 (0.1908)\taccuracy 95.312 (92.641)\tf1_score 95.746 (90.734)\n",
      "Epoch: [98][35/96]\tLoss 0.0478 (0.1914)\taccuracy 100.000 (92.752)\tf1_score 100.000 (90.959)\n",
      "Epoch: [98][40/96]\tLoss 0.0846 (0.1917)\taccuracy 95.312 (92.607)\tf1_score 94.389 (90.902)\n",
      "Epoch: [98][45/96]\tLoss 0.1647 (0.1910)\taccuracy 95.312 (92.595)\tf1_score 87.927 (90.846)\n",
      "Epoch: [98][50/96]\tLoss 0.1023 (0.1875)\taccuracy 98.438 (92.862)\tf1_score 96.825 (91.030)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [98][55/96]\tLoss 0.0726 (0.1817)\taccuracy 98.438 (93.192)\tf1_score 97.895 (91.308)\n",
      "Epoch: [98][60/96]\tLoss 0.0699 (0.1767)\taccuracy 98.438 (93.366)\tf1_score 98.095 (91.556)\n",
      "Epoch: [98][65/96]\tLoss 0.0980 (0.1750)\taccuracy 96.875 (93.371)\tf1_score 96.251 (91.598)\n",
      "Epoch: [98][70/96]\tLoss 0.2160 (0.1743)\taccuracy 92.188 (93.288)\tf1_score 91.841 (91.472)\n",
      "Epoch: [98][75/96]\tLoss 0.2721 (0.1747)\taccuracy 90.625 (93.257)\tf1_score 87.427 (91.477)\n",
      "Epoch: [98][80/96]\tLoss 0.1222 (0.1738)\taccuracy 95.312 (93.287)\tf1_score 95.079 (91.481)\n",
      "Epoch: [98][85/96]\tLoss 0.0837 (0.1731)\taccuracy 96.875 (93.350)\tf1_score 95.616 (91.572)\n",
      "Epoch: [98][90/96]\tLoss 0.1563 (0.1716)\taccuracy 95.312 (93.407)\tf1_score 94.389 (91.647)\n",
      "Epoch: [98][95/96]\tLoss 0.2704 (0.1774)\taccuracy 85.938 (93.132)\tf1_score 85.890 (91.381)\n",
      " Test: accuracy 75.456 f1_score 71.056\n",
      "Training time:  1574.1906328201294 Hour:  0 Minute:  26 Second:  14 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 99\n",
      "Epoch: [99][0/96]\tLoss 0.1636 (0.1636)\taccuracy 95.312 (95.312)\tf1_score 94.111 (94.111)\n",
      "Epoch: [99][5/96]\tLoss 0.1204 (0.1261)\taccuracy 98.438 (94.792)\tf1_score 98.286 (93.273)\n",
      "Epoch: [99][10/96]\tLoss 0.1871 (0.1460)\taccuracy 92.188 (94.034)\tf1_score 92.286 (92.457)\n",
      "Epoch: [99][15/96]\tLoss 0.1642 (0.1691)\taccuracy 90.625 (92.773)\tf1_score 89.626 (90.593)\n",
      "Epoch: [99][20/96]\tLoss 0.1620 (0.1739)\taccuracy 93.750 (92.634)\tf1_score 93.173 (90.729)\n",
      "Epoch: [99][25/96]\tLoss 0.1474 (0.1670)\taccuracy 93.750 (93.029)\tf1_score 95.556 (91.493)\n",
      "Epoch: [99][30/96]\tLoss 0.1475 (0.1648)\taccuracy 93.750 (93.196)\tf1_score 92.532 (91.626)\n",
      "Epoch: [99][35/96]\tLoss 0.0966 (0.1699)\taccuracy 98.438 (93.142)\tf1_score 97.980 (91.604)\n",
      "Epoch: [99][40/96]\tLoss 0.1011 (0.1654)\taccuracy 95.312 (93.407)\tf1_score 96.013 (91.825)\n",
      "Epoch: [99][45/96]\tLoss 0.1406 (0.1659)\taccuracy 92.188 (93.308)\tf1_score 92.424 (91.960)\n",
      "Epoch: [99][50/96]\tLoss 0.1833 (0.1635)\taccuracy 95.312 (93.536)\tf1_score 90.590 (91.906)\n",
      "Epoch: [99][55/96]\tLoss 0.1243 (0.1617)\taccuracy 95.312 (93.583)\tf1_score 95.365 (91.897)\n",
      "Epoch: [99][60/96]\tLoss 0.0493 (0.1629)\taccuracy 96.875 (93.622)\tf1_score 95.278 (91.818)\n",
      "Epoch: [99][65/96]\tLoss 0.1638 (0.1637)\taccuracy 95.312 (93.703)\tf1_score 93.492 (91.956)\n",
      "Epoch: [99][70/96]\tLoss 0.1846 (0.1659)\taccuracy 93.750 (93.530)\tf1_score 90.526 (91.740)\n",
      "Epoch: [99][75/96]\tLoss 0.1230 (0.1645)\taccuracy 95.312 (93.565)\tf1_score 94.866 (91.774)\n",
      "Epoch: [99][80/96]\tLoss 0.2431 (0.1657)\taccuracy 92.188 (93.538)\tf1_score 86.700 (91.695)\n",
      "Epoch: [99][85/96]\tLoss 0.2619 (0.1667)\taccuracy 89.062 (93.496)\tf1_score 79.190 (91.540)\n",
      "Epoch: [99][90/96]\tLoss 0.1127 (0.1663)\taccuracy 96.875 (93.595)\tf1_score 97.318 (91.679)\n",
      "Epoch: [99][95/96]\tLoss 0.1620 (0.1660)\taccuracy 95.312 (93.587)\tf1_score 91.217 (91.697)\n",
      " Test: accuracy 68.294 f1_score 62.718\n",
      "Training time:  1590.059578180313 Hour:  0 Minute:  26 Second:  30 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n",
      "\n",
      "Start of epoch NO: 100\n",
      "Epoch: [100][0/96]\tLoss 0.1360 (0.1360)\taccuracy 93.750 (93.750)\tf1_score 89.760 (89.760)\n",
      "Epoch: [100][5/96]\tLoss 0.2571 (0.1824)\taccuracy 92.188 (92.969)\tf1_score 90.690 (90.170)\n",
      "Epoch: [100][10/96]\tLoss 0.1575 (0.1568)\taccuracy 96.875 (94.318)\tf1_score 96.111 (92.307)\n",
      "Epoch: [100][15/96]\tLoss 0.1828 (0.1583)\taccuracy 93.750 (93.750)\tf1_score 95.457 (91.836)\n",
      "Epoch: [100][20/96]\tLoss 0.1795 (0.1553)\taccuracy 92.188 (93.750)\tf1_score 91.111 (91.807)\n",
      "Epoch: [100][25/96]\tLoss 0.0771 (0.1517)\taccuracy 96.875 (93.930)\tf1_score 93.367 (92.218)\n",
      "Epoch: [100][30/96]\tLoss 0.0889 (0.1569)\taccuracy 98.438 (93.800)\tf1_score 97.460 (91.897)\n",
      "Epoch: [100][35/96]\tLoss 0.1454 (0.1544)\taccuracy 95.312 (94.010)\tf1_score 93.397 (92.080)\n",
      "Epoch: [100][40/96]\tLoss 0.1121 (0.1591)\taccuracy 96.875 (93.826)\tf1_score 93.060 (91.258)\n",
      "Epoch: [100][45/96]\tLoss 0.1371 (0.1606)\taccuracy 93.750 (93.750)\tf1_score 93.428 (91.028)\n",
      "Epoch: [100][50/96]\tLoss 0.1457 (0.1692)\taccuracy 93.750 (93.352)\tf1_score 93.821 (90.910)\n",
      "Epoch: [100][55/96]\tLoss 0.1179 (0.1645)\taccuracy 96.875 (93.638)\tf1_score 92.900 (91.342)\n",
      "Epoch: [100][60/96]\tLoss 0.3588 (0.1674)\taccuracy 85.938 (93.596)\tf1_score 85.647 (91.329)\n",
      "Epoch: [100][65/96]\tLoss 0.1892 (0.1675)\taccuracy 90.625 (93.584)\tf1_score 89.206 (91.401)\n",
      "Epoch: [100][70/96]\tLoss 0.3546 (0.1700)\taccuracy 89.062 (93.552)\tf1_score 88.844 (91.242)\n",
      "Epoch: [100][75/96]\tLoss 0.3160 (0.1739)\taccuracy 87.500 (93.421)\tf1_score 84.060 (91.167)\n",
      "Epoch: [100][80/96]\tLoss 0.3376 (0.1745)\taccuracy 85.938 (93.403)\tf1_score 88.144 (91.260)\n",
      "Epoch: [100][85/96]\tLoss 0.2606 (0.1782)\taccuracy 90.625 (93.259)\tf1_score 85.146 (91.053)\n",
      "Epoch: [100][90/96]\tLoss 0.1568 (0.1814)\taccuracy 96.875 (93.115)\tf1_score 97.480 (90.879)\n",
      "Epoch: [100][95/96]\tLoss 0.1987 (0.1799)\taccuracy 93.750 (93.197)\tf1_score 92.661 (91.025)\n",
      " Test: accuracy 83.724 f1_score 80.503\n",
      "Training time:  1605.8864424228668 Hour:  0 Minute:  26 Second:  45 Test best accuracy: 90.55989583333333  Test best f1 score: 88.31191672319767\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch NO: %d\" % (epoch,))\n",
    "    adjust_learning_rate(optimizer, epoch, args=1)\n",
    "    train(train_loader, model, criterion,  optimizer, epoch, print_interval=5)\n",
    "    acc, f1 = validate(test_loader, model, criterion,  args=1)\n",
    "    \n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "    \n",
    "    if is_best:\n",
    "            print('Saving..')\n",
    "            best_f1 = f1\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'best_acc1': best_acc,\n",
    "                'best_acc5': best_f1,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            filename = \"best_model\"\n",
    "            torch.save(state, './checkpoint/' + filename + '_ckpt.t7')\n",
    "                    \n",
    "    time_interval = time.time() - start_time\n",
    "    time_split = time.gmtime(time_interval)\n",
    "    print(\"Training time: \", time_interval, \"Hour: \", time_split.tm_hour, \"Minute: \", time_split.tm_min, \"Second: \",\n",
    "              time_split.tm_sec, end='')\n",
    "    print(\" Test best accuracy:\", best_acc, \" Test best f1 score:\", best_f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed36599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb5b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399effc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
