{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b3032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033c4e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class\n",
       "0                0  2.660984 -9.653030  0.470237      1\n",
       "1                1  2.223091 -9.432167  2.223091      1\n",
       "2                2  2.098372 -9.481953  0.926070      1\n",
       "3                3  2.716461 -9.739352  0.912008      1\n",
       "4                4  2.288388 -9.371498  0.910390      1\n",
       "...            ...       ...       ...       ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21\n",
       "155403      155403  8.680778  4.261679 -0.159214     21\n",
       "155404      155404  8.756194  4.168306 -0.144251     21\n",
       "155405      155405  8.662222  4.219781 -0.183755     21\n",
       "155406      155406  8.738238  4.180277 -0.201711     21\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('no-outlier.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85fc78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0                0  2.660984 -9.653030  0.470237      1      0\n",
       "1                1  2.223091 -9.432167  2.223091      1      0\n",
       "2                2  2.098372 -9.481953  0.926070      1      0\n",
       "3                3  2.716461 -9.739352  0.912008      1      0\n",
       "4                4  2.288388 -9.371498  0.910390      1      0\n",
       "...            ...       ...       ...       ...    ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403      155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404      155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405      155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406      155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = LabelEncoder()\n",
    "data['label'] = label.fit_transform(data['Class'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30036d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209cd61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "fig=sns.boxplot(data=data.iloc[0:8000,1:4],whis=[0, 100])\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945a491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0       2.660984 -9.653030  0.470237      1      0\n",
       "1       2.223091 -9.432167  2.223091      1      0\n",
       "2       2.098372 -9.481953  0.926070      1      0\n",
       "3       2.716461 -9.739352  0.912008      1      0\n",
       "4       2.288388 -9.371498  0.910390      1      0\n",
       "...          ...       ...       ...    ...    ...\n",
       "155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = data.drop('Unnamed: 0', axis=1)  \n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d194de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11dbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn[['Acc_X', 'Acc_Y', 'Acc_Z']]\n",
    "y = dfn['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b72537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acc_X     Acc_Y     Acc_Z\n",
       "0       2.660984 -9.653030  0.470237\n",
       "1       2.223091 -9.432167  2.223091\n",
       "2       2.098372 -9.481953  0.926070\n",
       "3       2.716461 -9.739352  0.912008\n",
       "4       2.288388 -9.371498  0.910390\n",
       "...          ...       ...       ...\n",
       "155402  8.701128  4.238336 -0.194529\n",
       "155403  8.680778  4.261679 -0.159214\n",
       "155404  8.756194  4.168306 -0.144251\n",
       "155405  8.662222  4.219781 -0.183755\n",
       "155406  8.738238  4.180277 -0.201711\n",
       "\n",
       "[155407 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b306756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "155402    20\n",
       "155403    20\n",
       "155404    20\n",
       "155405    20\n",
       "155406    20\n",
       "Name: label, Length: 155407, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e39b31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985481</td>\n",
       "      <td>-0.807007</td>\n",
       "      <td>-0.491449</td>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865844</td>\n",
       "      <td>-0.763546</td>\n",
       "      <td>-0.059973</td>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.773343</td>\n",
       "      <td>-0.379243</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000638</td>\n",
       "      <td>-0.823993</td>\n",
       "      <td>-0.382704</td>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883684</td>\n",
       "      <td>-0.751608</td>\n",
       "      <td>-0.383103</td>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acc_X     Acc_Y     Acc_Z       mag  label\n",
       "0  0.985481 -0.807007 -0.491449  1.365267      0\n",
       "1  0.865844 -0.763546 -0.059973  1.155978      0\n",
       "2  0.831769 -0.773343 -0.379243  1.197382      0\n",
       "3  1.000638 -0.823993 -0.382704  1.351556      0\n",
       "4  0.883684 -0.751608 -0.383103  1.221712      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = ['Acc_X', 'Acc_Y', 'Acc_Z'])\n",
    "scaled_X['mag'] = np.sqrt(scaled_X['Acc_X'] ** 2 + scaled_X['Acc_Y'] ** 2 + scaled_X['Acc_Z'] ** 2)\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e7db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaled_X.drop(['Acc_X', 'Acc_Y', 'Acc_Z'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5aa828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>3.329777</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>3.326341</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>3.331364</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>3.318731</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>3.331576</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mag  label\n",
       "0       1.365267      0\n",
       "1       1.155978      0\n",
       "2       1.197382      0\n",
       "3       1.351556      0\n",
       "4       1.221712      0\n",
       "...          ...    ...\n",
       "155402  3.329777     20\n",
       "155403  3.326341     20\n",
       "155404  3.331364     20\n",
       "155405  3.318731     20\n",
       "155406  3.331576     20\n",
       "\n",
       "[155407 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f87bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f58ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer Nitro 5\\AppData\\Local\\Temp\\ipykernel_7304\\4114532512.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n"
     ]
    }
   ],
   "source": [
    "Fs = 20\n",
    "frame_size = Fs * 20\n",
    "hop_size = Fs * 5\n",
    "frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(scaled_X) - frame_size, hop_size):\n",
    "    x = scaled_X['mag'].values[i: i + frame_size]\n",
    "    label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n",
    "    frames.append([x])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c0a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " ...]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a79cf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.asarray(frames).reshape(-1, frame_size)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4046a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESHAPE SHAPE:  (1551, 400)\n",
      "LABELS:  0\n",
      "LABELS:  (1551,)\n"
     ]
    }
   ],
   "source": [
    "print(\"RESHAPE SHAPE: \",frames.shape)\n",
    "print(\"LABELS: \",labels[0])\n",
    "print(\"LABELS: \",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07a02761",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=frames\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c187522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "127cc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=123, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c6cba4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files=[x_train, y_train]\n",
    "subject_files=[x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60f8ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def print(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "459ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class LoadDataset_from_numpy(Dataset):\n",
    "    def __init__(self, np_data):\n",
    "        super(LoadDataset_from_numpy, self).__init__()\n",
    "        X_train = np_data[0]\n",
    "        y_train = np_data[1]\n",
    "        self.len = X_train.shape[0]\n",
    "        self.x_data = torch.from_numpy(X_train).float()\n",
    "        self.y_data = torch.from_numpy(y_train).long()\n",
    "        self.x_data = self.x_data.view(self.x_data.size()[0], 1, self.x_data.size()[1])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def data_generator_np(training_files, subject_files, batch_size):\n",
    "    train_dataset = LoadDataset_from_numpy(training_files)\n",
    "    test_dataset = LoadDataset_from_numpy(subject_files)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               drop_last=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              drop_last=True,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96893dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = data_generator_np(training_files, subject_files, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "78041b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "\n",
    "\"\"\"\n",
    "2.1  Signal Segments Representation\n",
    "\n",
    "Signal Segment Definition: class SignalSegmentDefinition(nn.Module)\n",
    "Signal Segment Representation: class SignalSegmentRepresentation(nn.Module)\n",
    "\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.1 Global Node Attention: class GNA(nn.Module):\n",
    "\n",
    "***\n",
    "(1) Signal Segment Definition -> (2) Signal Segment Representation -> (3) Global Node Attention\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SignalSegmentDefinition(nn.Module):\n",
    "    \"\"\"\n",
    "   (1) Signal Segment Definition\n",
    "\n",
    "    input size: B, 1, 1, L\n",
    "    output size: B, K, 1, D\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = f.unfold(x, kernel_size=self.kernel_size, stride=self.stride)  # overlapping sliding window\n",
    "        b = b.permute(0, 2, 1)\n",
    "        b = b.unsqueeze(-2)\n",
    "        return b\n",
    "\n",
    "\n",
    "class SignalSegmentRepresentation(nn.Module):\n",
    "    \"\"\"\n",
    "    (2) Signal Segment Representation\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    segment_num: number of the signal segments\n",
    "\n",
    "    input size:  B, 1, 1, L\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, segment_size, overlapping_rate, segment_num):\n",
    "        super(SignalSegmentRepresentation, self).__init__()\n",
    "        self.overlapping = int(segment_size - segment_size * overlapping_rate)\n",
    "        self.segment = SignalSegmentDefinition((1, segment_size), self.overlapping)\n",
    "        self.segment2vec = SignalSegment2Vec(30)\n",
    "        self.gna = GNA(segment_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        signal_segments = []\n",
    "        x = self.segment(x)\n",
    "        x = x.squeeze()\n",
    "        \"share the SignalSegment2Vec Encoder\"\n",
    "        for idx in range(x.size()[1]):\n",
    "            data = x[:, idx, :]\n",
    "            data = data.unsqueeze(1)\n",
    "            out = self.segment2vec(data)\n",
    "            out = out.view(x.size()[0], 1, -1)\n",
    "            signal_segments.append(out)\n",
    "        signal_segments = torch.cat(signal_segments, dim=1)\n",
    "        signal_segments = signal_segments .unsqueeze(2)\n",
    "        \"global node attention\"\n",
    "        signal_segments = self.gna(signal_segments).permute(0, 2, 1, 3)\n",
    "        return signal_segments\n",
    "\n",
    "\n",
    "class GNA(nn.Module):\n",
    "    \"\"\"\n",
    "    (3) Global Node Attention\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "\n",
    "    input size: B, K, 1, C\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(GNA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SignalSegment2Vec(nn.Module):\n",
    "    \"\"\"\n",
    "    SignalSegment2Vec Encoder module in Signal Segment Representation\n",
    "\n",
    "    input size:  B, K, 1, D\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, afr_reduced_cnn_size):\n",
    "        super(SignalSegment2Vec, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=49, stride=6, bias=False, padding=int(49//2)),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool1d(kernel_size=7, stride=4, padding=int(7//2)),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv1d(128, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=3, stride=4, padding=int(3//2)),\n",
    "        )\n",
    "\n",
    "        self.inplanes = 128\n",
    "        self.AFR = self._make_layer(ResBasicBlock, afr_reduced_cnn_size, 1)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.AFR(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"Residual Squeeze-and-Excitation(SE) Block\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class ResBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=4):\n",
    "        super(ResBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.GELU()\n",
    "        self.conv2 = nn.Conv1d(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.reslayer = ResLayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.reslayer(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cdfb2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.2 Graph-based Self Attention\n",
    "\n",
    "graph attention: class Attention(nn.Module)\n",
    "convolution-based multi-head attention: class Block(nn.Module)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention (see Eq.4)\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "    input size:  B, M, K, C\n",
    "    output size: B, M, K, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((None, 1)),\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, K, _ = x.size()\n",
    "        adj = self.pearson(x)  # adjacency matrix\n",
    "        x_ = self._prepare_attentional_mechanism_input(x)\n",
    "        e = self.attn(x_)\n",
    "        e = e.permute(0, 2, 1, 3).contiguous()\n",
    "        e = e.view(B, M, K, K)\n",
    "        zero_vec_adj = -9e15 * torch.ones_like(adj)\n",
    "        attention = torch.where(adj > 0, e, zero_vec_adj)\n",
    "        attention = f.softmax(attention, dim=-1)\n",
    "        x = torch.matmul(attention, x)\n",
    "        return x, adj\n",
    "\n",
    "    def h_matmul(self, x):\n",
    "        N = x.size()[-2]\n",
    "        x_repeated_in_chunks = x.repeat_interleave(N, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, N, 1)\n",
    "        result = torch.mul(x_repeated_in_chunks, x_repeated_alternating)\n",
    "        return result\n",
    "\n",
    "    def pearson(self, x):\n",
    "        \"Pearson Correlation\"\n",
    "        centered_h = x - x.mean(dim=-1, keepdim=True)\n",
    "        covariance = self.h_matmul(centered_h).sum(dim=-1, keepdim=True)\n",
    "        bessel_corrected_covariance = torch.div(covariance, (x.shape[-1] - 1))\n",
    "        std_h = x.std(dim=-1, keepdim=True)\n",
    "        p = torch.div(bessel_corrected_covariance, (self.h_matmul(std_h)))\n",
    "        p = p.view(x.size()[0], x.size()[1], x.size()[2], -1)\n",
    "        return p\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, x):\n",
    "        \"concatenation operation (see Eq.4) with positional encoding\"\n",
    "        B, _, K, _ = x.size()\n",
    "        x_repeated_in_chunks = x.repeat_interleave(K, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, K, 1)\n",
    "\n",
    "        \"positional encoding\"\n",
    "        pos = 2 * torch.ones_like(x_repeated_alternating)\n",
    "        one_vec = torch.ones_like(x_repeated_alternating)\n",
    "        x_repeated_in_chunks.eq(x_repeated_alternating)\n",
    "        pos = torch.where(x_repeated_in_chunks.eq(x_repeated_alternating) > 0, one_vec, pos)\n",
    "        x_repeated_alternating = pos * x_repeated_alternating\n",
    "\n",
    "        all_combinations_matrix = torch.cat([x_repeated_in_chunks, x_repeated_alternating], dim=-1)\n",
    "        all_combinations_matrix = all_combinations_matrix.permute(0, 2, 1, 3)\n",
    "        return all_combinations_matrix\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention (see Fig.2)\n",
    "\n",
    "    input arg:\n",
    "    node_size: number of the signal segments\n",
    "    input_size: Q in Fig. 2\n",
    "    multi_heads: number of heads\n",
    "\n",
    "    input size: B, J, K, C    J=1 when H=1\n",
    "    output size: B, M'', K, C''\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_size, input_size, kernel_size, stride, multi_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        expand = 1\n",
    "\n",
    "        padding = kernel_size//2\n",
    "        self.mid_channels_ = (multi_heads - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "        self.multi_head = nn.Sequential(\n",
    "            nn.Conv2d(input_size, multi_heads, 1, bias=False),\n",
    "            nn.Conv2d(multi_heads, multi_heads, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                      groups=node_size, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.attn = Attention(node_size * node_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Conv2d(self.mid_channels_, self.mid_channels_ * 4, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.mid_channels_ * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.mid_channels_ * 4, multi_heads * expand, 1, bias=False),\n",
    "            nn.BatchNorm2d(multi_heads)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.AdaptiveAvgPool2d((1, None))\n",
    "        )\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(multi_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x.permute(0, 2, 1, 3)                 # B, J, K, C -> B, K, J, C\n",
    "        \"Dense layers\"\n",
    "        out = self.multi_head(x)                    # B, J, K, C -> B, M, K, C, where M is the number of heads\n",
    "        out, adj = self.attn(out)\n",
    "        self.adj = adj                              # for visualization\n",
    "        out = f.gelu(self.norm(out))\n",
    "        out = out.permute(0, 2, 1, 3)               # B, M, K, C -> B, K, M, C\n",
    "        \"Attention Layers\"\n",
    "        out = self.feature_extraction(out)          # B, K, M, C -> B, K, M', C'\n",
    "        out = out.permute(0, 2, 1, 3)               # B, K, M', C' -> B, M', K, C'\n",
    "        out = self.feed_forward(out)                # B, M', K, C' -> B, M'', K, C''\n",
    "        shortcut = self.shortcut(res)               # B, K, J, C -> B, 1, K, C''\n",
    "        shortcut = shortcut.permute(0, 2, 1, 3)\n",
    "        out += shortcut                             # (B, M'', K, C'') + (B, 1, K, C'') -> (B, M'', K, C'') Broadcast\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9fee4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11d6c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRAPHSENSOR(nn.Module):\n",
    "    \"\"\"\n",
    "    GRAPHSENSOR main()\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    in_channels: number of the signal segments\n",
    "    class_num: class number\n",
    "\n",
    "    input size: B, 1, L\n",
    "    output size: B, class_num\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_size, overlapping_rate, in_channels, class_num):\n",
    "        super(GRAPHSENSOR, self).__init__()\n",
    "        self.segment_size = segment_size\n",
    "        self.signal_segments = SignalSegmentRepresentation(segment_size, overlapping_rate, in_channels)\n",
    "        \"\"\"\n",
    "        The encoder is composed of a stack of H=4 identical layers\n",
    "        Multi-head number: 16 -> 32 -> 64 -> 128\n",
    "        \"\"\"\n",
    "        self.attn = nn.Sequential(\n",
    "            Block(in_channels, 1,   5, 2, 16),\n",
    "            Block(in_channels, 16,  5, 2, 32),\n",
    "            Block(in_channels, 32,  5, 1, 64),\n",
    "            Block(in_channels, 64,  5, 1, 128),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 128, 512, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(1024, class_num, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.signal_segments(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.flatten(1)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99dadfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d5f53bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRAPHSENSOR(segment_size=80, overlapping_rate=0.5, in_channels=9, class_num=21).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aa86028f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,561,768 trainable parameter\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e960e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() >= 1:\n",
    "        print(\"num GPUs: \", torch.cuda.device_count())\n",
    "        model = nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ea4c5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d4f024b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "400e3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001, amsgrad=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ec3ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ddbb94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch == 10:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "11734a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "81676f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e013a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "        return correct * 100 / len(target)\n",
    "\n",
    "\n",
    "def f1_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "    return f1_score(pred.cpu().numpy(), target.data.cpu().numpy(), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "87b9d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_interval):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score', ':.4e')\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        acc = accuracy_(output, target)\n",
    "        f1 = f1_(output, target) * 100\n",
    "        accuracy.update(acc, data.size(0))\n",
    "        f1_score.update(f1, data.size(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'accuracy {accuracy.val:.3f} ({accuracy.avg:.3f})\\t'\n",
    "                  'f1_score {f1_score.val:.3f} ({f1_score.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), loss=losses, accuracy=accuracy, f1_score=f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8b32997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score ', ':.4e')\n",
    "    progress = ProgressMeter(len(val_loader), losses, accuracy, f1_score,\n",
    "                             prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            acc = accuracy_(output, target)\n",
    "            f1 = f1_(output, target) * 100\n",
    "            accuracy.update(acc, data.size(0))\n",
    "            f1_score.update(f1, data.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # TODO: this should also be done with the ProgressMeter\n",
    "        print(' Test: accuracy {accuracy.avg:.3f} f1_score {f1_score.avg:.3f}'\n",
    "              .format(accuracy=accuracy, f1_score=f1_score))\n",
    "\n",
    "        return accuracy.avg, f1_score.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9e2a07db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch NO: 0\n",
      "Epoch: [0][0/19]\tLoss 3.2016 (3.2016)\taccuracy 0.000 (0.000)\tf1_score 0.000 (0.000)\n",
      "Epoch: [0][5/19]\tLoss 2.5284 (2.7301)\taccuracy 9.375 (10.938)\tf1_score 4.731 (6.316)\n",
      "Epoch: [0][10/19]\tLoss 2.2316 (2.5330)\taccuracy 23.438 (15.057)\tf1_score 17.283 (9.838)\n",
      "Epoch: [0][15/19]\tLoss 2.2724 (2.4534)\taccuracy 26.562 (18.457)\tf1_score 15.507 (12.415)\n",
      " Test: accuracy 10.938 f1_score 3.623\n",
      "Training time:  7.551445484161377 Hour:  0 Minute:  0 Second:  7 Test best accuracy: 10.9375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 1\n",
      "Epoch: [1][0/19]\tLoss 2.2995 (2.2995)\taccuracy 21.875 (21.875)\tf1_score 14.363 (14.363)\n",
      "Epoch: [1][5/19]\tLoss 1.9878 (2.1742)\taccuracy 34.375 (24.740)\tf1_score 23.231 (18.114)\n",
      "Epoch: [1][10/19]\tLoss 2.1458 (2.1542)\taccuracy 26.562 (25.284)\tf1_score 18.153 (18.268)\n",
      "Epoch: [1][15/19]\tLoss 2.1775 (2.1427)\taccuracy 20.312 (25.488)\tf1_score 15.153 (18.248)\n",
      " Test: accuracy 16.016 f1_score 7.545\n",
      "Training time:  10.444706439971924 Hour:  0 Minute:  0 Second:  10 Test best accuracy: 16.015625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 2\n",
      "Epoch: [2][0/19]\tLoss 1.9247 (1.9247)\taccuracy 34.375 (34.375)\tf1_score 27.085 (27.085)\n",
      "Epoch: [2][5/19]\tLoss 1.7261 (1.8644)\taccuracy 37.500 (33.594)\tf1_score 22.055 (23.636)\n",
      "Epoch: [2][10/19]\tLoss 1.8884 (1.9405)\taccuracy 28.125 (30.398)\tf1_score 18.549 (21.407)\n",
      "Epoch: [2][15/19]\tLoss 2.0198 (1.9837)\taccuracy 21.875 (27.930)\tf1_score 17.651 (20.306)\n",
      " Test: accuracy 19.922 f1_score 13.129\n",
      "Training time:  13.33298110961914 Hour:  0 Minute:  0 Second:  13 Test best accuracy: 19.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 3\n",
      "Epoch: [3][0/19]\tLoss 1.9448 (1.9448)\taccuracy 28.125 (28.125)\tf1_score 21.091 (21.091)\n",
      "Epoch: [3][5/19]\tLoss 2.1363 (1.9576)\taccuracy 15.625 (26.042)\tf1_score 9.283 (18.444)\n",
      "Epoch: [3][10/19]\tLoss 1.6634 (1.8387)\taccuracy 37.500 (30.682)\tf1_score 26.604 (22.592)\n",
      "Epoch: [3][15/19]\tLoss 1.6577 (1.8264)\taccuracy 37.500 (31.641)\tf1_score 29.715 (23.718)\n",
      " Test: accuracy 31.250 f1_score 23.288\n",
      "Training time:  16.24219822883606 Hour:  0 Minute:  0 Second:  16 Test best accuracy: 31.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 4\n",
      "Epoch: [4][0/19]\tLoss 1.7002 (1.7002)\taccuracy 31.250 (31.250)\tf1_score 22.320 (22.320)\n",
      "Epoch: [4][5/19]\tLoss 1.6834 (1.8489)\taccuracy 32.812 (29.688)\tf1_score 27.677 (24.661)\n",
      "Epoch: [4][10/19]\tLoss 1.8888 (1.8180)\taccuracy 31.250 (30.824)\tf1_score 22.463 (24.830)\n",
      "Epoch: [4][15/19]\tLoss 1.8001 (1.8020)\taccuracy 31.250 (31.348)\tf1_score 27.023 (25.230)\n",
      " Test: accuracy 32.812 f1_score 23.234\n",
      "Training time:  19.15209984779358 Hour:  0 Minute:  0 Second:  19 Test best accuracy: 32.8125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 5\n",
      "Epoch: [5][0/19]\tLoss 1.6729 (1.6729)\taccuracy 34.375 (34.375)\tf1_score 21.379 (21.379)\n",
      "Epoch: [5][5/19]\tLoss 1.7487 (1.6068)\taccuracy 35.938 (39.062)\tf1_score 33.657 (33.045)\n",
      "Epoch: [5][10/19]\tLoss 1.6350 (1.5948)\taccuracy 39.062 (39.205)\tf1_score 31.670 (32.258)\n",
      "Epoch: [5][15/19]\tLoss 1.6028 (1.6047)\taccuracy 32.812 (37.500)\tf1_score 22.126 (31.071)\n",
      " Test: accuracy 36.328 f1_score 26.356\n",
      "Training time:  22.079302072525024 Hour:  0 Minute:  0 Second:  22 Test best accuracy: 36.328125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 6\n",
      "Epoch: [6][0/19]\tLoss 1.5208 (1.5208)\taccuracy 43.750 (43.750)\tf1_score 32.794 (32.794)\n",
      "Epoch: [6][5/19]\tLoss 1.4680 (1.5067)\taccuracy 40.625 (44.792)\tf1_score 31.144 (33.563)\n",
      "Epoch: [6][10/19]\tLoss 1.4092 (1.5055)\taccuracy 51.562 (44.034)\tf1_score 40.904 (34.417)\n",
      "Epoch: [6][15/19]\tLoss 1.8848 (1.5016)\taccuracy 18.750 (42.188)\tf1_score 17.319 (33.227)\n",
      " Test: accuracy 35.156 f1_score 27.233\n",
      "Training time:  24.984530687332153 Hour:  0 Minute:  0 Second:  24 Test best accuracy: 36.328125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 7\n",
      "Epoch: [7][0/19]\tLoss 1.3235 (1.3235)\taccuracy 43.750 (43.750)\tf1_score 35.123 (35.123)\n",
      "Epoch: [7][5/19]\tLoss 1.4554 (1.4976)\taccuracy 45.312 (41.927)\tf1_score 33.371 (33.434)\n",
      "Epoch: [7][10/19]\tLoss 1.6128 (1.4669)\taccuracy 42.188 (42.614)\tf1_score 39.174 (35.470)\n",
      "Epoch: [7][15/19]\tLoss 1.5281 (1.4484)\taccuracy 43.750 (45.410)\tf1_score 35.682 (37.646)\n",
      " Test: accuracy 39.453 f1_score 32.226\n",
      "Training time:  27.911689281463623 Hour:  0 Minute:  0 Second:  27 Test best accuracy: 39.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 8\n",
      "Epoch: [8][0/19]\tLoss 1.4350 (1.4350)\taccuracy 45.312 (45.312)\tf1_score 39.762 (39.762)\n",
      "Epoch: [8][5/19]\tLoss 1.8904 (1.4657)\taccuracy 28.125 (43.490)\tf1_score 19.923 (36.396)\n",
      "Epoch: [8][10/19]\tLoss 1.2195 (1.4492)\taccuracy 51.562 (43.892)\tf1_score 40.518 (36.460)\n",
      "Epoch: [8][15/19]\tLoss 1.4873 (1.4312)\taccuracy 53.125 (45.605)\tf1_score 51.471 (38.603)\n",
      " Test: accuracy 45.703 f1_score 36.367\n",
      "Training time:  30.82588529586792 Hour:  0 Minute:  0 Second:  30 Test best accuracy: 45.703125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 9\n",
      "Epoch: [9][0/19]\tLoss 1.2187 (1.2187)\taccuracy 54.688 (54.688)\tf1_score 45.928 (45.928)\n",
      "Epoch: [9][5/19]\tLoss 1.4384 (1.2548)\taccuracy 46.875 (52.604)\tf1_score 41.509 (44.971)\n",
      "Epoch: [9][10/19]\tLoss 1.5445 (1.3442)\taccuracy 37.500 (47.017)\tf1_score 34.490 (40.356)\n",
      "Epoch: [9][15/19]\tLoss 1.1744 (1.3426)\taccuracy 53.125 (46.875)\tf1_score 42.760 (40.919)\n",
      " Test: accuracy 46.094 f1_score 38.571\n",
      "Training time:  33.75519871711731 Hour:  0 Minute:  0 Second:  33 Test best accuracy: 46.09375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 10\n",
      "Epoch: [10][0/19]\tLoss 1.2470 (1.2470)\taccuracy 56.250 (56.250)\tf1_score 42.267 (42.267)\n",
      "Epoch: [10][5/19]\tLoss 1.3079 (1.2823)\taccuracy 48.438 (53.385)\tf1_score 41.013 (44.514)\n",
      "Epoch: [10][10/19]\tLoss 1.3021 (1.2355)\taccuracy 51.562 (54.830)\tf1_score 47.473 (46.404)\n",
      "Epoch: [10][15/19]\tLoss 1.2573 (1.2561)\taccuracy 48.438 (53.027)\tf1_score 43.595 (44.899)\n",
      " Test: accuracy 29.688 f1_score 22.571\n",
      "Training time:  36.67804193496704 Hour:  0 Minute:  0 Second:  36 Test best accuracy: 46.09375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 11\n",
      "Epoch: [11][0/19]\tLoss 1.1324 (1.1324)\taccuracy 51.562 (51.562)\tf1_score 43.984 (43.984)\n",
      "Epoch: [11][5/19]\tLoss 1.4047 (1.2636)\taccuracy 42.188 (47.656)\tf1_score 32.643 (42.132)\n",
      "Epoch: [11][10/19]\tLoss 1.3101 (1.2480)\taccuracy 45.312 (48.580)\tf1_score 39.810 (43.729)\n",
      "Epoch: [11][15/19]\tLoss 1.5406 (1.3054)\taccuracy 50.000 (48.926)\tf1_score 42.238 (43.087)\n",
      " Test: accuracy 48.828 f1_score 42.091\n",
      "Training time:  39.586262226104736 Hour:  0 Minute:  0 Second:  39 Test best accuracy: 48.828125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 12\n",
      "Epoch: [12][0/19]\tLoss 1.2769 (1.2769)\taccuracy 46.875 (46.875)\tf1_score 39.753 (39.753)\n",
      "Epoch: [12][5/19]\tLoss 1.5062 (1.3120)\taccuracy 42.188 (49.219)\tf1_score 32.893 (40.373)\n",
      "Epoch: [12][10/19]\tLoss 1.1984 (1.2846)\taccuracy 54.688 (49.432)\tf1_score 45.044 (41.025)\n",
      "Epoch: [12][15/19]\tLoss 1.2495 (1.2938)\taccuracy 48.438 (49.414)\tf1_score 42.159 (41.726)\n",
      " Test: accuracy 46.484 f1_score 38.618\n",
      "Training time:  42.492491483688354 Hour:  0 Minute:  0 Second:  42 Test best accuracy: 48.828125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 13\n",
      "Epoch: [13][0/19]\tLoss 1.3235 (1.3235)\taccuracy 53.125 (53.125)\tf1_score 45.823 (45.823)\n",
      "Epoch: [13][5/19]\tLoss 1.0192 (1.2023)\taccuracy 57.812 (54.167)\tf1_score 50.816 (48.185)\n",
      "Epoch: [13][10/19]\tLoss 1.1934 (1.1789)\taccuracy 51.562 (54.972)\tf1_score 44.619 (48.664)\n",
      "Epoch: [13][15/19]\tLoss 1.1434 (1.1723)\taccuracy 56.250 (54.492)\tf1_score 54.254 (48.299)\n",
      " Test: accuracy 43.750 f1_score 38.149\n",
      "Training time:  45.40470099449158 Hour:  0 Minute:  0 Second:  45 Test best accuracy: 48.828125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 14\n",
      "Epoch: [14][0/19]\tLoss 1.2568 (1.2568)\taccuracy 42.188 (42.188)\tf1_score 35.673 (35.673)\n",
      "Epoch: [14][5/19]\tLoss 1.1486 (1.2565)\taccuracy 59.375 (48.438)\tf1_score 54.967 (45.241)\n",
      "Epoch: [14][10/19]\tLoss 0.9092 (1.2155)\taccuracy 65.625 (51.847)\tf1_score 49.593 (46.636)\n",
      "Epoch: [14][15/19]\tLoss 0.9413 (1.1622)\taccuracy 65.625 (55.469)\tf1_score 53.310 (49.299)\n",
      " Test: accuracy 56.250 f1_score 49.469\n",
      "Training time:  48.55103898048401 Hour:  0 Minute:  0 Second:  48 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 15\n",
      "Epoch: [15][0/19]\tLoss 0.9924 (0.9924)\taccuracy 60.938 (60.938)\tf1_score 54.039 (54.039)\n",
      "Epoch: [15][5/19]\tLoss 0.9145 (1.2007)\taccuracy 67.188 (55.208)\tf1_score 62.955 (49.892)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][10/19]\tLoss 1.6163 (1.2810)\taccuracy 42.188 (51.989)\tf1_score 40.915 (46.682)\n",
      "Epoch: [15][15/19]\tLoss 1.2055 (1.2562)\taccuracy 51.562 (52.539)\tf1_score 45.357 (46.737)\n",
      " Test: accuracy 47.266 f1_score 38.549\n",
      "Training time:  51.90219187736511 Hour:  0 Minute:  0 Second:  51 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 16\n",
      "Epoch: [16][0/19]\tLoss 1.2242 (1.2242)\taccuracy 62.500 (62.500)\tf1_score 57.707 (57.707)\n",
      "Epoch: [16][5/19]\tLoss 1.2335 (1.1483)\taccuracy 50.000 (55.208)\tf1_score 45.670 (50.181)\n",
      "Epoch: [16][10/19]\tLoss 1.0353 (1.2324)\taccuracy 57.812 (51.278)\tf1_score 48.360 (44.606)\n",
      "Epoch: [16][15/19]\tLoss 1.1847 (1.2100)\taccuracy 53.125 (53.125)\tf1_score 46.410 (46.064)\n",
      " Test: accuracy 42.969 f1_score 36.964\n",
      "Training time:  55.20479106903076 Hour:  0 Minute:  0 Second:  55 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 17\n",
      "Epoch: [17][0/19]\tLoss 1.0479 (1.0479)\taccuracy 65.625 (65.625)\tf1_score 53.052 (53.052)\n",
      "Epoch: [17][5/19]\tLoss 1.1191 (1.0830)\taccuracy 51.562 (57.552)\tf1_score 48.314 (47.991)\n",
      "Epoch: [17][10/19]\tLoss 0.9864 (1.0760)\taccuracy 67.188 (58.523)\tf1_score 59.372 (50.225)\n",
      "Epoch: [17][15/19]\tLoss 1.1684 (1.1303)\taccuracy 53.125 (55.957)\tf1_score 44.550 (49.068)\n",
      " Test: accuracy 26.562 f1_score 20.917\n",
      "Training time:  58.37970590591431 Hour:  0 Minute:  0 Second:  58 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 18\n",
      "Epoch: [18][0/19]\tLoss 1.0328 (1.0328)\taccuracy 62.500 (62.500)\tf1_score 52.295 (52.295)\n",
      "Epoch: [18][5/19]\tLoss 1.2614 (1.1767)\taccuracy 50.000 (54.948)\tf1_score 47.563 (49.426)\n",
      "Epoch: [18][10/19]\tLoss 1.1018 (1.0990)\taccuracy 56.250 (57.670)\tf1_score 49.517 (51.872)\n",
      "Epoch: [18][15/19]\tLoss 1.1846 (1.0600)\taccuracy 50.000 (58.789)\tf1_score 47.882 (52.954)\n",
      " Test: accuracy 46.484 f1_score 38.868\n",
      "Training time:  61.3625271320343 Hour:  0 Minute:  1 Second:  1 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 19\n",
      "Epoch: [19][0/19]\tLoss 0.7591 (0.7591)\taccuracy 64.062 (64.062)\tf1_score 58.753 (58.753)\n",
      "Epoch: [19][5/19]\tLoss 0.8778 (0.9393)\taccuracy 70.312 (61.198)\tf1_score 55.533 (53.194)\n",
      "Epoch: [19][10/19]\tLoss 0.7869 (0.9597)\taccuracy 65.625 (60.227)\tf1_score 58.426 (53.466)\n",
      "Epoch: [19][15/19]\tLoss 1.2612 (1.1005)\taccuracy 53.125 (55.469)\tf1_score 50.395 (50.179)\n",
      " Test: accuracy 48.828 f1_score 43.994\n",
      "Training time:  64.34500527381897 Hour:  0 Minute:  1 Second:  4 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 20\n",
      "Epoch: [20][0/19]\tLoss 0.9706 (0.9706)\taccuracy 62.500 (62.500)\tf1_score 58.605 (58.605)\n",
      "Epoch: [20][5/19]\tLoss 1.0267 (1.0384)\taccuracy 64.062 (59.896)\tf1_score 62.802 (54.455)\n",
      "Epoch: [20][10/19]\tLoss 0.9284 (1.0172)\taccuracy 64.062 (60.511)\tf1_score 55.765 (54.426)\n",
      "Epoch: [20][15/19]\tLoss 1.1586 (1.0532)\taccuracy 53.125 (58.691)\tf1_score 47.643 (52.598)\n",
      " Test: accuracy 41.797 f1_score 33.697\n",
      "Training time:  67.33092927932739 Hour:  0 Minute:  1 Second:  7 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 21\n",
      "Epoch: [21][0/19]\tLoss 1.0764 (1.0764)\taccuracy 57.812 (57.812)\tf1_score 53.613 (53.613)\n",
      "Epoch: [21][5/19]\tLoss 1.0089 (1.0524)\taccuracy 51.562 (57.292)\tf1_score 43.484 (50.924)\n",
      "Epoch: [21][10/19]\tLoss 0.8793 (1.0338)\taccuracy 62.500 (58.807)\tf1_score 59.042 (52.850)\n",
      "Epoch: [21][15/19]\tLoss 1.2075 (1.0516)\taccuracy 54.688 (58.887)\tf1_score 47.060 (53.618)\n",
      " Test: accuracy 37.891 f1_score 31.547\n",
      "Training time:  70.34620809555054 Hour:  0 Minute:  1 Second:  10 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 22\n",
      "Epoch: [22][0/19]\tLoss 1.1669 (1.1669)\taccuracy 46.875 (46.875)\tf1_score 39.410 (39.410)\n",
      "Epoch: [22][5/19]\tLoss 1.5192 (1.0764)\taccuracy 35.938 (58.594)\tf1_score 35.100 (52.096)\n",
      "Epoch: [22][10/19]\tLoss 0.8867 (1.0407)\taccuracy 62.500 (59.091)\tf1_score 57.396 (52.456)\n",
      "Epoch: [22][15/19]\tLoss 0.8482 (1.0608)\taccuracy 60.938 (57.129)\tf1_score 54.231 (50.830)\n",
      " Test: accuracy 45.312 f1_score 39.003\n",
      "Training time:  73.33209133148193 Hour:  0 Minute:  1 Second:  13 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 23\n",
      "Epoch: [23][0/19]\tLoss 1.0486 (1.0486)\taccuracy 60.938 (60.938)\tf1_score 52.263 (52.263)\n",
      "Epoch: [23][5/19]\tLoss 1.3663 (1.1557)\taccuracy 45.312 (51.562)\tf1_score 43.439 (47.624)\n",
      "Epoch: [23][10/19]\tLoss 1.1709 (1.1254)\taccuracy 54.688 (54.261)\tf1_score 47.035 (49.310)\n",
      "Epoch: [23][15/19]\tLoss 1.1365 (1.1834)\taccuracy 59.375 (53.027)\tf1_score 56.808 (48.154)\n",
      " Test: accuracy 31.641 f1_score 23.436\n",
      "Training time:  76.32042598724365 Hour:  0 Minute:  1 Second:  16 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 24\n",
      "Epoch: [24][0/19]\tLoss 1.0248 (1.0248)\taccuracy 62.500 (62.500)\tf1_score 48.690 (48.690)\n",
      "Epoch: [24][5/19]\tLoss 1.1666 (1.2072)\taccuracy 51.562 (53.385)\tf1_score 43.419 (42.592)\n",
      "Epoch: [24][10/19]\tLoss 0.9296 (1.2126)\taccuracy 56.250 (53.267)\tf1_score 48.877 (44.883)\n",
      "Epoch: [24][15/19]\tLoss 1.0917 (1.1618)\taccuracy 57.812 (54.883)\tf1_score 56.466 (47.697)\n",
      " Test: accuracy 31.641 f1_score 25.051\n",
      "Training time:  79.34816813468933 Hour:  0 Minute:  1 Second:  19 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 25\n",
      "Epoch: [25][0/19]\tLoss 1.0082 (1.0082)\taccuracy 56.250 (56.250)\tf1_score 51.446 (51.446)\n",
      "Epoch: [25][5/19]\tLoss 0.9794 (1.0427)\taccuracy 62.500 (61.198)\tf1_score 50.571 (53.279)\n",
      "Epoch: [25][10/19]\tLoss 1.1866 (1.0792)\taccuracy 48.438 (58.381)\tf1_score 46.676 (51.720)\n",
      "Epoch: [25][15/19]\tLoss 1.1540 (1.0675)\taccuracy 56.250 (58.301)\tf1_score 52.705 (51.015)\n",
      " Test: accuracy 55.469 f1_score 50.173\n",
      "Training time:  82.34498262405396 Hour:  0 Minute:  1 Second:  22 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 26\n",
      "Epoch: [26][0/19]\tLoss 1.0225 (1.0225)\taccuracy 56.250 (56.250)\tf1_score 51.277 (51.277)\n",
      "Epoch: [26][5/19]\tLoss 0.9524 (0.9291)\taccuracy 64.062 (62.760)\tf1_score 53.660 (55.640)\n",
      "Epoch: [26][10/19]\tLoss 1.0179 (0.9435)\taccuracy 53.125 (61.790)\tf1_score 46.859 (55.653)\n",
      "Epoch: [26][15/19]\tLoss 1.0572 (0.9353)\taccuracy 51.562 (62.207)\tf1_score 51.160 (57.181)\n",
      " Test: accuracy 55.859 f1_score 50.549\n",
      "Training time:  85.37913084030151 Hour:  0 Minute:  1 Second:  25 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 27\n",
      "Epoch: [27][0/19]\tLoss 0.9343 (0.9343)\taccuracy 67.188 (67.188)\tf1_score 60.430 (60.430)\n",
      "Epoch: [27][5/19]\tLoss 0.7839 (0.8412)\taccuracy 71.875 (69.010)\tf1_score 69.034 (63.930)\n",
      "Epoch: [27][10/19]\tLoss 1.3255 (0.9322)\taccuracy 53.125 (65.483)\tf1_score 48.231 (60.848)\n",
      "Epoch: [27][15/19]\tLoss 0.8184 (0.9396)\taccuracy 73.438 (65.137)\tf1_score 67.290 (59.667)\n",
      " Test: accuracy 53.125 f1_score 47.037\n",
      "Training time:  88.68452572822571 Hour:  0 Minute:  1 Second:  28 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 28\n",
      "Epoch: [28][0/19]\tLoss 0.7301 (0.7301)\taccuracy 76.562 (76.562)\tf1_score 72.800 (72.800)\n",
      "Epoch: [28][5/19]\tLoss 0.9707 (0.8911)\taccuracy 60.938 (64.323)\tf1_score 58.753 (59.194)\n",
      "Epoch: [28][10/19]\tLoss 0.8344 (0.8436)\taccuracy 70.312 (66.903)\tf1_score 68.276 (61.617)\n",
      "Epoch: [28][15/19]\tLoss 0.7475 (0.8486)\taccuracy 67.188 (67.285)\tf1_score 55.855 (62.042)\n",
      " Test: accuracy 52.734 f1_score 46.560\n",
      "Training time:  91.76959228515625 Hour:  0 Minute:  1 Second:  31 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 29\n",
      "Epoch: [29][0/19]\tLoss 0.8711 (0.8711)\taccuracy 64.062 (64.062)\tf1_score 51.992 (51.992)\n",
      "Epoch: [29][5/19]\tLoss 0.8284 (0.8121)\taccuracy 64.062 (67.708)\tf1_score 57.826 (60.796)\n",
      "Epoch: [29][10/19]\tLoss 0.8471 (0.8063)\taccuracy 65.625 (68.040)\tf1_score 57.200 (61.208)\n",
      "Epoch: [29][15/19]\tLoss 0.8650 (0.8365)\taccuracy 65.625 (66.211)\tf1_score 58.327 (59.641)\n",
      " Test: accuracy 53.906 f1_score 47.834\n",
      "Training time:  94.77860593795776 Hour:  0 Minute:  1 Second:  34 Test best accuracy: 56.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 30\n",
      "Epoch: [30][0/19]\tLoss 0.8469 (0.8469)\taccuracy 70.312 (70.312)\tf1_score 67.149 (67.149)\n",
      "Epoch: [30][5/19]\tLoss 0.9458 (0.7920)\taccuracy 67.188 (71.354)\tf1_score 69.631 (67.787)\n",
      "Epoch: [30][10/19]\tLoss 0.8523 (0.8357)\taccuracy 68.750 (69.744)\tf1_score 61.128 (65.176)\n",
      "Epoch: [30][15/19]\tLoss 0.7816 (0.8851)\taccuracy 62.500 (66.211)\tf1_score 55.548 (62.256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test: accuracy 59.375 f1_score 53.809\n",
      "Training time:  97.79005336761475 Hour:  0 Minute:  1 Second:  37 Test best accuracy: 59.375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 31\n",
      "Epoch: [31][0/19]\tLoss 0.9010 (0.9010)\taccuracy 64.062 (64.062)\tf1_score 59.982 (59.982)\n",
      "Epoch: [31][5/19]\tLoss 0.7587 (0.8417)\taccuracy 70.312 (66.406)\tf1_score 57.673 (61.269)\n",
      "Epoch: [31][10/19]\tLoss 0.9217 (0.8197)\taccuracy 67.188 (68.182)\tf1_score 57.559 (62.497)\n",
      "Epoch: [31][15/19]\tLoss 0.9259 (0.8448)\taccuracy 68.750 (67.676)\tf1_score 63.829 (62.492)\n",
      " Test: accuracy 45.312 f1_score 39.378\n",
      "Training time:  100.83423185348511 Hour:  0 Minute:  1 Second:  40 Test best accuracy: 59.375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 32\n",
      "Epoch: [32][0/19]\tLoss 0.6793 (0.6793)\taccuracy 78.125 (78.125)\tf1_score 73.441 (73.441)\n",
      "Epoch: [32][5/19]\tLoss 0.8037 (0.7693)\taccuracy 65.625 (69.271)\tf1_score 60.771 (62.879)\n",
      "Epoch: [32][10/19]\tLoss 0.8242 (0.8156)\taccuracy 71.875 (68.892)\tf1_score 66.144 (63.558)\n",
      "Epoch: [32][15/19]\tLoss 0.7085 (0.8028)\taccuracy 76.562 (69.336)\tf1_score 70.209 (63.896)\n",
      " Test: accuracy 46.484 f1_score 40.040\n",
      "Training time:  103.85900902748108 Hour:  0 Minute:  1 Second:  43 Test best accuracy: 59.375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 33\n",
      "Epoch: [33][0/19]\tLoss 1.0282 (1.0282)\taccuracy 60.938 (60.938)\tf1_score 58.597 (58.597)\n",
      "Epoch: [33][5/19]\tLoss 0.7914 (0.9023)\taccuracy 73.438 (66.146)\tf1_score 64.703 (62.429)\n",
      "Epoch: [33][10/19]\tLoss 0.7472 (0.8295)\taccuracy 75.000 (68.466)\tf1_score 70.929 (64.842)\n",
      "Epoch: [33][15/19]\tLoss 1.0834 (0.8414)\taccuracy 64.062 (67.773)\tf1_score 53.926 (62.900)\n",
      " Test: accuracy 57.812 f1_score 50.912\n",
      "Training time:  106.88457655906677 Hour:  0 Minute:  1 Second:  46 Test best accuracy: 59.375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 34\n",
      "Epoch: [34][0/19]\tLoss 0.8442 (0.8442)\taccuracy 78.125 (78.125)\tf1_score 73.790 (73.790)\n",
      "Epoch: [34][5/19]\tLoss 0.7856 (0.8691)\taccuracy 60.938 (66.406)\tf1_score 57.532 (61.323)\n",
      "Epoch: [34][10/19]\tLoss 0.7158 (0.8350)\taccuracy 71.875 (67.188)\tf1_score 70.204 (62.240)\n",
      "Epoch: [34][15/19]\tLoss 0.6443 (0.8104)\taccuracy 75.000 (68.164)\tf1_score 67.473 (63.558)\n",
      " Test: accuracy 63.672 f1_score 58.284\n",
      "Training time:  109.90962791442871 Hour:  0 Minute:  1 Second:  49 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 35\n",
      "Epoch: [35][0/19]\tLoss 0.5966 (0.5966)\taccuracy 78.125 (78.125)\tf1_score 71.690 (71.690)\n",
      "Epoch: [35][5/19]\tLoss 0.6326 (0.6845)\taccuracy 73.438 (74.740)\tf1_score 67.844 (69.151)\n",
      "Epoch: [35][10/19]\tLoss 1.5568 (0.7951)\taccuracy 48.438 (70.739)\tf1_score 41.834 (65.028)\n",
      "Epoch: [35][15/19]\tLoss 0.8203 (0.8067)\taccuracy 70.312 (70.020)\tf1_score 68.288 (63.839)\n",
      " Test: accuracy 62.891 f1_score 62.160\n",
      "Training time:  113.03004479408264 Hour:  0 Minute:  1 Second:  53 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 36\n",
      "Epoch: [36][0/19]\tLoss 0.5338 (0.5338)\taccuracy 82.812 (82.812)\tf1_score 81.075 (81.075)\n",
      "Epoch: [36][5/19]\tLoss 0.8122 (0.8098)\taccuracy 68.750 (69.792)\tf1_score 65.397 (65.743)\n",
      "Epoch: [36][10/19]\tLoss 0.9654 (0.8213)\taccuracy 60.938 (67.330)\tf1_score 61.156 (62.542)\n",
      "Epoch: [36][15/19]\tLoss 0.8114 (0.8329)\taccuracy 67.188 (67.188)\tf1_score 59.093 (62.336)\n",
      " Test: accuracy 56.641 f1_score 50.141\n",
      "Training time:  116.1318211555481 Hour:  0 Minute:  1 Second:  56 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 37\n",
      "Epoch: [37][0/19]\tLoss 0.6916 (0.6916)\taccuracy 76.562 (76.562)\tf1_score 75.253 (75.253)\n",
      "Epoch: [37][5/19]\tLoss 0.9327 (0.7548)\taccuracy 62.500 (71.354)\tf1_score 64.261 (67.036)\n",
      "Epoch: [37][10/19]\tLoss 0.6285 (0.7568)\taccuracy 65.625 (70.170)\tf1_score 58.059 (65.611)\n",
      "Epoch: [37][15/19]\tLoss 0.7398 (0.7802)\taccuracy 73.438 (69.727)\tf1_score 74.543 (65.246)\n",
      " Test: accuracy 38.281 f1_score 31.534\n",
      "Training time:  119.17683458328247 Hour:  0 Minute:  1 Second:  59 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 38\n",
      "Epoch: [38][0/19]\tLoss 0.8914 (0.8914)\taccuracy 70.312 (70.312)\tf1_score 63.840 (63.840)\n",
      "Epoch: [38][5/19]\tLoss 0.7356 (0.7536)\taccuracy 75.000 (72.656)\tf1_score 67.436 (68.129)\n",
      "Epoch: [38][10/19]\tLoss 0.7089 (0.7721)\taccuracy 75.000 (70.739)\tf1_score 68.288 (67.535)\n",
      "Epoch: [38][15/19]\tLoss 0.7672 (0.7652)\taccuracy 67.188 (70.996)\tf1_score 62.358 (67.619)\n",
      " Test: accuracy 36.328 f1_score 31.838\n",
      "Training time:  122.2103488445282 Hour:  0 Minute:  2 Second:  2 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 39\n",
      "Epoch: [39][0/19]\tLoss 0.5469 (0.5469)\taccuracy 82.812 (82.812)\tf1_score 79.179 (79.179)\n",
      "Epoch: [39][5/19]\tLoss 0.7456 (0.7300)\taccuracy 71.875 (74.219)\tf1_score 62.400 (67.941)\n",
      "Epoch: [39][10/19]\tLoss 0.9745 (0.7239)\taccuracy 59.375 (74.432)\tf1_score 61.002 (70.028)\n",
      "Epoch: [39][15/19]\tLoss 0.6397 (0.7426)\taccuracy 79.688 (72.949)\tf1_score 75.125 (68.769)\n",
      " Test: accuracy 40.625 f1_score 32.818\n",
      "Training time:  125.23262310028076 Hour:  0 Minute:  2 Second:  5 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 40\n",
      "Epoch: [40][0/19]\tLoss 0.6218 (0.6218)\taccuracy 75.000 (75.000)\tf1_score 75.495 (75.495)\n",
      "Epoch: [40][5/19]\tLoss 0.8293 (0.6384)\taccuracy 68.750 (75.260)\tf1_score 62.540 (72.314)\n",
      "Epoch: [40][10/19]\tLoss 0.6062 (0.6781)\taccuracy 78.125 (74.006)\tf1_score 76.633 (70.968)\n",
      "Epoch: [40][15/19]\tLoss 0.6250 (0.6659)\taccuracy 75.000 (74.707)\tf1_score 68.179 (71.502)\n",
      " Test: accuracy 55.078 f1_score 47.616\n",
      "Training time:  128.27216029167175 Hour:  0 Minute:  2 Second:  8 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 41\n",
      "Epoch: [41][0/19]\tLoss 0.4657 (0.4657)\taccuracy 89.062 (89.062)\tf1_score 86.803 (86.803)\n",
      "Epoch: [41][5/19]\tLoss 1.0731 (0.6824)\taccuracy 67.188 (77.344)\tf1_score 61.331 (73.512)\n",
      "Epoch: [41][10/19]\tLoss 0.7416 (0.7862)\taccuracy 75.000 (73.580)\tf1_score 79.213 (69.931)\n",
      "Epoch: [41][15/19]\tLoss 0.5707 (0.7477)\taccuracy 82.812 (73.730)\tf1_score 75.282 (69.025)\n",
      " Test: accuracy 57.422 f1_score 53.733\n",
      "Training time:  131.38719725608826 Hour:  0 Minute:  2 Second:  11 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 42\n",
      "Epoch: [42][0/19]\tLoss 0.6426 (0.6426)\taccuracy 76.562 (76.562)\tf1_score 65.060 (65.060)\n",
      "Epoch: [42][5/19]\tLoss 0.9478 (0.8561)\taccuracy 60.938 (68.229)\tf1_score 59.631 (62.478)\n",
      "Epoch: [42][10/19]\tLoss 0.6832 (0.7278)\taccuracy 79.688 (73.153)\tf1_score 70.748 (66.975)\n",
      "Epoch: [42][15/19]\tLoss 0.9458 (0.7322)\taccuracy 65.625 (72.754)\tf1_score 59.867 (67.323)\n",
      " Test: accuracy 48.047 f1_score 41.480\n",
      "Training time:  134.82735109329224 Hour:  0 Minute:  2 Second:  14 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 43\n",
      "Epoch: [43][0/19]\tLoss 0.5413 (0.5413)\taccuracy 82.812 (82.812)\tf1_score 78.360 (78.360)\n",
      "Epoch: [43][5/19]\tLoss 0.6918 (0.6341)\taccuracy 75.000 (75.521)\tf1_score 75.024 (73.223)\n",
      "Epoch: [43][10/19]\tLoss 0.6029 (0.6124)\taccuracy 76.562 (75.568)\tf1_score 70.681 (73.058)\n",
      "Epoch: [43][15/19]\tLoss 1.0852 (0.6879)\taccuracy 64.062 (72.852)\tf1_score 55.828 (70.109)\n",
      " Test: accuracy 64.453 f1_score 58.449\n",
      "Training time:  137.91848802566528 Hour:  0 Minute:  2 Second:  17 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 44\n",
      "Epoch: [44][0/19]\tLoss 0.6452 (0.6452)\taccuracy 70.312 (70.312)\tf1_score 66.300 (66.300)\n",
      "Epoch: [44][5/19]\tLoss 0.5027 (0.6083)\taccuracy 81.250 (76.302)\tf1_score 78.704 (73.635)\n",
      "Epoch: [44][10/19]\tLoss 0.6154 (0.6111)\taccuracy 76.562 (75.852)\tf1_score 74.902 (73.059)\n",
      "Epoch: [44][15/19]\tLoss 0.5433 (0.6225)\taccuracy 81.250 (76.465)\tf1_score 71.652 (73.781)\n",
      " Test: accuracy 57.812 f1_score 53.697\n",
      "Training time:  141.1694049835205 Hour:  0 Minute:  2 Second:  21 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 45\n",
      "Epoch: [45][0/19]\tLoss 0.6367 (0.6367)\taccuracy 75.000 (75.000)\tf1_score 74.786 (74.786)\n",
      "Epoch: [45][5/19]\tLoss 1.0774 (0.7344)\taccuracy 64.062 (72.135)\tf1_score 57.721 (68.949)\n",
      "Epoch: [45][10/19]\tLoss 0.5511 (0.7010)\taccuracy 78.125 (74.006)\tf1_score 73.496 (69.719)\n",
      "Epoch: [45][15/19]\tLoss 0.5212 (0.7024)\taccuracy 84.375 (74.316)\tf1_score 83.404 (69.937)\n",
      " Test: accuracy 59.766 f1_score 54.834\n",
      "Training time:  144.4648461341858 Hour:  0 Minute:  2 Second:  24 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 46\n",
      "Epoch: [46][0/19]\tLoss 0.4955 (0.4955)\taccuracy 87.500 (87.500)\tf1_score 85.817 (85.817)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46][5/19]\tLoss 0.5438 (0.5555)\taccuracy 78.125 (79.427)\tf1_score 71.107 (76.094)\n",
      "Epoch: [46][10/19]\tLoss 0.6652 (0.6161)\taccuracy 75.000 (78.125)\tf1_score 69.105 (73.964)\n",
      "Epoch: [46][15/19]\tLoss 0.6296 (0.6679)\taccuracy 75.000 (75.684)\tf1_score 70.768 (71.984)\n",
      " Test: accuracy 64.453 f1_score 59.393\n",
      "Training time:  147.90381264686584 Hour:  0 Minute:  2 Second:  27 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 47\n",
      "Epoch: [47][0/19]\tLoss 0.4799 (0.4799)\taccuracy 78.125 (78.125)\tf1_score 77.385 (77.385)\n",
      "Epoch: [47][5/19]\tLoss 0.7106 (0.6978)\taccuracy 78.125 (73.177)\tf1_score 73.755 (68.825)\n",
      "Epoch: [47][10/19]\tLoss 0.7274 (0.7321)\taccuracy 68.750 (71.591)\tf1_score 67.732 (67.790)\n",
      "Epoch: [47][15/19]\tLoss 0.5593 (0.7126)\taccuracy 81.250 (72.070)\tf1_score 72.993 (67.302)\n",
      " Test: accuracy 50.000 f1_score 42.883\n",
      "Training time:  151.31313467025757 Hour:  0 Minute:  2 Second:  31 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 48\n",
      "Epoch: [48][0/19]\tLoss 0.7683 (0.7683)\taccuracy 67.188 (67.188)\tf1_score 62.562 (62.562)\n",
      "Epoch: [48][5/19]\tLoss 0.8094 (0.7473)\taccuracy 60.938 (69.792)\tf1_score 61.214 (63.781)\n",
      "Epoch: [48][10/19]\tLoss 0.4622 (0.7227)\taccuracy 85.938 (72.585)\tf1_score 76.566 (67.392)\n",
      "Epoch: [48][15/19]\tLoss 0.6088 (0.6802)\taccuracy 81.250 (75.000)\tf1_score 74.524 (69.758)\n",
      " Test: accuracy 51.562 f1_score 44.442\n",
      "Training time:  154.70541429519653 Hour:  0 Minute:  2 Second:  34 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 49\n",
      "Epoch: [49][0/19]\tLoss 0.6573 (0.6573)\taccuracy 78.125 (78.125)\tf1_score 77.627 (77.627)\n",
      "Epoch: [49][5/19]\tLoss 0.7367 (0.7395)\taccuracy 73.438 (73.177)\tf1_score 67.348 (69.991)\n",
      "Epoch: [49][10/19]\tLoss 0.7189 (0.7163)\taccuracy 73.438 (74.148)\tf1_score 70.073 (71.287)\n",
      "Epoch: [49][15/19]\tLoss 0.5404 (0.6627)\taccuracy 81.250 (75.977)\tf1_score 77.841 (72.083)\n",
      " Test: accuracy 64.453 f1_score 60.944\n",
      "Training time:  158.07994985580444 Hour:  0 Minute:  2 Second:  38 Test best accuracy: 64.453125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 50\n",
      "Epoch: [50][0/19]\tLoss 0.4964 (0.4964)\taccuracy 82.812 (82.812)\tf1_score 80.060 (80.060)\n",
      "Epoch: [50][5/19]\tLoss 0.5324 (0.6379)\taccuracy 78.125 (73.958)\tf1_score 76.575 (69.977)\n",
      "Epoch: [50][10/19]\tLoss 0.6692 (0.6951)\taccuracy 73.438 (72.869)\tf1_score 66.587 (69.230)\n",
      "Epoch: [50][15/19]\tLoss 0.6517 (0.6780)\taccuracy 73.438 (73.828)\tf1_score 65.480 (68.655)\n",
      " Test: accuracy 67.188 f1_score 63.668\n",
      "Training time:  161.15875053405762 Hour:  0 Minute:  2 Second:  41 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 51\n",
      "Epoch: [51][0/19]\tLoss 0.5762 (0.5762)\taccuracy 79.688 (79.688)\tf1_score 70.039 (70.039)\n",
      "Epoch: [51][5/19]\tLoss 0.7371 (0.7070)\taccuracy 71.875 (72.656)\tf1_score 71.985 (67.582)\n",
      "Epoch: [51][10/19]\tLoss 0.5660 (0.6526)\taccuracy 78.125 (74.148)\tf1_score 72.226 (68.967)\n",
      "Epoch: [51][15/19]\tLoss 0.6712 (0.6352)\taccuracy 73.438 (74.609)\tf1_score 70.430 (70.364)\n",
      " Test: accuracy 55.078 f1_score 48.017\n",
      "Training time:  164.2312114238739 Hour:  0 Minute:  2 Second:  44 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 52\n",
      "Epoch: [52][0/19]\tLoss 0.5013 (0.5013)\taccuracy 87.500 (87.500)\tf1_score 83.118 (83.118)\n",
      "Epoch: [52][5/19]\tLoss 0.5362 (0.5640)\taccuracy 81.250 (80.990)\tf1_score 82.592 (78.894)\n",
      "Epoch: [52][10/19]\tLoss 0.5664 (0.6067)\taccuracy 81.250 (78.409)\tf1_score 77.363 (74.935)\n",
      "Epoch: [52][15/19]\tLoss 0.7540 (0.5997)\taccuracy 67.188 (77.637)\tf1_score 60.684 (73.623)\n",
      " Test: accuracy 53.125 f1_score 46.721\n",
      "Training time:  167.2823827266693 Hour:  0 Minute:  2 Second:  47 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 53\n",
      "Epoch: [53][0/19]\tLoss 0.8617 (0.8617)\taccuracy 70.312 (70.312)\tf1_score 69.767 (69.767)\n",
      "Epoch: [53][5/19]\tLoss 0.6229 (0.5929)\taccuracy 78.125 (78.646)\tf1_score 71.045 (76.379)\n",
      "Epoch: [53][10/19]\tLoss 0.5117 (0.6455)\taccuracy 76.562 (75.426)\tf1_score 69.903 (71.719)\n",
      "Epoch: [53][15/19]\tLoss 0.8031 (0.6604)\taccuracy 62.500 (73.730)\tf1_score 58.875 (69.371)\n",
      " Test: accuracy 59.766 f1_score 52.257\n",
      "Training time:  170.3191192150116 Hour:  0 Minute:  2 Second:  50 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 54\n",
      "Epoch: [54][0/19]\tLoss 0.5203 (0.5203)\taccuracy 79.688 (79.688)\tf1_score 71.075 (71.075)\n",
      "Epoch: [54][5/19]\tLoss 0.5299 (0.5572)\taccuracy 82.812 (78.385)\tf1_score 81.720 (74.519)\n",
      "Epoch: [54][10/19]\tLoss 0.6108 (0.5687)\taccuracy 73.438 (77.983)\tf1_score 68.287 (74.632)\n",
      "Epoch: [54][15/19]\tLoss 0.4285 (0.5618)\taccuracy 81.250 (78.320)\tf1_score 73.841 (74.475)\n",
      " Test: accuracy 64.062 f1_score 61.126\n",
      "Training time:  173.47963094711304 Hour:  0 Minute:  2 Second:  53 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 55\n",
      "Epoch: [55][0/19]\tLoss 0.3566 (0.3566)\taccuracy 89.062 (89.062)\tf1_score 84.563 (84.563)\n",
      "Epoch: [55][5/19]\tLoss 0.6043 (0.4864)\taccuracy 73.438 (80.990)\tf1_score 64.689 (76.356)\n",
      "Epoch: [55][10/19]\tLoss 0.4262 (0.4900)\taccuracy 84.375 (80.824)\tf1_score 86.264 (76.912)\n",
      "Epoch: [55][15/19]\tLoss 0.5331 (0.4834)\taccuracy 81.250 (81.543)\tf1_score 78.690 (77.185)\n",
      " Test: accuracy 52.734 f1_score 45.194\n",
      "Training time:  176.76039576530457 Hour:  0 Minute:  2 Second:  56 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 56\n",
      "Epoch: [56][0/19]\tLoss 0.3705 (0.3705)\taccuracy 87.500 (87.500)\tf1_score 85.596 (85.596)\n",
      "Epoch: [56][5/19]\tLoss 0.5371 (0.4991)\taccuracy 79.688 (81.250)\tf1_score 76.263 (77.865)\n",
      "Epoch: [56][10/19]\tLoss 0.4379 (0.5178)\taccuracy 78.125 (80.540)\tf1_score 73.465 (76.611)\n",
      "Epoch: [56][15/19]\tLoss 0.6177 (0.5518)\taccuracy 75.000 (79.492)\tf1_score 66.241 (75.573)\n",
      " Test: accuracy 61.328 f1_score 55.966\n",
      "Training time:  179.9380979537964 Hour:  0 Minute:  2 Second:  59 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 57\n",
      "Epoch: [57][0/19]\tLoss 0.5531 (0.5531)\taccuracy 78.125 (78.125)\tf1_score 65.038 (65.038)\n",
      "Epoch: [57][5/19]\tLoss 0.4646 (0.6012)\taccuracy 81.250 (75.521)\tf1_score 73.598 (67.152)\n",
      "Epoch: [57][10/19]\tLoss 0.7125 (0.6489)\taccuracy 70.312 (73.580)\tf1_score 67.559 (67.482)\n",
      "Epoch: [57][15/19]\tLoss 0.5104 (0.6359)\taccuracy 79.688 (74.805)\tf1_score 79.376 (69.715)\n",
      " Test: accuracy 57.812 f1_score 54.017\n",
      "Training time:  183.00689673423767 Hour:  0 Minute:  3 Second:  3 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 58\n",
      "Epoch: [58][0/19]\tLoss 0.4316 (0.4316)\taccuracy 87.500 (87.500)\tf1_score 86.927 (86.927)\n",
      "Epoch: [58][5/19]\tLoss 0.6520 (0.5974)\taccuracy 70.312 (78.646)\tf1_score 65.605 (74.814)\n",
      "Epoch: [58][10/19]\tLoss 0.5803 (0.5651)\taccuracy 75.000 (78.693)\tf1_score 71.014 (74.611)\n",
      "Epoch: [58][15/19]\tLoss 0.6108 (0.5737)\taccuracy 75.000 (78.027)\tf1_score 69.843 (74.755)\n",
      " Test: accuracy 60.938 f1_score 53.692\n",
      "Training time:  186.0597312450409 Hour:  0 Minute:  3 Second:  6 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 59\n",
      "Epoch: [59][0/19]\tLoss 0.5580 (0.5580)\taccuracy 79.688 (79.688)\tf1_score 77.639 (77.639)\n",
      "Epoch: [59][5/19]\tLoss 0.4800 (0.5314)\taccuracy 78.125 (79.427)\tf1_score 70.375 (75.235)\n",
      "Epoch: [59][10/19]\tLoss 0.5721 (0.5097)\taccuracy 81.250 (80.256)\tf1_score 79.858 (76.081)\n",
      "Epoch: [59][15/19]\tLoss 0.4165 (0.5071)\taccuracy 84.375 (80.176)\tf1_score 78.593 (76.494)\n",
      " Test: accuracy 62.500 f1_score 54.520\n",
      "Training time:  189.10959839820862 Hour:  0 Minute:  3 Second:  9 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 60\n",
      "Epoch: [60][0/19]\tLoss 0.7861 (0.7861)\taccuracy 71.875 (71.875)\tf1_score 66.122 (66.122)\n",
      "Epoch: [60][5/19]\tLoss 0.5376 (0.5174)\taccuracy 76.562 (78.906)\tf1_score 79.708 (76.914)\n",
      "Epoch: [60][10/19]\tLoss 0.3602 (0.4925)\taccuracy 84.375 (79.972)\tf1_score 81.795 (77.953)\n",
      "Epoch: [60][15/19]\tLoss 0.4655 (0.4719)\taccuracy 79.688 (80.859)\tf1_score 73.794 (78.291)\n",
      " Test: accuracy 58.594 f1_score 53.028\n",
      "Training time:  192.16462016105652 Hour:  0 Minute:  3 Second:  12 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 61\n",
      "Epoch: [61][0/19]\tLoss 0.4867 (0.4867)\taccuracy 78.125 (78.125)\tf1_score 73.490 (73.490)\n",
      "Epoch: [61][5/19]\tLoss 0.4815 (0.4586)\taccuracy 81.250 (82.552)\tf1_score 82.275 (78.398)\n",
      "Epoch: [61][10/19]\tLoss 0.4295 (0.4647)\taccuracy 85.938 (82.244)\tf1_score 83.703 (77.591)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61][15/19]\tLoss 0.4930 (0.4652)\taccuracy 81.250 (82.324)\tf1_score 78.762 (78.621)\n",
      " Test: accuracy 55.469 f1_score 48.743\n",
      "Training time:  195.21246719360352 Hour:  0 Minute:  3 Second:  15 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 62\n",
      "Epoch: [62][0/19]\tLoss 0.4011 (0.4011)\taccuracy 85.938 (85.938)\tf1_score 84.115 (84.115)\n",
      "Epoch: [62][5/19]\tLoss 0.4792 (0.4511)\taccuracy 84.375 (84.896)\tf1_score 77.436 (81.102)\n",
      "Epoch: [62][10/19]\tLoss 0.4995 (0.4699)\taccuracy 82.812 (82.955)\tf1_score 83.679 (79.924)\n",
      "Epoch: [62][15/19]\tLoss 0.3666 (0.4606)\taccuracy 85.938 (82.227)\tf1_score 79.971 (79.120)\n",
      " Test: accuracy 60.938 f1_score 55.283\n",
      "Training time:  198.28624773025513 Hour:  0 Minute:  3 Second:  18 Test best accuracy: 67.1875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 63\n",
      "Epoch: [63][0/19]\tLoss 0.5729 (0.5729)\taccuracy 76.562 (76.562)\tf1_score 73.007 (73.007)\n",
      "Epoch: [63][5/19]\tLoss 0.3350 (0.4544)\taccuracy 89.062 (82.031)\tf1_score 89.798 (77.166)\n",
      "Epoch: [63][10/19]\tLoss 0.4385 (0.4738)\taccuracy 82.812 (80.824)\tf1_score 80.702 (76.727)\n",
      "Epoch: [63][15/19]\tLoss 0.4726 (0.4917)\taccuracy 84.375 (80.371)\tf1_score 82.124 (76.782)\n",
      " Test: accuracy 67.578 f1_score 64.664\n",
      "Training time:  201.35802912712097 Hour:  0 Minute:  3 Second:  21 Test best accuracy: 67.578125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 64\n",
      "Epoch: [64][0/19]\tLoss 0.3767 (0.3767)\taccuracy 87.500 (87.500)\tf1_score 82.794 (82.794)\n",
      "Epoch: [64][5/19]\tLoss 0.4251 (0.4670)\taccuracy 84.375 (80.729)\tf1_score 78.032 (76.447)\n",
      "Epoch: [64][10/19]\tLoss 0.5987 (0.5132)\taccuracy 78.125 (80.540)\tf1_score 73.533 (75.710)\n",
      "Epoch: [64][15/19]\tLoss 0.4461 (0.5214)\taccuracy 87.500 (80.078)\tf1_score 86.834 (75.927)\n",
      " Test: accuracy 64.453 f1_score 60.196\n",
      "Training time:  204.41534852981567 Hour:  0 Minute:  3 Second:  24 Test best accuracy: 67.578125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 65\n",
      "Epoch: [65][0/19]\tLoss 0.3895 (0.3895)\taccuracy 87.500 (87.500)\tf1_score 86.690 (86.690)\n",
      "Epoch: [65][5/19]\tLoss 0.3950 (0.5121)\taccuracy 84.375 (82.552)\tf1_score 84.711 (77.281)\n",
      "Epoch: [65][10/19]\tLoss 0.3052 (0.4777)\taccuracy 90.625 (82.955)\tf1_score 90.299 (78.866)\n",
      "Epoch: [65][15/19]\tLoss 0.4394 (0.4893)\taccuracy 82.812 (82.520)\tf1_score 78.675 (78.356)\n",
      " Test: accuracy 68.750 f1_score 65.206\n",
      "Training time:  207.46879053115845 Hour:  0 Minute:  3 Second:  27 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 66\n",
      "Epoch: [66][0/19]\tLoss 0.4562 (0.4562)\taccuracy 81.250 (81.250)\tf1_score 74.036 (74.036)\n",
      "Epoch: [66][5/19]\tLoss 0.5509 (0.5161)\taccuracy 78.125 (80.990)\tf1_score 74.810 (76.077)\n",
      "Epoch: [66][10/19]\tLoss 0.7094 (0.5517)\taccuracy 70.312 (79.119)\tf1_score 69.864 (75.367)\n",
      "Epoch: [66][15/19]\tLoss 1.0457 (0.6149)\taccuracy 67.188 (77.734)\tf1_score 62.657 (73.734)\n",
      " Test: accuracy 25.000 f1_score 15.983\n",
      "Training time:  210.51469206809998 Hour:  0 Minute:  3 Second:  30 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 67\n",
      "Epoch: [67][0/19]\tLoss 0.5787 (0.5787)\taccuracy 78.125 (78.125)\tf1_score 76.922 (76.922)\n",
      "Epoch: [67][5/19]\tLoss 0.6311 (0.7170)\taccuracy 68.750 (71.354)\tf1_score 69.325 (67.022)\n",
      "Epoch: [67][10/19]\tLoss 0.4932 (0.6578)\taccuracy 82.812 (74.432)\tf1_score 81.583 (71.333)\n",
      "Epoch: [67][15/19]\tLoss 0.9260 (0.7038)\taccuracy 71.875 (73.633)\tf1_score 64.371 (70.114)\n",
      " Test: accuracy 57.031 f1_score 51.044\n",
      "Training time:  213.6163980960846 Hour:  0 Minute:  3 Second:  33 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 68\n",
      "Epoch: [68][0/19]\tLoss 0.4702 (0.4702)\taccuracy 79.688 (79.688)\tf1_score 71.075 (71.075)\n",
      "Epoch: [68][5/19]\tLoss 0.6232 (0.5687)\taccuracy 76.562 (77.865)\tf1_score 73.798 (75.114)\n",
      "Epoch: [68][10/19]\tLoss 0.4294 (0.5492)\taccuracy 85.938 (79.403)\tf1_score 82.313 (75.649)\n",
      "Epoch: [68][15/19]\tLoss 0.6202 (0.5551)\taccuracy 81.250 (79.883)\tf1_score 78.295 (75.736)\n",
      " Test: accuracy 59.375 f1_score 54.226\n",
      "Training time:  216.64923644065857 Hour:  0 Minute:  3 Second:  36 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 69\n",
      "Epoch: [69][0/19]\tLoss 0.5889 (0.5889)\taccuracy 76.562 (76.562)\tf1_score 76.043 (76.043)\n",
      "Epoch: [69][5/19]\tLoss 0.4067 (0.4873)\taccuracy 82.812 (82.292)\tf1_score 78.265 (78.671)\n",
      "Epoch: [69][10/19]\tLoss 0.3949 (0.5135)\taccuracy 87.500 (80.966)\tf1_score 78.948 (76.970)\n",
      "Epoch: [69][15/19]\tLoss 0.7190 (0.5192)\taccuracy 73.438 (80.664)\tf1_score 75.204 (75.847)\n",
      " Test: accuracy 57.031 f1_score 49.535\n",
      "Training time:  219.68112516403198 Hour:  0 Minute:  3 Second:  39 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 70\n",
      "Epoch: [70][0/19]\tLoss 0.5710 (0.5710)\taccuracy 78.125 (78.125)\tf1_score 75.011 (75.011)\n",
      "Epoch: [70][5/19]\tLoss 0.3652 (0.5049)\taccuracy 85.938 (80.469)\tf1_score 85.585 (76.543)\n",
      "Epoch: [70][10/19]\tLoss 0.6757 (0.5225)\taccuracy 73.438 (80.256)\tf1_score 69.652 (76.584)\n",
      "Epoch: [70][15/19]\tLoss 0.3823 (0.4748)\taccuracy 85.938 (82.227)\tf1_score 83.135 (78.513)\n",
      " Test: accuracy 63.672 f1_score 57.817\n",
      "Training time:  222.71301555633545 Hour:  0 Minute:  3 Second:  42 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 71\n",
      "Epoch: [71][0/19]\tLoss 0.3036 (0.3036)\taccuracy 87.500 (87.500)\tf1_score 86.136 (86.136)\n",
      "Epoch: [71][5/19]\tLoss 0.7655 (0.5148)\taccuracy 65.625 (79.688)\tf1_score 63.401 (74.915)\n",
      "Epoch: [71][10/19]\tLoss 0.3811 (0.4444)\taccuracy 87.500 (82.955)\tf1_score 84.964 (79.211)\n",
      "Epoch: [71][15/19]\tLoss 0.5481 (0.4923)\taccuracy 76.562 (81.348)\tf1_score 75.591 (78.062)\n",
      " Test: accuracy 57.031 f1_score 51.794\n",
      "Training time:  225.74938368797302 Hour:  0 Minute:  3 Second:  45 Test best accuracy: 68.75  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 72\n",
      "Epoch: [72][0/19]\tLoss 0.9718 (0.9718)\taccuracy 62.500 (62.500)\tf1_score 62.961 (62.961)\n",
      "Epoch: [72][5/19]\tLoss 0.4199 (0.5478)\taccuracy 87.500 (80.729)\tf1_score 84.108 (78.933)\n",
      "Epoch: [72][10/19]\tLoss 0.4061 (0.5080)\taccuracy 82.812 (81.676)\tf1_score 76.342 (79.345)\n",
      "Epoch: [72][15/19]\tLoss 0.5724 (0.4973)\taccuracy 81.250 (81.934)\tf1_score 76.803 (79.112)\n",
      " Test: accuracy 71.484 f1_score 65.366\n",
      "Training time:  228.8206126689911 Hour:  0 Minute:  3 Second:  48 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 73\n",
      "Epoch: [73][0/19]\tLoss 0.3821 (0.3821)\taccuracy 85.938 (85.938)\tf1_score 81.672 (81.672)\n",
      "Epoch: [73][5/19]\tLoss 0.3916 (0.4813)\taccuracy 84.375 (85.156)\tf1_score 79.690 (79.628)\n",
      "Epoch: [73][10/19]\tLoss 0.3188 (0.4555)\taccuracy 89.062 (84.517)\tf1_score 88.324 (79.867)\n",
      "Epoch: [73][15/19]\tLoss 0.5315 (0.4688)\taccuracy 81.250 (82.324)\tf1_score 80.499 (78.233)\n",
      " Test: accuracy 40.234 f1_score 34.446\n",
      "Training time:  231.85851979255676 Hour:  0 Minute:  3 Second:  51 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 74\n",
      "Epoch: [74][0/19]\tLoss 0.3442 (0.3442)\taccuracy 89.062 (89.062)\tf1_score 81.463 (81.463)\n",
      "Epoch: [74][5/19]\tLoss 0.3680 (0.4645)\taccuracy 82.812 (81.771)\tf1_score 71.905 (77.170)\n",
      "Epoch: [74][10/19]\tLoss 0.4139 (0.4400)\taccuracy 81.250 (82.812)\tf1_score 74.352 (77.856)\n",
      "Epoch: [74][15/19]\tLoss 0.3492 (0.4668)\taccuracy 87.500 (81.445)\tf1_score 84.922 (76.818)\n",
      " Test: accuracy 62.891 f1_score 56.053\n",
      "Training time:  234.89379835128784 Hour:  0 Minute:  3 Second:  54 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 75\n",
      "Epoch: [75][0/19]\tLoss 0.4057 (0.4057)\taccuracy 89.062 (89.062)\tf1_score 85.767 (85.767)\n",
      "Epoch: [75][5/19]\tLoss 0.5904 (0.5279)\taccuracy 79.688 (83.073)\tf1_score 74.924 (79.211)\n",
      "Epoch: [75][10/19]\tLoss 0.4896 (0.4745)\taccuracy 84.375 (84.233)\tf1_score 86.553 (81.295)\n",
      "Epoch: [75][15/19]\tLoss 0.4136 (0.4596)\taccuracy 82.812 (83.594)\tf1_score 77.888 (80.067)\n",
      " Test: accuracy 70.703 f1_score 67.940\n",
      "Training time:  237.92992687225342 Hour:  0 Minute:  3 Second:  57 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 76\n",
      "Epoch: [76][0/19]\tLoss 0.5987 (0.5987)\taccuracy 81.250 (81.250)\tf1_score 70.752 (70.752)\n",
      "Epoch: [76][5/19]\tLoss 0.6987 (0.5218)\taccuracy 76.562 (80.990)\tf1_score 81.265 (77.329)\n",
      "Epoch: [76][10/19]\tLoss 0.4832 (0.4963)\taccuracy 81.250 (80.682)\tf1_score 78.533 (78.120)\n",
      "Epoch: [76][15/19]\tLoss 0.4283 (0.4913)\taccuracy 82.812 (81.836)\tf1_score 80.614 (79.592)\n",
      " Test: accuracy 62.500 f1_score 57.300\n",
      "Training time:  240.96580410003662 Hour:  0 Minute:  4 Second:  0 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 77\n",
      "Epoch: [77][0/19]\tLoss 0.5858 (0.5858)\taccuracy 76.562 (76.562)\tf1_score 69.028 (69.028)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [77][5/19]\tLoss 0.3493 (0.5151)\taccuracy 85.938 (78.385)\tf1_score 82.484 (75.483)\n",
      "Epoch: [77][10/19]\tLoss 0.4228 (0.4653)\taccuracy 87.500 (81.676)\tf1_score 84.124 (78.040)\n",
      "Epoch: [77][15/19]\tLoss 0.6837 (0.4746)\taccuracy 75.000 (80.762)\tf1_score 72.110 (77.934)\n",
      " Test: accuracy 67.578 f1_score 63.847\n",
      "Training time:  244.02675485610962 Hour:  0 Minute:  4 Second:  4 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 78\n",
      "Epoch: [78][0/19]\tLoss 0.4101 (0.4101)\taccuracy 81.250 (81.250)\tf1_score 80.061 (80.061)\n",
      "Epoch: [78][5/19]\tLoss 0.6530 (0.4409)\taccuracy 78.125 (82.552)\tf1_score 78.141 (79.687)\n",
      "Epoch: [78][10/19]\tLoss 0.6914 (0.4431)\taccuracy 73.438 (82.955)\tf1_score 73.830 (80.892)\n",
      "Epoch: [78][15/19]\tLoss 0.4358 (0.4748)\taccuracy 82.812 (81.934)\tf1_score 77.133 (78.744)\n",
      " Test: accuracy 67.188 f1_score 64.210\n",
      "Training time:  247.08565640449524 Hour:  0 Minute:  4 Second:  7 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 79\n",
      "Epoch: [79][0/19]\tLoss 0.6212 (0.6212)\taccuracy 81.250 (81.250)\tf1_score 80.896 (80.896)\n",
      "Epoch: [79][5/19]\tLoss 0.3813 (0.5285)\taccuracy 82.812 (79.688)\tf1_score 81.474 (79.846)\n",
      "Epoch: [79][10/19]\tLoss 0.3371 (0.4853)\taccuracy 85.938 (81.676)\tf1_score 81.950 (81.077)\n",
      "Epoch: [79][15/19]\tLoss 0.4981 (0.4743)\taccuracy 76.562 (81.348)\tf1_score 77.412 (80.368)\n",
      " Test: accuracy 69.531 f1_score 67.062\n",
      "Training time:  250.1255247592926 Hour:  0 Minute:  4 Second:  10 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 80\n",
      "Epoch: [80][0/19]\tLoss 0.2535 (0.2535)\taccuracy 90.625 (90.625)\tf1_score 84.743 (84.743)\n",
      "Epoch: [80][5/19]\tLoss 0.4236 (0.4894)\taccuracy 78.125 (81.510)\tf1_score 72.697 (77.079)\n",
      "Epoch: [80][10/19]\tLoss 0.5184 (0.4696)\taccuracy 76.562 (81.250)\tf1_score 67.804 (76.914)\n",
      "Epoch: [80][15/19]\tLoss 0.6284 (0.4739)\taccuracy 76.562 (81.543)\tf1_score 76.797 (77.038)\n",
      " Test: accuracy 60.547 f1_score 54.376\n",
      "Training time:  253.1673879623413 Hour:  0 Minute:  4 Second:  13 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 81\n",
      "Epoch: [81][0/19]\tLoss 0.8580 (0.8580)\taccuracy 65.625 (65.625)\tf1_score 57.494 (57.494)\n",
      "Epoch: [81][5/19]\tLoss 0.5208 (0.6049)\taccuracy 82.812 (76.562)\tf1_score 81.114 (74.573)\n",
      "Epoch: [81][10/19]\tLoss 0.4898 (0.5379)\taccuracy 84.375 (79.830)\tf1_score 79.873 (77.222)\n",
      "Epoch: [81][15/19]\tLoss 0.4017 (0.5288)\taccuracy 87.500 (80.469)\tf1_score 86.331 (77.609)\n",
      " Test: accuracy 57.812 f1_score 49.589\n",
      "Training time:  256.2091553211212 Hour:  0 Minute:  4 Second:  16 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 82\n",
      "Epoch: [82][0/19]\tLoss 0.6368 (0.6368)\taccuracy 73.438 (73.438)\tf1_score 70.147 (70.147)\n",
      "Epoch: [82][5/19]\tLoss 0.3146 (0.4486)\taccuracy 89.062 (82.552)\tf1_score 79.320 (80.177)\n",
      "Epoch: [82][10/19]\tLoss 0.3801 (0.4680)\taccuracy 89.062 (81.960)\tf1_score 87.939 (80.310)\n",
      "Epoch: [82][15/19]\tLoss 0.3721 (0.4435)\taccuracy 84.375 (83.301)\tf1_score 82.549 (80.608)\n",
      " Test: accuracy 51.562 f1_score 45.635\n",
      "Training time:  259.2480216026306 Hour:  0 Minute:  4 Second:  19 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 83\n",
      "Epoch: [83][0/19]\tLoss 0.4490 (0.4490)\taccuracy 85.938 (85.938)\tf1_score 81.988 (81.988)\n",
      "Epoch: [83][5/19]\tLoss 0.3383 (0.4610)\taccuracy 85.938 (84.115)\tf1_score 83.810 (79.742)\n",
      "Epoch: [83][10/19]\tLoss 0.3948 (0.4602)\taccuracy 81.250 (83.239)\tf1_score 76.349 (78.927)\n",
      "Epoch: [83][15/19]\tLoss 0.3749 (0.4441)\taccuracy 87.500 (83.691)\tf1_score 75.794 (79.725)\n",
      " Test: accuracy 63.672 f1_score 59.691\n",
      "Training time:  262.3277838230133 Hour:  0 Minute:  4 Second:  22 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 84\n",
      "Epoch: [84][0/19]\tLoss 0.4688 (0.4688)\taccuracy 79.688 (79.688)\tf1_score 80.549 (80.549)\n",
      "Epoch: [84][5/19]\tLoss 0.7061 (0.4528)\taccuracy 75.000 (82.031)\tf1_score 70.184 (80.085)\n",
      "Epoch: [84][10/19]\tLoss 0.5305 (0.4472)\taccuracy 76.562 (82.244)\tf1_score 66.973 (79.878)\n",
      "Epoch: [84][15/19]\tLoss 0.4832 (0.4286)\taccuracy 81.250 (83.301)\tf1_score 77.256 (80.950)\n",
      " Test: accuracy 59.375 f1_score 51.168\n",
      "Training time:  265.36565804481506 Hour:  0 Minute:  4 Second:  25 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 85\n",
      "Epoch: [85][0/19]\tLoss 0.4336 (0.4336)\taccuracy 87.500 (87.500)\tf1_score 85.805 (85.805)\n",
      "Epoch: [85][5/19]\tLoss 0.4835 (0.4274)\taccuracy 75.000 (84.896)\tf1_score 64.562 (79.313)\n",
      "Epoch: [85][10/19]\tLoss 0.6147 (0.4396)\taccuracy 81.250 (84.091)\tf1_score 64.618 (78.810)\n",
      "Epoch: [85][15/19]\tLoss 0.4155 (0.4382)\taccuracy 81.250 (83.594)\tf1_score 73.726 (79.548)\n",
      " Test: accuracy 56.250 f1_score 50.487\n",
      "Training time:  268.4084858894348 Hour:  0 Minute:  4 Second:  28 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 86\n",
      "Epoch: [86][0/19]\tLoss 0.4896 (0.4896)\taccuracy 87.500 (87.500)\tf1_score 86.119 (86.119)\n",
      "Epoch: [86][5/19]\tLoss 0.4954 (0.4171)\taccuracy 79.688 (85.417)\tf1_score 78.834 (81.709)\n",
      "Epoch: [86][10/19]\tLoss 0.3865 (0.4398)\taccuracy 84.375 (83.807)\tf1_score 79.940 (80.060)\n",
      "Epoch: [86][15/19]\tLoss 0.3176 (0.4194)\taccuracy 92.188 (84.863)\tf1_score 88.923 (81.345)\n",
      " Test: accuracy 69.922 f1_score 64.054\n",
      "Training time:  271.45436835289 Hour:  0 Minute:  4 Second:  31 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 87\n",
      "Epoch: [87][0/19]\tLoss 0.4641 (0.4641)\taccuracy 79.688 (79.688)\tf1_score 73.803 (73.803)\n",
      "Epoch: [87][5/19]\tLoss 0.3808 (0.4218)\taccuracy 84.375 (83.854)\tf1_score 82.620 (79.717)\n",
      "Epoch: [87][10/19]\tLoss 0.4065 (0.4410)\taccuracy 82.812 (82.955)\tf1_score 83.636 (79.104)\n",
      "Epoch: [87][15/19]\tLoss 0.4295 (0.4400)\taccuracy 82.812 (82.422)\tf1_score 81.837 (78.968)\n",
      " Test: accuracy 65.625 f1_score 60.450\n",
      "Training time:  274.50022315979004 Hour:  0 Minute:  4 Second:  34 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 88\n",
      "Epoch: [88][0/19]\tLoss 0.2282 (0.2282)\taccuracy 90.625 (90.625)\tf1_score 87.563 (87.563)\n",
      "Epoch: [88][5/19]\tLoss 0.2550 (0.3140)\taccuracy 90.625 (87.760)\tf1_score 91.721 (85.239)\n",
      "Epoch: [88][10/19]\tLoss 0.4229 (0.3294)\taccuracy 82.812 (86.790)\tf1_score 78.151 (84.009)\n",
      "Epoch: [88][15/19]\tLoss 0.5056 (0.3759)\taccuracy 78.125 (84.180)\tf1_score 76.542 (81.549)\n",
      " Test: accuracy 56.250 f1_score 51.166\n",
      "Training time:  277.5730097293854 Hour:  0 Minute:  4 Second:  37 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 89\n",
      "Epoch: [89][0/19]\tLoss 0.3624 (0.3624)\taccuracy 82.812 (82.812)\tf1_score 81.939 (81.939)\n",
      "Epoch: [89][5/19]\tLoss 0.3043 (0.3149)\taccuracy 89.062 (87.760)\tf1_score 82.944 (85.626)\n",
      "Epoch: [89][10/19]\tLoss 0.3322 (0.3475)\taccuracy 87.500 (87.074)\tf1_score 78.923 (84.524)\n",
      "Epoch: [89][15/19]\tLoss 0.3271 (0.3506)\taccuracy 89.062 (86.719)\tf1_score 88.040 (83.893)\n",
      " Test: accuracy 66.797 f1_score 63.158\n",
      "Training time:  280.619854927063 Hour:  0 Minute:  4 Second:  40 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 90\n",
      "Epoch: [90][0/19]\tLoss 0.3942 (0.3942)\taccuracy 85.938 (85.938)\tf1_score 87.041 (87.041)\n",
      "Epoch: [90][5/19]\tLoss 0.2105 (0.4421)\taccuracy 90.625 (82.031)\tf1_score 91.147 (78.313)\n",
      "Epoch: [90][10/19]\tLoss 0.3089 (0.4093)\taccuracy 87.500 (83.665)\tf1_score 86.727 (81.757)\n",
      "Epoch: [90][15/19]\tLoss 0.4047 (0.4269)\taccuracy 87.500 (83.203)\tf1_score 84.933 (80.604)\n",
      " Test: accuracy 57.031 f1_score 51.063\n",
      "Training time:  283.6637122631073 Hour:  0 Minute:  4 Second:  43 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 91\n",
      "Epoch: [91][0/19]\tLoss 0.3208 (0.3208)\taccuracy 89.062 (89.062)\tf1_score 86.710 (86.710)\n",
      "Epoch: [91][5/19]\tLoss 0.2646 (0.3435)\taccuracy 90.625 (87.500)\tf1_score 87.417 (84.496)\n",
      "Epoch: [91][10/19]\tLoss 0.3014 (0.3651)\taccuracy 90.625 (86.506)\tf1_score 84.276 (82.606)\n",
      "Epoch: [91][15/19]\tLoss 0.5848 (0.3885)\taccuracy 76.562 (85.840)\tf1_score 73.647 (82.274)\n",
      " Test: accuracy 62.500 f1_score 58.006\n",
      "Training time:  286.71056842803955 Hour:  0 Minute:  4 Second:  46 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 92\n",
      "Epoch: [92][0/19]\tLoss 0.4089 (0.4089)\taccuracy 85.938 (85.938)\tf1_score 86.746 (86.746)\n",
      "Epoch: [92][5/19]\tLoss 0.5022 (0.4390)\taccuracy 79.688 (81.250)\tf1_score 76.090 (80.449)\n",
      "Epoch: [92][10/19]\tLoss 0.2889 (0.4170)\taccuracy 87.500 (82.244)\tf1_score 83.584 (80.056)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [92][15/19]\tLoss 0.3514 (0.4030)\taccuracy 89.062 (83.984)\tf1_score 79.964 (81.023)\n",
      " Test: accuracy 49.609 f1_score 43.988\n",
      "Training time:  289.76044845581055 Hour:  0 Minute:  4 Second:  49 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 93\n",
      "Epoch: [93][0/19]\tLoss 0.6745 (0.6745)\taccuracy 76.562 (76.562)\tf1_score 72.075 (72.075)\n",
      "Epoch: [93][5/19]\tLoss 0.6170 (0.4524)\taccuracy 71.875 (83.073)\tf1_score 70.852 (79.231)\n",
      "Epoch: [93][10/19]\tLoss 0.3537 (0.4400)\taccuracy 84.375 (83.239)\tf1_score 81.324 (80.605)\n",
      "Epoch: [93][15/19]\tLoss 0.3354 (0.4303)\taccuracy 85.938 (83.691)\tf1_score 78.591 (80.560)\n",
      " Test: accuracy 54.297 f1_score 48.425\n",
      "Training time:  292.8791561126709 Hour:  0 Minute:  4 Second:  52 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 94\n",
      "Epoch: [94][0/19]\tLoss 0.2948 (0.2948)\taccuracy 90.625 (90.625)\tf1_score 90.170 (90.170)\n",
      "Epoch: [94][5/19]\tLoss 0.4097 (0.3817)\taccuracy 79.688 (83.594)\tf1_score 78.651 (78.973)\n",
      "Epoch: [94][10/19]\tLoss 0.3735 (0.3913)\taccuracy 89.062 (84.375)\tf1_score 90.828 (81.460)\n",
      "Epoch: [94][15/19]\tLoss 0.3044 (0.3831)\taccuracy 84.375 (84.082)\tf1_score 79.696 (81.459)\n",
      " Test: accuracy 46.875 f1_score 41.997\n",
      "Training time:  295.95907521247864 Hour:  0 Minute:  4 Second:  55 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 95\n",
      "Epoch: [95][0/19]\tLoss 0.3998 (0.3998)\taccuracy 84.375 (84.375)\tf1_score 79.347 (79.347)\n",
      "Epoch: [95][5/19]\tLoss 0.2568 (0.3531)\taccuracy 90.625 (85.677)\tf1_score 87.150 (80.384)\n",
      "Epoch: [95][10/19]\tLoss 0.2335 (0.3340)\taccuracy 92.188 (86.648)\tf1_score 85.094 (82.362)\n",
      "Epoch: [95][15/19]\tLoss 0.3247 (0.3679)\taccuracy 85.938 (85.059)\tf1_score 74.131 (80.052)\n",
      " Test: accuracy 66.406 f1_score 62.825\n",
      "Training time:  299.01504850387573 Hour:  0 Minute:  4 Second:  59 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 96\n",
      "Epoch: [96][0/19]\tLoss 0.3822 (0.3822)\taccuracy 85.938 (85.938)\tf1_score 84.894 (84.894)\n",
      "Epoch: [96][5/19]\tLoss 0.2748 (0.3507)\taccuracy 89.062 (86.979)\tf1_score 85.323 (84.524)\n",
      "Epoch: [96][10/19]\tLoss 0.5206 (0.3952)\taccuracy 75.000 (84.375)\tf1_score 74.206 (81.163)\n",
      "Epoch: [96][15/19]\tLoss 0.3336 (0.4228)\taccuracy 84.375 (83.594)\tf1_score 79.409 (79.643)\n",
      " Test: accuracy 51.562 f1_score 44.965\n",
      "Training time:  302.06104612350464 Hour:  0 Minute:  5 Second:  2 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 97\n",
      "Epoch: [97][0/19]\tLoss 0.3339 (0.3339)\taccuracy 87.500 (87.500)\tf1_score 78.651 (78.651)\n",
      "Epoch: [97][5/19]\tLoss 0.3700 (0.3971)\taccuracy 89.062 (83.854)\tf1_score 87.846 (79.445)\n",
      "Epoch: [97][10/19]\tLoss 0.5233 (0.4012)\taccuracy 78.125 (83.523)\tf1_score 77.994 (79.626)\n",
      "Epoch: [97][15/19]\tLoss 0.5015 (0.4002)\taccuracy 81.250 (83.887)\tf1_score 75.193 (80.865)\n",
      " Test: accuracy 67.969 f1_score 63.066\n",
      "Training time:  305.10789585113525 Hour:  0 Minute:  5 Second:  5 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 98\n",
      "Epoch: [98][0/19]\tLoss 0.4241 (0.4241)\taccuracy 81.250 (81.250)\tf1_score 77.749 (77.749)\n",
      "Epoch: [98][5/19]\tLoss 0.2849 (0.2904)\taccuracy 90.625 (88.802)\tf1_score 86.222 (87.517)\n",
      "Epoch: [98][10/19]\tLoss 0.2758 (0.3190)\taccuracy 90.625 (88.068)\tf1_score 82.874 (85.714)\n",
      "Epoch: [98][15/19]\tLoss 0.3409 (0.3251)\taccuracy 87.500 (87.793)\tf1_score 90.000 (85.529)\n",
      " Test: accuracy 68.359 f1_score 63.730\n",
      "Training time:  308.1821057796478 Hour:  0 Minute:  5 Second:  8 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 99\n",
      "Epoch: [99][0/19]\tLoss 0.1694 (0.1694)\taccuracy 96.875 (96.875)\tf1_score 96.770 (96.770)\n",
      "Epoch: [99][5/19]\tLoss 0.4188 (0.3715)\taccuracy 82.812 (86.979)\tf1_score 83.341 (86.285)\n",
      "Epoch: [99][10/19]\tLoss 0.3323 (0.3613)\taccuracy 82.812 (86.648)\tf1_score 79.143 (85.302)\n",
      "Epoch: [99][15/19]\tLoss 0.2773 (0.3755)\taccuracy 87.500 (85.156)\tf1_score 83.059 (82.742)\n",
      " Test: accuracy 68.750 f1_score 65.551\n",
      "Training time:  311.23992228507996 Hour:  0 Minute:  5 Second:  11 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 100\n",
      "Epoch: [100][0/19]\tLoss 0.2799 (0.2799)\taccuracy 92.188 (92.188)\tf1_score 88.716 (88.716)\n",
      "Epoch: [100][5/19]\tLoss 0.5614 (0.3321)\taccuracy 81.250 (88.802)\tf1_score 83.692 (86.746)\n",
      "Epoch: [100][10/19]\tLoss 0.2318 (0.3540)\taccuracy 89.062 (87.358)\tf1_score 88.672 (83.959)\n",
      "Epoch: [100][15/19]\tLoss 0.3571 (0.3440)\taccuracy 87.500 (87.695)\tf1_score 85.341 (84.755)\n",
      " Test: accuracy 63.281 f1_score 57.706\n",
      "Training time:  314.29874658584595 Hour:  0 Minute:  5 Second:  14 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 101\n",
      "Epoch: [101][0/19]\tLoss 0.3450 (0.3450)\taccuracy 84.375 (84.375)\tf1_score 81.492 (81.492)\n",
      "Epoch: [101][5/19]\tLoss 0.5794 (0.3452)\taccuracy 81.250 (86.719)\tf1_score 78.673 (83.111)\n",
      "Epoch: [101][10/19]\tLoss 0.3110 (0.3338)\taccuracy 89.062 (88.068)\tf1_score 86.190 (84.752)\n",
      "Epoch: [101][15/19]\tLoss 0.3929 (0.3606)\taccuracy 85.938 (87.109)\tf1_score 78.690 (83.437)\n",
      " Test: accuracy 65.234 f1_score 59.458\n",
      "Training time:  317.34958267211914 Hour:  0 Minute:  5 Second:  17 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 102\n",
      "Epoch: [102][0/19]\tLoss 0.4232 (0.4232)\taccuracy 81.250 (81.250)\tf1_score 77.266 (77.266)\n",
      "Epoch: [102][5/19]\tLoss 0.6675 (0.4834)\taccuracy 76.562 (79.167)\tf1_score 76.780 (79.403)\n",
      "Epoch: [102][10/19]\tLoss 0.3985 (0.3985)\taccuracy 85.938 (84.233)\tf1_score 84.111 (83.639)\n",
      "Epoch: [102][15/19]\tLoss 0.4230 (0.3701)\taccuracy 84.375 (84.961)\tf1_score 85.299 (82.950)\n",
      " Test: accuracy 47.656 f1_score 39.222\n",
      "Training time:  320.39747738838196 Hour:  0 Minute:  5 Second:  20 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 103\n",
      "Epoch: [103][0/19]\tLoss 0.4662 (0.4662)\taccuracy 81.250 (81.250)\tf1_score 82.167 (82.167)\n",
      "Epoch: [103][5/19]\tLoss 0.3146 (0.3692)\taccuracy 89.062 (85.677)\tf1_score 88.947 (85.681)\n",
      "Epoch: [103][10/19]\tLoss 0.7069 (0.3753)\taccuracy 73.438 (85.085)\tf1_score 68.639 (82.669)\n",
      "Epoch: [103][15/19]\tLoss 0.6889 (0.4328)\taccuracy 68.750 (82.617)\tf1_score 72.559 (79.906)\n",
      " Test: accuracy 58.984 f1_score 52.207\n",
      "Training time:  323.45339155197144 Hour:  0 Minute:  5 Second:  23 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 104\n",
      "Epoch: [104][0/19]\tLoss 0.5025 (0.5025)\taccuracy 75.000 (75.000)\tf1_score 75.249 (75.249)\n",
      "Epoch: [104][5/19]\tLoss 0.4903 (0.3229)\taccuracy 81.250 (87.760)\tf1_score 80.660 (84.274)\n",
      "Epoch: [104][10/19]\tLoss 0.5075 (0.3394)\taccuracy 82.812 (87.642)\tf1_score 79.788 (84.065)\n",
      "Epoch: [104][15/19]\tLoss 0.3463 (0.3278)\taccuracy 87.500 (88.184)\tf1_score 83.753 (84.788)\n",
      " Test: accuracy 60.938 f1_score 56.942\n",
      "Training time:  326.5272026062012 Hour:  0 Minute:  5 Second:  26 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 105\n",
      "Epoch: [105][0/19]\tLoss 0.2626 (0.2626)\taccuracy 90.625 (90.625)\tf1_score 85.367 (85.367)\n",
      "Epoch: [105][5/19]\tLoss 0.4005 (0.3754)\taccuracy 84.375 (85.156)\tf1_score 76.479 (82.441)\n",
      "Epoch: [105][10/19]\tLoss 0.4339 (0.3505)\taccuracy 81.250 (87.500)\tf1_score 85.837 (84.729)\n",
      "Epoch: [105][15/19]\tLoss 0.3264 (0.3290)\taccuracy 89.062 (88.281)\tf1_score 88.750 (86.592)\n",
      " Test: accuracy 68.750 f1_score 63.701\n",
      "Training time:  329.57464814186096 Hour:  0 Minute:  5 Second:  29 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 106\n",
      "Epoch: [106][0/19]\tLoss 0.3767 (0.3767)\taccuracy 81.250 (81.250)\tf1_score 76.871 (76.871)\n",
      "Epoch: [106][5/19]\tLoss 0.2978 (0.3727)\taccuracy 89.062 (84.375)\tf1_score 84.429 (81.053)\n",
      "Epoch: [106][10/19]\tLoss 0.4193 (0.3856)\taccuracy 85.938 (84.801)\tf1_score 82.568 (81.755)\n",
      "Epoch: [106][15/19]\tLoss 0.3999 (0.3904)\taccuracy 79.688 (83.789)\tf1_score 78.895 (81.014)\n",
      " Test: accuracy 62.109 f1_score 55.869\n",
      "Training time:  332.624276638031 Hour:  0 Minute:  5 Second:  32 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 107\n",
      "Epoch: [107][0/19]\tLoss 0.3120 (0.3120)\taccuracy 85.938 (85.938)\tf1_score 89.170 (89.170)\n",
      "Epoch: [107][5/19]\tLoss 0.2831 (0.3517)\taccuracy 85.938 (85.938)\tf1_score 78.319 (83.883)\n",
      "Epoch: [107][10/19]\tLoss 0.6896 (0.3665)\taccuracy 79.688 (86.080)\tf1_score 74.139 (83.315)\n",
      "Epoch: [107][15/19]\tLoss 0.2989 (0.3552)\taccuracy 87.500 (86.523)\tf1_score 83.314 (83.051)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test: accuracy 59.766 f1_score 52.316\n",
      "Training time:  335.67612171173096 Hour:  0 Minute:  5 Second:  35 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 108\n",
      "Epoch: [108][0/19]\tLoss 0.2444 (0.2444)\taccuracy 89.062 (89.062)\tf1_score 87.632 (87.632)\n",
      "Epoch: [108][5/19]\tLoss 0.4347 (0.3316)\taccuracy 89.062 (86.719)\tf1_score 86.284 (84.667)\n",
      "Epoch: [108][10/19]\tLoss 0.3077 (0.3372)\taccuracy 89.062 (86.080)\tf1_score 85.500 (83.610)\n",
      "Epoch: [108][15/19]\tLoss 0.3635 (0.3361)\taccuracy 89.062 (86.914)\tf1_score 88.180 (84.412)\n",
      " Test: accuracy 67.578 f1_score 63.584\n",
      "Training time:  338.7220153808594 Hour:  0 Minute:  5 Second:  38 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 109\n",
      "Epoch: [109][0/19]\tLoss 0.4690 (0.4690)\taccuracy 84.375 (84.375)\tf1_score 82.689 (82.689)\n",
      "Epoch: [109][5/19]\tLoss 0.3377 (0.3571)\taccuracy 84.375 (86.719)\tf1_score 79.762 (85.219)\n",
      "Epoch: [109][10/19]\tLoss 0.3641 (0.3404)\taccuracy 85.938 (86.222)\tf1_score 82.815 (83.838)\n",
      "Epoch: [109][15/19]\tLoss 0.2187 (0.3351)\taccuracy 92.188 (86.816)\tf1_score 91.018 (84.005)\n",
      " Test: accuracy 67.188 f1_score 60.783\n",
      "Training time:  341.8047685623169 Hour:  0 Minute:  5 Second:  41 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 110\n",
      "Epoch: [110][0/19]\tLoss 0.3253 (0.3253)\taccuracy 84.375 (84.375)\tf1_score 81.306 (81.306)\n",
      "Epoch: [110][5/19]\tLoss 0.4713 (0.3590)\taccuracy 82.812 (84.375)\tf1_score 87.639 (82.748)\n",
      "Epoch: [110][10/19]\tLoss 0.4723 (0.3226)\taccuracy 76.562 (86.080)\tf1_score 81.175 (83.992)\n",
      "Epoch: [110][15/19]\tLoss 0.3246 (0.3188)\taccuracy 85.938 (86.621)\tf1_score 81.568 (83.611)\n",
      " Test: accuracy 56.641 f1_score 48.524\n",
      "Training time:  344.8516209125519 Hour:  0 Minute:  5 Second:  44 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 111\n",
      "Epoch: [111][0/19]\tLoss 0.2897 (0.2897)\taccuracy 89.062 (89.062)\tf1_score 87.274 (87.274)\n",
      "Epoch: [111][5/19]\tLoss 0.4314 (0.3654)\taccuracy 81.250 (85.677)\tf1_score 69.363 (81.267)\n",
      "Epoch: [111][10/19]\tLoss 0.2805 (0.3555)\taccuracy 85.938 (84.943)\tf1_score 86.184 (81.913)\n",
      "Epoch: [111][15/19]\tLoss 0.2523 (0.3377)\taccuracy 92.188 (85.645)\tf1_score 91.387 (82.952)\n",
      " Test: accuracy 62.109 f1_score 56.686\n",
      "Training time:  347.9024589061737 Hour:  0 Minute:  5 Second:  47 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 112\n",
      "Epoch: [112][0/19]\tLoss 0.2960 (0.2960)\taccuracy 84.375 (84.375)\tf1_score 84.569 (84.569)\n",
      "Epoch: [112][5/19]\tLoss 0.3213 (0.2968)\taccuracy 85.938 (88.802)\tf1_score 87.258 (88.924)\n",
      "Epoch: [112][10/19]\tLoss 0.2924 (0.2973)\taccuracy 90.625 (88.636)\tf1_score 84.558 (86.019)\n",
      "Epoch: [112][15/19]\tLoss 0.3786 (0.3336)\taccuracy 89.062 (87.891)\tf1_score 85.964 (85.472)\n",
      " Test: accuracy 58.984 f1_score 51.364\n",
      "Training time:  350.9523000717163 Hour:  0 Minute:  5 Second:  50 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 113\n",
      "Epoch: [113][0/19]\tLoss 0.2384 (0.2384)\taccuracy 90.625 (90.625)\tf1_score 84.857 (84.857)\n",
      "Epoch: [113][5/19]\tLoss 0.2940 (0.3400)\taccuracy 87.500 (86.458)\tf1_score 85.756 (84.106)\n",
      "Epoch: [113][10/19]\tLoss 0.3342 (0.3264)\taccuracy 84.375 (86.648)\tf1_score 81.234 (84.905)\n",
      "Epoch: [113][15/19]\tLoss 0.3882 (0.3201)\taccuracy 85.938 (86.914)\tf1_score 82.370 (85.002)\n",
      " Test: accuracy 51.172 f1_score 44.420\n",
      "Training time:  354.0021414756775 Hour:  0 Minute:  5 Second:  54 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 114\n",
      "Epoch: [114][0/19]\tLoss 0.5408 (0.5408)\taccuracy 75.000 (75.000)\tf1_score 74.146 (74.146)\n",
      "Epoch: [114][5/19]\tLoss 0.2878 (0.3672)\taccuracy 93.750 (86.979)\tf1_score 92.256 (84.443)\n",
      "Epoch: [114][10/19]\tLoss 0.4311 (0.3586)\taccuracy 84.375 (87.074)\tf1_score 82.438 (84.746)\n",
      "Epoch: [114][15/19]\tLoss 0.1518 (0.3482)\taccuracy 95.312 (87.402)\tf1_score 94.603 (84.631)\n",
      " Test: accuracy 51.172 f1_score 45.419\n",
      "Training time:  357.09509348869324 Hour:  0 Minute:  5 Second:  57 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 115\n",
      "Epoch: [115][0/19]\tLoss 0.4421 (0.4421)\taccuracy 81.250 (81.250)\tf1_score 82.299 (82.299)\n",
      "Epoch: [115][5/19]\tLoss 0.4362 (0.3666)\taccuracy 82.812 (86.979)\tf1_score 75.212 (85.967)\n",
      "Epoch: [115][10/19]\tLoss 0.2400 (0.3425)\taccuracy 95.312 (87.358)\tf1_score 94.785 (85.534)\n",
      "Epoch: [115][15/19]\tLoss 0.2955 (0.3468)\taccuracy 92.188 (86.914)\tf1_score 92.208 (85.116)\n",
      " Test: accuracy 42.578 f1_score 33.346\n",
      "Training time:  360.164345741272 Hour:  0 Minute:  6 Second:  0 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 116\n",
      "Epoch: [116][0/19]\tLoss 0.3975 (0.3975)\taccuracy 81.250 (81.250)\tf1_score 83.894 (83.894)\n",
      "Epoch: [116][5/19]\tLoss 0.3957 (0.3993)\taccuracy 82.812 (83.333)\tf1_score 82.246 (80.133)\n",
      "Epoch: [116][10/19]\tLoss 0.1881 (0.3619)\taccuracy 93.750 (84.517)\tf1_score 94.053 (81.798)\n",
      "Epoch: [116][15/19]\tLoss 0.3046 (0.3674)\taccuracy 89.062 (85.352)\tf1_score 84.644 (82.504)\n",
      " Test: accuracy 60.547 f1_score 54.581\n",
      "Training time:  363.2680127620697 Hour:  0 Minute:  6 Second:  3 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 117\n",
      "Epoch: [117][0/19]\tLoss 0.2842 (0.2842)\taccuracy 92.188 (92.188)\tf1_score 84.462 (84.462)\n",
      "Epoch: [117][5/19]\tLoss 0.3253 (0.3041)\taccuracy 87.500 (88.802)\tf1_score 89.108 (84.577)\n",
      "Epoch: [117][10/19]\tLoss 0.3930 (0.3365)\taccuracy 84.375 (86.506)\tf1_score 85.202 (83.674)\n",
      "Epoch: [117][15/19]\tLoss 0.3803 (0.3516)\taccuracy 82.812 (85.840)\tf1_score 71.732 (82.891)\n",
      " Test: accuracy 55.469 f1_score 50.033\n",
      "Training time:  366.3635060787201 Hour:  0 Minute:  6 Second:  6 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 118\n",
      "Epoch: [118][0/19]\tLoss 0.3743 (0.3743)\taccuracy 85.938 (85.938)\tf1_score 84.684 (84.684)\n",
      "Epoch: [118][5/19]\tLoss 0.5506 (0.3828)\taccuracy 82.812 (86.458)\tf1_score 80.026 (85.000)\n",
      "Epoch: [118][10/19]\tLoss 0.3679 (0.3761)\taccuracy 81.250 (86.080)\tf1_score 74.227 (83.423)\n",
      "Epoch: [118][15/19]\tLoss 0.3995 (0.3581)\taccuracy 82.812 (86.914)\tf1_score 85.894 (84.360)\n",
      " Test: accuracy 69.141 f1_score 66.743\n",
      "Training time:  369.46321725845337 Hour:  0 Minute:  6 Second:  9 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 119\n",
      "Epoch: [119][0/19]\tLoss 0.3101 (0.3101)\taccuracy 89.062 (89.062)\tf1_score 70.844 (70.844)\n",
      "Epoch: [119][5/19]\tLoss 0.4284 (0.3418)\taccuracy 84.375 (87.240)\tf1_score 78.288 (82.028)\n",
      "Epoch: [119][10/19]\tLoss 0.2822 (0.2966)\taccuracy 87.500 (88.352)\tf1_score 88.768 (85.117)\n",
      "Epoch: [119][15/19]\tLoss 0.4697 (0.3356)\taccuracy 85.938 (87.305)\tf1_score 83.901 (84.066)\n",
      " Test: accuracy 60.938 f1_score 53.494\n",
      "Training time:  372.5859203338623 Hour:  0 Minute:  6 Second:  12 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 120\n",
      "Epoch: [120][0/19]\tLoss 0.2932 (0.2932)\taccuracy 89.062 (89.062)\tf1_score 84.968 (84.968)\n",
      "Epoch: [120][5/19]\tLoss 0.2554 (0.3209)\taccuracy 89.062 (87.240)\tf1_score 85.064 (84.784)\n",
      "Epoch: [120][10/19]\tLoss 0.3396 (0.3422)\taccuracy 85.938 (85.511)\tf1_score 87.447 (84.040)\n",
      "Epoch: [120][15/19]\tLoss 0.2920 (0.3474)\taccuracy 87.500 (85.645)\tf1_score 87.131 (83.232)\n",
      " Test: accuracy 66.797 f1_score 62.114\n",
      "Training time:  375.6597330570221 Hour:  0 Minute:  6 Second:  15 Test best accuracy: 71.484375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 121\n",
      "Epoch: [121][0/19]\tLoss 0.4447 (0.4447)\taccuracy 79.688 (79.688)\tf1_score 77.106 (77.106)\n",
      "Epoch: [121][5/19]\tLoss 0.3391 (0.3121)\taccuracy 87.500 (89.062)\tf1_score 77.415 (85.481)\n",
      "Epoch: [121][10/19]\tLoss 0.3356 (0.3158)\taccuracy 82.812 (87.358)\tf1_score 76.954 (84.741)\n",
      "Epoch: [121][15/19]\tLoss 0.4623 (0.3326)\taccuracy 82.812 (86.621)\tf1_score 73.515 (83.838)\n",
      " Test: accuracy 74.219 f1_score 68.778\n",
      "Training time:  378.73251152038574 Hour:  0 Minute:  6 Second:  18 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 122\n",
      "Epoch: [122][0/19]\tLoss 0.3262 (0.3262)\taccuracy 89.062 (89.062)\tf1_score 78.439 (78.439)\n",
      "Epoch: [122][5/19]\tLoss 0.2352 (0.2790)\taccuracy 89.062 (88.802)\tf1_score 81.563 (85.276)\n",
      "Epoch: [122][10/19]\tLoss 0.6146 (0.2983)\taccuracy 73.438 (87.642)\tf1_score 76.022 (84.600)\n",
      "Epoch: [122][15/19]\tLoss 0.5432 (0.3115)\taccuracy 82.812 (87.793)\tf1_score 79.664 (85.229)\n",
      " Test: accuracy 60.156 f1_score 53.890\n",
      "Training time:  381.80329966545105 Hour:  0 Minute:  6 Second:  21 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 123\n",
      "Epoch: [123][0/19]\tLoss 0.1460 (0.1460)\taccuracy 95.312 (95.312)\tf1_score 89.998 (89.998)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [123][5/19]\tLoss 0.2268 (0.2990)\taccuracy 93.750 (88.542)\tf1_score 94.261 (86.652)\n",
      "Epoch: [123][10/19]\tLoss 0.3106 (0.2829)\taccuracy 89.062 (89.915)\tf1_score 88.603 (87.979)\n",
      "Epoch: [123][15/19]\tLoss 0.1982 (0.2796)\taccuracy 93.750 (90.039)\tf1_score 89.751 (86.951)\n",
      " Test: accuracy 58.984 f1_score 54.745\n",
      "Training time:  384.8740839958191 Hour:  0 Minute:  6 Second:  24 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 124\n",
      "Epoch: [124][0/19]\tLoss 0.2138 (0.2138)\taccuracy 92.188 (92.188)\tf1_score 85.006 (85.006)\n",
      "Epoch: [124][5/19]\tLoss 0.3035 (0.2888)\taccuracy 81.250 (86.979)\tf1_score 80.056 (84.894)\n",
      "Epoch: [124][10/19]\tLoss 0.4055 (0.3001)\taccuracy 82.812 (86.790)\tf1_score 77.051 (83.879)\n",
      "Epoch: [124][15/19]\tLoss 0.3523 (0.3015)\taccuracy 85.938 (87.109)\tf1_score 82.540 (84.230)\n",
      " Test: accuracy 61.719 f1_score 57.704\n",
      "Training time:  387.96478366851807 Hour:  0 Minute:  6 Second:  27 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 125\n",
      "Epoch: [125][0/19]\tLoss 0.2573 (0.2573)\taccuracy 89.062 (89.062)\tf1_score 85.359 (85.359)\n",
      "Epoch: [125][5/19]\tLoss 0.4419 (0.3136)\taccuracy 82.812 (87.500)\tf1_score 75.850 (85.519)\n",
      "Epoch: [125][10/19]\tLoss 0.1650 (0.2744)\taccuracy 95.312 (89.631)\tf1_score 94.417 (87.742)\n",
      "Epoch: [125][15/19]\tLoss 0.2530 (0.2837)\taccuracy 89.062 (89.746)\tf1_score 84.683 (87.531)\n",
      " Test: accuracy 55.078 f1_score 48.757\n",
      "Training time:  391.06950855255127 Hour:  0 Minute:  6 Second:  31 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 126\n",
      "Epoch: [126][0/19]\tLoss 0.3230 (0.3230)\taccuracy 87.500 (87.500)\tf1_score 82.418 (82.418)\n",
      "Epoch: [126][5/19]\tLoss 0.2627 (0.2853)\taccuracy 90.625 (89.844)\tf1_score 92.047 (86.081)\n",
      "Epoch: [126][10/19]\tLoss 0.2848 (0.3352)\taccuracy 90.625 (88.068)\tf1_score 92.470 (84.991)\n",
      "Epoch: [126][15/19]\tLoss 0.2938 (0.3074)\taccuracy 85.938 (88.867)\tf1_score 87.661 (85.850)\n",
      " Test: accuracy 71.875 f1_score 67.919\n",
      "Training time:  394.14143347740173 Hour:  0 Minute:  6 Second:  34 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 127\n",
      "Epoch: [127][0/19]\tLoss 0.2567 (0.2567)\taccuracy 90.625 (90.625)\tf1_score 89.607 (89.607)\n",
      "Epoch: [127][5/19]\tLoss 0.2147 (0.2667)\taccuracy 89.062 (87.760)\tf1_score 89.140 (87.323)\n",
      "Epoch: [127][10/19]\tLoss 0.5363 (0.3058)\taccuracy 78.125 (86.222)\tf1_score 74.529 (84.622)\n",
      "Epoch: [127][15/19]\tLoss 0.2765 (0.3214)\taccuracy 87.500 (85.645)\tf1_score 78.592 (83.160)\n",
      " Test: accuracy 66.797 f1_score 63.279\n",
      "Training time:  397.2151789665222 Hour:  0 Minute:  6 Second:  37 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 128\n",
      "Epoch: [128][0/19]\tLoss 0.1678 (0.1678)\taccuracy 96.875 (96.875)\tf1_score 93.111 (93.111)\n",
      "Epoch: [128][5/19]\tLoss 0.5390 (0.3517)\taccuracy 79.688 (87.760)\tf1_score 77.756 (85.124)\n",
      "Epoch: [128][10/19]\tLoss 0.2575 (0.3455)\taccuracy 85.938 (86.648)\tf1_score 88.137 (84.982)\n",
      "Epoch: [128][15/19]\tLoss 0.2487 (0.3547)\taccuracy 92.188 (86.719)\tf1_score 89.683 (84.564)\n",
      " Test: accuracy 68.359 f1_score 65.115\n",
      "Training time:  400.28815841674805 Hour:  0 Minute:  6 Second:  40 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 129\n",
      "Epoch: [129][0/19]\tLoss 0.1901 (0.1901)\taccuracy 92.188 (92.188)\tf1_score 89.630 (89.630)\n",
      "Epoch: [129][5/19]\tLoss 0.4387 (0.2999)\taccuracy 84.375 (87.760)\tf1_score 81.028 (84.306)\n",
      "Epoch: [129][10/19]\tLoss 0.2880 (0.2905)\taccuracy 87.500 (88.068)\tf1_score 85.692 (86.070)\n",
      "Epoch: [129][15/19]\tLoss 0.5754 (0.3090)\taccuracy 79.688 (87.695)\tf1_score 75.991 (85.311)\n",
      " Test: accuracy 59.766 f1_score 56.148\n",
      "Training time:  403.35394620895386 Hour:  0 Minute:  6 Second:  43 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 130\n",
      "Epoch: [130][0/19]\tLoss 0.4223 (0.4223)\taccuracy 82.812 (82.812)\tf1_score 83.315 (83.315)\n",
      "Epoch: [130][5/19]\tLoss 0.3847 (0.3564)\taccuracy 87.500 (86.719)\tf1_score 82.404 (84.897)\n",
      "Epoch: [130][10/19]\tLoss 0.1601 (0.3219)\taccuracy 100.000 (88.778)\tf1_score 100.000 (87.434)\n",
      "Epoch: [130][15/19]\tLoss 0.3197 (0.3086)\taccuracy 90.625 (89.258)\tf1_score 90.261 (87.936)\n",
      " Test: accuracy 53.125 f1_score 45.841\n",
      "Training time:  406.45983362197876 Hour:  0 Minute:  6 Second:  46 Test best accuracy: 74.21875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 131\n",
      "Epoch: [131][0/19]\tLoss 0.2341 (0.2341)\taccuracy 89.062 (89.062)\tf1_score 77.853 (77.853)\n",
      "Epoch: [131][5/19]\tLoss 0.1701 (0.2341)\taccuracy 93.750 (91.146)\tf1_score 92.653 (87.746)\n",
      "Epoch: [131][10/19]\tLoss 0.2081 (0.2285)\taccuracy 93.750 (92.188)\tf1_score 92.571 (89.253)\n",
      "Epoch: [131][15/19]\tLoss 0.2502 (0.2397)\taccuracy 87.500 (91.211)\tf1_score 88.708 (89.061)\n",
      " Test: accuracy 75.391 f1_score 72.157\n",
      "Training time:  409.55329847335815 Hour:  0 Minute:  6 Second:  49 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 132\n",
      "Epoch: [132][0/19]\tLoss 0.3051 (0.3051)\taccuracy 89.062 (89.062)\tf1_score 86.701 (86.701)\n",
      "Epoch: [132][5/19]\tLoss 0.4307 (0.3141)\taccuracy 84.375 (88.542)\tf1_score 84.271 (86.603)\n",
      "Epoch: [132][10/19]\tLoss 0.4384 (0.3264)\taccuracy 84.375 (87.784)\tf1_score 84.379 (85.079)\n",
      "Epoch: [132][15/19]\tLoss 0.4535 (0.3148)\taccuracy 81.250 (88.477)\tf1_score 78.092 (86.005)\n",
      " Test: accuracy 55.859 f1_score 46.486\n",
      "Training time:  412.6530067920685 Hour:  0 Minute:  6 Second:  52 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 133\n",
      "Epoch: [133][0/19]\tLoss 0.4061 (0.4061)\taccuracy 81.250 (81.250)\tf1_score 85.034 (85.034)\n",
      "Epoch: [133][5/19]\tLoss 0.4935 (0.2869)\taccuracy 81.250 (88.542)\tf1_score 77.806 (87.905)\n",
      "Epoch: [133][10/19]\tLoss 0.1813 (0.2783)\taccuracy 93.750 (89.062)\tf1_score 92.878 (87.943)\n",
      "Epoch: [133][15/19]\tLoss 0.2760 (0.2813)\taccuracy 84.375 (88.574)\tf1_score 81.330 (87.102)\n",
      " Test: accuracy 68.359 f1_score 67.013\n",
      "Training time:  415.7482874393463 Hour:  0 Minute:  6 Second:  55 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 134\n",
      "Epoch: [134][0/19]\tLoss 0.1969 (0.1969)\taccuracy 95.312 (95.312)\tf1_score 93.833 (93.833)\n",
      "Epoch: [134][5/19]\tLoss 0.4322 (0.2789)\taccuracy 82.812 (91.146)\tf1_score 81.063 (90.394)\n",
      "Epoch: [134][10/19]\tLoss 0.1538 (0.2600)\taccuracy 95.312 (91.619)\tf1_score 95.317 (91.388)\n",
      "Epoch: [134][15/19]\tLoss 0.2825 (0.2747)\taccuracy 89.062 (91.016)\tf1_score 85.408 (90.329)\n",
      " Test: accuracy 68.359 f1_score 65.305\n",
      "Training time:  418.8300440311432 Hour:  0 Minute:  6 Second:  58 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 135\n",
      "Epoch: [135][0/19]\tLoss 0.4226 (0.4226)\taccuracy 79.688 (79.688)\tf1_score 78.078 (78.078)\n",
      "Epoch: [135][5/19]\tLoss 0.1394 (0.3166)\taccuracy 93.750 (85.938)\tf1_score 91.234 (81.889)\n",
      "Epoch: [135][10/19]\tLoss 0.4869 (0.3108)\taccuracy 82.812 (87.074)\tf1_score 77.341 (83.833)\n",
      "Epoch: [135][15/19]\tLoss 0.1677 (0.2779)\taccuracy 95.312 (88.574)\tf1_score 94.769 (86.355)\n",
      " Test: accuracy 64.453 f1_score 58.809\n",
      "Training time:  421.9385154247284 Hour:  0 Minute:  7 Second:  1 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 136\n",
      "Epoch: [136][0/19]\tLoss 0.1845 (0.1845)\taccuracy 95.312 (95.312)\tf1_score 90.703 (90.703)\n",
      "Epoch: [136][5/19]\tLoss 0.3307 (0.2924)\taccuracy 87.500 (90.365)\tf1_score 86.535 (88.019)\n",
      "Epoch: [136][10/19]\tLoss 0.2181 (0.2614)\taccuracy 92.188 (91.193)\tf1_score 94.774 (89.647)\n",
      "Epoch: [136][15/19]\tLoss 0.8515 (0.2984)\taccuracy 71.875 (89.355)\tf1_score 66.846 (86.755)\n",
      " Test: accuracy 65.625 f1_score 61.121\n",
      "Training time:  425.0085418224335 Hour:  0 Minute:  7 Second:  5 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 137\n",
      "Epoch: [137][0/19]\tLoss 0.2601 (0.2601)\taccuracy 90.625 (90.625)\tf1_score 92.381 (92.381)\n",
      "Epoch: [137][5/19]\tLoss 0.2267 (0.3334)\taccuracy 92.188 (86.719)\tf1_score 86.675 (83.635)\n",
      "Epoch: [137][10/19]\tLoss 0.3486 (0.3537)\taccuracy 85.938 (86.222)\tf1_score 83.059 (83.527)\n",
      "Epoch: [137][15/19]\tLoss 0.2496 (0.3180)\taccuracy 89.062 (87.598)\tf1_score 80.351 (84.626)\n",
      " Test: accuracy 49.609 f1_score 43.974\n",
      "Training time:  428.0794644355774 Hour:  0 Minute:  7 Second:  8 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 138\n",
      "Epoch: [138][0/19]\tLoss 0.2561 (0.2561)\taccuracy 90.625 (90.625)\tf1_score 87.521 (87.521)\n",
      "Epoch: [138][5/19]\tLoss 0.1934 (0.3266)\taccuracy 93.750 (87.240)\tf1_score 93.190 (84.538)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [138][10/19]\tLoss 0.5075 (0.4279)\taccuracy 76.562 (84.233)\tf1_score 75.285 (81.667)\n",
      "Epoch: [138][15/19]\tLoss 0.2770 (0.4021)\taccuracy 89.062 (84.082)\tf1_score 84.590 (81.504)\n",
      " Test: accuracy 61.719 f1_score 57.323\n",
      "Training time:  431.1512792110443 Hour:  0 Minute:  7 Second:  11 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 139\n",
      "Epoch: [139][0/19]\tLoss 0.2990 (0.2990)\taccuracy 89.062 (89.062)\tf1_score 87.355 (87.355)\n",
      "Epoch: [139][5/19]\tLoss 0.2557 (0.2286)\taccuracy 90.625 (91.927)\tf1_score 87.317 (89.343)\n",
      "Epoch: [139][10/19]\tLoss 0.3470 (0.2894)\taccuracy 90.625 (90.341)\tf1_score 86.857 (87.958)\n",
      "Epoch: [139][15/19]\tLoss 0.3265 (0.2779)\taccuracy 81.250 (89.844)\tf1_score 80.397 (86.968)\n",
      " Test: accuracy 60.547 f1_score 54.260\n",
      "Training time:  434.21769285202026 Hour:  0 Minute:  7 Second:  14 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 140\n",
      "Epoch: [140][0/19]\tLoss 0.3202 (0.3202)\taccuracy 89.062 (89.062)\tf1_score 83.761 (83.761)\n",
      "Epoch: [140][5/19]\tLoss 0.4073 (0.3637)\taccuracy 82.812 (86.198)\tf1_score 78.004 (81.800)\n",
      "Epoch: [140][10/19]\tLoss 0.2282 (0.3453)\taccuracy 92.188 (86.222)\tf1_score 91.823 (83.296)\n",
      "Epoch: [140][15/19]\tLoss 0.2265 (0.3467)\taccuracy 95.312 (86.816)\tf1_score 91.948 (83.239)\n",
      " Test: accuracy 53.906 f1_score 47.848\n",
      "Training time:  437.3118460178375 Hour:  0 Minute:  7 Second:  17 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 141\n",
      "Epoch: [141][0/19]\tLoss 0.3722 (0.3722)\taccuracy 84.375 (84.375)\tf1_score 82.220 (82.220)\n",
      "Epoch: [141][5/19]\tLoss 0.3003 (0.2806)\taccuracy 87.500 (88.281)\tf1_score 79.656 (85.599)\n",
      "Epoch: [141][10/19]\tLoss 0.1760 (0.2683)\taccuracy 92.188 (88.778)\tf1_score 90.113 (86.692)\n",
      "Epoch: [141][15/19]\tLoss 0.4448 (0.2923)\taccuracy 82.812 (88.281)\tf1_score 86.865 (85.947)\n",
      " Test: accuracy 62.500 f1_score 55.595\n",
      "Training time:  440.38113713264465 Hour:  0 Minute:  7 Second:  20 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 142\n",
      "Epoch: [142][0/19]\tLoss 0.2261 (0.2261)\taccuracy 92.188 (92.188)\tf1_score 86.528 (86.528)\n",
      "Epoch: [142][5/19]\tLoss 0.1490 (0.2506)\taccuracy 95.312 (89.583)\tf1_score 91.370 (86.724)\n",
      "Epoch: [142][10/19]\tLoss 0.2127 (0.2573)\taccuracy 92.188 (89.915)\tf1_score 90.586 (87.421)\n",
      "Epoch: [142][15/19]\tLoss 0.1712 (0.2507)\taccuracy 95.312 (90.625)\tf1_score 95.525 (88.218)\n",
      " Test: accuracy 72.656 f1_score 68.799\n",
      "Training time:  443.4549148082733 Hour:  0 Minute:  7 Second:  23 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 143\n",
      "Epoch: [143][0/19]\tLoss 0.1915 (0.1915)\taccuracy 92.188 (92.188)\tf1_score 82.833 (82.833)\n",
      "Epoch: [143][5/19]\tLoss 0.2658 (0.2015)\taccuracy 89.062 (91.667)\tf1_score 82.708 (86.246)\n",
      "Epoch: [143][10/19]\tLoss 0.2190 (0.2260)\taccuracy 92.188 (91.051)\tf1_score 92.045 (87.323)\n",
      "Epoch: [143][15/19]\tLoss 0.2140 (0.2478)\taccuracy 92.188 (90.332)\tf1_score 92.619 (87.372)\n",
      " Test: accuracy 55.469 f1_score 50.141\n",
      "Training time:  446.5279211997986 Hour:  0 Minute:  7 Second:  26 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 144\n",
      "Epoch: [144][0/19]\tLoss 0.2112 (0.2112)\taccuracy 92.188 (92.188)\tf1_score 86.212 (86.212)\n",
      "Epoch: [144][5/19]\tLoss 0.1803 (0.2889)\taccuracy 95.312 (88.021)\tf1_score 96.378 (86.416)\n",
      "Epoch: [144][10/19]\tLoss 0.2046 (0.2638)\taccuracy 93.750 (89.347)\tf1_score 92.113 (88.399)\n",
      "Epoch: [144][15/19]\tLoss 0.2456 (0.2909)\taccuracy 85.938 (88.965)\tf1_score 84.221 (87.643)\n",
      " Test: accuracy 68.359 f1_score 64.251\n",
      "Training time:  449.60468888282776 Hour:  0 Minute:  7 Second:  29 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 145\n",
      "Epoch: [145][0/19]\tLoss 0.2349 (0.2349)\taccuracy 93.750 (93.750)\tf1_score 87.243 (87.243)\n",
      "Epoch: [145][5/19]\tLoss 0.2790 (0.3401)\taccuracy 90.625 (88.542)\tf1_score 90.250 (86.275)\n",
      "Epoch: [145][10/19]\tLoss 0.3048 (0.3148)\taccuracy 85.938 (88.494)\tf1_score 85.833 (86.728)\n",
      "Epoch: [145][15/19]\tLoss 0.4106 (0.2961)\taccuracy 85.938 (89.160)\tf1_score 81.909 (86.914)\n",
      " Test: accuracy 60.547 f1_score 54.401\n",
      "Training time:  452.7163324356079 Hour:  0 Minute:  7 Second:  32 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 146\n",
      "Epoch: [146][0/19]\tLoss 0.4551 (0.4551)\taccuracy 84.375 (84.375)\tf1_score 84.804 (84.804)\n",
      "Epoch: [146][5/19]\tLoss 0.1653 (0.2470)\taccuracy 92.188 (91.406)\tf1_score 91.746 (89.153)\n",
      "Epoch: [146][10/19]\tLoss 0.1133 (0.2538)\taccuracy 95.312 (91.335)\tf1_score 95.083 (88.637)\n",
      "Epoch: [146][15/19]\tLoss 0.2648 (0.2931)\taccuracy 89.062 (89.648)\tf1_score 88.598 (87.538)\n",
      " Test: accuracy 70.703 f1_score 68.358\n",
      "Training time:  455.7891492843628 Hour:  0 Minute:  7 Second:  35 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 147\n",
      "Epoch: [147][0/19]\tLoss 0.2147 (0.2147)\taccuracy 95.312 (95.312)\tf1_score 95.528 (95.528)\n",
      "Epoch: [147][5/19]\tLoss 0.2373 (0.2284)\taccuracy 89.062 (92.188)\tf1_score 88.613 (91.120)\n",
      "Epoch: [147][10/19]\tLoss 0.2030 (0.2362)\taccuracy 93.750 (91.477)\tf1_score 94.524 (91.210)\n",
      "Epoch: [147][15/19]\tLoss 0.3376 (0.2519)\taccuracy 84.375 (90.527)\tf1_score 85.498 (89.502)\n",
      " Test: accuracy 62.891 f1_score 57.141\n",
      "Training time:  458.89184617996216 Hour:  0 Minute:  7 Second:  38 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 148\n",
      "Epoch: [148][0/19]\tLoss 0.1763 (0.1763)\taccuracy 90.625 (90.625)\tf1_score 90.278 (90.278)\n",
      "Epoch: [148][5/19]\tLoss 0.2152 (0.2738)\taccuracy 92.188 (88.281)\tf1_score 91.720 (87.838)\n",
      "Epoch: [148][10/19]\tLoss 0.1444 (0.2406)\taccuracy 95.312 (90.625)\tf1_score 93.799 (89.787)\n",
      "Epoch: [148][15/19]\tLoss 0.2357 (0.2556)\taccuracy 89.062 (90.039)\tf1_score 90.136 (88.604)\n",
      " Test: accuracy 62.500 f1_score 56.917\n",
      "Training time:  461.9975063800812 Hour:  0 Minute:  7 Second:  41 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 149\n",
      "Epoch: [149][0/19]\tLoss 0.1791 (0.1791)\taccuracy 92.188 (92.188)\tf1_score 90.899 (90.899)\n",
      "Epoch: [149][5/19]\tLoss 0.4024 (0.2231)\taccuracy 84.375 (91.927)\tf1_score 85.806 (89.894)\n",
      "Epoch: [149][10/19]\tLoss 0.2997 (0.2248)\taccuracy 84.375 (91.051)\tf1_score 77.451 (88.653)\n",
      "Epoch: [149][15/19]\tLoss 0.2006 (0.2226)\taccuracy 92.188 (91.211)\tf1_score 91.109 (89.196)\n",
      " Test: accuracy 64.062 f1_score 56.711\n",
      "Training time:  465.0711534023285 Hour:  0 Minute:  7 Second:  45 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 150\n",
      "Epoch: [150][0/19]\tLoss 0.1546 (0.1546)\taccuracy 95.312 (95.312)\tf1_score 94.467 (94.467)\n",
      "Epoch: [150][5/19]\tLoss 0.0855 (0.1583)\taccuracy 96.875 (94.010)\tf1_score 92.381 (92.721)\n",
      "Epoch: [150][10/19]\tLoss 0.1442 (0.1541)\taccuracy 95.312 (94.744)\tf1_score 94.505 (93.199)\n",
      "Epoch: [150][15/19]\tLoss 0.1669 (0.1854)\taccuracy 92.188 (92.871)\tf1_score 93.757 (91.229)\n",
      " Test: accuracy 66.016 f1_score 60.732\n",
      "Training time:  468.1608531475067 Hour:  0 Minute:  7 Second:  48 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 151\n",
      "Epoch: [151][0/19]\tLoss 0.4768 (0.4768)\taccuracy 79.688 (79.688)\tf1_score 77.256 (77.256)\n",
      "Epoch: [151][5/19]\tLoss 0.3645 (0.3957)\taccuracy 90.625 (85.677)\tf1_score 89.617 (85.855)\n",
      "Epoch: [151][10/19]\tLoss 0.2277 (0.3310)\taccuracy 90.625 (87.642)\tf1_score 90.326 (86.683)\n",
      "Epoch: [151][15/19]\tLoss 0.2490 (0.2984)\taccuracy 89.062 (88.379)\tf1_score 88.965 (87.290)\n",
      " Test: accuracy 63.281 f1_score 59.943\n",
      "Training time:  471.2590367794037 Hour:  0 Minute:  7 Second:  51 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 152\n",
      "Epoch: [152][0/19]\tLoss 0.3452 (0.3452)\taccuracy 84.375 (84.375)\tf1_score 81.361 (81.361)\n",
      "Epoch: [152][5/19]\tLoss 0.1791 (0.2723)\taccuracy 93.750 (89.062)\tf1_score 80.393 (84.600)\n",
      "Epoch: [152][10/19]\tLoss 0.2924 (0.2570)\taccuracy 89.062 (90.057)\tf1_score 81.702 (86.671)\n",
      "Epoch: [152][15/19]\tLoss 0.2228 (0.2728)\taccuracy 90.625 (89.941)\tf1_score 85.165 (87.040)\n",
      " Test: accuracy 64.453 f1_score 60.432\n",
      "Training time:  474.33822441101074 Hour:  0 Minute:  7 Second:  54 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 153\n",
      "Epoch: [153][0/19]\tLoss 0.2660 (0.2660)\taccuracy 90.625 (90.625)\tf1_score 87.909 (87.909)\n",
      "Epoch: [153][5/19]\tLoss 0.2053 (0.2859)\taccuracy 90.625 (89.844)\tf1_score 90.454 (87.659)\n",
      "Epoch: [153][10/19]\tLoss 0.3320 (0.2408)\taccuracy 85.938 (91.761)\tf1_score 83.595 (90.011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [153][15/19]\tLoss 0.6557 (0.2776)\taccuracy 76.562 (90.137)\tf1_score 72.494 (88.509)\n",
      " Test: accuracy 43.750 f1_score 36.952\n",
      "Training time:  477.41299510002136 Hour:  0 Minute:  7 Second:  57 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 154\n",
      "Epoch: [154][0/19]\tLoss 0.4479 (0.4479)\taccuracy 82.812 (82.812)\tf1_score 79.236 (79.236)\n",
      "Epoch: [154][5/19]\tLoss 0.3711 (0.2903)\taccuracy 92.188 (89.844)\tf1_score 88.879 (86.859)\n",
      "Epoch: [154][10/19]\tLoss 0.3227 (0.3058)\taccuracy 85.938 (87.926)\tf1_score 85.986 (86.054)\n",
      "Epoch: [154][15/19]\tLoss 0.2418 (0.3080)\taccuracy 90.625 (88.184)\tf1_score 85.127 (86.482)\n",
      " Test: accuracy 53.125 f1_score 45.967\n",
      "Training time:  480.487770318985 Hour:  0 Minute:  8 Second:  0 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 155\n",
      "Epoch: [155][0/19]\tLoss 0.2747 (0.2747)\taccuracy 92.188 (92.188)\tf1_score 91.635 (91.635)\n",
      "Epoch: [155][5/19]\tLoss 0.2692 (0.2974)\taccuracy 89.062 (89.844)\tf1_score 82.810 (87.296)\n",
      "Epoch: [155][10/19]\tLoss 0.2199 (0.2588)\taccuracy 90.625 (90.909)\tf1_score 84.810 (88.757)\n",
      "Epoch: [155][15/19]\tLoss 0.2292 (0.2713)\taccuracy 90.625 (90.430)\tf1_score 89.335 (88.356)\n",
      " Test: accuracy 69.922 f1_score 66.886\n",
      "Training time:  483.56931710243225 Hour:  0 Minute:  8 Second:  3 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 156\n",
      "Epoch: [156][0/19]\tLoss 0.1426 (0.1426)\taccuracy 95.312 (95.312)\tf1_score 95.748 (95.748)\n",
      "Epoch: [156][5/19]\tLoss 0.1339 (0.1857)\taccuracy 96.875 (93.229)\tf1_score 97.296 (92.670)\n",
      "Epoch: [156][10/19]\tLoss 0.1655 (0.2160)\taccuracy 95.312 (92.472)\tf1_score 92.238 (91.173)\n",
      "Epoch: [156][15/19]\tLoss 0.0869 (0.2071)\taccuracy 98.438 (92.480)\tf1_score 98.519 (91.285)\n",
      " Test: accuracy 61.719 f1_score 57.023\n",
      "Training time:  486.6809995174408 Hour:  0 Minute:  8 Second:  6 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 157\n",
      "Epoch: [157][0/19]\tLoss 0.2167 (0.2167)\taccuracy 93.750 (93.750)\tf1_score 95.614 (95.614)\n",
      "Epoch: [157][5/19]\tLoss 0.1633 (0.2017)\taccuracy 95.312 (93.490)\tf1_score 93.730 (91.881)\n",
      "Epoch: [157][10/19]\tLoss 0.7109 (0.2646)\taccuracy 75.000 (91.477)\tf1_score 82.303 (90.648)\n",
      "Epoch: [157][15/19]\tLoss 0.1400 (0.2366)\taccuracy 93.750 (92.090)\tf1_score 83.283 (90.367)\n",
      " Test: accuracy 66.797 f1_score 61.141\n",
      "Training time:  489.7587637901306 Hour:  0 Minute:  8 Second:  9 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 158\n",
      "Epoch: [158][0/19]\tLoss 0.2004 (0.2004)\taccuracy 90.625 (90.625)\tf1_score 91.291 (91.291)\n",
      "Epoch: [158][5/19]\tLoss 0.2237 (0.2209)\taccuracy 90.625 (91.667)\tf1_score 91.896 (90.168)\n",
      "Epoch: [158][10/19]\tLoss 0.2025 (0.2485)\taccuracy 93.750 (90.057)\tf1_score 94.902 (88.676)\n",
      "Epoch: [158][15/19]\tLoss 0.1441 (0.2526)\taccuracy 96.875 (90.137)\tf1_score 96.939 (88.475)\n",
      " Test: accuracy 64.062 f1_score 56.909\n",
      "Training time:  492.8345396518707 Hour:  0 Minute:  8 Second:  12 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 159\n",
      "Epoch: [159][0/19]\tLoss 0.2880 (0.2880)\taccuracy 90.625 (90.625)\tf1_score 87.188 (87.188)\n",
      "Epoch: [159][5/19]\tLoss 0.1847 (0.2949)\taccuracy 93.750 (89.323)\tf1_score 94.053 (85.710)\n",
      "Epoch: [159][10/19]\tLoss 0.2673 (0.3071)\taccuracy 90.625 (88.352)\tf1_score 90.023 (85.762)\n",
      "Epoch: [159][15/19]\tLoss 0.3024 (0.2770)\taccuracy 87.500 (89.453)\tf1_score 84.769 (87.124)\n",
      " Test: accuracy 72.656 f1_score 70.169\n",
      "Training time:  495.93236899375916 Hour:  0 Minute:  8 Second:  15 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 160\n",
      "Epoch: [160][0/19]\tLoss 0.1382 (0.1382)\taccuracy 93.750 (93.750)\tf1_score 88.250 (88.250)\n",
      "Epoch: [160][5/19]\tLoss 0.2403 (0.2030)\taccuracy 92.188 (91.406)\tf1_score 92.667 (90.336)\n",
      "Epoch: [160][10/19]\tLoss 0.1016 (0.1839)\taccuracy 96.875 (92.330)\tf1_score 97.309 (91.212)\n",
      "Epoch: [160][15/19]\tLoss 0.2267 (0.1900)\taccuracy 90.625 (92.285)\tf1_score 92.855 (91.340)\n",
      " Test: accuracy 62.500 f1_score 56.264\n",
      "Training time:  499.0312988758087 Hour:  0 Minute:  8 Second:  19 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 161\n",
      "Epoch: [161][0/19]\tLoss 0.1897 (0.1897)\taccuracy 95.312 (95.312)\tf1_score 94.563 (94.563)\n",
      "Epoch: [161][5/19]\tLoss 0.2424 (0.1803)\taccuracy 92.188 (94.010)\tf1_score 89.665 (91.367)\n",
      "Epoch: [161][10/19]\tLoss 0.1701 (0.2047)\taccuracy 93.750 (92.045)\tf1_score 92.889 (90.415)\n",
      "Epoch: [161][15/19]\tLoss 0.1315 (0.1913)\taccuracy 96.875 (92.480)\tf1_score 97.193 (91.196)\n",
      " Test: accuracy 57.422 f1_score 49.116\n",
      "Training time:  502.1529405117035 Hour:  0 Minute:  8 Second:  22 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 162\n",
      "Epoch: [162][0/19]\tLoss 0.6037 (0.6037)\taccuracy 81.250 (81.250)\tf1_score 76.058 (76.058)\n",
      "Epoch: [162][5/19]\tLoss 0.2779 (0.3165)\taccuracy 89.062 (89.062)\tf1_score 89.091 (85.906)\n",
      "Epoch: [162][10/19]\tLoss 0.1656 (0.2577)\taccuracy 90.625 (90.341)\tf1_score 88.224 (87.984)\n",
      "Epoch: [162][15/19]\tLoss 0.2586 (0.2476)\taccuracy 90.625 (90.918)\tf1_score 88.428 (88.034)\n",
      " Test: accuracy 75.391 f1_score 73.541\n",
      "Training time:  505.24367666244507 Hour:  0 Minute:  8 Second:  25 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 163\n",
      "Epoch: [163][0/19]\tLoss 0.1948 (0.1948)\taccuracy 92.188 (92.188)\tf1_score 92.611 (92.611)\n",
      "Epoch: [163][5/19]\tLoss 0.3455 (0.2858)\taccuracy 85.938 (87.760)\tf1_score 79.452 (84.516)\n",
      "Epoch: [163][10/19]\tLoss 0.2424 (0.2669)\taccuracy 92.188 (89.347)\tf1_score 91.221 (86.425)\n",
      "Epoch: [163][15/19]\tLoss 0.5123 (0.2860)\taccuracy 78.125 (88.672)\tf1_score 77.752 (86.234)\n",
      " Test: accuracy 32.422 f1_score 23.733\n",
      "Training time:  508.34438824653625 Hour:  0 Minute:  8 Second:  28 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 164\n",
      "Epoch: [164][0/19]\tLoss 0.4159 (0.4159)\taccuracy 92.188 (92.188)\tf1_score 84.094 (84.094)\n",
      "Epoch: [164][5/19]\tLoss 0.3809 (0.3746)\taccuracy 85.938 (88.021)\tf1_score 77.777 (83.192)\n",
      "Epoch: [164][10/19]\tLoss 0.2562 (0.3336)\taccuracy 93.750 (88.920)\tf1_score 90.907 (85.257)\n",
      "Epoch: [164][15/19]\tLoss 0.4697 (0.3520)\taccuracy 79.688 (87.305)\tf1_score 78.548 (83.923)\n",
      " Test: accuracy 48.828 f1_score 43.076\n",
      "Training time:  511.4424102306366 Hour:  0 Minute:  8 Second:  31 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 165\n",
      "Epoch: [165][0/19]\tLoss 0.1381 (0.1381)\taccuracy 93.750 (93.750)\tf1_score 92.925 (92.925)\n",
      "Epoch: [165][5/19]\tLoss 0.2498 (0.2522)\taccuracy 90.625 (89.583)\tf1_score 80.692 (87.308)\n",
      "Epoch: [165][10/19]\tLoss 0.2890 (0.2873)\taccuracy 89.062 (87.500)\tf1_score 87.891 (85.656)\n",
      "Epoch: [165][15/19]\tLoss 0.1467 (0.2748)\taccuracy 96.875 (88.379)\tf1_score 96.571 (86.484)\n",
      " Test: accuracy 51.172 f1_score 42.650\n",
      "Training time:  514.5442843437195 Hour:  0 Minute:  8 Second:  34 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 166\n",
      "Epoch: [166][0/19]\tLoss 0.3036 (0.3036)\taccuracy 85.938 (85.938)\tf1_score 86.712 (86.712)\n",
      "Epoch: [166][5/19]\tLoss 0.2627 (0.2829)\taccuracy 90.625 (89.323)\tf1_score 91.056 (89.620)\n",
      "Epoch: [166][10/19]\tLoss 0.3181 (0.2823)\taccuracy 93.750 (89.773)\tf1_score 88.254 (88.675)\n",
      "Epoch: [166][15/19]\tLoss 0.2938 (0.2669)\taccuracy 90.625 (90.625)\tf1_score 88.454 (89.000)\n",
      " Test: accuracy 69.141 f1_score 63.892\n",
      "Training time:  517.6830732822418 Hour:  0 Minute:  8 Second:  37 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 167\n",
      "Epoch: [167][0/19]\tLoss 0.5193 (0.5193)\taccuracy 78.125 (78.125)\tf1_score 77.816 (77.816)\n",
      "Epoch: [167][5/19]\tLoss 0.3287 (0.2861)\taccuracy 89.062 (89.062)\tf1_score 87.562 (88.045)\n",
      "Epoch: [167][10/19]\tLoss 0.1846 (0.2718)\taccuracy 93.750 (90.341)\tf1_score 93.050 (88.479)\n",
      "Epoch: [167][15/19]\tLoss 0.3714 (0.2657)\taccuracy 87.500 (90.332)\tf1_score 79.822 (87.917)\n",
      " Test: accuracy 69.531 f1_score 66.893\n",
      "Training time:  520.7598431110382 Hour:  0 Minute:  8 Second:  40 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 168\n",
      "Epoch: [168][0/19]\tLoss 0.2262 (0.2262)\taccuracy 89.062 (89.062)\tf1_score 89.914 (89.914)\n",
      "Epoch: [168][5/19]\tLoss 0.4925 (0.2573)\taccuracy 78.125 (88.542)\tf1_score 71.922 (86.392)\n",
      "Epoch: [168][10/19]\tLoss 0.2529 (0.2314)\taccuracy 90.625 (89.915)\tf1_score 89.430 (87.752)\n",
      "Epoch: [168][15/19]\tLoss 0.2402 (0.2503)\taccuracy 90.625 (89.551)\tf1_score 88.406 (87.562)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test: accuracy 64.453 f1_score 59.147\n",
      "Training time:  523.8376107215881 Hour:  0 Minute:  8 Second:  43 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 169\n",
      "Epoch: [169][0/19]\tLoss 0.2393 (0.2393)\taccuracy 89.062 (89.062)\tf1_score 84.482 (84.482)\n",
      "Epoch: [169][5/19]\tLoss 0.2155 (0.2283)\taccuracy 89.062 (90.885)\tf1_score 87.619 (87.739)\n",
      "Epoch: [169][10/19]\tLoss 0.3205 (0.2434)\taccuracy 85.938 (90.625)\tf1_score 81.892 (88.090)\n",
      "Epoch: [169][15/19]\tLoss 0.2569 (0.2412)\taccuracy 90.625 (91.309)\tf1_score 86.712 (89.098)\n",
      " Test: accuracy 67.578 f1_score 61.984\n",
      "Training time:  526.9094424247742 Hour:  0 Minute:  8 Second:  46 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 170\n",
      "Epoch: [170][0/19]\tLoss 0.2807 (0.2807)\taccuracy 85.938 (85.938)\tf1_score 78.314 (78.314)\n",
      "Epoch: [170][5/19]\tLoss 0.1865 (0.1903)\taccuracy 90.625 (92.708)\tf1_score 91.345 (91.652)\n",
      "Epoch: [170][10/19]\tLoss 0.2838 (0.2286)\taccuracy 90.625 (90.625)\tf1_score 88.672 (89.020)\n",
      "Epoch: [170][15/19]\tLoss 0.3526 (0.2345)\taccuracy 89.062 (91.406)\tf1_score 87.604 (89.212)\n",
      " Test: accuracy 67.188 f1_score 65.068\n",
      "Training time:  529.9812259674072 Hour:  0 Minute:  8 Second:  49 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 171\n",
      "Epoch: [171][0/19]\tLoss 0.2151 (0.2151)\taccuracy 89.062 (89.062)\tf1_score 85.782 (85.782)\n",
      "Epoch: [171][5/19]\tLoss 0.1037 (0.1899)\taccuracy 96.875 (92.708)\tf1_score 96.939 (92.112)\n",
      "Epoch: [171][10/19]\tLoss 0.2750 (0.2364)\taccuracy 89.062 (91.051)\tf1_score 86.393 (90.200)\n",
      "Epoch: [171][15/19]\tLoss 0.6188 (0.2520)\taccuracy 78.125 (90.527)\tf1_score 79.056 (88.605)\n",
      " Test: accuracy 64.844 f1_score 60.416\n",
      "Training time:  533.093870639801 Hour:  0 Minute:  8 Second:  53 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 172\n",
      "Epoch: [172][0/19]\tLoss 0.3568 (0.3568)\taccuracy 90.625 (90.625)\tf1_score 84.748 (84.748)\n",
      "Epoch: [172][5/19]\tLoss 0.1379 (0.2094)\taccuracy 95.312 (92.969)\tf1_score 92.897 (89.496)\n",
      "Epoch: [172][10/19]\tLoss 0.2895 (0.2072)\taccuracy 87.500 (92.472)\tf1_score 88.776 (89.923)\n",
      "Epoch: [172][15/19]\tLoss 0.2809 (0.2316)\taccuracy 90.625 (91.309)\tf1_score 85.060 (88.568)\n",
      " Test: accuracy 60.547 f1_score 54.210\n",
      "Training time:  536.1610705852509 Hour:  0 Minute:  8 Second:  56 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 173\n",
      "Epoch: [173][0/19]\tLoss 0.1759 (0.1759)\taccuracy 92.188 (92.188)\tf1_score 91.452 (91.452)\n",
      "Epoch: [173][5/19]\tLoss 0.1565 (0.2079)\taccuracy 96.875 (91.146)\tf1_score 93.206 (88.289)\n",
      "Epoch: [173][10/19]\tLoss 0.2528 (0.2198)\taccuracy 90.625 (91.051)\tf1_score 84.118 (88.494)\n",
      "Epoch: [173][15/19]\tLoss 0.1563 (0.2451)\taccuracy 95.312 (91.016)\tf1_score 95.640 (88.934)\n",
      " Test: accuracy 59.766 f1_score 53.774\n",
      "Training time:  539.2318551540375 Hour:  0 Minute:  8 Second:  59 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 174\n",
      "Epoch: [174][0/19]\tLoss 0.1268 (0.1268)\taccuracy 95.312 (95.312)\tf1_score 95.344 (95.344)\n",
      "Epoch: [174][5/19]\tLoss 0.4396 (0.2975)\taccuracy 85.938 (90.625)\tf1_score 79.002 (86.578)\n",
      "Epoch: [174][10/19]\tLoss 0.2747 (0.2925)\taccuracy 89.062 (90.625)\tf1_score 81.846 (86.999)\n",
      "Epoch: [174][15/19]\tLoss 0.2372 (0.2832)\taccuracy 89.062 (90.137)\tf1_score 85.583 (87.070)\n",
      " Test: accuracy 66.016 f1_score 59.502\n",
      "Training time:  542.3078799247742 Hour:  0 Minute:  9 Second:  2 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 175\n",
      "Epoch: [175][0/19]\tLoss 0.3634 (0.3634)\taccuracy 87.500 (87.500)\tf1_score 81.762 (81.762)\n",
      "Epoch: [175][5/19]\tLoss 0.1202 (0.2214)\taccuracy 98.438 (92.188)\tf1_score 97.884 (89.117)\n",
      "Epoch: [175][10/19]\tLoss 0.2506 (0.2204)\taccuracy 92.188 (91.903)\tf1_score 89.139 (89.083)\n",
      "Epoch: [175][15/19]\tLoss 0.1869 (0.2080)\taccuracy 92.188 (92.090)\tf1_score 91.767 (89.662)\n",
      " Test: accuracy 60.938 f1_score 54.636\n",
      "Training time:  545.3837065696716 Hour:  0 Minute:  9 Second:  5 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 176\n",
      "Epoch: [176][0/19]\tLoss 0.2644 (0.2644)\taccuracy 89.062 (89.062)\tf1_score 87.949 (87.949)\n",
      "Epoch: [176][5/19]\tLoss 0.1866 (0.2273)\taccuracy 93.750 (91.667)\tf1_score 92.963 (90.373)\n",
      "Epoch: [176][10/19]\tLoss 0.3312 (0.2296)\taccuracy 87.500 (91.193)\tf1_score 79.833 (89.697)\n",
      "Epoch: [176][15/19]\tLoss 0.5730 (0.2457)\taccuracy 84.375 (91.211)\tf1_score 82.319 (89.495)\n",
      " Test: accuracy 59.375 f1_score 53.782\n",
      "Training time:  548.4963529109955 Hour:  0 Minute:  9 Second:  8 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 177\n",
      "Epoch: [177][0/19]\tLoss 0.1581 (0.1581)\taccuracy 96.875 (96.875)\tf1_score 90.952 (90.952)\n",
      "Epoch: [177][5/19]\tLoss 0.1996 (0.2443)\taccuracy 92.188 (91.146)\tf1_score 88.734 (86.994)\n",
      "Epoch: [177][10/19]\tLoss 0.4944 (0.2936)\taccuracy 81.250 (88.920)\tf1_score 79.992 (85.620)\n",
      "Epoch: [177][15/19]\tLoss 0.2697 (0.2611)\taccuracy 89.062 (90.430)\tf1_score 88.169 (87.759)\n",
      " Test: accuracy 56.641 f1_score 49.929\n",
      "Training time:  551.5811321735382 Hour:  0 Minute:  9 Second:  11 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 178\n",
      "Epoch: [178][0/19]\tLoss 0.2292 (0.2292)\taccuracy 90.625 (90.625)\tf1_score 87.286 (87.286)\n",
      "Epoch: [178][5/19]\tLoss 0.2822 (0.2215)\taccuracy 87.500 (92.188)\tf1_score 87.937 (90.125)\n",
      "Epoch: [178][10/19]\tLoss 0.4016 (0.2419)\taccuracy 89.062 (90.909)\tf1_score 77.041 (88.405)\n",
      "Epoch: [178][15/19]\tLoss 0.2056 (0.2378)\taccuracy 93.750 (91.113)\tf1_score 88.148 (88.660)\n",
      " Test: accuracy 62.500 f1_score 56.234\n",
      "Training time:  554.6590857505798 Hour:  0 Minute:  9 Second:  14 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 179\n",
      "Epoch: [179][0/19]\tLoss 0.1724 (0.1724)\taccuracy 93.750 (93.750)\tf1_score 93.492 (93.492)\n",
      "Epoch: [179][5/19]\tLoss 0.1305 (0.1642)\taccuracy 93.750 (94.271)\tf1_score 95.323 (92.418)\n",
      "Epoch: [179][10/19]\tLoss 0.2446 (0.1855)\taccuracy 87.500 (92.614)\tf1_score 87.736 (91.100)\n",
      "Epoch: [179][15/19]\tLoss 0.1876 (0.1904)\taccuracy 90.625 (92.090)\tf1_score 91.578 (91.158)\n",
      " Test: accuracy 67.969 f1_score 66.199\n",
      "Training time:  557.737176656723 Hour:  0 Minute:  9 Second:  17 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 180\n",
      "Epoch: [180][0/19]\tLoss 0.1892 (0.1892)\taccuracy 95.312 (95.312)\tf1_score 95.476 (95.476)\n",
      "Epoch: [180][5/19]\tLoss 0.2303 (0.2053)\taccuracy 89.062 (91.406)\tf1_score 88.653 (88.420)\n",
      "Epoch: [180][10/19]\tLoss 0.3326 (0.1983)\taccuracy 85.938 (91.619)\tf1_score 85.464 (89.321)\n",
      "Epoch: [180][15/19]\tLoss 0.1878 (0.1926)\taccuracy 93.750 (92.578)\tf1_score 93.810 (91.166)\n",
      " Test: accuracy 67.578 f1_score 62.008\n",
      "Training time:  560.827910900116 Hour:  0 Minute:  9 Second:  20 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 181\n",
      "Epoch: [181][0/19]\tLoss 0.0724 (0.0724)\taccuracy 98.438 (98.438)\tf1_score 98.942 (98.942)\n",
      "Epoch: [181][5/19]\tLoss 0.0825 (0.1143)\taccuracy 96.875 (96.354)\tf1_score 95.238 (95.301)\n",
      "Epoch: [181][10/19]\tLoss 0.2223 (0.1501)\taccuracy 92.188 (94.744)\tf1_score 91.310 (93.445)\n",
      "Epoch: [181][15/19]\tLoss 0.2275 (0.1632)\taccuracy 89.062 (93.750)\tf1_score 87.470 (92.705)\n",
      " Test: accuracy 57.031 f1_score 50.278\n",
      "Training time:  563.9383804798126 Hour:  0 Minute:  9 Second:  23 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 182\n",
      "Epoch: [182][0/19]\tLoss 0.2726 (0.2726)\taccuracy 87.500 (87.500)\tf1_score 85.275 (85.275)\n",
      "Epoch: [182][5/19]\tLoss 0.1956 (0.2637)\taccuracy 93.750 (89.323)\tf1_score 94.607 (87.908)\n",
      "Epoch: [182][10/19]\tLoss 0.2253 (0.2387)\taccuracy 93.750 (90.199)\tf1_score 92.653 (88.878)\n",
      "Epoch: [182][15/19]\tLoss 0.2388 (0.2313)\taccuracy 93.750 (91.211)\tf1_score 92.675 (89.904)\n",
      " Test: accuracy 53.906 f1_score 48.937\n",
      "Training time:  567.0597040653229 Hour:  0 Minute:  9 Second:  27 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 183\n",
      "Epoch: [183][0/19]\tLoss 0.1702 (0.1702)\taccuracy 93.750 (93.750)\tf1_score 95.179 (95.179)\n",
      "Epoch: [183][5/19]\tLoss 0.5237 (0.3049)\taccuracy 82.812 (87.500)\tf1_score 73.692 (83.646)\n",
      "Epoch: [183][10/19]\tLoss 0.0847 (0.2535)\taccuracy 98.438 (89.631)\tf1_score 98.000 (86.949)\n",
      "Epoch: [183][15/19]\tLoss 0.1326 (0.2639)\taccuracy 96.875 (90.332)\tf1_score 96.157 (88.154)\n",
      " Test: accuracy 64.844 f1_score 60.846\n",
      "Training time:  570.1643679141998 Hour:  0 Minute:  9 Second:  30 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 184\n",
      "Epoch: [184][0/19]\tLoss 0.1532 (0.1532)\taccuracy 96.875 (96.875)\tf1_score 96.725 (96.725)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [184][5/19]\tLoss 0.2842 (0.2114)\taccuracy 92.188 (93.490)\tf1_score 91.339 (91.844)\n",
      "Epoch: [184][10/19]\tLoss 0.3379 (0.2103)\taccuracy 89.062 (93.040)\tf1_score 88.504 (91.136)\n",
      "Epoch: [184][15/19]\tLoss 0.1948 (0.1975)\taccuracy 90.625 (92.969)\tf1_score 91.607 (90.940)\n",
      " Test: accuracy 63.672 f1_score 57.085\n",
      "Training time:  573.2695670127869 Hour:  0 Minute:  9 Second:  33 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 185\n",
      "Epoch: [185][0/19]\tLoss 0.1258 (0.1258)\taccuracy 95.312 (95.312)\tf1_score 90.986 (90.986)\n",
      "Epoch: [185][5/19]\tLoss 0.1329 (0.1654)\taccuracy 96.875 (92.969)\tf1_score 93.615 (91.824)\n",
      "Epoch: [185][10/19]\tLoss 0.1801 (0.1778)\taccuracy 95.312 (93.182)\tf1_score 96.107 (92.213)\n",
      "Epoch: [185][15/19]\tLoss 0.1772 (0.1951)\taccuracy 92.188 (92.090)\tf1_score 84.989 (90.615)\n",
      " Test: accuracy 72.656 f1_score 68.932\n",
      "Training time:  576.370275259018 Hour:  0 Minute:  9 Second:  36 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 186\n",
      "Epoch: [186][0/19]\tLoss 0.2864 (0.2864)\taccuracy 85.938 (85.938)\tf1_score 81.440 (81.440)\n",
      "Epoch: [186][5/19]\tLoss 0.2522 (0.2093)\taccuracy 87.500 (92.188)\tf1_score 77.719 (88.456)\n",
      "Epoch: [186][10/19]\tLoss 0.2847 (0.2412)\taccuracy 90.625 (90.341)\tf1_score 81.980 (87.053)\n",
      "Epoch: [186][15/19]\tLoss 0.1828 (0.2313)\taccuracy 93.750 (91.211)\tf1_score 93.159 (88.350)\n",
      " Test: accuracy 71.484 f1_score 68.238\n",
      "Training time:  579.4709465503693 Hour:  0 Minute:  9 Second:  39 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 187\n",
      "Epoch: [187][0/19]\tLoss 0.2298 (0.2298)\taccuracy 90.625 (90.625)\tf1_score 89.875 (89.875)\n",
      "Epoch: [187][5/19]\tLoss 0.1237 (0.1753)\taccuracy 96.875 (92.969)\tf1_score 97.203 (91.651)\n",
      "Epoch: [187][10/19]\tLoss 0.2508 (0.1764)\taccuracy 93.750 (93.182)\tf1_score 89.889 (90.413)\n",
      "Epoch: [187][15/19]\tLoss 0.4055 (0.1859)\taccuracy 81.250 (92.676)\tf1_score 79.383 (90.221)\n",
      " Test: accuracy 71.094 f1_score 67.480\n",
      "Training time:  582.6033327579498 Hour:  0 Minute:  9 Second:  42 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 188\n",
      "Epoch: [188][0/19]\tLoss 0.1352 (0.1352)\taccuracy 92.188 (92.188)\tf1_score 82.872 (82.872)\n",
      "Epoch: [188][5/19]\tLoss 0.2315 (0.1524)\taccuracy 92.188 (94.531)\tf1_score 93.093 (91.518)\n",
      "Epoch: [188][10/19]\tLoss 0.1943 (0.1987)\taccuracy 92.188 (92.330)\tf1_score 92.184 (90.635)\n",
      "Epoch: [188][15/19]\tLoss 0.1384 (0.2252)\taccuracy 92.188 (91.406)\tf1_score 93.870 (89.440)\n",
      " Test: accuracy 64.453 f1_score 60.919\n",
      "Training time:  585.7079286575317 Hour:  0 Minute:  9 Second:  45 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 189\n",
      "Epoch: [189][0/19]\tLoss 0.2900 (0.2900)\taccuracy 85.938 (85.938)\tf1_score 85.185 (85.185)\n",
      "Epoch: [189][5/19]\tLoss 0.4763 (0.2727)\taccuracy 87.500 (90.625)\tf1_score 83.187 (87.611)\n",
      "Epoch: [189][10/19]\tLoss 0.1543 (0.2620)\taccuracy 93.750 (90.199)\tf1_score 91.472 (88.056)\n",
      "Epoch: [189][15/19]\tLoss 0.2222 (0.2545)\taccuracy 93.750 (90.527)\tf1_score 92.813 (89.173)\n",
      " Test: accuracy 71.484 f1_score 66.509\n",
      "Training time:  588.8107035160065 Hour:  0 Minute:  9 Second:  48 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 190\n",
      "Epoch: [190][0/19]\tLoss 0.1945 (0.1945)\taccuracy 90.625 (90.625)\tf1_score 89.830 (89.830)\n",
      "Epoch: [190][5/19]\tLoss 0.2812 (0.2492)\taccuracy 89.062 (90.365)\tf1_score 83.917 (89.162)\n",
      "Epoch: [190][10/19]\tLoss 0.1897 (0.2329)\taccuracy 95.312 (91.335)\tf1_score 91.619 (89.865)\n",
      "Epoch: [190][15/19]\tLoss 0.1081 (0.2248)\taccuracy 95.312 (91.406)\tf1_score 96.528 (90.020)\n",
      " Test: accuracy 69.141 f1_score 66.274\n",
      "Training time:  591.9096117019653 Hour:  0 Minute:  9 Second:  51 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 191\n",
      "Epoch: [191][0/19]\tLoss 0.1476 (0.1476)\taccuracy 92.188 (92.188)\tf1_score 92.322 (92.322)\n",
      "Epoch: [191][5/19]\tLoss 0.3179 (0.2251)\taccuracy 87.500 (90.625)\tf1_score 82.188 (88.273)\n",
      "Epoch: [191][10/19]\tLoss 0.1869 (0.2424)\taccuracy 96.875 (91.051)\tf1_score 96.500 (88.729)\n",
      "Epoch: [191][15/19]\tLoss 0.2573 (0.2325)\taccuracy 93.750 (91.406)\tf1_score 88.252 (89.111)\n",
      " Test: accuracy 63.281 f1_score 58.518\n",
      "Training time:  594.9826891422272 Hour:  0 Minute:  9 Second:  54 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 192\n",
      "Epoch: [192][0/19]\tLoss 0.2881 (0.2881)\taccuracy 90.625 (90.625)\tf1_score 86.286 (86.286)\n",
      "Epoch: [192][5/19]\tLoss 0.2300 (0.1894)\taccuracy 89.062 (92.708)\tf1_score 85.624 (90.700)\n",
      "Epoch: [192][10/19]\tLoss 0.2349 (0.2062)\taccuracy 90.625 (91.903)\tf1_score 91.547 (89.893)\n",
      "Epoch: [192][15/19]\tLoss 0.1962 (0.2153)\taccuracy 92.188 (91.797)\tf1_score 88.592 (89.089)\n",
      " Test: accuracy 59.375 f1_score 54.438\n",
      "Training time:  598.1189224720001 Hour:  0 Minute:  9 Second:  58 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 193\n",
      "Epoch: [193][0/19]\tLoss 0.2617 (0.2617)\taccuracy 87.500 (87.500)\tf1_score 77.869 (77.869)\n",
      "Epoch: [193][5/19]\tLoss 0.3393 (0.2928)\taccuracy 84.375 (88.021)\tf1_score 80.901 (83.835)\n",
      "Epoch: [193][10/19]\tLoss 0.1513 (0.2506)\taccuracy 96.875 (90.341)\tf1_score 96.786 (87.120)\n",
      "Epoch: [193][15/19]\tLoss 0.1994 (0.2746)\taccuracy 93.750 (89.453)\tf1_score 93.488 (86.683)\n",
      " Test: accuracy 67.578 f1_score 62.282\n",
      "Training time:  601.2205893993378 Hour:  0 Minute:  10 Second:  1 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 194\n",
      "Epoch: [194][0/19]\tLoss 0.1450 (0.1450)\taccuracy 95.312 (95.312)\tf1_score 95.858 (95.858)\n",
      "Epoch: [194][5/19]\tLoss 0.2060 (0.2285)\taccuracy 92.188 (90.625)\tf1_score 89.108 (88.267)\n",
      "Epoch: [194][10/19]\tLoss 0.2182 (0.2629)\taccuracy 95.312 (90.483)\tf1_score 95.333 (86.818)\n",
      "Epoch: [194][15/19]\tLoss 0.0698 (0.2551)\taccuracy 98.438 (90.430)\tf1_score 97.732 (87.683)\n",
      " Test: accuracy 71.875 f1_score 68.935\n",
      "Training time:  604.3183374404907 Hour:  0 Minute:  10 Second:  4 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 195\n",
      "Epoch: [195][0/19]\tLoss 0.1819 (0.1819)\taccuracy 93.750 (93.750)\tf1_score 92.098 (92.098)\n",
      "Epoch: [195][5/19]\tLoss 0.1762 (0.2016)\taccuracy 92.188 (92.188)\tf1_score 87.685 (90.424)\n",
      "Epoch: [195][10/19]\tLoss 0.1935 (0.2011)\taccuracy 92.188 (92.188)\tf1_score 92.494 (89.842)\n",
      "Epoch: [195][15/19]\tLoss 0.1485 (0.1940)\taccuracy 95.312 (92.578)\tf1_score 92.667 (89.658)\n",
      " Test: accuracy 68.750 f1_score 67.147\n",
      "Training time:  607.4246079921722 Hour:  0 Minute:  10 Second:  7 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 196\n",
      "Epoch: [196][0/19]\tLoss 0.2116 (0.2116)\taccuracy 93.750 (93.750)\tf1_score 88.163 (88.163)\n",
      "Epoch: [196][5/19]\tLoss 0.2036 (0.1726)\taccuracy 93.750 (94.010)\tf1_score 94.743 (92.581)\n",
      "Epoch: [196][10/19]\tLoss 0.1731 (0.1785)\taccuracy 93.750 (93.608)\tf1_score 93.675 (92.351)\n",
      "Epoch: [196][15/19]\tLoss 0.6671 (0.2023)\taccuracy 85.938 (93.164)\tf1_score 80.071 (91.356)\n",
      " Test: accuracy 54.688 f1_score 49.128\n",
      "Training time:  610.5141727924347 Hour:  0 Minute:  10 Second:  10 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 197\n",
      "Epoch: [197][0/19]\tLoss 0.1891 (0.1891)\taccuracy 92.188 (92.188)\tf1_score 91.194 (91.194)\n",
      "Epoch: [197][5/19]\tLoss 0.2812 (0.2266)\taccuracy 89.062 (91.667)\tf1_score 89.156 (90.249)\n",
      "Epoch: [197][10/19]\tLoss 0.3437 (0.3080)\taccuracy 81.250 (89.631)\tf1_score 73.764 (87.433)\n",
      "Epoch: [197][15/19]\tLoss 0.2487 (0.2900)\taccuracy 89.062 (90.234)\tf1_score 91.313 (88.373)\n",
      " Test: accuracy 61.719 f1_score 57.271\n",
      "Training time:  613.6783549785614 Hour:  0 Minute:  10 Second:  13 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 198\n",
      "Epoch: [198][0/19]\tLoss 0.3838 (0.3838)\taccuracy 84.375 (84.375)\tf1_score 81.545 (81.545)\n",
      "Epoch: [198][5/19]\tLoss 0.2756 (0.3012)\taccuracy 92.188 (87.500)\tf1_score 91.841 (84.319)\n",
      "Epoch: [198][10/19]\tLoss 0.2208 (0.2807)\taccuracy 89.062 (88.352)\tf1_score 86.000 (84.682)\n",
      "Epoch: [198][15/19]\tLoss 0.4730 (0.2799)\taccuracy 79.688 (88.574)\tf1_score 83.493 (85.348)\n",
      " Test: accuracy 67.578 f1_score 63.121\n",
      "Training time:  616.7840473651886 Hour:  0 Minute:  10 Second:  16 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 199\n",
      "Epoch: [199][0/19]\tLoss 0.1641 (0.1641)\taccuracy 93.750 (93.750)\tf1_score 92.957 (92.957)\n",
      "Epoch: [199][5/19]\tLoss 0.2237 (0.2157)\taccuracy 89.062 (92.188)\tf1_score 88.390 (91.099)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [199][10/19]\tLoss 0.1137 (0.2200)\taccuracy 96.875 (92.188)\tf1_score 97.857 (91.112)\n",
      "Epoch: [199][15/19]\tLoss 0.2258 (0.2719)\taccuracy 92.188 (90.234)\tf1_score 79.955 (88.393)\n",
      " Test: accuracy 66.406 f1_score 63.339\n",
      "Training time:  619.898716211319 Hour:  0 Minute:  10 Second:  19 Test best accuracy: 75.390625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 200\n",
      "Epoch: [200][0/19]\tLoss 0.1462 (0.1462)\taccuracy 93.750 (93.750)\tf1_score 94.125 (94.125)\n",
      "Epoch: [200][5/19]\tLoss 0.2203 (0.1943)\taccuracy 92.188 (92.969)\tf1_score 84.195 (90.336)\n",
      "Epoch: [200][10/19]\tLoss 0.2782 (0.2274)\taccuracy 89.062 (91.051)\tf1_score 83.417 (87.972)\n",
      "Epoch: [200][15/19]\tLoss 0.2182 (0.2449)\taccuracy 93.750 (90.527)\tf1_score 93.921 (87.566)\n",
      " Test: accuracy 68.750 f1_score 65.372\n",
      "Training time:  623.0054059028625 Hour:  0 Minute:  10 Second:  23 Test best accuracy: 75.390625  Test best f1 score: 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch NO: %d\" % (epoch,))\n",
    "    adjust_learning_rate(optimizer, epoch, args=1)\n",
    "    train(train_loader, model, criterion,  optimizer, epoch, print_interval=5)\n",
    "    acc, f1 = validate(test_loader, model, criterion,  args=1)\n",
    "    \n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "            \n",
    "    time_interval = time.time() - start_time\n",
    "    time_split = time.gmtime(time_interval)\n",
    "    print(\"Training time: \", time_interval, \"Hour: \", time_split.tm_hour, \"Minute: \", time_split.tm_min, \"Second: \",\n",
    "              time_split.tm_sec, end='')\n",
    "    print(\" Test best accuracy:\", best_acc, \" Test best f1 score:\", best_f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d948cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba691b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
