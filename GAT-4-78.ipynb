{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b3032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033c4e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class\n",
       "0                0  2.660984 -9.653030  0.470237      1\n",
       "1                1  2.223091 -9.432167  2.223091      1\n",
       "2                2  2.098372 -9.481953  0.926070      1\n",
       "3                3  2.716461 -9.739352  0.912008      1\n",
       "4                4  2.288388 -9.371498  0.910390      1\n",
       "...            ...       ...       ...       ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21\n",
       "155403      155403  8.680778  4.261679 -0.159214     21\n",
       "155404      155404  8.756194  4.168306 -0.144251     21\n",
       "155405      155405  8.662222  4.219781 -0.183755     21\n",
       "155406      155406  8.738238  4.180277 -0.201711     21\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('no-outlier.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85fc78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0                0  2.660984 -9.653030  0.470237      1      0\n",
       "1                1  2.223091 -9.432167  2.223091      1      0\n",
       "2                2  2.098372 -9.481953  0.926070      1      0\n",
       "3                3  2.716461 -9.739352  0.912008      1      0\n",
       "4                4  2.288388 -9.371498  0.910390      1      0\n",
       "...            ...       ...       ...       ...    ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403      155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404      155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405      155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406      155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = LabelEncoder()\n",
    "data['label'] = label.fit_transform(data['Class'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30036d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209cd61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "fig=sns.boxplot(data=data.iloc[0:8000,1:4],whis=[0, 100])\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945a491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0       2.660984 -9.653030  0.470237      1      0\n",
       "1       2.223091 -9.432167  2.223091      1      0\n",
       "2       2.098372 -9.481953  0.926070      1      0\n",
       "3       2.716461 -9.739352  0.912008      1      0\n",
       "4       2.288388 -9.371498  0.910390      1      0\n",
       "...          ...       ...       ...    ...    ...\n",
       "155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = data.drop('Unnamed: 0', axis=1)  \n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d194de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11dbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn[['Acc_X', 'Acc_Y', 'Acc_Z']]\n",
    "y = dfn['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b72537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acc_X     Acc_Y     Acc_Z\n",
       "0       2.660984 -9.653030  0.470237\n",
       "1       2.223091 -9.432167  2.223091\n",
       "2       2.098372 -9.481953  0.926070\n",
       "3       2.716461 -9.739352  0.912008\n",
       "4       2.288388 -9.371498  0.910390\n",
       "...          ...       ...       ...\n",
       "155402  8.701128  4.238336 -0.194529\n",
       "155403  8.680778  4.261679 -0.159214\n",
       "155404  8.756194  4.168306 -0.144251\n",
       "155405  8.662222  4.219781 -0.183755\n",
       "155406  8.738238  4.180277 -0.201711\n",
       "\n",
       "[155407 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b306756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "155402    20\n",
       "155403    20\n",
       "155404    20\n",
       "155405    20\n",
       "155406    20\n",
       "Name: label, Length: 155407, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e39b31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985481</td>\n",
       "      <td>-0.807007</td>\n",
       "      <td>-0.491449</td>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865844</td>\n",
       "      <td>-0.763546</td>\n",
       "      <td>-0.059973</td>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.773343</td>\n",
       "      <td>-0.379243</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000638</td>\n",
       "      <td>-0.823993</td>\n",
       "      <td>-0.382704</td>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883684</td>\n",
       "      <td>-0.751608</td>\n",
       "      <td>-0.383103</td>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acc_X     Acc_Y     Acc_Z       mag  label\n",
       "0  0.985481 -0.807007 -0.491449  1.365267      0\n",
       "1  0.865844 -0.763546 -0.059973  1.155978      0\n",
       "2  0.831769 -0.773343 -0.379243  1.197382      0\n",
       "3  1.000638 -0.823993 -0.382704  1.351556      0\n",
       "4  0.883684 -0.751608 -0.383103  1.221712      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = ['Acc_X', 'Acc_Y', 'Acc_Z'])\n",
    "scaled_X['mag'] = np.sqrt(scaled_X['Acc_X'] ** 2 + scaled_X['Acc_Y'] ** 2 + scaled_X['Acc_Z'] ** 2)\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e7db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaled_X.drop(['Acc_X', 'Acc_Y', 'Acc_Z'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5aa828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>3.329777</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>3.326341</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>3.331364</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>3.318731</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>3.331576</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mag  label\n",
       "0       1.365267      0\n",
       "1       1.155978      0\n",
       "2       1.197382      0\n",
       "3       1.351556      0\n",
       "4       1.221712      0\n",
       "...          ...    ...\n",
       "155402  3.329777     20\n",
       "155403  3.326341     20\n",
       "155404  3.331364     20\n",
       "155405  3.318731     20\n",
       "155406  3.331576     20\n",
       "\n",
       "[155407 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f87bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f58ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer Nitro 5\\AppData\\Local\\Temp\\ipykernel_7304\\4114532512.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n"
     ]
    }
   ],
   "source": [
    "Fs = 20\n",
    "frame_size = Fs * 20\n",
    "hop_size = Fs * 5\n",
    "frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(scaled_X) - frame_size, hop_size):\n",
    "    x = scaled_X['mag'].values[i: i + frame_size]\n",
    "    label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n",
    "    frames.append([x])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c0a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " ...]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a79cf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.asarray(frames).reshape(-1, frame_size)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4046a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESHAPE SHAPE:  (1551, 400)\n",
      "LABELS:  0\n",
      "LABELS:  (1551,)\n"
     ]
    }
   ],
   "source": [
    "print(\"RESHAPE SHAPE: \",frames.shape)\n",
    "print(\"LABELS: \",labels[0])\n",
    "print(\"LABELS: \",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07a02761",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=frames\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c187522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "127cc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=123, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c6cba4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files=[x_train, y_train]\n",
    "subject_files=[x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60f8ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def print(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "459ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class LoadDataset_from_numpy(Dataset):\n",
    "    def __init__(self, np_data):\n",
    "        super(LoadDataset_from_numpy, self).__init__()\n",
    "        X_train = np_data[0]\n",
    "        y_train = np_data[1]\n",
    "        self.len = X_train.shape[0]\n",
    "        self.x_data = torch.from_numpy(X_train).float()\n",
    "        self.y_data = torch.from_numpy(y_train).long()\n",
    "        self.x_data = self.x_data.view(self.x_data.size()[0], 1, self.x_data.size()[1])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def data_generator_np(training_files, subject_files, batch_size):\n",
    "    train_dataset = LoadDataset_from_numpy(training_files)\n",
    "    test_dataset = LoadDataset_from_numpy(subject_files)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               drop_last=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              drop_last=True,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96893dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = data_generator_np(training_files, subject_files, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "78041b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "\n",
    "\"\"\"\n",
    "2.1  Signal Segments Representation\n",
    "\n",
    "Signal Segment Definition: class SignalSegmentDefinition(nn.Module)\n",
    "Signal Segment Representation: class SignalSegmentRepresentation(nn.Module)\n",
    "\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.1 Global Node Attention: class GNA(nn.Module):\n",
    "\n",
    "***\n",
    "(1) Signal Segment Definition -> (2) Signal Segment Representation -> (3) Global Node Attention\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SignalSegmentDefinition(nn.Module):\n",
    "    \"\"\"\n",
    "   (1) Signal Segment Definition\n",
    "\n",
    "    input size: B, 1, 1, L\n",
    "    output size: B, K, 1, D\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = f.unfold(x, kernel_size=self.kernel_size, stride=self.stride)  # overlapping sliding window\n",
    "        b = b.permute(0, 2, 1)\n",
    "        b = b.unsqueeze(-2)\n",
    "        return b\n",
    "\n",
    "\n",
    "class SignalSegmentRepresentation(nn.Module):\n",
    "    \"\"\"\n",
    "    (2) Signal Segment Representation\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    segment_num: number of the signal segments\n",
    "\n",
    "    input size:  B, 1, 1, L\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, segment_size, overlapping_rate, segment_num):\n",
    "        super(SignalSegmentRepresentation, self).__init__()\n",
    "        self.overlapping = int(segment_size - segment_size * overlapping_rate)\n",
    "        self.segment = SignalSegmentDefinition((1, segment_size), self.overlapping)\n",
    "        self.segment2vec = SignalSegment2Vec(30)\n",
    "        self.gna = GNA(segment_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        signal_segments = []\n",
    "        x = self.segment(x)\n",
    "        x = x.squeeze()\n",
    "        \"share the SignalSegment2Vec Encoder\"\n",
    "        for idx in range(x.size()[1]):\n",
    "            data = x[:, idx, :]\n",
    "            data = data.unsqueeze(1)\n",
    "            out = self.segment2vec(data)\n",
    "            out = out.view(x.size()[0], 1, -1)\n",
    "            signal_segments.append(out)\n",
    "        signal_segments = torch.cat(signal_segments, dim=1)\n",
    "        signal_segments = signal_segments .unsqueeze(2)\n",
    "        \"global node attention\"\n",
    "        signal_segments = self.gna(signal_segments).permute(0, 2, 1, 3)\n",
    "        return signal_segments\n",
    "\n",
    "\n",
    "class GNA(nn.Module):\n",
    "    \"\"\"\n",
    "    (3) Global Node Attention\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "\n",
    "    input size: B, K, 1, C\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(GNA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SignalSegment2Vec(nn.Module):\n",
    "    \"\"\"\n",
    "    SignalSegment2Vec Encoder module in Signal Segment Representation\n",
    "\n",
    "    input size:  B, K, 1, D\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, afr_reduced_cnn_size):\n",
    "        super(SignalSegment2Vec, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=49, stride=6, bias=False, padding=int(49//2)),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool1d(kernel_size=7, stride=4, padding=int(7//2)),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv1d(128, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=3, stride=4, padding=int(3//2)),\n",
    "        )\n",
    "\n",
    "        self.inplanes = 128\n",
    "        self.AFR = self._make_layer(ResBasicBlock, afr_reduced_cnn_size, 1)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.AFR(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"Residual Squeeze-and-Excitation(SE) Block\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class ResBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=4):\n",
    "        super(ResBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.GELU()\n",
    "        self.conv2 = nn.Conv1d(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.reslayer = ResLayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.reslayer(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cdfb2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.2 Graph-based Self Attention\n",
    "\n",
    "graph attention: class Attention(nn.Module)\n",
    "convolution-based multi-head attention: class Block(nn.Module)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention (see Eq.4)\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "    input size:  B, M, K, C\n",
    "    output size: B, M, K, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((None, 1)),\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, K, _ = x.size()\n",
    "        adj = self.pearson(x)  # adjacency matrix\n",
    "        x_ = self._prepare_attentional_mechanism_input(x)\n",
    "        e = self.attn(x_)\n",
    "        e = e.permute(0, 2, 1, 3).contiguous()\n",
    "        e = e.view(B, M, K, K)\n",
    "        zero_vec_adj = -9e15 * torch.ones_like(adj)\n",
    "        attention = torch.where(adj > 0, e, zero_vec_adj)\n",
    "        attention = f.softmax(attention, dim=-1)\n",
    "        x = torch.matmul(attention, x)\n",
    "        return x, adj\n",
    "\n",
    "    def h_matmul(self, x):\n",
    "        N = x.size()[-2]\n",
    "        x_repeated_in_chunks = x.repeat_interleave(N, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, N, 1)\n",
    "        result = torch.mul(x_repeated_in_chunks, x_repeated_alternating)\n",
    "        return result\n",
    "\n",
    "    def pearson(self, x):\n",
    "        \"Pearson Correlation\"\n",
    "        centered_h = x - x.mean(dim=-1, keepdim=True)\n",
    "        covariance = self.h_matmul(centered_h).sum(dim=-1, keepdim=True)\n",
    "        bessel_corrected_covariance = torch.div(covariance, (x.shape[-1] - 1))\n",
    "        std_h = x.std(dim=-1, keepdim=True)\n",
    "        p = torch.div(bessel_corrected_covariance, (self.h_matmul(std_h)))\n",
    "        p = p.view(x.size()[0], x.size()[1], x.size()[2], -1)\n",
    "        return p\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, x):\n",
    "        \"concatenation operation (see Eq.4) with positional encoding\"\n",
    "        B, _, K, _ = x.size()\n",
    "        x_repeated_in_chunks = x.repeat_interleave(K, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, K, 1)\n",
    "\n",
    "        \"positional encoding\"\n",
    "        pos = 2 * torch.ones_like(x_repeated_alternating)\n",
    "        one_vec = torch.ones_like(x_repeated_alternating)\n",
    "        x_repeated_in_chunks.eq(x_repeated_alternating)\n",
    "        pos = torch.where(x_repeated_in_chunks.eq(x_repeated_alternating) > 0, one_vec, pos)\n",
    "        x_repeated_alternating = pos * x_repeated_alternating\n",
    "\n",
    "        all_combinations_matrix = torch.cat([x_repeated_in_chunks, x_repeated_alternating], dim=-1)\n",
    "        all_combinations_matrix = all_combinations_matrix.permute(0, 2, 1, 3)\n",
    "        return all_combinations_matrix\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention (see Fig.2)\n",
    "\n",
    "    input arg:\n",
    "    node_size: number of the signal segments\n",
    "    input_size: Q in Fig. 2\n",
    "    multi_heads: number of heads\n",
    "\n",
    "    input size: B, J, K, C    J=1 when H=1\n",
    "    output size: B, M'', K, C''\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_size, input_size, kernel_size, stride, multi_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        expand = 1\n",
    "\n",
    "        padding = kernel_size//2\n",
    "        self.mid_channels_ = (multi_heads - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "        self.multi_head = nn.Sequential(\n",
    "            nn.Conv2d(input_size, multi_heads, 1, bias=False),\n",
    "            nn.Conv2d(multi_heads, multi_heads, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                      groups=node_size, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.attn = Attention(node_size * node_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Conv2d(self.mid_channels_, self.mid_channels_ * 4, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.mid_channels_ * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.mid_channels_ * 4, multi_heads * expand, 1, bias=False),\n",
    "            nn.BatchNorm2d(multi_heads)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.AdaptiveAvgPool2d((1, None))\n",
    "        )\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(multi_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x.permute(0, 2, 1, 3)                 # B, J, K, C -> B, K, J, C\n",
    "        \"Dense layers\"\n",
    "        out = self.multi_head(x)                    # B, J, K, C -> B, M, K, C, where M is the number of heads\n",
    "        out, adj = self.attn(out)\n",
    "        self.adj = adj                              # for visualization\n",
    "        out = f.gelu(self.norm(out))\n",
    "        out = out.permute(0, 2, 1, 3)               # B, M, K, C -> B, K, M, C\n",
    "        \"Attention Layers\"\n",
    "        out = self.feature_extraction(out)          # B, K, M, C -> B, K, M', C'\n",
    "        out = out.permute(0, 2, 1, 3)               # B, K, M', C' -> B, M', K, C'\n",
    "        out = self.feed_forward(out)                # B, M', K, C' -> B, M'', K, C''\n",
    "        shortcut = self.shortcut(res)               # B, K, J, C -> B, 1, K, C''\n",
    "        shortcut = shortcut.permute(0, 2, 1, 3)\n",
    "        out += shortcut                             # (B, M'', K, C'') + (B, 1, K, C'') -> (B, M'', K, C'') Broadcast\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9fee4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "11d6c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRAPHSENSOR(nn.Module):\n",
    "    \"\"\"\n",
    "    GRAPHSENSOR main()\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    in_channels: number of the signal segments\n",
    "    class_num: class number\n",
    "\n",
    "    input size: B, 1, L\n",
    "    output size: B, class_num\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_size, overlapping_rate, in_channels, class_num):\n",
    "        super(GRAPHSENSOR, self).__init__()\n",
    "        self.segment_size = segment_size\n",
    "        self.signal_segments = SignalSegmentRepresentation(segment_size, overlapping_rate, in_channels)\n",
    "        \"\"\"\n",
    "        The encoder is composed of a stack of H=4 identical layers\n",
    "        Multi-head number: 16 -> 32 -> 64 -> 128\n",
    "        \"\"\"\n",
    "        self.attn = nn.Sequential(\n",
    "            Block(in_channels, 1,   5, 2, 16),\n",
    "            Block(in_channels, 16,  5, 2, 32),\n",
    "            Block(in_channels, 32,  5, 1, 64),\n",
    "            Block(in_channels, 64,  5, 1, 128),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 128, 512, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(1024, class_num, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.signal_segments(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.flatten(1)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "99dadfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d5f53bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRAPHSENSOR(segment_size=80, overlapping_rate=0.5, in_channels=9, class_num=21).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aa86028f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,561,768 trainable parameter\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e960e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() >= 1:\n",
    "        print(\"num GPUs: \", torch.cuda.device_count())\n",
    "        model = nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ea4c5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d4f024b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "400e3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001, amsgrad=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ec3ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ddbb94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch == 10:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11734a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "81676f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e013a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "        return correct * 100 / len(target)\n",
    "\n",
    "\n",
    "def f1_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "    return f1_score(pred.cpu().numpy(), target.data.cpu().numpy(), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87b9d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_interval):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score', ':.4e')\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        acc = accuracy_(output, target)\n",
    "        f1 = f1_(output, target) * 100\n",
    "        accuracy.update(acc, data.size(0))\n",
    "        f1_score.update(f1, data.size(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'accuracy {accuracy.val:.3f} ({accuracy.avg:.3f})\\t'\n",
    "                  'f1_score {f1_score.val:.3f} ({f1_score.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), loss=losses, accuracy=accuracy, f1_score=f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8b32997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score ', ':.4e')\n",
    "    progress = ProgressMeter(len(val_loader), losses, accuracy, f1_score,\n",
    "                             prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            acc = accuracy_(output, target)\n",
    "            f1 = f1_(output, target) * 100\n",
    "            accuracy.update(acc, data.size(0))\n",
    "            f1_score.update(f1, data.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # TODO: this should also be done with the ProgressMeter\n",
    "        print(' Test: accuracy {accuracy.avg:.3f} f1_score {f1_score.avg:.3f}'\n",
    "              .format(accuracy=accuracy, f1_score=f1_score))\n",
    "\n",
    "        return accuracy.avg, f1_score.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b498d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9e2a07db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch NO: 0\n",
      "Epoch: [0][0/9]\tLoss 3.1866 (3.1866)\taccuracy 5.469 (5.469)\tf1_score 3.296 (3.296)\n",
      "Epoch: [0][5/9]\tLoss 2.2169 (2.5941)\taccuracy 23.438 (19.010)\tf1_score 16.893 (12.406)\n",
      " Test: accuracy 5.469 f1_score 2.030\n",
      "Training time:  48.8658983707428 Hour:  0 Minute:  0 Second:  48 Test best accuracy: 5.46875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 1\n",
      "Epoch: [1][0/9]\tLoss 2.2374 (2.2374)\taccuracy 25.000 (25.000)\tf1_score 15.556 (15.556)\n",
      "Epoch: [1][5/9]\tLoss 2.0201 (2.1727)\taccuracy 31.250 (25.391)\tf1_score 25.079 (18.903)\n",
      " Test: accuracy 6.250 f1_score 2.359\n",
      "Training time:  51.32432532310486 Hour:  0 Minute:  0 Second:  51 Test best accuracy: 6.25  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 2\n",
      "Epoch: [2][0/9]\tLoss 2.0165 (2.0165)\taccuracy 28.125 (28.125)\tf1_score 19.717 (19.717)\n",
      "Epoch: [2][5/9]\tLoss 1.9871 (2.0540)\taccuracy 35.156 (29.688)\tf1_score 24.656 (21.197)\n",
      " Test: accuracy 8.203 f1_score 1.558\n",
      "Training time:  53.78873014450073 Hour:  0 Minute:  0 Second:  53 Test best accuracy: 8.203125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 3\n",
      "Epoch: [3][0/9]\tLoss 1.9273 (1.9273)\taccuracy 32.812 (32.812)\tf1_score 27.690 (27.690)\n",
      "Epoch: [3][5/9]\tLoss 1.7099 (1.7680)\taccuracy 35.156 (37.630)\tf1_score 30.851 (30.337)\n",
      " Test: accuracy 15.234 f1_score 6.955\n",
      "Training time:  56.4785041809082 Hour:  0 Minute:  0 Second:  56 Test best accuracy: 15.234375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 4\n",
      "Epoch: [4][0/9]\tLoss 1.5378 (1.5378)\taccuracy 45.312 (45.312)\tf1_score 37.548 (37.548)\n",
      "Epoch: [4][5/9]\tLoss 1.4707 (1.5335)\taccuracy 41.406 (41.797)\tf1_score 34.027 (33.978)\n",
      " Test: accuracy 26.172 f1_score 19.486\n",
      "Training time:  59.243141174316406 Hour:  0 Minute:  0 Second:  59 Test best accuracy: 26.171875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 5\n",
      "Epoch: [5][0/9]\tLoss 1.6674 (1.6674)\taccuracy 38.281 (38.281)\tf1_score 33.783 (33.783)\n",
      "Epoch: [5][5/9]\tLoss 1.4143 (1.5332)\taccuracy 45.312 (39.453)\tf1_score 41.476 (35.580)\n",
      " Test: accuracy 45.312 f1_score 40.408\n",
      "Training time:  61.71948313713074 Hour:  0 Minute:  1 Second:  1 Test best accuracy: 45.3125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 6\n",
      "Epoch: [6][0/9]\tLoss 1.4006 (1.4006)\taccuracy 51.562 (51.562)\tf1_score 45.394 (45.394)\n",
      "Epoch: [6][5/9]\tLoss 1.3203 (1.4147)\taccuracy 46.094 (45.312)\tf1_score 37.679 (39.015)\n",
      " Test: accuracy 46.875 f1_score 40.011\n",
      "Training time:  64.2132396697998 Hour:  0 Minute:  1 Second:  4 Test best accuracy: 46.875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 7\n",
      "Epoch: [7][0/9]\tLoss 1.3402 (1.3402)\taccuracy 53.125 (53.125)\tf1_score 49.766 (49.766)\n",
      "Epoch: [7][5/9]\tLoss 1.3451 (1.3208)\taccuracy 46.875 (46.354)\tf1_score 46.817 (43.043)\n",
      " Test: accuracy 47.656 f1_score 42.825\n",
      "Training time:  66.73203253746033 Hour:  0 Minute:  1 Second:  6 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 8\n",
      "Epoch: [8][0/9]\tLoss 1.4030 (1.4030)\taccuracy 53.125 (53.125)\tf1_score 46.686 (46.686)\n",
      "Epoch: [8][5/9]\tLoss 1.3780 (1.2519)\taccuracy 46.094 (54.818)\tf1_score 43.318 (49.949)\n",
      " Test: accuracy 36.328 f1_score 32.801\n",
      "Training time:  69.25500631332397 Hour:  0 Minute:  1 Second:  9 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 9\n",
      "Epoch: [9][0/9]\tLoss 1.2372 (1.2372)\taccuracy 50.000 (50.000)\tf1_score 46.356 (46.356)\n",
      "Epoch: [9][5/9]\tLoss 1.3814 (1.3407)\taccuracy 45.312 (43.880)\tf1_score 41.891 (41.695)\n",
      " Test: accuracy 39.844 f1_score 33.071\n",
      "Training time:  71.78898239135742 Hour:  0 Minute:  1 Second:  11 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 10\n",
      "Epoch: [10][0/9]\tLoss 1.1049 (1.1049)\taccuracy 54.688 (54.688)\tf1_score 48.537 (48.537)\n",
      "Epoch: [10][5/9]\tLoss 1.3764 (1.1667)\taccuracy 48.438 (54.948)\tf1_score 39.681 (49.358)\n",
      " Test: accuracy 40.234 f1_score 35.271\n",
      "Training time:  74.29123139381409 Hour:  0 Minute:  1 Second:  14 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 11\n",
      "Epoch: [11][0/9]\tLoss 1.1013 (1.1013)\taccuracy 57.031 (57.031)\tf1_score 50.494 (50.494)\n",
      "Epoch: [11][5/9]\tLoss 1.0293 (1.1301)\taccuracy 55.469 (55.469)\tf1_score 48.934 (49.841)\n",
      " Test: accuracy 45.312 f1_score 39.649\n",
      "Training time:  76.77668333053589 Hour:  0 Minute:  1 Second:  16 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 12\n",
      "Epoch: [12][0/9]\tLoss 1.3451 (1.3451)\taccuracy 53.125 (53.125)\tf1_score 46.470 (46.470)\n",
      "Epoch: [12][5/9]\tLoss 1.0695 (1.1902)\taccuracy 53.906 (51.823)\tf1_score 48.739 (47.542)\n",
      " Test: accuracy 45.703 f1_score 37.994\n",
      "Training time:  79.28259134292603 Hour:  0 Minute:  1 Second:  19 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 13\n",
      "Epoch: [13][0/9]\tLoss 1.1321 (1.1321)\taccuracy 53.906 (53.906)\tf1_score 50.359 (50.359)\n",
      "Epoch: [13][5/9]\tLoss 1.0913 (1.1534)\taccuracy 55.469 (53.776)\tf1_score 50.561 (49.564)\n",
      " Test: accuracy 44.531 f1_score 40.043\n",
      "Training time:  81.787921667099 Hour:  0 Minute:  1 Second:  21 Test best accuracy: 47.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 14\n",
      "Epoch: [14][0/9]\tLoss 1.0386 (1.0386)\taccuracy 59.375 (59.375)\tf1_score 56.774 (56.774)\n",
      "Epoch: [14][5/9]\tLoss 1.2242 (1.2653)\taccuracy 50.781 (53.125)\tf1_score 47.217 (50.308)\n",
      " Test: accuracy 51.562 f1_score 46.846\n",
      "Training time:  84.2863757610321 Hour:  0 Minute:  1 Second:  24 Test best accuracy: 51.5625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 15\n",
      "Epoch: [15][0/9]\tLoss 1.0116 (1.0116)\taccuracy 62.500 (62.500)\tf1_score 56.554 (56.554)\n",
      "Epoch: [15][5/9]\tLoss 1.2451 (1.0704)\taccuracy 53.125 (59.115)\tf1_score 47.957 (53.799)\n",
      " Test: accuracy 48.828 f1_score 43.678\n",
      "Training time:  86.82156300544739 Hour:  0 Minute:  1 Second:  26 Test best accuracy: 51.5625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 16\n",
      "Epoch: [16][0/9]\tLoss 1.0167 (1.0167)\taccuracy 65.625 (65.625)\tf1_score 61.097 (61.097)\n",
      "Epoch: [16][5/9]\tLoss 1.1985 (1.1098)\taccuracy 50.781 (55.208)\tf1_score 45.425 (51.509)\n",
      " Test: accuracy 34.375 f1_score 29.206\n",
      "Training time:  89.38215708732605 Hour:  0 Minute:  1 Second:  29 Test best accuracy: 51.5625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 17\n",
      "Epoch: [17][0/9]\tLoss 0.9915 (0.9915)\taccuracy 64.844 (64.844)\tf1_score 60.012 (60.012)\n",
      "Epoch: [17][5/9]\tLoss 0.9918 (1.0438)\taccuracy 58.594 (59.766)\tf1_score 55.636 (54.879)\n",
      " Test: accuracy 57.422 f1_score 54.238\n",
      "Training time:  91.94530057907104 Hour:  0 Minute:  1 Second:  31 Test best accuracy: 57.421875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 18\n",
      "Epoch: [18][0/9]\tLoss 0.9294 (0.9294)\taccuracy 64.062 (64.062)\tf1_score 59.083 (59.083)\n",
      "Epoch: [18][5/9]\tLoss 1.1284 (0.9791)\taccuracy 53.906 (60.938)\tf1_score 54.896 (57.091)\n",
      " Test: accuracy 46.094 f1_score 39.685\n",
      "Training time:  94.46280574798584 Hour:  0 Minute:  1 Second:  34 Test best accuracy: 57.421875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 19\n",
      "Epoch: [19][0/9]\tLoss 0.9258 (0.9258)\taccuracy 66.406 (66.406)\tf1_score 64.028 (64.028)\n",
      "Epoch: [19][5/9]\tLoss 0.9513 (0.9371)\taccuracy 66.406 (63.932)\tf1_score 61.421 (60.295)\n",
      " Test: accuracy 39.844 f1_score 35.496\n",
      "Training time:  96.97228169441223 Hour:  0 Minute:  1 Second:  36 Test best accuracy: 57.421875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 20\n",
      "Epoch: [20][0/9]\tLoss 0.7534 (0.7534)\taccuracy 70.312 (70.312)\tf1_score 66.441 (66.441)\n",
      "Epoch: [20][5/9]\tLoss 0.9858 (0.8379)\taccuracy 60.156 (67.188)\tf1_score 61.190 (64.511)\n",
      " Test: accuracy 50.391 f1_score 45.902\n",
      "Training time:  99.47099566459656 Hour:  0 Minute:  1 Second:  39 Test best accuracy: 57.421875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 21\n",
      "Epoch: [21][0/9]\tLoss 0.8742 (0.8742)\taccuracy 60.938 (60.938)\tf1_score 56.400 (56.400)\n",
      "Epoch: [21][5/9]\tLoss 0.8022 (0.7761)\taccuracy 67.969 (69.792)\tf1_score 63.986 (66.093)\n",
      " Test: accuracy 62.500 f1_score 60.067\n",
      "Training time:  101.96994280815125 Hour:  0 Minute:  1 Second:  41 Test best accuracy: 62.5  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 22\n",
      "Epoch: [22][0/9]\tLoss 0.8194 (0.8194)\taccuracy 72.656 (72.656)\tf1_score 68.487 (68.487)\n",
      "Epoch: [22][5/9]\tLoss 0.7597 (0.7746)\taccuracy 73.438 (71.745)\tf1_score 74.226 (69.955)\n",
      " Test: accuracy 55.078 f1_score 50.063\n",
      "Training time:  104.46133208274841 Hour:  0 Minute:  1 Second:  44 Test best accuracy: 62.5  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 23\n",
      "Epoch: [23][0/9]\tLoss 0.7038 (0.7038)\taccuracy 67.969 (67.969)\tf1_score 64.461 (64.461)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23][5/9]\tLoss 0.8997 (0.7730)\taccuracy 60.938 (68.620)\tf1_score 58.586 (65.178)\n",
      " Test: accuracy 28.516 f1_score 23.185\n",
      "Training time:  106.95466208457947 Hour:  0 Minute:  1 Second:  46 Test best accuracy: 62.5  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 24\n",
      "Epoch: [24][0/9]\tLoss 0.7718 (0.7718)\taccuracy 69.531 (69.531)\tf1_score 67.267 (67.267)\n",
      "Epoch: [24][5/9]\tLoss 0.8319 (0.7066)\taccuracy 67.969 (73.438)\tf1_score 65.661 (71.222)\n",
      " Test: accuracy 30.469 f1_score 24.898\n",
      "Training time:  109.4503026008606 Hour:  0 Minute:  1 Second:  49 Test best accuracy: 62.5  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 25\n",
      "Epoch: [25][0/9]\tLoss 0.6071 (0.6071)\taccuracy 75.000 (75.000)\tf1_score 68.209 (68.209)\n",
      "Epoch: [25][5/9]\tLoss 0.6715 (0.7003)\taccuracy 77.344 (73.828)\tf1_score 75.935 (71.545)\n",
      " Test: accuracy 32.422 f1_score 24.374\n",
      "Training time:  111.96739506721497 Hour:  0 Minute:  1 Second:  51 Test best accuracy: 62.5  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 26\n",
      "Epoch: [26][0/9]\tLoss 0.8031 (0.8031)\taccuracy 67.188 (67.188)\tf1_score 64.498 (64.498)\n",
      "Epoch: [26][5/9]\tLoss 0.6498 (0.7185)\taccuracy 75.000 (72.005)\tf1_score 72.568 (69.149)\n",
      " Test: accuracy 53.906 f1_score 48.789\n",
      "Training time:  114.47332572937012 Hour:  0 Minute:  1 Second:  54 Test best accuracy: 62.5  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 27\n",
      "Epoch: [27][0/9]\tLoss 0.7661 (0.7661)\taccuracy 65.625 (65.625)\tf1_score 63.828 (63.828)\n",
      "Epoch: [27][5/9]\tLoss 0.6360 (0.7025)\taccuracy 77.344 (72.396)\tf1_score 73.800 (69.938)\n",
      " Test: accuracy 63.672 f1_score 60.928\n",
      "Training time:  116.97463726997375 Hour:  0 Minute:  1 Second:  56 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 28\n",
      "Epoch: [28][0/9]\tLoss 0.5889 (0.5889)\taccuracy 73.438 (73.438)\tf1_score 66.798 (66.798)\n",
      "Epoch: [28][5/9]\tLoss 0.6997 (0.8217)\taccuracy 73.438 (67.578)\tf1_score 71.766 (65.855)\n",
      " Test: accuracy 49.219 f1_score 42.896\n",
      "Training time:  119.47993493080139 Hour:  0 Minute:  1 Second:  59 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 29\n",
      "Epoch: [29][0/9]\tLoss 0.6553 (0.6553)\taccuracy 76.562 (76.562)\tf1_score 73.929 (73.929)\n",
      "Epoch: [29][5/9]\tLoss 0.5893 (0.7252)\taccuracy 81.250 (72.396)\tf1_score 75.852 (69.877)\n",
      " Test: accuracy 42.969 f1_score 37.709\n",
      "Training time:  121.98523426055908 Hour:  0 Minute:  2 Second:  1 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 30\n",
      "Epoch: [30][0/9]\tLoss 0.5574 (0.5574)\taccuracy 76.562 (76.562)\tf1_score 72.132 (72.132)\n",
      "Epoch: [30][5/9]\tLoss 0.8000 (0.6928)\taccuracy 73.438 (71.094)\tf1_score 70.483 (69.102)\n",
      " Test: accuracy 49.219 f1_score 45.045\n",
      "Training time:  124.49851107597351 Hour:  0 Minute:  2 Second:  4 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 31\n",
      "Epoch: [31][0/9]\tLoss 0.5726 (0.5726)\taccuracy 78.125 (78.125)\tf1_score 77.991 (77.991)\n",
      "Epoch: [31][5/9]\tLoss 0.6581 (0.7733)\taccuracy 73.438 (69.792)\tf1_score 69.009 (68.455)\n",
      " Test: accuracy 28.516 f1_score 22.868\n",
      "Training time:  127.02774596214294 Hour:  0 Minute:  2 Second:  7 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 32\n",
      "Epoch: [32][0/9]\tLoss 0.7717 (0.7717)\taccuracy 69.531 (69.531)\tf1_score 71.432 (71.432)\n",
      "Epoch: [32][5/9]\tLoss 0.8755 (0.7515)\taccuracy 66.406 (70.052)\tf1_score 66.245 (69.363)\n",
      " Test: accuracy 36.719 f1_score 30.826\n",
      "Training time:  129.5397448539734 Hour:  0 Minute:  2 Second:  9 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 33\n",
      "Epoch: [33][0/9]\tLoss 0.5978 (0.5978)\taccuracy 74.219 (74.219)\tf1_score 72.335 (72.335)\n",
      "Epoch: [33][5/9]\tLoss 0.5546 (0.6737)\taccuracy 81.250 (73.958)\tf1_score 79.534 (71.457)\n",
      " Test: accuracy 59.375 f1_score 56.111\n",
      "Training time:  132.06498670578003 Hour:  0 Minute:  2 Second:  12 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 34\n",
      "Epoch: [34][0/9]\tLoss 0.5673 (0.5673)\taccuracy 81.250 (81.250)\tf1_score 80.938 (80.938)\n",
      "Epoch: [34][5/9]\tLoss 0.6313 (0.6220)\taccuracy 78.125 (78.125)\tf1_score 74.674 (77.031)\n",
      " Test: accuracy 54.297 f1_score 48.606\n",
      "Training time:  134.57828426361084 Hour:  0 Minute:  2 Second:  14 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 35\n",
      "Epoch: [35][0/9]\tLoss 0.5492 (0.5492)\taccuracy 77.344 (77.344)\tf1_score 77.728 (77.728)\n",
      "Epoch: [35][5/9]\tLoss 0.4964 (0.5818)\taccuracy 80.469 (77.865)\tf1_score 79.709 (77.443)\n",
      " Test: accuracy 54.688 f1_score 49.962\n",
      "Training time:  137.09953951835632 Hour:  0 Minute:  2 Second:  17 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 36\n",
      "Epoch: [36][0/9]\tLoss 0.4791 (0.4791)\taccuracy 80.469 (80.469)\tf1_score 77.804 (77.804)\n",
      "Epoch: [36][5/9]\tLoss 0.6591 (0.6621)\taccuracy 76.562 (75.130)\tf1_score 73.191 (72.223)\n",
      " Test: accuracy 24.219 f1_score 17.264\n",
      "Training time:  139.61680436134338 Hour:  0 Minute:  2 Second:  19 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 37\n",
      "Epoch: [37][0/9]\tLoss 0.5594 (0.5594)\taccuracy 82.031 (82.031)\tf1_score 81.000 (81.000)\n",
      "Epoch: [37][5/9]\tLoss 0.4083 (0.6086)\taccuracy 85.938 (77.214)\tf1_score 82.096 (74.395)\n",
      " Test: accuracy 57.422 f1_score 55.625\n",
      "Training time:  142.1382122039795 Hour:  0 Minute:  2 Second:  22 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 38\n",
      "Epoch: [38][0/9]\tLoss 0.5108 (0.5108)\taccuracy 80.469 (80.469)\tf1_score 80.026 (80.026)\n",
      "Epoch: [38][5/9]\tLoss 0.7682 (0.6230)\taccuracy 72.656 (75.130)\tf1_score 72.595 (73.657)\n",
      " Test: accuracy 30.469 f1_score 25.320\n",
      "Training time:  144.667329788208 Hour:  0 Minute:  2 Second:  24 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 39\n",
      "Epoch: [39][0/9]\tLoss 0.4441 (0.4441)\taccuracy 82.031 (82.031)\tf1_score 79.629 (79.629)\n",
      "Epoch: [39][5/9]\tLoss 0.4850 (0.5508)\taccuracy 78.125 (78.255)\tf1_score 73.679 (75.565)\n",
      " Test: accuracy 50.781 f1_score 45.413\n",
      "Training time:  147.18802189826965 Hour:  0 Minute:  2 Second:  27 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 40\n",
      "Epoch: [40][0/9]\tLoss 0.5364 (0.5364)\taccuracy 78.125 (78.125)\tf1_score 76.284 (76.284)\n",
      "Epoch: [40][5/9]\tLoss 0.5532 (0.6001)\taccuracy 78.906 (76.823)\tf1_score 78.871 (74.790)\n",
      " Test: accuracy 58.203 f1_score 54.911\n",
      "Training time:  149.70888662338257 Hour:  0 Minute:  2 Second:  29 Test best accuracy: 63.671875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 41\n",
      "Epoch: [41][0/9]\tLoss 0.4605 (0.4605)\taccuracy 83.594 (83.594)\tf1_score 82.130 (82.130)\n",
      "Epoch: [41][5/9]\tLoss 0.5189 (0.5082)\taccuracy 79.688 (79.688)\tf1_score 77.613 (78.126)\n",
      " Test: accuracy 67.969 f1_score 65.017\n",
      "Training time:  152.2301423549652 Hour:  0 Minute:  2 Second:  32 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 42\n",
      "Epoch: [42][0/9]\tLoss 0.6320 (0.6320)\taccuracy 73.438 (73.438)\tf1_score 72.724 (72.724)\n",
      "Epoch: [42][5/9]\tLoss 0.5637 (0.5462)\taccuracy 77.344 (78.646)\tf1_score 77.667 (77.842)\n",
      " Test: accuracy 50.000 f1_score 44.749\n",
      "Training time:  154.75439262390137 Hour:  0 Minute:  2 Second:  34 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 43\n",
      "Epoch: [43][0/9]\tLoss 0.5447 (0.5447)\taccuracy 79.688 (79.688)\tf1_score 79.286 (79.286)\n",
      "Epoch: [43][5/9]\tLoss 0.3998 (0.4570)\taccuracy 85.156 (82.943)\tf1_score 82.307 (81.626)\n",
      " Test: accuracy 39.062 f1_score 35.136\n",
      "Training time:  157.27805185317993 Hour:  0 Minute:  2 Second:  37 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 44\n",
      "Epoch: [44][0/9]\tLoss 0.5943 (0.5943)\taccuracy 76.562 (76.562)\tf1_score 78.208 (78.208)\n",
      "Epoch: [44][5/9]\tLoss 0.5464 (0.5187)\taccuracy 78.906 (79.818)\tf1_score 77.320 (79.908)\n",
      " Test: accuracy 26.953 f1_score 19.184\n",
      "Training time:  159.8229444026947 Hour:  0 Minute:  2 Second:  39 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 45\n",
      "Epoch: [45][0/9]\tLoss 0.4861 (0.4861)\taccuracy 78.125 (78.125)\tf1_score 76.175 (76.175)\n",
      "Epoch: [45][5/9]\tLoss 0.5632 (0.4915)\taccuracy 81.250 (80.859)\tf1_score 78.909 (79.111)\n",
      " Test: accuracy 42.578 f1_score 35.856\n",
      "Training time:  162.34854769706726 Hour:  0 Minute:  2 Second:  42 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 46\n",
      "Epoch: [46][0/9]\tLoss 0.5378 (0.5378)\taccuracy 78.125 (78.125)\tf1_score 78.893 (78.893)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46][5/9]\tLoss 0.4106 (0.5487)\taccuracy 83.594 (77.734)\tf1_score 81.341 (77.540)\n",
      " Test: accuracy 64.453 f1_score 61.933\n",
      "Training time:  164.87279152870178 Hour:  0 Minute:  2 Second:  44 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 47\n",
      "Epoch: [47][0/9]\tLoss 0.5643 (0.5643)\taccuracy 78.125 (78.125)\tf1_score 82.332 (82.332)\n",
      "Epoch: [47][5/9]\tLoss 0.5732 (0.5442)\taccuracy 77.344 (79.167)\tf1_score 79.921 (77.013)\n",
      " Test: accuracy 59.375 f1_score 55.282\n",
      "Training time:  167.39903831481934 Hour:  0 Minute:  2 Second:  47 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 48\n",
      "Epoch: [48][0/9]\tLoss 0.3999 (0.3999)\taccuracy 82.812 (82.812)\tf1_score 80.023 (80.023)\n",
      "Epoch: [48][5/9]\tLoss 0.4488 (0.4384)\taccuracy 82.812 (83.464)\tf1_score 81.507 (81.375)\n",
      " Test: accuracy 49.219 f1_score 43.290\n",
      "Training time:  169.92527985572815 Hour:  0 Minute:  2 Second:  49 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 49\n",
      "Epoch: [49][0/9]\tLoss 0.3796 (0.3796)\taccuracy 85.156 (85.156)\tf1_score 84.654 (84.654)\n",
      "Epoch: [49][5/9]\tLoss 0.4350 (0.4338)\taccuracy 78.125 (82.292)\tf1_score 74.771 (79.523)\n",
      " Test: accuracy 54.297 f1_score 49.636\n",
      "Training time:  172.4545135498047 Hour:  0 Minute:  2 Second:  52 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 50\n",
      "Epoch: [50][0/9]\tLoss 0.3571 (0.3571)\taccuracy 87.500 (87.500)\tf1_score 82.707 (82.707)\n",
      "Epoch: [50][5/9]\tLoss 0.4970 (0.4370)\taccuracy 76.562 (81.510)\tf1_score 74.512 (80.517)\n",
      " Test: accuracy 45.703 f1_score 40.447\n",
      "Training time:  175.0086476802826 Hour:  0 Minute:  2 Second:  55 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 51\n",
      "Epoch: [51][0/9]\tLoss 0.4596 (0.4596)\taccuracy 80.469 (80.469)\tf1_score 80.743 (80.743)\n",
      "Epoch: [51][5/9]\tLoss 0.3465 (0.3982)\taccuracy 86.719 (84.896)\tf1_score 83.191 (84.493)\n",
      " Test: accuracy 41.797 f1_score 37.775\n",
      "Training time:  177.54410409927368 Hour:  0 Minute:  2 Second:  57 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 52\n",
      "Epoch: [52][0/9]\tLoss 0.4252 (0.4252)\taccuracy 89.062 (89.062)\tf1_score 89.563 (89.563)\n",
      "Epoch: [52][5/9]\tLoss 0.4298 (0.3937)\taccuracy 83.594 (86.198)\tf1_score 84.237 (85.421)\n",
      " Test: accuracy 44.922 f1_score 38.770\n",
      "Training time:  180.07733058929443 Hour:  0 Minute:  3 Second:  0 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 53\n",
      "Epoch: [53][0/9]\tLoss 0.5243 (0.5243)\taccuracy 79.688 (79.688)\tf1_score 72.411 (72.411)\n",
      "Epoch: [53][5/9]\tLoss 0.3977 (0.5240)\taccuracy 85.938 (80.208)\tf1_score 82.287 (78.077)\n",
      " Test: accuracy 50.781 f1_score 47.858\n",
      "Training time:  182.61160349845886 Hour:  0 Minute:  3 Second:  2 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 54\n",
      "Epoch: [54][0/9]\tLoss 0.4603 (0.4603)\taccuracy 82.031 (82.031)\tf1_score 83.380 (83.380)\n",
      "Epoch: [54][5/9]\tLoss 0.6379 (0.4746)\taccuracy 79.688 (82.943)\tf1_score 81.811 (81.410)\n",
      " Test: accuracy 32.031 f1_score 27.559\n",
      "Training time:  185.14283084869385 Hour:  0 Minute:  3 Second:  5 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 55\n",
      "Epoch: [55][0/9]\tLoss 0.3679 (0.3679)\taccuracy 84.375 (84.375)\tf1_score 81.095 (81.095)\n",
      "Epoch: [55][5/9]\tLoss 0.4280 (0.4528)\taccuracy 80.469 (81.641)\tf1_score 79.135 (80.571)\n",
      " Test: accuracy 47.266 f1_score 42.251\n",
      "Training time:  187.6760549545288 Hour:  0 Minute:  3 Second:  7 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 56\n",
      "Epoch: [56][0/9]\tLoss 0.3826 (0.3826)\taccuracy 87.500 (87.500)\tf1_score 87.546 (87.546)\n",
      "Epoch: [56][5/9]\tLoss 0.4211 (0.4691)\taccuracy 82.031 (80.859)\tf1_score 80.514 (80.039)\n",
      " Test: accuracy 54.297 f1_score 51.804\n",
      "Training time:  190.215229511261 Hour:  0 Minute:  3 Second:  10 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 57\n",
      "Epoch: [57][0/9]\tLoss 0.3397 (0.3397)\taccuracy 88.281 (88.281)\tf1_score 85.015 (85.015)\n",
      "Epoch: [57][5/9]\tLoss 0.4561 (0.4012)\taccuracy 83.594 (84.766)\tf1_score 82.652 (83.229)\n",
      " Test: accuracy 47.656 f1_score 44.579\n",
      "Training time:  192.76101636886597 Hour:  0 Minute:  3 Second:  12 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 58\n",
      "Epoch: [58][0/9]\tLoss 0.3070 (0.3070)\taccuracy 89.844 (89.844)\tf1_score 87.392 (87.392)\n",
      "Epoch: [58][5/9]\tLoss 0.3577 (0.3924)\taccuracy 87.500 (85.026)\tf1_score 86.210 (83.672)\n",
      " Test: accuracy 44.141 f1_score 40.417\n",
      "Training time:  195.29723453521729 Hour:  0 Minute:  3 Second:  15 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 59\n",
      "Epoch: [59][0/9]\tLoss 0.2798 (0.2798)\taccuracy 92.188 (92.188)\tf1_score 92.126 (92.126)\n",
      "Epoch: [59][5/9]\tLoss 0.5082 (0.4214)\taccuracy 77.344 (83.464)\tf1_score 75.013 (80.849)\n",
      " Test: accuracy 53.906 f1_score 47.186\n",
      "Training time:  197.83444786071777 Hour:  0 Minute:  3 Second:  17 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 60\n",
      "Epoch: [60][0/9]\tLoss 0.5763 (0.5763)\taccuracy 77.344 (77.344)\tf1_score 76.788 (76.788)\n",
      "Epoch: [60][5/9]\tLoss 0.4570 (0.4666)\taccuracy 82.812 (81.641)\tf1_score 79.455 (80.722)\n",
      " Test: accuracy 53.906 f1_score 49.504\n",
      "Training time:  200.3706614971161 Hour:  0 Minute:  3 Second:  20 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 61\n",
      "Epoch: [61][0/9]\tLoss 0.4190 (0.4190)\taccuracy 85.156 (85.156)\tf1_score 84.291 (84.291)\n",
      "Epoch: [61][5/9]\tLoss 0.2973 (0.3229)\taccuracy 85.938 (87.370)\tf1_score 82.919 (85.791)\n",
      " Test: accuracy 55.078 f1_score 52.078\n",
      "Training time:  202.91186213493347 Hour:  0 Minute:  3 Second:  22 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 62\n",
      "Epoch: [62][0/9]\tLoss 0.2971 (0.2971)\taccuracy 89.062 (89.062)\tf1_score 87.801 (87.801)\n",
      "Epoch: [62][5/9]\tLoss 0.4615 (0.3258)\taccuracy 80.469 (87.370)\tf1_score 78.844 (86.188)\n",
      " Test: accuracy 67.578 f1_score 65.990\n",
      "Training time:  205.45816278457642 Hour:  0 Minute:  3 Second:  25 Test best accuracy: 67.96875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 63\n",
      "Epoch: [63][0/9]\tLoss 0.2920 (0.2920)\taccuracy 87.500 (87.500)\tf1_score 88.080 (88.080)\n",
      "Epoch: [63][5/9]\tLoss 0.3532 (0.3682)\taccuracy 85.938 (86.068)\tf1_score 85.533 (85.092)\n",
      " Test: accuracy 69.922 f1_score 68.529\n",
      "Training time:  208.02131009101868 Hour:  0 Minute:  3 Second:  28 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 64\n",
      "Epoch: [64][0/9]\tLoss 0.4809 (0.4809)\taccuracy 78.906 (78.906)\tf1_score 82.889 (82.889)\n",
      "Epoch: [64][5/9]\tLoss 0.2230 (0.3057)\taccuracy 92.188 (87.500)\tf1_score 87.082 (87.316)\n",
      " Test: accuracy 55.078 f1_score 51.766\n",
      "Training time:  210.56417441368103 Hour:  0 Minute:  3 Second:  30 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 65\n",
      "Epoch: [65][0/9]\tLoss 0.3540 (0.3540)\taccuracy 85.156 (85.156)\tf1_score 83.111 (83.111)\n",
      "Epoch: [65][5/9]\tLoss 0.3995 (0.3736)\taccuracy 87.500 (84.766)\tf1_score 89.551 (82.246)\n",
      " Test: accuracy 19.922 f1_score 15.729\n",
      "Training time:  213.11243867874146 Hour:  0 Minute:  3 Second:  33 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 66\n",
      "Epoch: [66][0/9]\tLoss 0.3894 (0.3894)\taccuracy 84.375 (84.375)\tf1_score 85.019 (85.019)\n",
      "Epoch: [66][5/9]\tLoss 0.3497 (0.3791)\taccuracy 88.281 (84.896)\tf1_score 86.913 (84.505)\n",
      " Test: accuracy 61.328 f1_score 59.417\n",
      "Training time:  215.66261196136475 Hour:  0 Minute:  3 Second:  35 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 67\n",
      "Epoch: [67][0/9]\tLoss 0.2805 (0.2805)\taccuracy 88.281 (88.281)\tf1_score 85.347 (85.347)\n",
      "Epoch: [67][5/9]\tLoss 0.4248 (0.3470)\taccuracy 82.812 (86.719)\tf1_score 78.425 (85.176)\n",
      " Test: accuracy 53.125 f1_score 48.472\n",
      "Training time:  218.21379041671753 Hour:  0 Minute:  3 Second:  38 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 68\n",
      "Epoch: [68][0/9]\tLoss 0.3406 (0.3406)\taccuracy 86.719 (86.719)\tf1_score 85.602 (85.602)\n",
      "Epoch: [68][5/9]\tLoss 0.3461 (0.3629)\taccuracy 85.938 (86.198)\tf1_score 85.194 (85.641)\n",
      " Test: accuracy 57.422 f1_score 53.314\n",
      "Training time:  220.76397132873535 Hour:  0 Minute:  3 Second:  40 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 69\n",
      "Epoch: [69][0/9]\tLoss 0.3494 (0.3494)\taccuracy 87.500 (87.500)\tf1_score 86.480 (86.480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][5/9]\tLoss 0.4623 (0.4184)\taccuracy 82.812 (83.854)\tf1_score 79.141 (82.184)\n",
      " Test: accuracy 41.016 f1_score 37.535\n",
      "Training time:  223.3404529094696 Hour:  0 Minute:  3 Second:  43 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 70\n",
      "Epoch: [70][0/9]\tLoss 0.3394 (0.3394)\taccuracy 89.062 (89.062)\tf1_score 89.446 (89.446)\n",
      "Epoch: [70][5/9]\tLoss 0.5728 (0.4015)\taccuracy 75.781 (84.896)\tf1_score 71.636 (84.134)\n",
      " Test: accuracy 52.344 f1_score 48.440\n",
      "Training time:  225.89536142349243 Hour:  0 Minute:  3 Second:  45 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 71\n",
      "Epoch: [71][0/9]\tLoss 0.4005 (0.4005)\taccuracy 85.156 (85.156)\tf1_score 85.234 (85.234)\n",
      "Epoch: [71][5/9]\tLoss 0.4169 (0.4755)\taccuracy 83.594 (83.073)\tf1_score 77.585 (80.507)\n",
      " Test: accuracy 54.688 f1_score 50.152\n",
      "Training time:  228.44753623008728 Hour:  0 Minute:  3 Second:  48 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 72\n",
      "Epoch: [72][0/9]\tLoss 0.3862 (0.3862)\taccuracy 82.031 (82.031)\tf1_score 74.948 (74.948)\n",
      "Epoch: [72][5/9]\tLoss 0.3324 (0.3975)\taccuracy 87.500 (84.115)\tf1_score 87.776 (82.287)\n",
      " Test: accuracy 44.141 f1_score 38.279\n",
      "Training time:  230.99967527389526 Hour:  0 Minute:  3 Second:  50 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 73\n",
      "Epoch: [73][0/9]\tLoss 0.4711 (0.4711)\taccuracy 86.719 (86.719)\tf1_score 82.420 (82.420)\n",
      "Epoch: [73][5/9]\tLoss 0.4046 (0.3732)\taccuracy 80.469 (85.286)\tf1_score 79.615 (83.861)\n",
      " Test: accuracy 60.156 f1_score 57.172\n",
      "Training time:  233.58077144622803 Hour:  0 Minute:  3 Second:  53 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 74\n",
      "Epoch: [74][0/9]\tLoss 0.3785 (0.3785)\taccuracy 85.938 (85.938)\tf1_score 86.447 (86.447)\n",
      "Epoch: [74][5/9]\tLoss 0.2588 (0.3369)\taccuracy 90.625 (86.719)\tf1_score 84.196 (85.247)\n",
      " Test: accuracy 65.234 f1_score 63.430\n",
      "Training time:  236.1479365825653 Hour:  0 Minute:  3 Second:  56 Test best accuracy: 69.921875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 75\n",
      "Epoch: [75][0/9]\tLoss 0.2984 (0.2984)\taccuracy 88.281 (88.281)\tf1_score 88.375 (88.375)\n",
      "Epoch: [75][5/9]\tLoss 0.2655 (0.3340)\taccuracy 89.844 (85.547)\tf1_score 90.553 (84.742)\n",
      " Test: accuracy 72.656 f1_score 71.086\n",
      "Training time:  238.71005201339722 Hour:  0 Minute:  3 Second:  58 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 76\n",
      "Epoch: [76][0/9]\tLoss 0.2654 (0.2654)\taccuracy 89.844 (89.844)\tf1_score 89.072 (89.072)\n",
      "Epoch: [76][5/9]\tLoss 0.4014 (0.3057)\taccuracy 83.594 (87.109)\tf1_score 83.453 (85.931)\n",
      " Test: accuracy 57.422 f1_score 52.250\n",
      "Training time:  241.26969480514526 Hour:  0 Minute:  4 Second:  1 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 77\n",
      "Epoch: [77][0/9]\tLoss 0.2970 (0.2970)\taccuracy 86.719 (86.719)\tf1_score 85.803 (85.803)\n",
      "Epoch: [77][5/9]\tLoss 0.4831 (0.3507)\taccuracy 82.031 (85.677)\tf1_score 79.737 (83.856)\n",
      " Test: accuracy 49.219 f1_score 41.273\n",
      "Training time:  243.8209249973297 Hour:  0 Minute:  4 Second:  3 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 78\n",
      "Epoch: [78][0/9]\tLoss 0.2603 (0.2603)\taccuracy 90.625 (90.625)\tf1_score 90.809 (90.809)\n",
      "Epoch: [78][5/9]\tLoss 0.3057 (0.2893)\taccuracy 89.062 (89.193)\tf1_score 90.128 (89.183)\n",
      " Test: accuracy 48.438 f1_score 41.454\n",
      "Training time:  246.3701033592224 Hour:  0 Minute:  4 Second:  6 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 79\n",
      "Epoch: [79][0/9]\tLoss 0.3376 (0.3376)\taccuracy 88.281 (88.281)\tf1_score 83.656 (83.656)\n",
      "Epoch: [79][5/9]\tLoss 0.3320 (0.3406)\taccuracy 82.812 (86.979)\tf1_score 85.524 (85.692)\n",
      " Test: accuracy 30.078 f1_score 23.485\n",
      "Training time:  248.9212818145752 Hour:  0 Minute:  4 Second:  8 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 80\n",
      "Epoch: [80][0/9]\tLoss 0.5520 (0.5520)\taccuracy 82.031 (82.031)\tf1_score 81.934 (81.934)\n",
      "Epoch: [80][5/9]\tLoss 0.3620 (0.3712)\taccuracy 85.938 (86.458)\tf1_score 86.108 (85.390)\n",
      " Test: accuracy 39.844 f1_score 37.295\n",
      "Training time:  251.4725399017334 Hour:  0 Minute:  4 Second:  11 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 81\n",
      "Epoch: [81][0/9]\tLoss 0.2851 (0.2851)\taccuracy 90.625 (90.625)\tf1_score 90.046 (90.046)\n",
      "Epoch: [81][5/9]\tLoss 0.2396 (0.3045)\taccuracy 90.625 (87.500)\tf1_score 87.735 (85.944)\n",
      " Test: accuracy 38.281 f1_score 31.836\n",
      "Training time:  254.0266978740692 Hour:  0 Minute:  4 Second:  14 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 82\n",
      "Epoch: [82][0/9]\tLoss 0.2129 (0.2129)\taccuracy 91.406 (91.406)\tf1_score 91.262 (91.262)\n",
      "Epoch: [82][5/9]\tLoss 0.3747 (0.2644)\taccuracy 84.375 (88.802)\tf1_score 80.514 (87.419)\n",
      " Test: accuracy 55.859 f1_score 51.053\n",
      "Training time:  256.5918445587158 Hour:  0 Minute:  4 Second:  16 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 83\n",
      "Epoch: [83][0/9]\tLoss 0.2507 (0.2507)\taccuracy 92.188 (92.188)\tf1_score 91.447 (91.447)\n",
      "Epoch: [83][5/9]\tLoss 0.4801 (0.3174)\taccuracy 78.906 (85.807)\tf1_score 78.445 (84.096)\n",
      " Test: accuracy 54.688 f1_score 48.988\n",
      "Training time:  259.1392071247101 Hour:  0 Minute:  4 Second:  19 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 84\n",
      "Epoch: [84][0/9]\tLoss 0.2214 (0.2214)\taccuracy 93.750 (93.750)\tf1_score 93.153 (93.153)\n",
      "Epoch: [84][5/9]\tLoss 0.4742 (0.3065)\taccuracy 79.688 (88.932)\tf1_score 81.266 (88.836)\n",
      " Test: accuracy 64.062 f1_score 62.129\n",
      "Training time:  261.68739318847656 Hour:  0 Minute:  4 Second:  21 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 85\n",
      "Epoch: [85][0/9]\tLoss 0.2719 (0.2719)\taccuracy 92.188 (92.188)\tf1_score 91.055 (91.055)\n",
      "Epoch: [85][5/9]\tLoss 0.2132 (0.3112)\taccuracy 89.844 (88.281)\tf1_score 89.053 (88.222)\n",
      " Test: accuracy 58.203 f1_score 55.407\n",
      "Training time:  264.2375752925873 Hour:  0 Minute:  4 Second:  24 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 86\n",
      "Epoch: [86][0/9]\tLoss 0.3958 (0.3958)\taccuracy 83.594 (83.594)\tf1_score 83.245 (83.245)\n",
      "Epoch: [86][5/9]\tLoss 0.3317 (0.2895)\taccuracy 85.938 (88.932)\tf1_score 86.187 (88.468)\n",
      " Test: accuracy 47.656 f1_score 42.797\n",
      "Training time:  266.78874230384827 Hour:  0 Minute:  4 Second:  26 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 87\n",
      "Epoch: [87][0/9]\tLoss 0.1911 (0.1911)\taccuracy 92.969 (92.969)\tf1_score 92.554 (92.554)\n",
      "Epoch: [87][5/9]\tLoss 0.3213 (0.2624)\taccuracy 88.281 (89.974)\tf1_score 88.116 (89.849)\n",
      " Test: accuracy 57.031 f1_score 53.566\n",
      "Training time:  269.33892607688904 Hour:  0 Minute:  4 Second:  29 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 88\n",
      "Epoch: [88][0/9]\tLoss 0.3250 (0.3250)\taccuracy 85.938 (85.938)\tf1_score 87.325 (87.325)\n",
      "Epoch: [88][5/9]\tLoss 0.2509 (0.3041)\taccuracy 91.406 (88.672)\tf1_score 91.979 (88.322)\n",
      " Test: accuracy 60.938 f1_score 57.344\n",
      "Training time:  271.91804671287537 Hour:  0 Minute:  4 Second:  31 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 89\n",
      "Epoch: [89][0/9]\tLoss 0.2222 (0.2222)\taccuracy 91.406 (91.406)\tf1_score 88.303 (88.303)\n",
      "Epoch: [89][5/9]\tLoss 0.1602 (0.2514)\taccuracy 94.531 (91.276)\tf1_score 94.091 (90.553)\n",
      " Test: accuracy 35.547 f1_score 28.644\n",
      "Training time:  274.4692556858063 Hour:  0 Minute:  4 Second:  34 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 90\n",
      "Epoch: [90][0/9]\tLoss 0.2393 (0.2393)\taccuracy 91.406 (91.406)\tf1_score 92.442 (92.442)\n",
      "Epoch: [90][5/9]\tLoss 0.2780 (0.3022)\taccuracy 90.625 (87.630)\tf1_score 91.454 (87.898)\n",
      " Test: accuracy 66.797 f1_score 64.300\n",
      "Training time:  277.0195128917694 Hour:  0 Minute:  4 Second:  37 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 91\n",
      "Epoch: [91][0/9]\tLoss 0.2650 (0.2650)\taccuracy 90.625 (90.625)\tf1_score 89.995 (89.995)\n",
      "Epoch: [91][5/9]\tLoss 0.2836 (0.3053)\taccuracy 88.281 (88.281)\tf1_score 88.941 (87.180)\n",
      " Test: accuracy 54.688 f1_score 52.014\n",
      "Training time:  279.5707471370697 Hour:  0 Minute:  4 Second:  39 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 92\n",
      "Epoch: [92][0/9]\tLoss 0.3122 (0.3122)\taccuracy 88.281 (88.281)\tf1_score 83.817 (83.817)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [92][5/9]\tLoss 0.3750 (0.3562)\taccuracy 88.281 (87.240)\tf1_score 89.103 (86.072)\n",
      " Test: accuracy 59.766 f1_score 55.146\n",
      "Training time:  282.12093138694763 Hour:  0 Minute:  4 Second:  42 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 93\n",
      "Epoch: [93][0/9]\tLoss 0.2161 (0.2161)\taccuracy 93.750 (93.750)\tf1_score 91.626 (91.626)\n",
      "Epoch: [93][5/9]\tLoss 0.2723 (0.2796)\taccuracy 88.281 (89.714)\tf1_score 89.322 (88.947)\n",
      " Test: accuracy 55.469 f1_score 48.812\n",
      "Training time:  284.6799952983856 Hour:  0 Minute:  4 Second:  44 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 94\n",
      "Epoch: [94][0/9]\tLoss 0.2858 (0.2858)\taccuracy 91.406 (91.406)\tf1_score 91.310 (91.310)\n",
      "Epoch: [94][5/9]\tLoss 0.3573 (0.2797)\taccuracy 85.938 (89.323)\tf1_score 86.837 (88.883)\n",
      " Test: accuracy 21.875 f1_score 15.924\n",
      "Training time:  287.2471582889557 Hour:  0 Minute:  4 Second:  47 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 95\n",
      "Epoch: [95][0/9]\tLoss 0.3507 (0.3507)\taccuracy 88.281 (88.281)\tf1_score 85.256 (85.256)\n",
      "Epoch: [95][5/9]\tLoss 0.3805 (0.2967)\taccuracy 85.156 (88.542)\tf1_score 78.917 (87.204)\n",
      " Test: accuracy 69.531 f1_score 64.826\n",
      "Training time:  289.7993311882019 Hour:  0 Minute:  4 Second:  49 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 96\n",
      "Epoch: [96][0/9]\tLoss 0.1712 (0.1712)\taccuracy 95.312 (95.312)\tf1_score 94.723 (94.723)\n",
      "Epoch: [96][5/9]\tLoss 0.3212 (0.2500)\taccuracy 88.281 (89.974)\tf1_score 86.743 (88.719)\n",
      " Test: accuracy 30.469 f1_score 25.927\n",
      "Training time:  292.3505072593689 Hour:  0 Minute:  4 Second:  52 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 97\n",
      "Epoch: [97][0/9]\tLoss 0.2472 (0.2472)\taccuracy 92.188 (92.188)\tf1_score 92.736 (92.736)\n",
      "Epoch: [97][5/9]\tLoss 0.3687 (0.2922)\taccuracy 86.719 (88.932)\tf1_score 88.764 (89.100)\n",
      " Test: accuracy 62.500 f1_score 58.425\n",
      "Training time:  294.9036784172058 Hour:  0 Minute:  4 Second:  54 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 98\n",
      "Epoch: [98][0/9]\tLoss 0.1821 (0.1821)\taccuracy 93.750 (93.750)\tf1_score 93.964 (93.964)\n",
      "Epoch: [98][5/9]\tLoss 0.3007 (0.2216)\taccuracy 86.719 (91.667)\tf1_score 87.109 (91.428)\n",
      " Test: accuracy 40.625 f1_score 36.655\n",
      "Training time:  297.45385694503784 Hour:  0 Minute:  4 Second:  57 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 99\n",
      "Epoch: [99][0/9]\tLoss 0.2153 (0.2153)\taccuracy 91.406 (91.406)\tf1_score 91.481 (91.481)\n",
      "Epoch: [99][5/9]\tLoss 0.2664 (0.2220)\taccuracy 85.156 (90.234)\tf1_score 85.854 (89.510)\n",
      " Test: accuracy 61.328 f1_score 59.170\n",
      "Training time:  300.00602746009827 Hour:  0 Minute:  5 Second:  0 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 100\n",
      "Epoch: [100][0/9]\tLoss 0.3504 (0.3504)\taccuracy 88.281 (88.281)\tf1_score 84.608 (84.608)\n",
      "Epoch: [100][5/9]\tLoss 0.2734 (0.2772)\taccuracy 87.500 (88.281)\tf1_score 88.492 (87.441)\n",
      " Test: accuracy 40.234 f1_score 33.876\n",
      "Training time:  302.5930781364441 Hour:  0 Minute:  5 Second:  2 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 101\n",
      "Epoch: [101][0/9]\tLoss 0.2118 (0.2118)\taccuracy 91.406 (91.406)\tf1_score 91.272 (91.272)\n",
      "Epoch: [101][5/9]\tLoss 0.3201 (0.3338)\taccuracy 86.719 (86.979)\tf1_score 83.259 (85.236)\n",
      " Test: accuracy 35.938 f1_score 30.210\n",
      "Training time:  305.1991081237793 Hour:  0 Minute:  5 Second:  5 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 102\n",
      "Epoch: [102][0/9]\tLoss 0.4288 (0.4288)\taccuracy 83.594 (83.594)\tf1_score 82.851 (82.851)\n",
      "Epoch: [102][5/9]\tLoss 0.2945 (0.3228)\taccuracy 88.281 (87.109)\tf1_score 86.738 (86.493)\n",
      " Test: accuracy 56.250 f1_score 48.859\n",
      "Training time:  307.7602572441101 Hour:  0 Minute:  5 Second:  7 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 103\n",
      "Epoch: [103][0/9]\tLoss 0.2145 (0.2145)\taccuracy 92.188 (92.188)\tf1_score 93.714 (93.714)\n",
      "Epoch: [103][5/9]\tLoss 0.3532 (0.2643)\taccuracy 89.844 (90.104)\tf1_score 88.192 (88.541)\n",
      " Test: accuracy 39.453 f1_score 37.719\n",
      "Training time:  310.3155755996704 Hour:  0 Minute:  5 Second:  10 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 104\n",
      "Epoch: [104][0/9]\tLoss 0.2314 (0.2314)\taccuracy 91.406 (91.406)\tf1_score 88.306 (88.306)\n",
      "Epoch: [104][5/9]\tLoss 0.3029 (0.3068)\taccuracy 84.375 (87.891)\tf1_score 84.808 (86.119)\n",
      " Test: accuracy 49.219 f1_score 44.199\n",
      "Training time:  312.8946957588196 Hour:  0 Minute:  5 Second:  12 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 105\n",
      "Epoch: [105][0/9]\tLoss 0.2605 (0.2605)\taccuracy 86.719 (86.719)\tf1_score 87.579 (87.579)\n",
      "Epoch: [105][5/9]\tLoss 0.3187 (0.2630)\taccuracy 86.719 (89.062)\tf1_score 86.188 (88.888)\n",
      " Test: accuracy 37.109 f1_score 31.066\n",
      "Training time:  315.44770073890686 Hour:  0 Minute:  5 Second:  15 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 106\n",
      "Epoch: [106][0/9]\tLoss 0.2438 (0.2438)\taccuracy 89.844 (89.844)\tf1_score 85.918 (85.918)\n",
      "Epoch: [106][5/9]\tLoss 0.3556 (0.2481)\taccuracy 86.719 (90.104)\tf1_score 82.927 (88.645)\n",
      " Test: accuracy 66.797 f1_score 64.603\n",
      "Training time:  318.00286650657654 Hour:  0 Minute:  5 Second:  18 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 107\n",
      "Epoch: [107][0/9]\tLoss 0.1806 (0.1806)\taccuracy 94.531 (94.531)\tf1_score 94.226 (94.226)\n",
      "Epoch: [107][5/9]\tLoss 0.2463 (0.2882)\taccuracy 92.188 (89.583)\tf1_score 92.466 (89.398)\n",
      " Test: accuracy 52.734 f1_score 47.420\n",
      "Training time:  320.5809910297394 Hour:  0 Minute:  5 Second:  20 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 108\n",
      "Epoch: [108][0/9]\tLoss 0.2556 (0.2556)\taccuracy 86.719 (86.719)\tf1_score 88.241 (88.241)\n",
      "Epoch: [108][5/9]\tLoss 0.2679 (0.2556)\taccuracy 90.625 (90.365)\tf1_score 89.676 (89.228)\n",
      " Test: accuracy 36.719 f1_score 30.478\n",
      "Training time:  323.13021636009216 Hour:  0 Minute:  5 Second:  23 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 109\n",
      "Epoch: [109][0/9]\tLoss 0.2315 (0.2315)\taccuracy 92.969 (92.969)\tf1_score 92.212 (92.212)\n",
      "Epoch: [109][5/9]\tLoss 0.1746 (0.2279)\taccuracy 93.750 (91.927)\tf1_score 92.288 (91.886)\n",
      " Test: accuracy 58.984 f1_score 54.400\n",
      "Training time:  325.6803946495056 Hour:  0 Minute:  5 Second:  25 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 110\n",
      "Epoch: [110][0/9]\tLoss 0.1117 (0.1117)\taccuracy 99.219 (99.219)\tf1_score 99.201 (99.201)\n",
      "Epoch: [110][5/9]\tLoss 0.1760 (0.1969)\taccuracy 92.969 (93.490)\tf1_score 90.844 (93.174)\n",
      " Test: accuracy 49.609 f1_score 43.116\n",
      "Training time:  328.232568025589 Hour:  0 Minute:  5 Second:  28 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 111\n",
      "Epoch: [111][0/9]\tLoss 0.1925 (0.1925)\taccuracy 89.844 (89.844)\tf1_score 88.787 (88.787)\n",
      "Epoch: [111][5/9]\tLoss 0.3631 (0.3033)\taccuracy 88.281 (88.411)\tf1_score 85.833 (86.953)\n",
      " Test: accuracy 51.562 f1_score 48.298\n",
      "Training time:  330.7827501296997 Hour:  0 Minute:  5 Second:  30 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 112\n",
      "Epoch: [112][0/9]\tLoss 0.2118 (0.2118)\taccuracy 95.312 (95.312)\tf1_score 96.053 (96.053)\n",
      "Epoch: [112][5/9]\tLoss 0.2425 (0.2811)\taccuracy 90.625 (89.323)\tf1_score 87.927 (88.251)\n",
      " Test: accuracy 62.109 f1_score 57.737\n",
      "Training time:  333.3489582538605 Hour:  0 Minute:  5 Second:  33 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 113\n",
      "Epoch: [113][0/9]\tLoss 0.2122 (0.2122)\taccuracy 91.406 (91.406)\tf1_score 90.051 (90.051)\n",
      "Epoch: [113][5/9]\tLoss 0.2850 (0.2333)\taccuracy 89.062 (90.495)\tf1_score 89.877 (90.210)\n",
      " Test: accuracy 58.984 f1_score 53.854\n",
      "Training time:  335.91547441482544 Hour:  0 Minute:  5 Second:  35 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 114\n",
      "Epoch: [114][0/9]\tLoss 0.2242 (0.2242)\taccuracy 92.969 (92.969)\tf1_score 91.768 (91.768)\n",
      "Epoch: [114][5/9]\tLoss 0.2958 (0.2197)\taccuracy 85.938 (92.448)\tf1_score 86.084 (91.692)\n",
      " Test: accuracy 49.609 f1_score 44.851\n",
      "Training time:  338.46864461898804 Hour:  0 Minute:  5 Second:  38 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 115\n",
      "Epoch: [115][0/9]\tLoss 0.3171 (0.3171)\taccuracy 87.500 (87.500)\tf1_score 87.944 (87.944)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [115][5/9]\tLoss 0.1910 (0.1991)\taccuracy 90.625 (92.057)\tf1_score 89.282 (91.135)\n",
      " Test: accuracy 60.156 f1_score 56.180\n",
      "Training time:  341.0547299385071 Hour:  0 Minute:  5 Second:  41 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 116\n",
      "Epoch: [116][0/9]\tLoss 0.2170 (0.2170)\taccuracy 92.969 (92.969)\tf1_score 92.277 (92.277)\n",
      "Epoch: [116][5/9]\tLoss 0.1691 (0.1709)\taccuracy 92.188 (94.141)\tf1_score 91.949 (93.668)\n",
      " Test: accuracy 51.562 f1_score 44.593\n",
      "Training time:  343.60989236831665 Hour:  0 Minute:  5 Second:  43 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 117\n",
      "Epoch: [117][0/9]\tLoss 0.1517 (0.1517)\taccuracy 94.531 (94.531)\tf1_score 93.472 (93.472)\n",
      "Epoch: [117][5/9]\tLoss 0.2450 (0.2063)\taccuracy 92.188 (92.578)\tf1_score 92.582 (91.400)\n",
      " Test: accuracy 42.969 f1_score 36.150\n",
      "Training time:  346.1620657444 Hour:  0 Minute:  5 Second:  46 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 118\n",
      "Epoch: [118][0/9]\tLoss 0.1998 (0.1998)\taccuracy 91.406 (91.406)\tf1_score 90.254 (90.254)\n",
      "Epoch: [118][5/9]\tLoss 0.4187 (0.2891)\taccuracy 83.594 (89.193)\tf1_score 85.424 (88.820)\n",
      " Test: accuracy 49.609 f1_score 40.452\n",
      "Training time:  348.7142415046692 Hour:  0 Minute:  5 Second:  48 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 119\n",
      "Epoch: [119][0/9]\tLoss 0.2676 (0.2676)\taccuracy 89.844 (89.844)\tf1_score 90.445 (90.445)\n",
      "Epoch: [119][5/9]\tLoss 0.2258 (0.2556)\taccuracy 92.188 (91.276)\tf1_score 91.298 (90.210)\n",
      " Test: accuracy 60.156 f1_score 56.850\n",
      "Training time:  351.2803750038147 Hour:  0 Minute:  5 Second:  51 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 120\n",
      "Epoch: [120][0/9]\tLoss 0.2069 (0.2069)\taccuracy 91.406 (91.406)\tf1_score 91.275 (91.275)\n",
      "Epoch: [120][5/9]\tLoss 0.2318 (0.2205)\taccuracy 92.969 (91.927)\tf1_score 91.261 (91.171)\n",
      " Test: accuracy 34.766 f1_score 27.523\n",
      "Training time:  353.83254861831665 Hour:  0 Minute:  5 Second:  53 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 121\n",
      "Epoch: [121][0/9]\tLoss 0.2197 (0.2197)\taccuracy 92.188 (92.188)\tf1_score 88.119 (88.119)\n",
      "Epoch: [121][5/9]\tLoss 0.5687 (0.2746)\taccuracy 81.250 (89.714)\tf1_score 81.078 (88.559)\n",
      " Test: accuracy 41.016 f1_score 33.556\n",
      "Training time:  356.38685178756714 Hour:  0 Minute:  5 Second:  56 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 122\n",
      "Epoch: [122][0/9]\tLoss 0.3015 (0.3015)\taccuracy 87.500 (87.500)\tf1_score 88.944 (88.944)\n",
      "Epoch: [122][5/9]\tLoss 0.2192 (0.2344)\taccuracy 92.188 (91.276)\tf1_score 92.489 (90.483)\n",
      " Test: accuracy 61.328 f1_score 55.574\n",
      "Training time:  358.9510278701782 Hour:  0 Minute:  5 Second:  58 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 123\n",
      "Epoch: [123][0/9]\tLoss 0.1157 (0.1157)\taccuracy 96.875 (96.875)\tf1_score 96.612 (96.612)\n",
      "Epoch: [123][5/9]\tLoss 0.4359 (0.2283)\taccuracy 83.594 (91.797)\tf1_score 82.346 (91.040)\n",
      " Test: accuracy 55.469 f1_score 50.578\n",
      "Training time:  361.51117730140686 Hour:  0 Minute:  6 Second:  1 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 124\n",
      "Epoch: [124][0/9]\tLoss 0.2613 (0.2613)\taccuracy 89.844 (89.844)\tf1_score 86.250 (86.250)\n",
      "Epoch: [124][5/9]\tLoss 0.3246 (0.2901)\taccuracy 90.625 (88.932)\tf1_score 87.013 (86.891)\n",
      " Test: accuracy 33.594 f1_score 28.843\n",
      "Training time:  364.063353061676 Hour:  0 Minute:  6 Second:  4 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 125\n",
      "Epoch: [125][0/9]\tLoss 0.2456 (0.2456)\taccuracy 92.188 (92.188)\tf1_score 90.296 (90.296)\n",
      "Epoch: [125][5/9]\tLoss 0.2191 (0.2670)\taccuracy 92.188 (89.583)\tf1_score 91.246 (88.729)\n",
      " Test: accuracy 68.750 f1_score 66.170\n",
      "Training time:  366.62950706481934 Hour:  0 Minute:  6 Second:  6 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 126\n",
      "Epoch: [126][0/9]\tLoss 0.1684 (0.1684)\taccuracy 94.531 (94.531)\tf1_score 93.775 (93.775)\n",
      "Epoch: [126][5/9]\tLoss 0.2700 (0.2734)\taccuracy 91.406 (88.932)\tf1_score 91.041 (88.478)\n",
      " Test: accuracy 67.188 f1_score 64.852\n",
      "Training time:  369.1896929740906 Hour:  0 Minute:  6 Second:  9 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 127\n",
      "Epoch: [127][0/9]\tLoss 0.1922 (0.1922)\taccuracy 92.969 (92.969)\tf1_score 92.839 (92.839)\n",
      "Epoch: [127][5/9]\tLoss 0.2845 (0.2227)\taccuracy 88.281 (91.406)\tf1_score 87.218 (91.079)\n",
      " Test: accuracy 29.297 f1_score 22.897\n",
      "Training time:  371.7418632507324 Hour:  0 Minute:  6 Second:  11 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 128\n",
      "Epoch: [128][0/9]\tLoss 0.2956 (0.2956)\taccuracy 90.625 (90.625)\tf1_score 87.050 (87.050)\n",
      "Epoch: [128][5/9]\tLoss 0.4021 (0.2681)\taccuracy 83.594 (90.495)\tf1_score 81.012 (89.080)\n",
      " Test: accuracy 69.141 f1_score 68.463\n",
      "Training time:  374.293039560318 Hour:  0 Minute:  6 Second:  14 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 129\n",
      "Epoch: [129][0/9]\tLoss 0.1652 (0.1652)\taccuracy 94.531 (94.531)\tf1_score 93.999 (93.999)\n",
      "Epoch: [129][5/9]\tLoss 0.2377 (0.2293)\taccuracy 89.062 (90.625)\tf1_score 89.482 (89.964)\n",
      " Test: accuracy 48.828 f1_score 45.147\n",
      "Training time:  376.8491690158844 Hour:  0 Minute:  6 Second:  16 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 130\n",
      "Epoch: [130][0/9]\tLoss 0.1715 (0.1715)\taccuracy 95.312 (95.312)\tf1_score 95.280 (95.280)\n",
      "Epoch: [130][5/9]\tLoss 0.4708 (0.2786)\taccuracy 82.031 (90.104)\tf1_score 81.691 (88.927)\n",
      " Test: accuracy 58.203 f1_score 54.002\n",
      "Training time:  379.4003818035126 Hour:  0 Minute:  6 Second:  19 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 131\n",
      "Epoch: [131][0/9]\tLoss 0.2807 (0.2807)\taccuracy 88.281 (88.281)\tf1_score 89.332 (89.332)\n",
      "Epoch: [131][5/9]\tLoss 0.1984 (0.2437)\taccuracy 94.531 (91.016)\tf1_score 94.176 (90.072)\n",
      " Test: accuracy 59.375 f1_score 54.926\n",
      "Training time:  381.9555575847626 Hour:  0 Minute:  6 Second:  21 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 132\n",
      "Epoch: [132][0/9]\tLoss 0.2143 (0.2143)\taccuracy 92.188 (92.188)\tf1_score 92.291 (92.291)\n",
      "Epoch: [132][5/9]\tLoss 0.2139 (0.2220)\taccuracy 92.188 (91.536)\tf1_score 90.681 (90.558)\n",
      " Test: accuracy 51.953 f1_score 47.221\n",
      "Training time:  384.5244936943054 Hour:  0 Minute:  6 Second:  24 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 133\n",
      "Epoch: [133][0/9]\tLoss 0.2333 (0.2333)\taccuracy 90.625 (90.625)\tf1_score 91.886 (91.886)\n",
      "Epoch: [133][5/9]\tLoss 0.1264 (0.1863)\taccuracy 95.312 (91.667)\tf1_score 94.725 (91.430)\n",
      " Test: accuracy 61.328 f1_score 56.397\n",
      "Training time:  387.0766632556915 Hour:  0 Minute:  6 Second:  27 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 134\n",
      "Epoch: [134][0/9]\tLoss 0.1768 (0.1768)\taccuracy 92.969 (92.969)\tf1_score 92.695 (92.695)\n",
      "Epoch: [134][5/9]\tLoss 0.1186 (0.1585)\taccuracy 94.531 (93.750)\tf1_score 93.812 (93.547)\n",
      " Test: accuracy 50.391 f1_score 45.522\n",
      "Training time:  389.62983441352844 Hour:  0 Minute:  6 Second:  29 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 135\n",
      "Epoch: [135][0/9]\tLoss 0.2741 (0.2741)\taccuracy 89.844 (89.844)\tf1_score 89.743 (89.743)\n",
      "Epoch: [135][5/9]\tLoss 0.1764 (0.1923)\taccuracy 93.750 (92.839)\tf1_score 89.877 (91.780)\n",
      " Test: accuracy 61.328 f1_score 57.649\n",
      "Training time:  392.19969296455383 Hour:  0 Minute:  6 Second:  32 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 136\n",
      "Epoch: [136][0/9]\tLoss 0.1633 (0.1633)\taccuracy 92.969 (92.969)\tf1_score 91.179 (91.179)\n",
      "Epoch: [136][5/9]\tLoss 0.1546 (0.1608)\taccuracy 95.312 (93.229)\tf1_score 94.927 (92.594)\n",
      " Test: accuracy 50.391 f1_score 44.520\n",
      "Training time:  394.7568185329437 Hour:  0 Minute:  6 Second:  34 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 137\n",
      "Epoch: [137][0/9]\tLoss 0.1900 (0.1900)\taccuracy 92.969 (92.969)\tf1_score 93.051 (93.051)\n",
      "Epoch: [137][5/9]\tLoss 0.1510 (0.1558)\taccuracy 94.531 (94.271)\tf1_score 92.626 (93.540)\n",
      " Test: accuracy 63.281 f1_score 58.676\n",
      "Training time:  397.3100242614746 Hour:  0 Minute:  6 Second:  37 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 138\n",
      "Epoch: [138][0/9]\tLoss 0.1053 (0.1053)\taccuracy 96.094 (96.094)\tf1_score 95.948 (95.948)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [138][5/9]\tLoss 0.3001 (0.1794)\taccuracy 89.062 (93.490)\tf1_score 87.069 (92.434)\n",
      " Test: accuracy 49.609 f1_score 44.470\n",
      "Training time:  399.89108514785767 Hour:  0 Minute:  6 Second:  39 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 139\n",
      "Epoch: [139][0/9]\tLoss 0.1235 (0.1235)\taccuracy 94.531 (94.531)\tf1_score 95.029 (95.029)\n",
      "Epoch: [139][5/9]\tLoss 0.1930 (0.2073)\taccuracy 93.750 (91.016)\tf1_score 94.346 (91.213)\n",
      " Test: accuracy 43.359 f1_score 37.125\n",
      "Training time:  402.46431851387024 Hour:  0 Minute:  6 Second:  42 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 140\n",
      "Epoch: [140][0/9]\tLoss 0.1208 (0.1208)\taccuracy 93.750 (93.750)\tf1_score 92.324 (92.324)\n",
      "Epoch: [140][5/9]\tLoss 0.3253 (0.1961)\taccuracy 89.062 (92.448)\tf1_score 88.076 (91.813)\n",
      " Test: accuracy 68.359 f1_score 67.233\n",
      "Training time:  405.02347350120544 Hour:  0 Minute:  6 Second:  45 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 141\n",
      "Epoch: [141][0/9]\tLoss 0.1248 (0.1248)\taccuracy 96.875 (96.875)\tf1_score 97.187 (97.187)\n",
      "Epoch: [141][5/9]\tLoss 0.1100 (0.1552)\taccuracy 96.094 (93.620)\tf1_score 94.765 (93.193)\n",
      " Test: accuracy 57.812 f1_score 52.119\n",
      "Training time:  407.57571053504944 Hour:  0 Minute:  6 Second:  47 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 142\n",
      "Epoch: [142][0/9]\tLoss 0.1878 (0.1878)\taccuracy 92.969 (92.969)\tf1_score 94.039 (94.039)\n",
      "Epoch: [142][5/9]\tLoss 0.1427 (0.1949)\taccuracy 94.531 (92.708)\tf1_score 93.417 (92.015)\n",
      " Test: accuracy 72.266 f1_score 70.027\n",
      "Training time:  410.1288809776306 Hour:  0 Minute:  6 Second:  50 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 143\n",
      "Epoch: [143][0/9]\tLoss 0.3465 (0.3465)\taccuracy 85.938 (85.938)\tf1_score 86.370 (86.370)\n",
      "Epoch: [143][5/9]\tLoss 0.1279 (0.1679)\taccuracy 96.094 (93.880)\tf1_score 94.362 (93.461)\n",
      " Test: accuracy 56.250 f1_score 50.869\n",
      "Training time:  412.6845576763153 Hour:  0 Minute:  6 Second:  52 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 144\n",
      "Epoch: [144][0/9]\tLoss 0.1484 (0.1484)\taccuracy 95.312 (95.312)\tf1_score 95.114 (95.114)\n",
      "Epoch: [144][5/9]\tLoss 0.1949 (0.1655)\taccuracy 92.969 (94.010)\tf1_score 92.724 (93.288)\n",
      " Test: accuracy 64.453 f1_score 61.875\n",
      "Training time:  415.26351380348206 Hour:  0 Minute:  6 Second:  55 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 145\n",
      "Epoch: [145][0/9]\tLoss 0.2179 (0.2179)\taccuracy 89.062 (89.062)\tf1_score 91.625 (91.625)\n",
      "Epoch: [145][5/9]\tLoss 0.3910 (0.1938)\taccuracy 84.375 (91.927)\tf1_score 81.636 (91.281)\n",
      " Test: accuracy 58.203 f1_score 52.458\n",
      "Training time:  417.8306791782379 Hour:  0 Minute:  6 Second:  57 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 146\n",
      "Epoch: [146][0/9]\tLoss 0.2011 (0.2011)\taccuracy 93.750 (93.750)\tf1_score 94.033 (94.033)\n",
      "Epoch: [146][5/9]\tLoss 0.1270 (0.1503)\taccuracy 94.531 (95.052)\tf1_score 93.506 (95.011)\n",
      " Test: accuracy 62.500 f1_score 57.383\n",
      "Training time:  420.3968164920807 Hour:  0 Minute:  7 Second:  0 Test best accuracy: 72.65625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 147\n",
      "Epoch: [147][0/9]\tLoss 0.1873 (0.1873)\taccuracy 92.188 (92.188)\tf1_score 91.275 (91.275)\n",
      "Epoch: [147][5/9]\tLoss 0.2784 (0.1697)\taccuracy 90.625 (94.010)\tf1_score 90.203 (92.788)\n",
      " Test: accuracy 74.609 f1_score 73.900\n",
      "Training time:  422.9589614868164 Hour:  0 Minute:  7 Second:  2 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 148\n",
      "Epoch: [148][0/9]\tLoss 0.1555 (0.1555)\taccuracy 93.750 (93.750)\tf1_score 93.239 (93.239)\n",
      "Epoch: [148][5/9]\tLoss 0.1239 (0.1483)\taccuracy 97.656 (94.922)\tf1_score 96.980 (94.445)\n",
      " Test: accuracy 69.141 f1_score 65.900\n",
      "Training time:  425.52011036872864 Hour:  0 Minute:  7 Second:  5 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 149\n",
      "Epoch: [149][0/9]\tLoss 0.1224 (0.1224)\taccuracy 96.094 (96.094)\tf1_score 95.154 (95.154)\n",
      "Epoch: [149][5/9]\tLoss 0.0840 (0.1750)\taccuracy 97.656 (94.271)\tf1_score 97.180 (93.638)\n",
      " Test: accuracy 73.438 f1_score 71.180\n",
      "Training time:  428.08325386047363 Hour:  0 Minute:  7 Second:  8 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 150\n",
      "Epoch: [150][0/9]\tLoss 0.1604 (0.1604)\taccuracy 94.531 (94.531)\tf1_score 95.080 (95.080)\n",
      "Epoch: [150][5/9]\tLoss 0.1290 (0.1555)\taccuracy 96.094 (94.792)\tf1_score 96.191 (94.690)\n",
      " Test: accuracy 60.938 f1_score 57.025\n",
      "Training time:  430.66036009788513 Hour:  0 Minute:  7 Second:  10 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 151\n",
      "Epoch: [151][0/9]\tLoss 0.1096 (0.1096)\taccuracy 94.531 (94.531)\tf1_score 93.402 (93.402)\n",
      "Epoch: [151][5/9]\tLoss 0.1236 (0.1403)\taccuracy 96.875 (95.182)\tf1_score 97.484 (94.680)\n",
      " Test: accuracy 41.406 f1_score 33.393\n",
      "Training time:  433.228492975235 Hour:  0 Minute:  7 Second:  13 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 152\n",
      "Epoch: [152][0/9]\tLoss 0.1378 (0.1378)\taccuracy 94.531 (94.531)\tf1_score 94.842 (94.842)\n",
      "Epoch: [152][5/9]\tLoss 0.0890 (0.1421)\taccuracy 97.656 (94.661)\tf1_score 97.330 (94.388)\n",
      " Test: accuracy 66.016 f1_score 63.142\n",
      "Training time:  435.7846505641937 Hour:  0 Minute:  7 Second:  15 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 153\n",
      "Epoch: [153][0/9]\tLoss 0.1322 (0.1322)\taccuracy 96.094 (96.094)\tf1_score 96.301 (96.301)\n",
      "Epoch: [153][5/9]\tLoss 0.1154 (0.1402)\taccuracy 95.312 (94.792)\tf1_score 94.235 (94.482)\n",
      " Test: accuracy 68.359 f1_score 65.753\n",
      "Training time:  438.35777044296265 Hour:  0 Minute:  7 Second:  18 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 154\n",
      "Epoch: [154][0/9]\tLoss 0.0942 (0.0942)\taccuracy 96.094 (96.094)\tf1_score 95.655 (95.655)\n",
      "Epoch: [154][5/9]\tLoss 0.2028 (0.1328)\taccuracy 90.625 (94.922)\tf1_score 91.616 (94.754)\n",
      " Test: accuracy 67.969 f1_score 68.110\n",
      "Training time:  440.9328899383545 Hour:  0 Minute:  7 Second:  20 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 155\n",
      "Epoch: [155][0/9]\tLoss 0.1485 (0.1485)\taccuracy 93.750 (93.750)\tf1_score 93.184 (93.184)\n",
      "Epoch: [155][5/9]\tLoss 0.1497 (0.1435)\taccuracy 95.312 (94.141)\tf1_score 94.961 (94.212)\n",
      " Test: accuracy 71.875 f1_score 70.957\n",
      "Training time:  443.5433690547943 Hour:  0 Minute:  7 Second:  23 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 156\n",
      "Epoch: [156][0/9]\tLoss 0.0856 (0.0856)\taccuracy 96.094 (96.094)\tf1_score 95.522 (95.522)\n",
      "Epoch: [156][5/9]\tLoss 0.0913 (0.1373)\taccuracy 98.438 (94.010)\tf1_score 98.494 (94.066)\n",
      " Test: accuracy 56.641 f1_score 51.037\n",
      "Training time:  446.11751651763916 Hour:  0 Minute:  7 Second:  26 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 157\n",
      "Epoch: [157][0/9]\tLoss 0.2064 (0.2064)\taccuracy 90.625 (90.625)\tf1_score 90.126 (90.126)\n",
      "Epoch: [157][5/9]\tLoss 0.1371 (0.1633)\taccuracy 95.312 (93.750)\tf1_score 95.643 (93.844)\n",
      " Test: accuracy 63.672 f1_score 60.947\n",
      "Training time:  448.72653675079346 Hour:  0 Minute:  7 Second:  28 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 158\n",
      "Epoch: [158][0/9]\tLoss 0.1702 (0.1702)\taccuracy 93.750 (93.750)\tf1_score 93.929 (93.929)\n",
      "Epoch: [158][5/9]\tLoss 0.1667 (0.1520)\taccuracy 93.750 (94.271)\tf1_score 92.329 (94.414)\n",
      " Test: accuracy 63.672 f1_score 60.852\n",
      "Training time:  451.4002916812897 Hour:  0 Minute:  7 Second:  31 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 159\n",
      "Epoch: [159][0/9]\tLoss 0.1267 (0.1267)\taccuracy 96.094 (96.094)\tf1_score 95.338 (95.338)\n",
      "Epoch: [159][5/9]\tLoss 0.2357 (0.1331)\taccuracy 92.188 (95.312)\tf1_score 91.173 (94.857)\n",
      " Test: accuracy 55.469 f1_score 48.913\n",
      "Training time:  454.12995505332947 Hour:  0 Minute:  7 Second:  34 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 160\n",
      "Epoch: [160][0/9]\tLoss 0.1223 (0.1223)\taccuracy 95.312 (95.312)\tf1_score 96.361 (96.361)\n",
      "Epoch: [160][5/9]\tLoss 0.1908 (0.1599)\taccuracy 89.844 (93.620)\tf1_score 90.235 (94.054)\n",
      " Test: accuracy 64.062 f1_score 59.351\n",
      "Training time:  456.7723515033722 Hour:  0 Minute:  7 Second:  36 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 161\n",
      "Epoch: [161][0/9]\tLoss 0.1183 (0.1183)\taccuracy 95.312 (95.312)\tf1_score 95.484 (95.484)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [161][5/9]\tLoss 0.1544 (0.1235)\taccuracy 93.750 (95.573)\tf1_score 94.085 (95.918)\n",
      " Test: accuracy 64.453 f1_score 61.017\n",
      "Training time:  459.4150803089142 Hour:  0 Minute:  7 Second:  39 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 162\n",
      "Epoch: [162][0/9]\tLoss 0.1259 (0.1259)\taccuracy 96.094 (96.094)\tf1_score 96.047 (96.047)\n",
      "Epoch: [162][5/9]\tLoss 0.1743 (0.1274)\taccuracy 91.406 (95.052)\tf1_score 92.493 (95.194)\n",
      " Test: accuracy 64.453 f1_score 60.226\n",
      "Training time:  462.0052237510681 Hour:  0 Minute:  7 Second:  42 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 163\n",
      "Epoch: [163][0/9]\tLoss 0.0856 (0.0856)\taccuracy 99.219 (99.219)\tf1_score 99.134 (99.134)\n",
      "Epoch: [163][5/9]\tLoss 0.1566 (0.1156)\taccuracy 94.531 (96.745)\tf1_score 93.664 (96.593)\n",
      " Test: accuracy 64.844 f1_score 59.648\n",
      "Training time:  464.6025159358978 Hour:  0 Minute:  7 Second:  44 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 164\n",
      "Epoch: [164][0/9]\tLoss 0.0623 (0.0623)\taccuracy 97.656 (97.656)\tf1_score 97.653 (97.653)\n",
      "Epoch: [164][5/9]\tLoss 0.1384 (0.1043)\taccuracy 92.969 (95.964)\tf1_score 92.814 (95.617)\n",
      " Test: accuracy 71.094 f1_score 69.648\n",
      "Training time:  467.16170382499695 Hour:  0 Minute:  7 Second:  47 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 165\n",
      "Epoch: [165][0/9]\tLoss 0.0949 (0.0949)\taccuracy 95.312 (95.312)\tf1_score 94.178 (94.178)\n",
      "Epoch: [165][5/9]\tLoss 0.0788 (0.1062)\taccuracy 96.094 (95.703)\tf1_score 95.737 (95.256)\n",
      " Test: accuracy 45.312 f1_score 39.315\n",
      "Training time:  469.72185492515564 Hour:  0 Minute:  7 Second:  49 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 166\n",
      "Epoch: [166][0/9]\tLoss 0.1367 (0.1367)\taccuracy 96.094 (96.094)\tf1_score 96.524 (96.524)\n",
      "Epoch: [166][5/9]\tLoss 0.3112 (0.1575)\taccuracy 89.844 (94.792)\tf1_score 88.144 (94.634)\n",
      " Test: accuracy 62.891 f1_score 60.297\n",
      "Training time:  472.28400135040283 Hour:  0 Minute:  7 Second:  52 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 167\n",
      "Epoch: [167][0/9]\tLoss 0.0622 (0.0622)\taccuracy 97.656 (97.656)\tf1_score 97.359 (97.359)\n",
      "Epoch: [167][5/9]\tLoss 0.0850 (0.1182)\taccuracy 96.094 (94.661)\tf1_score 95.668 (94.396)\n",
      " Test: accuracy 36.719 f1_score 32.001\n",
      "Training time:  474.8452033996582 Hour:  0 Minute:  7 Second:  54 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 168\n",
      "Epoch: [168][0/9]\tLoss 0.1729 (0.1729)\taccuracy 92.188 (92.188)\tf1_score 92.030 (92.030)\n",
      "Epoch: [168][5/9]\tLoss 0.0957 (0.1755)\taccuracy 96.875 (94.271)\tf1_score 95.228 (93.720)\n",
      " Test: accuracy 66.406 f1_score 63.825\n",
      "Training time:  477.406352519989 Hour:  0 Minute:  7 Second:  57 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 169\n",
      "Epoch: [169][0/9]\tLoss 0.0925 (0.0925)\taccuracy 96.875 (96.875)\tf1_score 97.294 (97.294)\n",
      "Epoch: [169][5/9]\tLoss 0.1270 (0.1863)\taccuracy 94.531 (92.839)\tf1_score 94.137 (92.721)\n",
      " Test: accuracy 60.938 f1_score 55.720\n",
      "Training time:  480.00935769081116 Hour:  0 Minute:  8 Second:  0 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 170\n",
      "Epoch: [170][0/9]\tLoss 0.1602 (0.1602)\taccuracy 93.750 (93.750)\tf1_score 93.337 (93.337)\n",
      "Epoch: [170][5/9]\tLoss 0.1206 (0.1986)\taccuracy 96.094 (92.057)\tf1_score 95.893 (91.583)\n",
      " Test: accuracy 59.375 f1_score 55.290\n",
      "Training time:  482.61640763282776 Hour:  0 Minute:  8 Second:  2 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 171\n",
      "Epoch: [171][0/9]\tLoss 0.1167 (0.1167)\taccuracy 97.656 (97.656)\tf1_score 96.757 (96.757)\n",
      "Epoch: [171][5/9]\tLoss 0.1345 (0.1149)\taccuracy 93.750 (95.703)\tf1_score 92.464 (95.166)\n",
      " Test: accuracy 63.281 f1_score 59.372\n",
      "Training time:  485.20249938964844 Hour:  0 Minute:  8 Second:  5 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 172\n",
      "Epoch: [172][0/9]\tLoss 0.1103 (0.1103)\taccuracy 95.312 (95.312)\tf1_score 94.902 (94.902)\n",
      "Epoch: [172][5/9]\tLoss 0.1338 (0.1120)\taccuracy 95.312 (96.224)\tf1_score 94.086 (95.830)\n",
      " Test: accuracy 58.984 f1_score 52.824\n",
      "Training time:  487.7863097190857 Hour:  0 Minute:  8 Second:  7 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 173\n",
      "Epoch: [173][0/9]\tLoss 0.1069 (0.1069)\taccuracy 96.094 (96.094)\tf1_score 96.315 (96.315)\n",
      "Epoch: [173][5/9]\tLoss 0.1140 (0.1209)\taccuracy 96.094 (95.182)\tf1_score 96.727 (95.635)\n",
      " Test: accuracy 52.344 f1_score 47.018\n",
      "Training time:  490.4352250099182 Hour:  0 Minute:  8 Second:  10 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 174\n",
      "Epoch: [174][0/9]\tLoss 0.0948 (0.0948)\taccuracy 97.656 (97.656)\tf1_score 97.178 (97.178)\n",
      "Epoch: [174][5/9]\tLoss 0.1322 (0.1298)\taccuracy 96.094 (95.312)\tf1_score 95.218 (95.059)\n",
      " Test: accuracy 55.859 f1_score 50.942\n",
      "Training time:  493.12331366539 Hour:  0 Minute:  8 Second:  13 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 175\n",
      "Epoch: [175][0/9]\tLoss 0.1167 (0.1167)\taccuracy 95.312 (95.312)\tf1_score 96.864 (96.864)\n",
      "Epoch: [175][5/9]\tLoss 0.1267 (0.1490)\taccuracy 93.750 (93.229)\tf1_score 91.865 (93.259)\n",
      " Test: accuracy 62.109 f1_score 58.505\n",
      "Training time:  495.8899040222168 Hour:  0 Minute:  8 Second:  15 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 176\n",
      "Epoch: [176][0/9]\tLoss 0.0829 (0.0829)\taccuracy 97.656 (97.656)\tf1_score 97.181 (97.181)\n",
      "Epoch: [176][5/9]\tLoss 0.1012 (0.1149)\taccuracy 95.312 (95.182)\tf1_score 94.970 (94.791)\n",
      " Test: accuracy 64.062 f1_score 60.275\n",
      "Training time:  498.48604011535645 Hour:  0 Minute:  8 Second:  18 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 177\n",
      "Epoch: [177][0/9]\tLoss 0.1222 (0.1222)\taccuracy 95.312 (95.312)\tf1_score 94.856 (94.856)\n",
      "Epoch: [177][5/9]\tLoss 0.1537 (0.1419)\taccuracy 95.312 (94.792)\tf1_score 94.974 (94.394)\n",
      " Test: accuracy 62.109 f1_score 60.450\n",
      "Training time:  501.06554675102234 Hour:  0 Minute:  8 Second:  21 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 178\n",
      "Epoch: [178][0/9]\tLoss 0.0912 (0.0912)\taccuracy 97.656 (97.656)\tf1_score 97.514 (97.514)\n",
      "Epoch: [178][5/9]\tLoss 0.0739 (0.1065)\taccuracy 97.656 (96.224)\tf1_score 97.602 (96.408)\n",
      " Test: accuracy 57.812 f1_score 53.897\n",
      "Training time:  503.65362215042114 Hour:  0 Minute:  8 Second:  23 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 179\n",
      "Epoch: [179][0/9]\tLoss 0.1442 (0.1442)\taccuracy 95.312 (95.312)\tf1_score 95.289 (95.289)\n",
      "Epoch: [179][5/9]\tLoss 0.0951 (0.1264)\taccuracy 95.312 (94.661)\tf1_score 94.363 (94.469)\n",
      " Test: accuracy 63.672 f1_score 60.719\n",
      "Training time:  506.25403594970703 Hour:  0 Minute:  8 Second:  26 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 180\n",
      "Epoch: [180][0/9]\tLoss 0.0453 (0.0453)\taccuracy 99.219 (99.219)\tf1_score 99.250 (99.250)\n",
      "Epoch: [180][5/9]\tLoss 0.0783 (0.1212)\taccuracy 97.656 (96.484)\tf1_score 97.778 (95.870)\n",
      " Test: accuracy 73.438 f1_score 73.399\n",
      "Training time:  508.9210591316223 Hour:  0 Minute:  8 Second:  28 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 181\n",
      "Epoch: [181][0/9]\tLoss 0.1615 (0.1615)\taccuracy 94.531 (94.531)\tf1_score 94.320 (94.320)\n",
      "Epoch: [181][5/9]\tLoss 0.1181 (0.1094)\taccuracy 96.094 (95.964)\tf1_score 95.588 (95.111)\n",
      " Test: accuracy 62.109 f1_score 57.714\n",
      "Training time:  511.56302762031555 Hour:  0 Minute:  8 Second:  31 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 182\n",
      "Epoch: [182][0/9]\tLoss 0.0612 (0.0612)\taccuracy 99.219 (99.219)\tf1_score 99.316 (99.316)\n",
      "Epoch: [182][5/9]\tLoss 0.1524 (0.0898)\taccuracy 93.750 (96.745)\tf1_score 92.284 (96.066)\n",
      " Test: accuracy 61.328 f1_score 56.969\n",
      "Training time:  514.1531307697296 Hour:  0 Minute:  8 Second:  34 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 183\n",
      "Epoch: [183][0/9]\tLoss 0.0879 (0.0879)\taccuracy 96.094 (96.094)\tf1_score 96.336 (96.336)\n",
      "Epoch: [183][5/9]\tLoss 0.1210 (0.1323)\taccuracy 95.312 (95.052)\tf1_score 94.810 (94.765)\n",
      " Test: accuracy 50.781 f1_score 45.294\n",
      "Training time:  516.7621331214905 Hour:  0 Minute:  8 Second:  36 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 184\n",
      "Epoch: [184][0/9]\tLoss 0.1704 (0.1704)\taccuracy 92.969 (92.969)\tf1_score 92.821 (92.821)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [184][5/9]\tLoss 0.2938 (0.2170)\taccuracy 88.281 (91.536)\tf1_score 89.739 (91.022)\n",
      " Test: accuracy 60.547 f1_score 57.161\n",
      "Training time:  519.3565919399261 Hour:  0 Minute:  8 Second:  39 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 185\n",
      "Epoch: [185][0/9]\tLoss 0.1472 (0.1472)\taccuracy 94.531 (94.531)\tf1_score 89.687 (89.687)\n",
      "Epoch: [185][5/9]\tLoss 0.1845 (0.1909)\taccuracy 92.188 (93.359)\tf1_score 89.732 (91.775)\n",
      " Test: accuracy 62.109 f1_score 60.281\n",
      "Training time:  521.9673686027527 Hour:  0 Minute:  8 Second:  41 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 186\n",
      "Epoch: [186][0/9]\tLoss 0.1204 (0.1204)\taccuracy 94.531 (94.531)\tf1_score 94.719 (94.719)\n",
      "Epoch: [186][5/9]\tLoss 0.1441 (0.1545)\taccuracy 95.312 (93.490)\tf1_score 96.093 (93.837)\n",
      " Test: accuracy 48.828 f1_score 44.153\n",
      "Training time:  524.5584502220154 Hour:  0 Minute:  8 Second:  44 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 187\n",
      "Epoch: [187][0/9]\tLoss 0.1440 (0.1440)\taccuracy 93.750 (93.750)\tf1_score 93.789 (93.789)\n",
      "Epoch: [187][5/9]\tLoss 0.1786 (0.2324)\taccuracy 91.406 (90.755)\tf1_score 90.675 (89.180)\n",
      " Test: accuracy 53.516 f1_score 50.571\n",
      "Training time:  527.2035694122314 Hour:  0 Minute:  8 Second:  47 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 188\n",
      "Epoch: [188][0/9]\tLoss 0.4753 (0.4753)\taccuracy 84.375 (84.375)\tf1_score 83.586 (83.586)\n",
      "Epoch: [188][5/9]\tLoss 0.4838 (0.3844)\taccuracy 81.250 (87.240)\tf1_score 81.928 (86.688)\n",
      " Test: accuracy 54.688 f1_score 49.618\n",
      "Training time:  529.7977240085602 Hour:  0 Minute:  8 Second:  49 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 189\n",
      "Epoch: [189][0/9]\tLoss 0.2203 (0.2203)\taccuracy 89.844 (89.844)\tf1_score 89.992 (89.992)\n",
      "Epoch: [189][5/9]\tLoss 0.2246 (0.2203)\taccuracy 93.750 (90.625)\tf1_score 92.202 (90.362)\n",
      " Test: accuracy 59.766 f1_score 57.237\n",
      "Training time:  532.3695313930511 Hour:  0 Minute:  8 Second:  52 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 190\n",
      "Epoch: [190][0/9]\tLoss 0.1344 (0.1344)\taccuracy 95.312 (95.312)\tf1_score 94.539 (94.539)\n",
      "Epoch: [190][5/9]\tLoss 0.2827 (0.2079)\taccuracy 92.188 (93.229)\tf1_score 90.566 (92.381)\n",
      " Test: accuracy 61.719 f1_score 57.347\n",
      "Training time:  534.9847257137299 Hour:  0 Minute:  8 Second:  54 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 191\n",
      "Epoch: [191][0/9]\tLoss 0.1499 (0.1499)\taccuracy 96.094 (96.094)\tf1_score 95.941 (95.941)\n",
      "Epoch: [191][5/9]\tLoss 0.2323 (0.1560)\taccuracy 91.406 (94.922)\tf1_score 91.833 (94.880)\n",
      " Test: accuracy 66.797 f1_score 60.895\n",
      "Training time:  537.575660943985 Hour:  0 Minute:  8 Second:  57 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 192\n",
      "Epoch: [192][0/9]\tLoss 0.0976 (0.0976)\taccuracy 97.656 (97.656)\tf1_score 97.253 (97.253)\n",
      "Epoch: [192][5/9]\tLoss 0.1447 (0.1650)\taccuracy 96.094 (94.010)\tf1_score 95.253 (93.604)\n",
      " Test: accuracy 57.031 f1_score 52.328\n",
      "Training time:  540.1733231544495 Hour:  0 Minute:  9 Second:  0 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 193\n",
      "Epoch: [193][0/9]\tLoss 0.1405 (0.1405)\taccuracy 92.969 (92.969)\tf1_score 93.174 (93.174)\n",
      "Epoch: [193][5/9]\tLoss 0.1099 (0.1599)\taccuracy 97.656 (94.531)\tf1_score 98.204 (93.884)\n",
      " Test: accuracy 14.453 f1_score 12.865\n",
      "Training time:  542.8338820934296 Hour:  0 Minute:  9 Second:  2 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 194\n",
      "Epoch: [194][0/9]\tLoss 0.3702 (0.3702)\taccuracy 89.062 (89.062)\tf1_score 88.488 (88.488)\n",
      "Epoch: [194][5/9]\tLoss 0.5188 (0.5425)\taccuracy 82.031 (81.771)\tf1_score 83.497 (79.782)\n",
      " Test: accuracy 46.875 f1_score 42.846\n",
      "Training time:  545.4963808059692 Hour:  0 Minute:  9 Second:  5 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 195\n",
      "Epoch: [195][0/9]\tLoss 0.3120 (0.3120)\taccuracy 91.406 (91.406)\tf1_score 91.570 (91.570)\n",
      "Epoch: [195][5/9]\tLoss 0.3910 (0.3488)\taccuracy 89.062 (87.630)\tf1_score 88.277 (86.404)\n",
      " Test: accuracy 35.547 f1_score 31.446\n",
      "Training time:  548.2781167030334 Hour:  0 Minute:  9 Second:  8 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 196\n",
      "Epoch: [196][0/9]\tLoss 0.2649 (0.2649)\taccuracy 88.281 (88.281)\tf1_score 88.872 (88.872)\n",
      "Epoch: [196][5/9]\tLoss 0.2132 (0.2989)\taccuracy 92.188 (89.844)\tf1_score 91.508 (89.836)\n",
      " Test: accuracy 67.578 f1_score 63.604\n",
      "Training time:  551.0229845046997 Hour:  0 Minute:  9 Second:  11 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 197\n",
      "Epoch: [197][0/9]\tLoss 0.1370 (0.1370)\taccuracy 94.531 (94.531)\tf1_score 92.063 (92.063)\n",
      "Epoch: [197][5/9]\tLoss 0.6321 (0.2578)\taccuracy 82.031 (91.016)\tf1_score 85.648 (90.582)\n",
      " Test: accuracy 52.344 f1_score 46.678\n",
      "Training time:  553.7483341693878 Hour:  0 Minute:  9 Second:  13 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 198\n",
      "Epoch: [198][0/9]\tLoss 0.2246 (0.2246)\taccuracy 92.969 (92.969)\tf1_score 93.195 (93.195)\n",
      "Epoch: [198][5/9]\tLoss 0.2538 (0.2641)\taccuracy 89.062 (89.453)\tf1_score 89.833 (89.756)\n",
      " Test: accuracy 59.375 f1_score 52.496\n",
      "Training time:  556.3843805789948 Hour:  0 Minute:  9 Second:  16 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 199\n",
      "Epoch: [199][0/9]\tLoss 0.1573 (0.1573)\taccuracy 92.969 (92.969)\tf1_score 92.551 (92.551)\n",
      "Epoch: [199][5/9]\tLoss 0.2150 (0.2125)\taccuracy 91.406 (91.276)\tf1_score 91.168 (91.755)\n",
      " Test: accuracy 69.141 f1_score 66.922\n",
      "Training time:  559.0674104690552 Hour:  0 Minute:  9 Second:  19 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 200\n",
      "Epoch: [200][0/9]\tLoss 0.1897 (0.1897)\taccuracy 92.188 (92.188)\tf1_score 88.853 (88.853)\n",
      "Epoch: [200][5/9]\tLoss 0.1868 (0.2081)\taccuracy 96.094 (92.448)\tf1_score 94.329 (91.406)\n",
      " Test: accuracy 47.266 f1_score 42.482\n",
      "Training time:  561.7665069103241 Hour:  0 Minute:  9 Second:  21 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 201\n",
      "Epoch: [201][0/9]\tLoss 0.1273 (0.1273)\taccuracy 95.312 (95.312)\tf1_score 95.178 (95.178)\n",
      "Epoch: [201][5/9]\tLoss 0.2048 (0.1531)\taccuracy 90.625 (93.490)\tf1_score 90.503 (92.128)\n",
      " Test: accuracy 60.938 f1_score 57.293\n",
      "Training time:  564.4084782600403 Hour:  0 Minute:  9 Second:  24 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 202\n",
      "Epoch: [202][0/9]\tLoss 0.1450 (0.1450)\taccuracy 96.875 (96.875)\tf1_score 96.939 (96.939)\n",
      "Epoch: [202][5/9]\tLoss 0.0791 (0.1704)\taccuracy 97.656 (93.490)\tf1_score 97.116 (93.187)\n",
      " Test: accuracy 68.750 f1_score 65.633\n",
      "Training time:  567.0992777347565 Hour:  0 Minute:  9 Second:  27 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 203\n",
      "Epoch: [203][0/9]\tLoss 0.1556 (0.1556)\taccuracy 92.969 (92.969)\tf1_score 93.358 (93.358)\n",
      "Epoch: [203][5/9]\tLoss 0.1520 (0.1337)\taccuracy 92.188 (94.531)\tf1_score 92.985 (94.356)\n",
      " Test: accuracy 73.438 f1_score 72.408\n",
      "Training time:  569.7441725730896 Hour:  0 Minute:  9 Second:  29 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 204\n",
      "Epoch: [204][0/9]\tLoss 0.1816 (0.1816)\taccuracy 90.625 (90.625)\tf1_score 90.024 (90.024)\n",
      "Epoch: [204][5/9]\tLoss 0.0935 (0.1220)\taccuracy 97.656 (95.443)\tf1_score 96.834 (95.387)\n",
      " Test: accuracy 47.656 f1_score 42.223\n",
      "Training time:  572.3832674026489 Hour:  0 Minute:  9 Second:  32 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 205\n",
      "Epoch: [205][0/9]\tLoss 0.0607 (0.0607)\taccuracy 97.656 (97.656)\tf1_score 97.553 (97.553)\n",
      "Epoch: [205][5/9]\tLoss 0.1127 (0.1210)\taccuracy 95.312 (95.182)\tf1_score 94.442 (94.695)\n",
      " Test: accuracy 68.750 f1_score 66.955\n",
      "Training time:  575.0000441074371 Hour:  0 Minute:  9 Second:  35 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 206\n",
      "Epoch: [206][0/9]\tLoss 0.2609 (0.2609)\taccuracy 93.750 (93.750)\tf1_score 93.077 (93.077)\n",
      "Epoch: [206][5/9]\tLoss 0.1071 (0.1452)\taccuracy 96.094 (95.443)\tf1_score 96.568 (95.363)\n",
      " Test: accuracy 55.078 f1_score 50.097\n",
      "Training time:  577.7057869434357 Hour:  0 Minute:  9 Second:  37 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 207\n",
      "Epoch: [207][0/9]\tLoss 0.0633 (0.0633)\taccuracy 98.438 (98.438)\tf1_score 98.488 (98.488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [207][5/9]\tLoss 0.1614 (0.1597)\taccuracy 92.188 (93.229)\tf1_score 89.422 (92.935)\n",
      " Test: accuracy 60.938 f1_score 60.110\n",
      "Training time:  580.2798676490784 Hour:  0 Minute:  9 Second:  40 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 208\n",
      "Epoch: [208][0/9]\tLoss 0.0905 (0.0905)\taccuracy 96.875 (96.875)\tf1_score 96.313 (96.313)\n",
      "Epoch: [208][5/9]\tLoss 0.0879 (0.1153)\taccuracy 96.875 (95.443)\tf1_score 96.856 (94.651)\n",
      " Test: accuracy 67.969 f1_score 65.409\n",
      "Training time:  582.8759574890137 Hour:  0 Minute:  9 Second:  42 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 209\n",
      "Epoch: [209][0/9]\tLoss 0.1399 (0.1399)\taccuracy 95.312 (95.312)\tf1_score 94.461 (94.461)\n",
      "Epoch: [209][5/9]\tLoss 0.3117 (0.1513)\taccuracy 84.375 (93.880)\tf1_score 86.457 (93.198)\n",
      " Test: accuracy 63.281 f1_score 57.908\n",
      "Training time:  585.471962928772 Hour:  0 Minute:  9 Second:  45 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 210\n",
      "Epoch: [210][0/9]\tLoss 0.1370 (0.1370)\taccuracy 93.750 (93.750)\tf1_score 93.898 (93.898)\n",
      "Epoch: [210][5/9]\tLoss 0.0522 (0.1038)\taccuracy 100.000 (95.703)\tf1_score 100.000 (95.587)\n",
      " Test: accuracy 67.578 f1_score 64.479\n",
      "Training time:  588.0940506458282 Hour:  0 Minute:  9 Second:  48 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 211\n",
      "Epoch: [211][0/9]\tLoss 0.1220 (0.1220)\taccuracy 95.312 (95.312)\tf1_score 95.784 (95.784)\n",
      "Epoch: [211][5/9]\tLoss 0.1539 (0.1079)\taccuracy 94.531 (95.964)\tf1_score 94.061 (95.998)\n",
      " Test: accuracy 62.109 f1_score 58.120\n",
      "Training time:  590.691103219986 Hour:  0 Minute:  9 Second:  50 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 212\n",
      "Epoch: [212][0/9]\tLoss 0.1264 (0.1264)\taccuracy 94.531 (94.531)\tf1_score 95.095 (95.095)\n",
      "Epoch: [212][5/9]\tLoss 0.0560 (0.1083)\taccuracy 96.875 (95.312)\tf1_score 95.571 (94.617)\n",
      " Test: accuracy 69.531 f1_score 67.521\n",
      "Training time:  593.2876832485199 Hour:  0 Minute:  9 Second:  53 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 213\n",
      "Epoch: [213][0/9]\tLoss 0.1092 (0.1092)\taccuracy 95.312 (95.312)\tf1_score 94.639 (94.639)\n",
      "Epoch: [213][5/9]\tLoss 0.1215 (0.1223)\taccuracy 96.875 (94.922)\tf1_score 97.337 (94.870)\n",
      " Test: accuracy 71.484 f1_score 70.714\n",
      "Training time:  595.881275177002 Hour:  0 Minute:  9 Second:  55 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 214\n",
      "Epoch: [214][0/9]\tLoss 0.0540 (0.0540)\taccuracy 98.438 (98.438)\tf1_score 97.729 (97.729)\n",
      "Epoch: [214][5/9]\tLoss 0.0639 (0.0751)\taccuracy 96.875 (97.526)\tf1_score 94.752 (96.465)\n",
      " Test: accuracy 48.438 f1_score 43.842\n",
      "Training time:  598.4543921947479 Hour:  0 Minute:  9 Second:  58 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 215\n",
      "Epoch: [215][0/9]\tLoss 0.0941 (0.0941)\taccuracy 96.094 (96.094)\tf1_score 95.852 (95.852)\n",
      "Epoch: [215][5/9]\tLoss 0.2633 (0.1546)\taccuracy 91.406 (94.661)\tf1_score 89.778 (93.912)\n",
      " Test: accuracy 73.438 f1_score 72.394\n",
      "Training time:  601.0295052528381 Hour:  0 Minute:  10 Second:  1 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 216\n",
      "Epoch: [216][0/9]\tLoss 0.1226 (0.1226)\taccuracy 96.094 (96.094)\tf1_score 95.779 (95.779)\n",
      "Epoch: [216][5/9]\tLoss 0.1790 (0.1390)\taccuracy 90.625 (94.401)\tf1_score 89.390 (93.949)\n",
      " Test: accuracy 63.672 f1_score 60.873\n",
      "Training time:  603.6674156188965 Hour:  0 Minute:  10 Second:  3 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 217\n",
      "Epoch: [217][0/9]\tLoss 0.0991 (0.0991)\taccuracy 95.312 (95.312)\tf1_score 95.321 (95.321)\n",
      "Epoch: [217][5/9]\tLoss 0.3048 (0.1352)\taccuracy 87.500 (94.661)\tf1_score 86.381 (94.487)\n",
      " Test: accuracy 46.875 f1_score 41.139\n",
      "Training time:  606.2609741687775 Hour:  0 Minute:  10 Second:  6 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 218\n",
      "Epoch: [218][0/9]\tLoss 0.0758 (0.0758)\taccuracy 96.875 (96.875)\tf1_score 96.414 (96.414)\n",
      "Epoch: [218][5/9]\tLoss 0.1391 (0.1342)\taccuracy 92.969 (94.401)\tf1_score 92.222 (93.551)\n",
      " Test: accuracy 62.500 f1_score 62.483\n",
      "Training time:  608.8550806045532 Hour:  0 Minute:  10 Second:  8 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 219\n",
      "Epoch: [219][0/9]\tLoss 0.1688 (0.1688)\taccuracy 92.969 (92.969)\tf1_score 94.337 (94.337)\n",
      "Epoch: [219][5/9]\tLoss 0.1236 (0.1291)\taccuracy 96.875 (95.312)\tf1_score 96.133 (95.298)\n",
      " Test: accuracy 71.094 f1_score 70.027\n",
      "Training time:  611.4343094825745 Hour:  0 Minute:  10 Second:  11 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 220\n",
      "Epoch: [220][0/9]\tLoss 0.2054 (0.2054)\taccuracy 90.625 (90.625)\tf1_score 90.855 (90.855)\n",
      "Epoch: [220][5/9]\tLoss 0.0902 (0.1177)\taccuracy 97.656 (95.833)\tf1_score 97.490 (95.509)\n",
      " Test: accuracy 64.453 f1_score 60.063\n",
      "Training time:  614.0063962936401 Hour:  0 Minute:  10 Second:  14 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 221\n",
      "Epoch: [221][0/9]\tLoss 0.1638 (0.1638)\taccuracy 94.531 (94.531)\tf1_score 94.285 (94.285)\n",
      "Epoch: [221][5/9]\tLoss 0.1185 (0.1070)\taccuracy 96.094 (96.615)\tf1_score 94.646 (95.735)\n",
      " Test: accuracy 67.578 f1_score 64.313\n",
      "Training time:  616.5735621452332 Hour:  0 Minute:  10 Second:  16 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 222\n",
      "Epoch: [222][0/9]\tLoss 0.0764 (0.0764)\taccuracy 96.094 (96.094)\tf1_score 95.966 (95.966)\n",
      "Epoch: [222][5/9]\tLoss 0.1189 (0.0835)\taccuracy 96.875 (97.135)\tf1_score 96.655 (97.137)\n",
      " Test: accuracy 71.875 f1_score 70.924\n",
      "Training time:  619.1557052135468 Hour:  0 Minute:  10 Second:  19 Test best accuracy: 74.609375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 223\n",
      "Epoch: [223][0/9]\tLoss 0.0822 (0.0822)\taccuracy 97.656 (97.656)\tf1_score 98.227 (98.227)\n",
      "Epoch: [223][5/9]\tLoss 0.0451 (0.0835)\taccuracy 99.219 (97.396)\tf1_score 99.250 (97.260)\n",
      " Test: accuracy 75.000 f1_score 74.271\n",
      "Training time:  621.7662129402161 Hour:  0 Minute:  10 Second:  21 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 224\n",
      "Epoch: [224][0/9]\tLoss 0.0789 (0.0789)\taccuracy 96.094 (96.094)\tf1_score 96.588 (96.588)\n",
      "Epoch: [224][5/9]\tLoss 0.1036 (0.1066)\taccuracy 95.312 (95.312)\tf1_score 95.553 (95.460)\n",
      " Test: accuracy 66.406 f1_score 65.462\n",
      "Training time:  624.4366247653961 Hour:  0 Minute:  10 Second:  24 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 225\n",
      "Epoch: [225][0/9]\tLoss 0.1657 (0.1657)\taccuracy 93.750 (93.750)\tf1_score 95.208 (95.208)\n",
      "Epoch: [225][5/9]\tLoss 0.0736 (0.1180)\taccuracy 98.438 (95.182)\tf1_score 97.511 (95.442)\n",
      " Test: accuracy 62.891 f1_score 58.045\n",
      "Training time:  627.0486381053925 Hour:  0 Minute:  10 Second:  27 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 226\n",
      "Epoch: [226][0/9]\tLoss 0.0759 (0.0759)\taccuracy 96.094 (96.094)\tf1_score 95.563 (95.563)\n",
      "Epoch: [226][5/9]\tLoss 0.0456 (0.0823)\taccuracy 99.219 (96.875)\tf1_score 99.354 (96.800)\n",
      " Test: accuracy 73.828 f1_score 72.829\n",
      "Training time:  629.6267440319061 Hour:  0 Minute:  10 Second:  29 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 227\n",
      "Epoch: [227][0/9]\tLoss 0.0874 (0.0874)\taccuracy 96.875 (96.875)\tf1_score 95.435 (95.435)\n",
      "Epoch: [227][5/9]\tLoss 0.1243 (0.0934)\taccuracy 96.094 (96.354)\tf1_score 97.007 (96.010)\n",
      " Test: accuracy 67.578 f1_score 63.973\n",
      "Training time:  632.1908848285675 Hour:  0 Minute:  10 Second:  32 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 228\n",
      "Epoch: [228][0/9]\tLoss 0.1082 (0.1082)\taccuracy 96.875 (96.875)\tf1_score 95.842 (95.842)\n",
      "Epoch: [228][5/9]\tLoss 0.1084 (0.0935)\taccuracy 96.875 (96.615)\tf1_score 96.304 (96.158)\n",
      " Test: accuracy 64.453 f1_score 62.062\n",
      "Training time:  634.7739734649658 Hour:  0 Minute:  10 Second:  34 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 229\n",
      "Epoch: [229][0/9]\tLoss 0.0527 (0.0527)\taccuracy 97.656 (97.656)\tf1_score 97.451 (97.451)\n",
      "Epoch: [229][5/9]\tLoss 0.0904 (0.0720)\taccuracy 96.875 (97.396)\tf1_score 96.636 (97.027)\n",
      " Test: accuracy 57.031 f1_score 51.716\n",
      "Training time:  637.3490855693817 Hour:  0 Minute:  10 Second:  37 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 230\n",
      "Epoch: [230][0/9]\tLoss 0.0765 (0.0765)\taccuracy 96.875 (96.875)\tf1_score 96.789 (96.789)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [230][5/9]\tLoss 0.1260 (0.0844)\taccuracy 96.094 (97.135)\tf1_score 94.529 (96.697)\n",
      " Test: accuracy 68.750 f1_score 67.152\n",
      "Training time:  640.0110812187195 Hour:  0 Minute:  10 Second:  40 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 231\n",
      "Epoch: [231][0/9]\tLoss 0.0570 (0.0570)\taccuracy 98.438 (98.438)\tf1_score 98.606 (98.606)\n",
      "Epoch: [231][5/9]\tLoss 0.0418 (0.0684)\taccuracy 98.438 (97.786)\tf1_score 97.821 (97.560)\n",
      " Test: accuracy 67.188 f1_score 64.747\n",
      "Training time:  642.5985219478607 Hour:  0 Minute:  10 Second:  42 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 232\n",
      "Epoch: [232][0/9]\tLoss 0.0943 (0.0943)\taccuracy 96.875 (96.875)\tf1_score 95.085 (95.085)\n",
      "Epoch: [232][5/9]\tLoss 0.0557 (0.0685)\taccuracy 97.656 (97.135)\tf1_score 97.451 (96.792)\n",
      " Test: accuracy 53.516 f1_score 49.040\n",
      "Training time:  645.1825771331787 Hour:  0 Minute:  10 Second:  45 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 233\n",
      "Epoch: [233][0/9]\tLoss 0.0428 (0.0428)\taccuracy 98.438 (98.438)\tf1_score 98.456 (98.456)\n",
      "Epoch: [233][5/9]\tLoss 0.1120 (0.0711)\taccuracy 95.312 (97.135)\tf1_score 95.309 (97.289)\n",
      " Test: accuracy 58.203 f1_score 53.508\n",
      "Training time:  647.7856471538544 Hour:  0 Minute:  10 Second:  47 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 234\n",
      "Epoch: [234][0/9]\tLoss 0.0568 (0.0568)\taccuracy 99.219 (99.219)\tf1_score 99.212 (99.212)\n",
      "Epoch: [234][5/9]\tLoss 0.1062 (0.0773)\taccuracy 96.094 (97.396)\tf1_score 96.621 (97.157)\n",
      " Test: accuracy 74.609 f1_score 73.791\n",
      "Training time:  650.4445016384125 Hour:  0 Minute:  10 Second:  50 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 235\n",
      "Epoch: [235][0/9]\tLoss 0.0817 (0.0817)\taccuracy 96.094 (96.094)\tf1_score 96.581 (96.581)\n",
      "Epoch: [235][5/9]\tLoss 0.1012 (0.0934)\taccuracy 96.875 (96.745)\tf1_score 97.214 (96.233)\n",
      " Test: accuracy 74.219 f1_score 73.358\n",
      "Training time:  653.0231418609619 Hour:  0 Minute:  10 Second:  53 Test best accuracy: 75.0  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 236\n",
      "Epoch: [236][0/9]\tLoss 0.0682 (0.0682)\taccuracy 97.656 (97.656)\tf1_score 97.379 (97.379)\n",
      "Epoch: [236][5/9]\tLoss 0.0892 (0.0873)\taccuracy 95.312 (96.745)\tf1_score 95.375 (96.398)\n",
      " Test: accuracy 78.906 f1_score 78.141\n",
      "Training time:  655.6331632137299 Hour:  0 Minute:  10 Second:  55 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 237\n",
      "Epoch: [237][0/9]\tLoss 0.0776 (0.0776)\taccuracy 96.094 (96.094)\tf1_score 96.715 (96.715)\n",
      "Epoch: [237][5/9]\tLoss 0.1194 (0.0823)\taccuracy 96.094 (97.005)\tf1_score 95.384 (96.827)\n",
      " Test: accuracy 52.734 f1_score 48.473\n",
      "Training time:  658.2511584758759 Hour:  0 Minute:  10 Second:  58 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 238\n",
      "Epoch: [238][0/9]\tLoss 0.1324 (0.1324)\taccuracy 97.656 (97.656)\tf1_score 96.296 (96.296)\n",
      "Epoch: [238][5/9]\tLoss 0.1241 (0.1053)\taccuracy 94.531 (95.964)\tf1_score 95.830 (95.723)\n",
      " Test: accuracy 68.750 f1_score 66.227\n",
      "Training time:  660.8644909858704 Hour:  0 Minute:  11 Second:  0 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 239\n",
      "Epoch: [239][0/9]\tLoss 0.0880 (0.0880)\taccuracy 96.875 (96.875)\tf1_score 97.014 (97.014)\n",
      "Epoch: [239][5/9]\tLoss 0.0959 (0.0867)\taccuracy 96.094 (96.745)\tf1_score 96.808 (96.714)\n",
      " Test: accuracy 55.859 f1_score 51.119\n",
      "Training time:  663.5188457965851 Hour:  0 Minute:  11 Second:  3 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 240\n",
      "Epoch: [240][0/9]\tLoss 0.1682 (0.1682)\taccuracy 93.750 (93.750)\tf1_score 93.824 (93.824)\n",
      "Epoch: [240][5/9]\tLoss 0.1711 (0.1380)\taccuracy 91.406 (94.922)\tf1_score 91.484 (94.637)\n",
      " Test: accuracy 66.016 f1_score 61.653\n",
      "Training time:  666.1705651283264 Hour:  0 Minute:  11 Second:  6 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 241\n",
      "Epoch: [241][0/9]\tLoss 0.0756 (0.0756)\taccuracy 97.656 (97.656)\tf1_score 97.609 (97.609)\n",
      "Epoch: [241][5/9]\tLoss 0.1838 (0.1372)\taccuracy 94.531 (95.703)\tf1_score 94.386 (95.635)\n",
      " Test: accuracy 62.891 f1_score 60.833\n",
      "Training time:  668.9619538784027 Hour:  0 Minute:  11 Second:  8 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 242\n",
      "Epoch: [242][0/9]\tLoss 0.0426 (0.0426)\taccuracy 99.219 (99.219)\tf1_score 99.250 (99.250)\n",
      "Epoch: [242][5/9]\tLoss 0.0695 (0.1250)\taccuracy 96.875 (95.833)\tf1_score 95.748 (95.716)\n",
      " Test: accuracy 68.750 f1_score 66.847\n",
      "Training time:  671.6292214393616 Hour:  0 Minute:  11 Second:  11 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 243\n",
      "Epoch: [243][0/9]\tLoss 0.0626 (0.0626)\taccuracy 99.219 (99.219)\tf1_score 99.002 (99.002)\n",
      "Epoch: [243][5/9]\tLoss 0.1374 (0.0990)\taccuracy 96.094 (96.745)\tf1_score 95.756 (96.392)\n",
      " Test: accuracy 53.125 f1_score 47.468\n",
      "Training time:  674.2537205219269 Hour:  0 Minute:  11 Second:  14 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 244\n",
      "Epoch: [244][0/9]\tLoss 0.1163 (0.1163)\taccuracy 94.531 (94.531)\tf1_score 94.815 (94.815)\n",
      "Epoch: [244][5/9]\tLoss 0.0925 (0.1047)\taccuracy 96.875 (95.573)\tf1_score 95.094 (95.457)\n",
      " Test: accuracy 41.797 f1_score 37.186\n",
      "Training time:  676.910614490509 Hour:  0 Minute:  11 Second:  16 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 245\n",
      "Epoch: [245][0/9]\tLoss 0.3969 (0.3969)\taccuracy 92.188 (92.188)\tf1_score 87.259 (87.259)\n",
      "Epoch: [245][5/9]\tLoss 0.1127 (0.1622)\taccuracy 95.312 (95.573)\tf1_score 95.460 (94.363)\n",
      " Test: accuracy 53.516 f1_score 49.876\n",
      "Training time:  679.6011970043182 Hour:  0 Minute:  11 Second:  19 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 246\n",
      "Epoch: [246][0/9]\tLoss 0.0692 (0.0692)\taccuracy 95.312 (95.312)\tf1_score 94.777 (94.777)\n",
      "Epoch: [246][5/9]\tLoss 0.2483 (0.1141)\taccuracy 91.406 (95.312)\tf1_score 91.526 (94.982)\n",
      " Test: accuracy 69.531 f1_score 67.949\n",
      "Training time:  682.3381385803223 Hour:  0 Minute:  11 Second:  22 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 247\n",
      "Epoch: [247][0/9]\tLoss 0.0307 (0.0307)\taccuracy 99.219 (99.219)\tf1_score 99.191 (99.191)\n",
      "Epoch: [247][5/9]\tLoss 0.2709 (0.1281)\taccuracy 91.406 (95.443)\tf1_score 87.927 (93.800)\n",
      " Test: accuracy 57.812 f1_score 52.469\n",
      "Training time:  685.1018259525299 Hour:  0 Minute:  11 Second:  25 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 248\n",
      "Epoch: [248][0/9]\tLoss 0.0807 (0.0807)\taccuracy 96.875 (96.875)\tf1_score 96.212 (96.212)\n",
      "Epoch: [248][5/9]\tLoss 0.0916 (0.0959)\taccuracy 97.656 (96.615)\tf1_score 97.709 (96.566)\n",
      " Test: accuracy 57.812 f1_score 53.394\n",
      "Training time:  687.8652188777924 Hour:  0 Minute:  11 Second:  27 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 249\n",
      "Epoch: [249][0/9]\tLoss 0.0979 (0.0979)\taccuracy 97.656 (97.656)\tf1_score 97.909 (97.909)\n",
      "Epoch: [249][5/9]\tLoss 0.1276 (0.0952)\taccuracy 96.094 (97.135)\tf1_score 91.876 (96.373)\n",
      " Test: accuracy 68.750 f1_score 65.619\n",
      "Training time:  690.6625070571899 Hour:  0 Minute:  11 Second:  30 Test best accuracy: 78.90625  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 250\n",
      "Epoch: [250][0/9]\tLoss 0.0536 (0.0536)\taccuracy 98.438 (98.438)\tf1_score 98.163 (98.163)\n",
      "Epoch: [250][5/9]\tLoss 0.2375 (0.0911)\taccuracy 89.062 (95.573)\tf1_score 88.281 (94.893)\n",
      " Test: accuracy 56.641 f1_score 52.245\n",
      "Training time:  693.3147850036621 Hour:  0 Minute:  11 Second:  33 Test best accuracy: 78.90625  Test best f1 score: 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch NO: %d\" % (epoch,))\n",
    "    adjust_learning_rate(optimizer, epoch, args=1)\n",
    "    train(train_loader, model, criterion,  optimizer, epoch, print_interval=5)\n",
    "    acc, f1 = validate(test_loader, model, criterion,  args=1)\n",
    "    \n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "            \n",
    "    time_interval = time.time() - start_time\n",
    "    time_split = time.gmtime(time_interval)\n",
    "    print(\"Training time: \", time_interval, \"Hour: \", time_split.tm_hour, \"Minute: \", time_split.tm_min, \"Second: \",\n",
    "              time_split.tm_sec, end='')\n",
    "    print(\" Test best accuracy:\", best_acc, \" Test best f1 score:\", best_f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d948cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba691b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
