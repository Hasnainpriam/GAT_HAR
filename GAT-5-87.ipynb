{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f288f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0017ca5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class\n",
       "0                0  2.660984 -9.653030  0.470237      1\n",
       "1                1  2.223091 -9.432167  2.223091      1\n",
       "2                2  2.098372 -9.481953  0.926070      1\n",
       "3                3  2.716461 -9.739352  0.912008      1\n",
       "4                4  2.288388 -9.371498  0.910390      1\n",
       "...            ...       ...       ...       ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21\n",
       "155403      155403  8.680778  4.261679 -0.159214     21\n",
       "155404      155404  8.756194  4.168306 -0.144251     21\n",
       "155405      155405  8.662222  4.219781 -0.183755     21\n",
       "155406      155406  8.738238  4.180277 -0.201711     21\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('no-outlier.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c51b238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>155402</td>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>155403</td>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>155404</td>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>155405</td>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>155406</td>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0                0  2.660984 -9.653030  0.470237      1      0\n",
       "1                1  2.223091 -9.432167  2.223091      1      0\n",
       "2                2  2.098372 -9.481953  0.926070      1      0\n",
       "3                3  2.716461 -9.739352  0.912008      1      0\n",
       "4                4  2.288388 -9.371498  0.910390      1      0\n",
       "...            ...       ...       ...       ...    ...    ...\n",
       "155402      155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403      155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404      155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405      155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406      155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = LabelEncoder()\n",
    "data['label'] = label.fit_transform(data['Class'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c6752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "fig=sns.boxplot(data=data.iloc[0:8000,1:4],whis=[0, 100])\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777795b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.660984</td>\n",
       "      <td>-9.653030</td>\n",
       "      <td>0.470237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223091</td>\n",
       "      <td>-9.432167</td>\n",
       "      <td>2.223091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.098372</td>\n",
       "      <td>-9.481953</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.716461</td>\n",
       "      <td>-9.739352</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.288388</td>\n",
       "      <td>-9.371498</td>\n",
       "      <td>0.910390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>8.701128</td>\n",
       "      <td>4.238336</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>8.680778</td>\n",
       "      <td>4.261679</td>\n",
       "      <td>-0.159214</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>8.756194</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>-0.144251</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>8.662222</td>\n",
       "      <td>4.219781</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>8.738238</td>\n",
       "      <td>4.180277</td>\n",
       "      <td>-0.201711</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acc_X     Acc_Y     Acc_Z  Class  label\n",
       "0       2.660984 -9.653030  0.470237      1      0\n",
       "1       2.223091 -9.432167  2.223091      1      0\n",
       "2       2.098372 -9.481953  0.926070      1      0\n",
       "3       2.716461 -9.739352  0.912008      1      0\n",
       "4       2.288388 -9.371498  0.910390      1      0\n",
       "...          ...       ...       ...    ...    ...\n",
       "155402  8.701128  4.238336 -0.194529     21     20\n",
       "155403  8.680778  4.261679 -0.159214     21     20\n",
       "155404  8.756194  4.168306 -0.144251     21     20\n",
       "155405  8.662222  4.219781 -0.183755     21     20\n",
       "155406  8.738238  4.180277 -0.201711     21     20\n",
       "\n",
       "[155407 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = data.drop('Unnamed: 0', axis=1)  \n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cce5ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bcdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn[['Acc_X', 'Acc_Y', 'Acc_Z']]\n",
    "y = dfn['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346d3bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985481</td>\n",
       "      <td>-0.807007</td>\n",
       "      <td>-0.491449</td>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865844</td>\n",
       "      <td>-0.763546</td>\n",
       "      <td>-0.059973</td>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.773343</td>\n",
       "      <td>-0.379243</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000638</td>\n",
       "      <td>-0.823993</td>\n",
       "      <td>-0.382704</td>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883684</td>\n",
       "      <td>-0.751608</td>\n",
       "      <td>-0.383103</td>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acc_X     Acc_Y     Acc_Z       mag  label\n",
       "0  0.985481 -0.807007 -0.491449  1.365267      0\n",
       "1  0.865844 -0.763546 -0.059973  1.155978      0\n",
       "2  0.831769 -0.773343 -0.379243  1.197382      0\n",
       "3  1.000638 -0.823993 -0.382704  1.351556      0\n",
       "4  0.883684 -0.751608 -0.383103  1.221712      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = ['Acc_X', 'Acc_Y', 'Acc_Z'])\n",
    "scaled_X['mag'] = np.sqrt(scaled_X['Acc_X'] ** 2 + scaled_X['Acc_Y'] ** 2 + scaled_X['Acc_Z'] ** 2)\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f2b34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.365267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.155978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.197382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.221712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155402</th>\n",
       "      <td>3.329777</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>3.326341</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155404</th>\n",
       "      <td>3.331364</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155405</th>\n",
       "      <td>3.318731</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155406</th>\n",
       "      <td>3.331576</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mag  label\n",
       "0       1.365267      0\n",
       "1       1.155978      0\n",
       "2       1.197382      0\n",
       "3       1.351556      0\n",
       "4       1.221712      0\n",
       "...          ...    ...\n",
       "155402  3.329777     20\n",
       "155403  3.326341     20\n",
       "155404  3.331364     20\n",
       "155405  3.318731     20\n",
       "155406  3.331576     20\n",
       "\n",
       "[155407 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X = scaled_X.drop(['Acc_X', 'Acc_Y', 'Acc_Z'], axis=1)\n",
    "\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d53643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a1152f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer Nitro 5\\AppData\\Local\\Temp\\ipykernel_4260\\1805871090.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n"
     ]
    }
   ],
   "source": [
    "Fs = 20\n",
    "frame_size = Fs * 20\n",
    "hop_size = Fs * 1\n",
    "frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(scaled_X) - frame_size, hop_size):\n",
    "    x = scaled_X['mag'].values[i: i + frame_size]\n",
    "    label = stats.mode(scaled_X['label'][i: i + frame_size])[0][0]\n",
    "    frames.append([x])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "194a32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.asarray(frames).reshape(-1, frame_size)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f42c64bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESHAPE SHAPE:  (7751, 400)\n",
      "LABELS:  (7751,)\n",
      "LABELS:  0\n",
      "LABELS:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"RESHAPE SHAPE: \",frames.shape)\n",
    "print(\"LABELS: \",labels.shape)\n",
    "print(\"LABELS: \",labels[0])\n",
    "print(\"LABELS: \",labels[487])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "669b01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=frames\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcde6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=123, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85780267",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files=[x_train, y_train]\n",
    "subject_files=[x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e386eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def print(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad998893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class LoadDataset_from_numpy(Dataset):\n",
    "    def __init__(self, np_data):\n",
    "        super(LoadDataset_from_numpy, self).__init__()\n",
    "        X_train = np_data[0]\n",
    "        y_train = np_data[1]\n",
    "        self.len = X_train.shape[0]\n",
    "        self.x_data = torch.from_numpy(X_train).float()\n",
    "        self.y_data = torch.from_numpy(y_train).long()\n",
    "        self.x_data = self.x_data.view(self.x_data.size()[0], 1, self.x_data.size()[1])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def data_generator_np(training_files, subject_files, batch_size):\n",
    "    train_dataset = LoadDataset_from_numpy(training_files)\n",
    "    test_dataset = LoadDataset_from_numpy(subject_files)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               drop_last=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              drop_last=True,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eaf2b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = data_generator_np(training_files, subject_files, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91118e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "\n",
    "\"\"\"\n",
    "2.1  Signal Segments Representation\n",
    "\n",
    "Signal Segment Definition: class SignalSegmentDefinition(nn.Module)\n",
    "Signal Segment Representation: class SignalSegmentRepresentation(nn.Module)\n",
    "\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.1 Global Node Attention: class GNA(nn.Module):\n",
    "\n",
    "***\n",
    "(1) Signal Segment Definition -> (2) Signal Segment Representation -> (3) Global Node Attention\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SignalSegmentDefinition(nn.Module):\n",
    "    \"\"\"\n",
    "   (1) Signal Segment Definition\n",
    "\n",
    "    input size: B, 1, 1, L\n",
    "    output size: B, K, 1, D\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = f.unfold(x, kernel_size=self.kernel_size, stride=self.stride)  # overlapping sliding window\n",
    "        b = b.permute(0, 2, 1)\n",
    "        b = b.unsqueeze(-2)\n",
    "        return b\n",
    "\n",
    "\n",
    "class SignalSegmentRepresentation(nn.Module):\n",
    "    \"\"\"\n",
    "    (2) Signal Segment Representation\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    segment_num: number of the signal segments\n",
    "\n",
    "    input size:  B, 1, 1, L\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, segment_size, overlapping_rate, segment_num):\n",
    "        super(SignalSegmentRepresentation, self).__init__()\n",
    "        self.overlapping = int(segment_size - segment_size * overlapping_rate)\n",
    "        self.segment = SignalSegmentDefinition((1, segment_size), self.overlapping)\n",
    "        self.segment2vec = SignalSegment2Vec(30)\n",
    "        self.gna = GNA(segment_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        signal_segments = []\n",
    "        x = self.segment(x)\n",
    "        x = x.squeeze()\n",
    "        \"share the SignalSegment2Vec Encoder\"\n",
    "        for idx in range(x.size()[1]):\n",
    "            data = x[:, idx, :]\n",
    "            data = data.unsqueeze(1)\n",
    "            out = self.segment2vec(data)\n",
    "            out = out.view(x.size()[0], 1, -1)\n",
    "            signal_segments.append(out)\n",
    "        signal_segments = torch.cat(signal_segments, dim=1)\n",
    "        signal_segments = signal_segments .unsqueeze(2)\n",
    "        \"global node attention\"\n",
    "        signal_segments = self.gna(signal_segments).permute(0, 2, 1, 3)\n",
    "        return signal_segments\n",
    "\n",
    "\n",
    "class GNA(nn.Module):\n",
    "    \"\"\"\n",
    "    (3) Global Node Attention\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "\n",
    "    input size: B, K, 1, C\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(GNA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SignalSegment2Vec(nn.Module):\n",
    "    \"\"\"\n",
    "    SignalSegment2Vec Encoder module in Signal Segment Representation\n",
    "\n",
    "    input size:  B, K, 1, D\n",
    "    output size: B, K, 1, C\n",
    "    \"\"\"\n",
    "    def __init__(self, afr_reduced_cnn_size):\n",
    "        super(SignalSegment2Vec, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=49, stride=6, bias=False, padding=int(49//2)),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool1d(kernel_size=7, stride=4, padding=int(7//2)),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv1d(128, 128, kernel_size=7, stride=1, bias=False, padding=int(7//2)),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=3, stride=4, padding=int(3//2)),\n",
    "        )\n",
    "\n",
    "        self.inplanes = 128\n",
    "        self.AFR = self._make_layer(ResBasicBlock, afr_reduced_cnn_size, 1)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.AFR(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"Residual Squeeze-and-Excitation(SE) Block\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class ResBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=4):\n",
    "        super(ResBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.GELU()\n",
    "        self.conv2 = nn.Conv1d(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.reslayer = ResLayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.reslayer(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0938c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2.2 Relationship Learning\n",
    "\n",
    "2.2.2 Graph-based Self Attention\n",
    "\n",
    "graph attention: class Attention(nn.Module)\n",
    "convolution-based multi-head attention: class Block(nn.Module)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention (see Eq.4)\n",
    "\n",
    "    input arg:\n",
    "    channel: number of the signal segments\n",
    "    input size:  B, M, K, C\n",
    "    output size: B, M, K, C\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((None, 1)),\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, K, _ = x.size()\n",
    "        adj = self.pearson(x)  # adjacency matrix\n",
    "        x_ = self._prepare_attentional_mechanism_input(x)\n",
    "        e = self.attn(x_)\n",
    "        e = e.permute(0, 2, 1, 3).contiguous()\n",
    "        e = e.view(B, M, K, K)\n",
    "        zero_vec_adj = -9e15 * torch.ones_like(adj)\n",
    "        attention = torch.where(adj > 0, e, zero_vec_adj)\n",
    "        attention = f.softmax(attention, dim=-1)\n",
    "        x = torch.matmul(attention, x)\n",
    "        return x, adj\n",
    "\n",
    "    def h_matmul(self, x):\n",
    "        N = x.size()[-2]\n",
    "        x_repeated_in_chunks = x.repeat_interleave(N, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, N, 1)\n",
    "        result = torch.mul(x_repeated_in_chunks, x_repeated_alternating)\n",
    "        return result\n",
    "\n",
    "    def pearson(self, x):\n",
    "        \"Pearson Correlation\"\n",
    "        centered_h = x - x.mean(dim=-1, keepdim=True)\n",
    "        covariance = self.h_matmul(centered_h).sum(dim=-1, keepdim=True)\n",
    "        bessel_corrected_covariance = torch.div(covariance, (x.shape[-1] - 1))\n",
    "        std_h = x.std(dim=-1, keepdim=True)\n",
    "        p = torch.div(bessel_corrected_covariance, (self.h_matmul(std_h)))\n",
    "        p = p.view(x.size()[0], x.size()[1], x.size()[2], -1)\n",
    "        return p\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, x):\n",
    "        \"concatenation operation (see Eq.4) with positional encoding\"\n",
    "        B, _, K, _ = x.size()\n",
    "        x_repeated_in_chunks = x.repeat_interleave(K, dim=-2)\n",
    "        x_repeated_alternating = x.repeat(1, 1, K, 1)\n",
    "\n",
    "        \"positional encoding\"\n",
    "        pos = 2 * torch.ones_like(x_repeated_alternating)\n",
    "        one_vec = torch.ones_like(x_repeated_alternating)\n",
    "        x_repeated_in_chunks.eq(x_repeated_alternating)\n",
    "        pos = torch.where(x_repeated_in_chunks.eq(x_repeated_alternating) > 0, one_vec, pos)\n",
    "        x_repeated_alternating = pos * x_repeated_alternating\n",
    "\n",
    "        all_combinations_matrix = torch.cat([x_repeated_in_chunks, x_repeated_alternating], dim=-1)\n",
    "        all_combinations_matrix = all_combinations_matrix.permute(0, 2, 1, 3)\n",
    "        return all_combinations_matrix\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention (see Fig.2)\n",
    "\n",
    "    input arg:\n",
    "    node_size: number of the signal segments\n",
    "    input_size: Q in Fig. 2\n",
    "    multi_heads: number of heads\n",
    "\n",
    "    input size: B, J, K, C    J=1 when H=1\n",
    "    output size: B, M'', K, C''\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_size, input_size, kernel_size, stride, multi_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        expand = 1\n",
    "\n",
    "        padding = kernel_size//2\n",
    "        self.mid_channels_ = (multi_heads - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "        self.multi_head = nn.Sequential(\n",
    "            nn.Conv2d(input_size, multi_heads, 1, bias=False),\n",
    "            nn.Conv2d(multi_heads, multi_heads, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                      groups=node_size, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.attn = Attention(node_size * node_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Conv2d(self.mid_channels_, self.mid_channels_ * 4, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.mid_channels_ * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.mid_channels_ * 4, multi_heads * expand, 1, bias=False),\n",
    "            nn.BatchNorm2d(multi_heads)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(node_size, node_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(node_size),\n",
    "            nn.AdaptiveAvgPool2d((1, None))\n",
    "        )\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(multi_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x.permute(0, 2, 1, 3)                 # B, J, K, C -> B, K, J, C\n",
    "        \"Dense layers\"\n",
    "        out = self.multi_head(x)                    # B, J, K, C -> B, M, K, C, where M is the number of heads\n",
    "        out, adj = self.attn(out)\n",
    "        self.adj = adj                              # for visualization\n",
    "        out = f.gelu(self.norm(out))\n",
    "        out = out.permute(0, 2, 1, 3)               # B, M, K, C -> B, K, M, C\n",
    "        \"Attention Layers\"\n",
    "        out = self.feature_extraction(out)          # B, K, M, C -> B, K, M', C'\n",
    "        out = out.permute(0, 2, 1, 3)               # B, K, M', C' -> B, M', K, C'\n",
    "        out = self.feed_forward(out)                # B, M', K, C' -> B, M'', K, C''\n",
    "        shortcut = self.shortcut(res)               # B, K, J, C -> B, 1, K, C''\n",
    "        shortcut = shortcut.permute(0, 2, 1, 3)\n",
    "        out += shortcut                             # (B, M'', K, C'') + (B, 1, K, C'') -> (B, M'', K, C'') Broadcast\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f43a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b51c7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRAPHSENSOR(nn.Module):\n",
    "    \"\"\"\n",
    "    GRAPHSENSOR main()\n",
    "\n",
    "    input arg:\n",
    "    segment_size: a single signal segment size\n",
    "    overlapping_rate: sliding window overlapping rate\n",
    "    in_channels: number of the signal segments\n",
    "    class_num: class number\n",
    "\n",
    "    input size: B, 1, L\n",
    "    output size: B, class_num\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_size, overlapping_rate, in_channels, class_num):\n",
    "        super(GRAPHSENSOR, self).__init__()\n",
    "        self.segment_size = segment_size\n",
    "        self.signal_segments = SignalSegmentRepresentation(segment_size, overlapping_rate, in_channels)\n",
    "        \"\"\"\n",
    "        The encoder is composed of a stack of H=4 identical layers\n",
    "        Multi-head number: 16 -> 32 -> 64 -> 128\n",
    "        \"\"\"\n",
    "        self.attn = nn.Sequential(\n",
    "            Block(in_channels, 1,   5, 2, 16),\n",
    "            Block(in_channels, 16,  5, 2, 32),\n",
    "            Block(in_channels, 32,  5, 1, 64),\n",
    "            Block(in_channels, 64,  5, 1, 128),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 128, 512, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(1024, class_num, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.signal_segments(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.flatten(1)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37e5c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "768d83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRAPHSENSOR(segment_size=80, overlapping_rate=0.5, in_channels=9, class_num=21).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2162450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,561,768 trainable parameter\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2613a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() >= 1:\n",
    "        print(\"num GPUs: \", torch.cuda.device_count())\n",
    "        model = nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe534d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4100232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b781d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001, amsgrad=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a427e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5e994bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch == 10:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b6d8fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9be844ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "        return correct * 100 / len(target)\n",
    "\n",
    "\n",
    "def f1_(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "    return f1_score(pred.cpu().numpy(), target.data.cpu().numpy(), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee104cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_interval):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score', ':.4e')\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        acc = accuracy_(output, target)\n",
    "        f1 = f1_(output, target) * 100\n",
    "        accuracy.update(acc, data.size(0))\n",
    "        f1_score.update(f1, data.size(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'accuracy {accuracy.val:.3f} ({accuracy.avg:.3f})\\t'\n",
    "                  'f1_score {f1_score.val:.3f} ({f1_score.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), loss=losses, accuracy=accuracy, f1_score=f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb34657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    accuracy = AverageMeter('accuracy', ':.4e')\n",
    "    f1_score = AverageMeter('f1_score ', ':.4e')\n",
    "    progress = ProgressMeter(len(val_loader), losses, accuracy, f1_score,\n",
    "                             prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            acc = accuracy_(output, target)\n",
    "            f1 = f1_(output, target) * 100\n",
    "            accuracy.update(acc, data.size(0))\n",
    "            f1_score.update(f1, data.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # TODO: this should also be done with the ProgressMeter\n",
    "        print(' Test: accuracy {accuracy.avg:.3f} f1_score {f1_score.avg:.3f}'\n",
    "              .format(accuracy=accuracy, f1_score=f1_score))\n",
    "\n",
    "        return accuracy.avg, f1_score.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9a32067",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44493805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch NO: 0\n",
      "Epoch: [0][0/96]\tLoss 1.1435 (1.1435)\taccuracy 59.375 (59.375)\tf1_score 55.548 (55.548)\n",
      "Epoch: [0][5/96]\tLoss 1.2769 (1.2443)\taccuracy 50.000 (53.125)\tf1_score 47.418 (48.371)\n",
      "Epoch: [0][10/96]\tLoss 1.1407 (1.2464)\taccuracy 57.812 (53.409)\tf1_score 50.790 (47.174)\n",
      "Epoch: [0][15/96]\tLoss 1.5796 (1.2885)\taccuracy 40.625 (50.391)\tf1_score 39.249 (44.323)\n",
      "Epoch: [0][20/96]\tLoss 1.2338 (1.2909)\taccuracy 56.250 (49.777)\tf1_score 48.008 (43.254)\n",
      "Epoch: [0][25/96]\tLoss 1.1041 (1.2907)\taccuracy 56.250 (49.519)\tf1_score 53.700 (42.855)\n",
      "Epoch: [0][30/96]\tLoss 1.1848 (1.2763)\taccuracy 57.812 (50.151)\tf1_score 42.568 (43.585)\n",
      "Epoch: [0][35/96]\tLoss 1.4136 (1.2809)\taccuracy 45.312 (49.957)\tf1_score 36.595 (43.340)\n",
      "Epoch: [0][40/96]\tLoss 1.0402 (1.2697)\taccuracy 60.938 (50.800)\tf1_score 47.657 (43.765)\n",
      "Epoch: [0][45/96]\tLoss 1.1870 (1.2624)\taccuracy 53.125 (51.155)\tf1_score 51.230 (44.244)\n",
      "Epoch: [0][50/96]\tLoss 1.1980 (1.2621)\taccuracy 51.562 (51.011)\tf1_score 41.931 (44.151)\n",
      "Epoch: [0][55/96]\tLoss 1.1084 (1.2543)\taccuracy 56.250 (50.921)\tf1_score 45.469 (44.048)\n",
      "Epoch: [0][60/96]\tLoss 1.0796 (1.2507)\taccuracy 56.250 (51.101)\tf1_score 45.675 (44.238)\n",
      "Epoch: [0][65/96]\tLoss 1.2591 (1.2433)\taccuracy 54.688 (51.539)\tf1_score 54.842 (44.670)\n",
      "Epoch: [0][70/96]\tLoss 1.3267 (1.2504)\taccuracy 43.750 (51.320)\tf1_score 38.660 (44.547)\n",
      "Epoch: [0][75/96]\tLoss 2.0207 (1.2594)\taccuracy 42.188 (51.131)\tf1_score 38.018 (44.381)\n",
      "Epoch: [0][80/96]\tLoss 1.5843 (1.2687)\taccuracy 42.188 (50.984)\tf1_score 27.142 (44.042)\n",
      "Epoch: [0][85/96]\tLoss 1.3357 (1.2701)\taccuracy 43.750 (50.981)\tf1_score 43.441 (43.932)\n",
      "Epoch: [0][90/96]\tLoss 1.3742 (1.2661)\taccuracy 50.000 (51.219)\tf1_score 44.007 (44.151)\n",
      "Epoch: [0][95/96]\tLoss 1.2164 (1.2598)\taccuracy 50.000 (51.367)\tf1_score 43.472 (44.348)\n",
      " Test: accuracy 47.070 f1_score 40.826\n",
      "Training time:  188.6093339920044 Hour:  0 Minute:  3 Second:  8 Test best accuracy: 47.0703125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 1\n",
      "Epoch: [1][0/96]\tLoss 1.3086 (1.3086)\taccuracy 46.875 (46.875)\tf1_score 42.771 (42.771)\n",
      "Epoch: [1][5/96]\tLoss 1.4444 (1.3346)\taccuracy 39.062 (47.135)\tf1_score 33.068 (39.522)\n",
      "Epoch: [1][10/96]\tLoss 1.2114 (1.2896)\taccuracy 51.562 (48.864)\tf1_score 41.519 (41.502)\n",
      "Epoch: [1][15/96]\tLoss 1.1695 (1.2754)\taccuracy 54.688 (48.633)\tf1_score 47.939 (41.409)\n",
      "Epoch: [1][20/96]\tLoss 1.0241 (1.2522)\taccuracy 59.375 (49.182)\tf1_score 49.113 (42.035)\n",
      "Epoch: [1][25/96]\tLoss 1.1089 (1.2447)\taccuracy 54.688 (49.159)\tf1_score 47.937 (42.108)\n",
      "Epoch: [1][30/96]\tLoss 1.0437 (1.2282)\taccuracy 60.938 (50.202)\tf1_score 50.341 (43.234)\n",
      "Epoch: [1][35/96]\tLoss 1.0864 (1.2130)\taccuracy 60.938 (51.476)\tf1_score 56.493 (44.457)\n",
      "Epoch: [1][40/96]\tLoss 0.8703 (1.2041)\taccuracy 70.312 (51.791)\tf1_score 64.061 (44.930)\n",
      "Epoch: [1][45/96]\tLoss 1.2155 (1.1991)\taccuracy 56.250 (51.970)\tf1_score 49.445 (45.151)\n",
      "Epoch: [1][50/96]\tLoss 1.2545 (1.1976)\taccuracy 48.438 (52.482)\tf1_score 48.674 (45.597)\n",
      "Epoch: [1][55/96]\tLoss 1.0011 (1.1859)\taccuracy 56.250 (52.595)\tf1_score 48.367 (45.822)\n",
      "Epoch: [1][60/96]\tLoss 0.9405 (1.1808)\taccuracy 53.125 (52.433)\tf1_score 52.562 (45.942)\n",
      "Epoch: [1][65/96]\tLoss 1.1288 (1.1761)\taccuracy 56.250 (52.865)\tf1_score 48.274 (45.978)\n",
      "Epoch: [1][70/96]\tLoss 1.2929 (1.1794)\taccuracy 54.688 (52.949)\tf1_score 42.022 (45.998)\n",
      "Epoch: [1][75/96]\tLoss 0.9778 (1.1716)\taccuracy 59.375 (53.269)\tf1_score 53.373 (46.184)\n",
      "Epoch: [1][80/96]\tLoss 1.0491 (1.1665)\taccuracy 56.250 (53.511)\tf1_score 46.088 (46.385)\n",
      "Epoch: [1][85/96]\tLoss 0.9947 (1.1599)\taccuracy 51.562 (53.670)\tf1_score 39.735 (46.519)\n",
      "Epoch: [1][90/96]\tLoss 1.1241 (1.1527)\taccuracy 48.438 (53.932)\tf1_score 43.652 (46.843)\n",
      "Epoch: [1][95/96]\tLoss 1.2678 (1.1523)\taccuracy 57.812 (54.004)\tf1_score 43.456 (46.932)\n",
      " Test: accuracy 29.557 f1_score 21.577\n",
      "Training time:  204.59388947486877 Hour:  0 Minute:  3 Second:  24 Test best accuracy: 47.0703125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 2\n",
      "Epoch: [2][0/96]\tLoss 0.9919 (0.9919)\taccuracy 51.562 (51.562)\tf1_score 48.084 (48.084)\n",
      "Epoch: [2][5/96]\tLoss 0.9387 (1.0767)\taccuracy 65.625 (54.688)\tf1_score 62.696 (49.983)\n",
      "Epoch: [2][10/96]\tLoss 0.9280 (0.9889)\taccuracy 62.500 (59.801)\tf1_score 50.741 (52.492)\n",
      "Epoch: [2][15/96]\tLoss 0.9013 (0.9962)\taccuracy 65.625 (59.473)\tf1_score 52.038 (52.476)\n",
      "Epoch: [2][20/96]\tLoss 1.2294 (1.0306)\taccuracy 43.750 (57.812)\tf1_score 39.011 (51.136)\n",
      "Epoch: [2][25/96]\tLoss 0.9417 (1.0194)\taccuracy 65.625 (58.293)\tf1_score 57.845 (51.622)\n",
      "Epoch: [2][30/96]\tLoss 1.1140 (1.0119)\taccuracy 54.688 (59.173)\tf1_score 50.387 (52.408)\n",
      "Epoch: [2][35/96]\tLoss 0.8671 (1.0014)\taccuracy 75.000 (59.896)\tf1_score 68.702 (52.933)\n",
      "Epoch: [2][40/96]\tLoss 1.2012 (1.0001)\taccuracy 51.562 (59.985)\tf1_score 45.946 (52.957)\n",
      "Epoch: [2][45/96]\tLoss 1.2197 (1.0042)\taccuracy 57.812 (59.885)\tf1_score 47.677 (52.851)\n",
      "Epoch: [2][50/96]\tLoss 0.9457 (1.0001)\taccuracy 57.812 (60.263)\tf1_score 50.029 (53.258)\n",
      "Epoch: [2][55/96]\tLoss 0.9665 (1.0100)\taccuracy 65.625 (60.128)\tf1_score 58.096 (53.120)\n",
      "Epoch: [2][60/96]\tLoss 0.9312 (1.0126)\taccuracy 65.625 (59.964)\tf1_score 59.989 (53.108)\n",
      "Epoch: [2][65/96]\tLoss 0.9347 (1.0166)\taccuracy 65.625 (59.706)\tf1_score 58.494 (53.011)\n",
      "Epoch: [2][70/96]\tLoss 1.2026 (1.0174)\taccuracy 56.250 (59.705)\tf1_score 48.757 (52.995)\n",
      "Epoch: [2][75/96]\tLoss 0.7660 (1.0081)\taccuracy 71.875 (60.156)\tf1_score 60.854 (53.355)\n",
      "Epoch: [2][80/96]\tLoss 0.9038 (0.9986)\taccuracy 62.500 (60.590)\tf1_score 57.436 (53.764)\n",
      "Epoch: [2][85/96]\tLoss 0.9381 (0.9931)\taccuracy 64.062 (60.774)\tf1_score 55.606 (53.969)\n",
      "Epoch: [2][90/96]\tLoss 0.8262 (0.9883)\taccuracy 68.750 (61.041)\tf1_score 61.101 (54.265)\n",
      "Epoch: [2][95/96]\tLoss 1.0729 (0.9898)\taccuracy 56.250 (60.758)\tf1_score 51.097 (54.142)\n",
      " Test: accuracy 50.846 f1_score 43.399\n",
      "Training time:  220.7341685295105 Hour:  0 Minute:  3 Second:  40 Test best accuracy: 50.846354166666664  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 3\n",
      "Epoch: [3][0/96]\tLoss 1.0851 (1.0851)\taccuracy 57.812 (57.812)\tf1_score 54.667 (54.667)\n",
      "Epoch: [3][5/96]\tLoss 0.9959 (1.0389)\taccuracy 59.375 (59.635)\tf1_score 52.075 (54.709)\n",
      "Epoch: [3][10/96]\tLoss 0.8168 (0.9490)\taccuracy 68.750 (62.358)\tf1_score 59.142 (54.370)\n",
      "Epoch: [3][15/96]\tLoss 0.9183 (0.9329)\taccuracy 70.312 (62.402)\tf1_score 70.079 (55.625)\n",
      "Epoch: [3][20/96]\tLoss 0.9022 (1.0281)\taccuracy 67.188 (59.449)\tf1_score 58.276 (52.820)\n",
      "Epoch: [3][25/96]\tLoss 0.9941 (1.0260)\taccuracy 60.938 (59.435)\tf1_score 52.393 (52.650)\n",
      "Epoch: [3][30/96]\tLoss 0.9514 (1.0062)\taccuracy 54.688 (60.181)\tf1_score 48.857 (53.056)\n",
      "Epoch: [3][35/96]\tLoss 0.7470 (0.9898)\taccuracy 71.875 (60.634)\tf1_score 58.207 (53.167)\n",
      "Epoch: [3][40/96]\tLoss 1.1562 (0.9901)\taccuracy 54.688 (60.899)\tf1_score 50.485 (53.790)\n",
      "Epoch: [3][45/96]\tLoss 0.6986 (0.9928)\taccuracy 76.562 (60.836)\tf1_score 66.444 (53.697)\n",
      "Epoch: [3][50/96]\tLoss 0.9992 (0.9920)\taccuracy 59.375 (60.815)\tf1_score 57.193 (53.891)\n",
      "Epoch: [3][55/96]\tLoss 0.8682 (0.9914)\taccuracy 67.188 (60.798)\tf1_score 64.460 (54.006)\n",
      "Epoch: [3][60/96]\tLoss 0.8581 (0.9838)\taccuracy 67.188 (60.989)\tf1_score 56.498 (54.104)\n",
      "Epoch: [3][65/96]\tLoss 0.9109 (0.9762)\taccuracy 62.500 (61.529)\tf1_score 57.547 (54.689)\n",
      "Epoch: [3][70/96]\tLoss 0.8491 (0.9837)\taccuracy 68.750 (61.378)\tf1_score 62.591 (54.451)\n",
      "Epoch: [3][75/96]\tLoss 0.9157 (0.9911)\taccuracy 67.188 (61.308)\tf1_score 57.529 (54.423)\n",
      "Epoch: [3][80/96]\tLoss 1.2257 (0.9991)\taccuracy 51.562 (60.918)\tf1_score 49.251 (54.158)\n",
      "Epoch: [3][85/96]\tLoss 1.2771 (1.0030)\taccuracy 53.125 (60.810)\tf1_score 52.200 (54.133)\n",
      "Epoch: [3][90/96]\tLoss 0.8679 (0.9976)\taccuracy 67.188 (61.075)\tf1_score 62.581 (54.464)\n",
      "Epoch: [3][95/96]\tLoss 0.8597 (0.9981)\taccuracy 67.188 (60.889)\tf1_score 63.485 (54.396)\n",
      " Test: accuracy 30.534 f1_score 24.642\n",
      "Training time:  237.1818926334381 Hour:  0 Minute:  3 Second:  57 Test best accuracy: 50.846354166666664  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 4\n",
      "Epoch: [4][0/96]\tLoss 0.7804 (0.7804)\taccuracy 64.062 (64.062)\tf1_score 57.421 (57.421)\n",
      "Epoch: [4][5/96]\tLoss 0.9348 (0.8734)\taccuracy 53.125 (64.062)\tf1_score 55.061 (59.851)\n",
      "Epoch: [4][10/96]\tLoss 0.7498 (0.8486)\taccuracy 71.875 (65.909)\tf1_score 67.583 (60.688)\n",
      "Epoch: [4][15/96]\tLoss 0.9172 (0.8412)\taccuracy 65.625 (67.090)\tf1_score 57.082 (62.268)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][20/96]\tLoss 0.7689 (0.8289)\taccuracy 73.438 (67.708)\tf1_score 71.544 (62.993)\n",
      "Epoch: [4][25/96]\tLoss 0.8938 (0.8408)\taccuracy 65.625 (67.548)\tf1_score 58.199 (62.836)\n",
      "Epoch: [4][30/96]\tLoss 0.8490 (0.8440)\taccuracy 70.312 (67.440)\tf1_score 59.977 (62.578)\n",
      "Epoch: [4][35/96]\tLoss 0.7078 (0.8470)\taccuracy 79.688 (67.448)\tf1_score 74.152 (62.613)\n",
      "Epoch: [4][40/96]\tLoss 0.6640 (0.8525)\taccuracy 71.875 (67.111)\tf1_score 65.599 (62.218)\n",
      "Epoch: [4][45/96]\tLoss 0.7899 (0.8556)\taccuracy 64.062 (66.644)\tf1_score 57.530 (61.709)\n",
      "Epoch: [4][50/96]\tLoss 0.7274 (0.8619)\taccuracy 76.562 (66.330)\tf1_score 72.526 (60.952)\n",
      "Epoch: [4][55/96]\tLoss 0.6235 (0.8582)\taccuracy 78.125 (66.323)\tf1_score 75.476 (61.039)\n",
      "Epoch: [4][60/96]\tLoss 0.7563 (0.8564)\taccuracy 67.188 (66.291)\tf1_score 62.877 (61.047)\n",
      "Epoch: [4][65/96]\tLoss 0.8990 (0.8554)\taccuracy 60.938 (66.170)\tf1_score 54.033 (60.963)\n",
      "Epoch: [4][70/96]\tLoss 0.8453 (0.8552)\taccuracy 70.312 (66.263)\tf1_score 70.527 (61.098)\n",
      "Epoch: [4][75/96]\tLoss 0.7850 (0.8503)\taccuracy 70.312 (66.488)\tf1_score 67.322 (61.466)\n",
      "Epoch: [4][80/96]\tLoss 0.9257 (0.8509)\taccuracy 62.500 (66.454)\tf1_score 61.196 (61.449)\n",
      "Epoch: [4][85/96]\tLoss 0.7200 (0.8463)\taccuracy 75.000 (66.751)\tf1_score 74.654 (61.724)\n",
      "Epoch: [4][90/96]\tLoss 0.9507 (0.8434)\taccuracy 64.062 (66.947)\tf1_score 60.784 (62.008)\n",
      "Epoch: [4][95/96]\tLoss 0.6642 (0.8430)\taccuracy 70.312 (66.862)\tf1_score 63.875 (61.900)\n",
      " Test: accuracy 61.133 f1_score 55.367\n",
      "Training time:  253.4104344844818 Hour:  0 Minute:  4 Second:  13 Test best accuracy: 61.1328125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 5\n",
      "Epoch: [5][0/96]\tLoss 0.7583 (0.7583)\taccuracy 68.750 (68.750)\tf1_score 61.512 (61.512)\n",
      "Epoch: [5][5/96]\tLoss 0.7688 (0.7849)\taccuracy 73.438 (69.792)\tf1_score 66.614 (64.161)\n",
      "Epoch: [5][10/96]\tLoss 1.0025 (0.8481)\taccuracy 59.375 (65.483)\tf1_score 48.327 (60.545)\n",
      "Epoch: [5][15/96]\tLoss 0.8362 (0.8518)\taccuracy 64.062 (64.551)\tf1_score 57.809 (60.318)\n",
      "Epoch: [5][20/96]\tLoss 0.8150 (0.8324)\taccuracy 67.188 (65.774)\tf1_score 64.036 (61.678)\n",
      "Epoch: [5][25/96]\tLoss 0.7249 (0.8377)\taccuracy 70.312 (66.106)\tf1_score 63.598 (61.824)\n",
      "Epoch: [5][30/96]\tLoss 0.8241 (0.8372)\taccuracy 68.750 (65.927)\tf1_score 63.059 (61.565)\n",
      "Epoch: [5][35/96]\tLoss 0.7683 (0.8319)\taccuracy 68.750 (65.885)\tf1_score 56.786 (61.125)\n",
      "Epoch: [5][40/96]\tLoss 0.8020 (0.8274)\taccuracy 67.188 (66.273)\tf1_score 58.431 (61.424)\n",
      "Epoch: [5][45/96]\tLoss 0.8678 (0.8177)\taccuracy 62.500 (66.542)\tf1_score 62.060 (61.750)\n",
      "Epoch: [5][50/96]\tLoss 0.6876 (0.8066)\taccuracy 70.312 (66.942)\tf1_score 61.067 (62.012)\n",
      "Epoch: [5][55/96]\tLoss 0.6901 (0.8092)\taccuracy 71.875 (66.881)\tf1_score 68.448 (61.647)\n",
      "Epoch: [5][60/96]\tLoss 0.8515 (0.8085)\taccuracy 60.938 (66.931)\tf1_score 48.325 (61.540)\n",
      "Epoch: [5][65/96]\tLoss 0.8043 (0.8096)\taccuracy 65.625 (67.045)\tf1_score 58.515 (61.573)\n",
      "Epoch: [5][70/96]\tLoss 0.9087 (0.8110)\taccuracy 65.625 (67.077)\tf1_score 65.325 (61.606)\n",
      "Epoch: [5][75/96]\tLoss 1.1643 (0.8151)\taccuracy 51.562 (67.064)\tf1_score 58.236 (61.638)\n",
      "Epoch: [5][80/96]\tLoss 0.8961 (0.8184)\taccuracy 65.625 (67.033)\tf1_score 64.930 (61.675)\n",
      "Epoch: [5][85/96]\tLoss 0.9203 (0.8204)\taccuracy 57.812 (66.969)\tf1_score 52.048 (61.592)\n",
      "Epoch: [5][90/96]\tLoss 0.8187 (0.8148)\taccuracy 70.312 (67.291)\tf1_score 65.899 (61.900)\n",
      "Epoch: [5][95/96]\tLoss 0.7388 (0.8143)\taccuracy 75.000 (67.432)\tf1_score 62.109 (61.907)\n",
      " Test: accuracy 40.169 f1_score 33.094\n",
      "Training time:  269.1753900051117 Hour:  0 Minute:  4 Second:  29 Test best accuracy: 61.1328125  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 6\n",
      "Epoch: [6][0/96]\tLoss 0.7560 (0.7560)\taccuracy 75.000 (75.000)\tf1_score 73.091 (73.091)\n",
      "Epoch: [6][5/96]\tLoss 0.5860 (0.7727)\taccuracy 76.562 (71.615)\tf1_score 70.222 (68.375)\n",
      "Epoch: [6][10/96]\tLoss 0.6942 (0.7449)\taccuracy 76.562 (72.017)\tf1_score 72.220 (68.911)\n",
      "Epoch: [6][15/96]\tLoss 0.6896 (0.7301)\taccuracy 70.312 (72.852)\tf1_score 64.590 (69.446)\n",
      "Epoch: [6][20/96]\tLoss 0.8521 (0.7295)\taccuracy 62.500 (72.470)\tf1_score 61.916 (68.446)\n",
      "Epoch: [6][25/96]\tLoss 0.5046 (0.7145)\taccuracy 82.812 (72.296)\tf1_score 78.945 (67.688)\n",
      "Epoch: [6][30/96]\tLoss 0.7377 (0.7148)\taccuracy 73.438 (72.480)\tf1_score 72.329 (68.206)\n",
      "Epoch: [6][35/96]\tLoss 0.7366 (0.7110)\taccuracy 68.750 (72.613)\tf1_score 60.431 (68.077)\n",
      "Epoch: [6][40/96]\tLoss 0.5602 (0.7081)\taccuracy 75.000 (72.599)\tf1_score 65.876 (67.966)\n",
      "Epoch: [6][45/96]\tLoss 0.8581 (0.7266)\taccuracy 67.188 (71.705)\tf1_score 59.908 (67.021)\n",
      "Epoch: [6][50/96]\tLoss 0.8197 (0.7301)\taccuracy 68.750 (71.752)\tf1_score 68.497 (67.246)\n",
      "Epoch: [6][55/96]\tLoss 0.6374 (0.7555)\taccuracy 78.125 (70.898)\tf1_score 75.960 (66.215)\n",
      "Epoch: [6][60/96]\tLoss 0.7636 (0.7606)\taccuracy 68.750 (70.774)\tf1_score 65.688 (65.627)\n",
      "Epoch: [6][65/96]\tLoss 0.9062 (0.7759)\taccuracy 60.938 (70.123)\tf1_score 55.272 (64.839)\n",
      "Epoch: [6][70/96]\tLoss 0.8793 (0.7822)\taccuracy 68.750 (69.982)\tf1_score 63.329 (64.385)\n",
      "Epoch: [6][75/96]\tLoss 0.8280 (0.7843)\taccuracy 57.812 (69.634)\tf1_score 56.063 (64.059)\n",
      "Epoch: [6][80/96]\tLoss 0.8564 (0.7858)\taccuracy 71.875 (69.483)\tf1_score 66.543 (63.898)\n",
      "Epoch: [6][85/96]\tLoss 0.9194 (0.7822)\taccuracy 62.500 (69.586)\tf1_score 59.825 (64.072)\n",
      "Epoch: [6][90/96]\tLoss 0.9374 (0.7811)\taccuracy 64.062 (69.712)\tf1_score 57.944 (64.030)\n",
      "Epoch: [6][95/96]\tLoss 0.9656 (0.7837)\taccuracy 60.938 (69.548)\tf1_score 55.435 (64.062)\n",
      " Test: accuracy 64.974 f1_score 59.214\n",
      "Training time:  285.5599641799927 Hour:  0 Minute:  4 Second:  45 Test best accuracy: 64.97395833333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 7\n",
      "Epoch: [7][0/96]\tLoss 0.7188 (0.7188)\taccuracy 75.000 (75.000)\tf1_score 70.675 (70.675)\n",
      "Epoch: [7][5/96]\tLoss 0.8237 (0.7018)\taccuracy 65.625 (71.094)\tf1_score 67.880 (64.804)\n",
      "Epoch: [7][10/96]\tLoss 1.0393 (0.7612)\taccuracy 56.250 (69.886)\tf1_score 54.323 (64.495)\n",
      "Epoch: [7][15/96]\tLoss 0.7230 (0.7681)\taccuracy 65.625 (69.434)\tf1_score 59.085 (64.235)\n",
      "Epoch: [7][20/96]\tLoss 0.6709 (0.7816)\taccuracy 78.125 (69.345)\tf1_score 72.358 (63.492)\n",
      "Epoch: [7][25/96]\tLoss 0.7480 (0.7695)\taccuracy 71.875 (70.433)\tf1_score 62.817 (64.705)\n",
      "Epoch: [7][30/96]\tLoss 0.9174 (0.7854)\taccuracy 64.062 (69.607)\tf1_score 56.195 (63.637)\n",
      "Epoch: [7][35/96]\tLoss 0.8474 (0.8035)\taccuracy 68.750 (68.533)\tf1_score 63.827 (62.825)\n",
      "Epoch: [7][40/96]\tLoss 0.8188 (0.7805)\taccuracy 62.500 (68.979)\tf1_score 59.445 (63.267)\n",
      "Epoch: [7][45/96]\tLoss 1.1112 (0.7946)\taccuracy 57.812 (68.920)\tf1_score 54.558 (63.352)\n",
      "Epoch: [7][50/96]\tLoss 0.6806 (0.7920)\taccuracy 78.125 (69.240)\tf1_score 72.582 (63.745)\n",
      "Epoch: [7][55/96]\tLoss 0.7580 (0.7873)\taccuracy 75.000 (69.475)\tf1_score 74.934 (64.040)\n",
      "Epoch: [7][60/96]\tLoss 0.9144 (0.7821)\taccuracy 75.000 (69.928)\tf1_score 69.565 (64.420)\n",
      "Epoch: [7][65/96]\tLoss 0.9326 (0.7837)\taccuracy 64.062 (70.028)\tf1_score 59.884 (64.716)\n",
      "Epoch: [7][70/96]\tLoss 0.5764 (0.7818)\taccuracy 76.562 (69.938)\tf1_score 71.903 (64.738)\n",
      "Epoch: [7][75/96]\tLoss 1.1268 (0.7825)\taccuracy 50.000 (69.696)\tf1_score 51.580 (64.578)\n",
      "Epoch: [7][80/96]\tLoss 1.1528 (0.7909)\taccuracy 62.500 (69.541)\tf1_score 60.297 (64.409)\n",
      "Epoch: [7][85/96]\tLoss 0.7008 (0.7815)\taccuracy 68.750 (69.822)\tf1_score 57.153 (64.583)\n",
      "Epoch: [7][90/96]\tLoss 0.5916 (0.7733)\taccuracy 78.125 (70.124)\tf1_score 77.381 (65.012)\n",
      "Epoch: [7][95/96]\tLoss 0.5810 (0.7658)\taccuracy 76.562 (70.410)\tf1_score 68.448 (65.326)\n",
      " Test: accuracy 68.359 f1_score 63.095\n",
      "Training time:  301.32849860191345 Hour:  0 Minute:  5 Second:  1 Test best accuracy: 68.359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 8\n",
      "Epoch: [8][0/96]\tLoss 1.1285 (1.1285)\taccuracy 56.250 (56.250)\tf1_score 49.774 (49.774)\n",
      "Epoch: [8][5/96]\tLoss 0.5389 (0.7152)\taccuracy 76.562 (71.875)\tf1_score 76.081 (68.873)\n",
      "Epoch: [8][10/96]\tLoss 0.6011 (0.6968)\taccuracy 70.312 (72.159)\tf1_score 65.795 (68.736)\n",
      "Epoch: [8][15/96]\tLoss 0.6077 (0.6889)\taccuracy 68.750 (72.363)\tf1_score 65.476 (68.950)\n",
      "Epoch: [8][20/96]\tLoss 0.6149 (0.6824)\taccuracy 68.750 (72.991)\tf1_score 67.426 (69.460)\n",
      "Epoch: [8][25/96]\tLoss 0.6561 (0.6666)\taccuracy 71.875 (73.377)\tf1_score 67.198 (69.369)\n",
      "Epoch: [8][30/96]\tLoss 0.6859 (0.6681)\taccuracy 71.875 (73.337)\tf1_score 71.774 (69.555)\n",
      "Epoch: [8][35/96]\tLoss 0.6929 (0.6845)\taccuracy 75.000 (73.177)\tf1_score 70.818 (69.430)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][40/96]\tLoss 0.6777 (0.6869)\taccuracy 68.750 (72.904)\tf1_score 60.778 (68.885)\n",
      "Epoch: [8][45/96]\tLoss 1.0283 (0.6929)\taccuracy 64.062 (72.894)\tf1_score 59.781 (69.045)\n",
      "Epoch: [8][50/96]\tLoss 0.7435 (0.6901)\taccuracy 75.000 (73.131)\tf1_score 66.111 (69.385)\n",
      "Epoch: [8][55/96]\tLoss 0.5503 (0.6876)\taccuracy 81.250 (73.214)\tf1_score 77.770 (69.408)\n",
      "Epoch: [8][60/96]\tLoss 0.8259 (0.6956)\taccuracy 67.188 (73.284)\tf1_score 66.602 (69.543)\n",
      "Epoch: [8][65/96]\tLoss 0.7538 (0.7045)\taccuracy 73.438 (72.964)\tf1_score 68.430 (69.170)\n",
      "Epoch: [8][70/96]\tLoss 0.7767 (0.6973)\taccuracy 70.312 (73.349)\tf1_score 69.389 (69.698)\n",
      "Epoch: [8][75/96]\tLoss 0.6070 (0.6913)\taccuracy 76.562 (73.602)\tf1_score 66.129 (69.957)\n",
      "Epoch: [8][80/96]\tLoss 0.4875 (0.6840)\taccuracy 82.812 (73.765)\tf1_score 75.667 (70.114)\n",
      "Epoch: [8][85/96]\tLoss 0.5752 (0.6791)\taccuracy 81.250 (73.892)\tf1_score 69.223 (70.007)\n",
      "Epoch: [8][90/96]\tLoss 0.5102 (0.6726)\taccuracy 78.125 (74.124)\tf1_score 68.751 (70.207)\n",
      "Epoch: [8][95/96]\tLoss 0.7076 (0.6682)\taccuracy 76.562 (74.463)\tf1_score 67.534 (70.500)\n",
      " Test: accuracy 69.596 f1_score 64.115\n",
      "Training time:  317.1982569694519 Hour:  0 Minute:  5 Second:  17 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 9\n",
      "Epoch: [9][0/96]\tLoss 0.5608 (0.5608)\taccuracy 79.688 (79.688)\tf1_score 73.645 (73.645)\n",
      "Epoch: [9][5/96]\tLoss 0.4949 (0.5689)\taccuracy 79.688 (77.083)\tf1_score 77.808 (74.379)\n",
      "Epoch: [9][10/96]\tLoss 0.6451 (0.5839)\taccuracy 73.438 (76.278)\tf1_score 61.298 (73.197)\n",
      "Epoch: [9][15/96]\tLoss 0.8652 (0.5990)\taccuracy 71.875 (76.660)\tf1_score 64.368 (72.819)\n",
      "Epoch: [9][20/96]\tLoss 0.9802 (0.6151)\taccuracy 70.312 (76.339)\tf1_score 65.556 (72.232)\n",
      "Epoch: [9][25/96]\tLoss 0.8167 (0.6126)\taccuracy 67.188 (76.022)\tf1_score 66.643 (71.734)\n",
      "Epoch: [9][30/96]\tLoss 0.5465 (0.6096)\taccuracy 82.812 (76.411)\tf1_score 73.205 (72.183)\n",
      "Epoch: [9][35/96]\tLoss 0.5386 (0.6222)\taccuracy 78.125 (75.998)\tf1_score 70.401 (71.236)\n",
      "Epoch: [9][40/96]\tLoss 0.7250 (0.6172)\taccuracy 65.625 (75.991)\tf1_score 62.102 (71.312)\n",
      "Epoch: [9][45/96]\tLoss 0.6462 (0.6149)\taccuracy 78.125 (76.291)\tf1_score 77.748 (71.579)\n",
      "Epoch: [9][50/96]\tLoss 0.5922 (0.6211)\taccuracy 71.875 (75.950)\tf1_score 71.175 (71.548)\n",
      "Epoch: [9][55/96]\tLoss 0.6256 (0.6213)\taccuracy 76.562 (76.060)\tf1_score 67.955 (71.873)\n",
      "Epoch: [9][60/96]\tLoss 0.9526 (0.6278)\taccuracy 70.312 (75.871)\tf1_score 65.038 (71.558)\n",
      "Epoch: [9][65/96]\tLoss 0.9545 (0.6393)\taccuracy 62.500 (75.355)\tf1_score 52.310 (70.856)\n",
      "Epoch: [9][70/96]\tLoss 0.6640 (0.6341)\taccuracy 71.875 (75.572)\tf1_score 70.937 (71.027)\n",
      "Epoch: [9][75/96]\tLoss 0.6027 (0.6284)\taccuracy 75.000 (75.822)\tf1_score 74.074 (71.377)\n",
      "Epoch: [9][80/96]\tLoss 0.8434 (0.6336)\taccuracy 70.312 (75.559)\tf1_score 64.097 (70.990)\n",
      "Epoch: [9][85/96]\tLoss 0.8108 (0.6341)\taccuracy 62.500 (75.436)\tf1_score 52.547 (70.933)\n",
      "Epoch: [9][90/96]\tLoss 0.6277 (0.6314)\taccuracy 76.562 (75.378)\tf1_score 60.002 (70.706)\n",
      "Epoch: [9][95/96]\tLoss 0.4503 (0.6291)\taccuracy 81.250 (75.423)\tf1_score 76.327 (70.732)\n",
      " Test: accuracy 40.560 f1_score 34.684\n",
      "Training time:  333.0867512226105 Hour:  0 Minute:  5 Second:  33 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 10\n",
      "Epoch: [10][0/96]\tLoss 0.4608 (0.4608)\taccuracy 84.375 (84.375)\tf1_score 83.331 (83.331)\n",
      "Epoch: [10][5/96]\tLoss 0.6606 (0.5729)\taccuracy 76.562 (77.865)\tf1_score 76.417 (74.320)\n",
      "Epoch: [10][10/96]\tLoss 0.5101 (0.6236)\taccuracy 84.375 (77.131)\tf1_score 80.617 (73.770)\n",
      "Epoch: [10][15/96]\tLoss 0.8335 (0.6463)\taccuracy 67.188 (76.172)\tf1_score 53.216 (72.339)\n",
      "Epoch: [10][20/96]\tLoss 0.3601 (0.6167)\taccuracy 89.062 (77.158)\tf1_score 87.563 (73.668)\n",
      "Epoch: [10][25/96]\tLoss 0.9053 (0.6213)\taccuracy 65.625 (76.623)\tf1_score 63.602 (72.878)\n",
      "Epoch: [10][30/96]\tLoss 0.7330 (0.6310)\taccuracy 75.000 (76.310)\tf1_score 72.305 (72.488)\n",
      "Epoch: [10][35/96]\tLoss 0.4078 (0.6193)\taccuracy 85.938 (76.649)\tf1_score 78.495 (72.594)\n",
      "Epoch: [10][40/96]\tLoss 0.5430 (0.6205)\taccuracy 81.250 (76.639)\tf1_score 72.381 (72.362)\n",
      "Epoch: [10][45/96]\tLoss 0.5157 (0.6114)\taccuracy 76.562 (76.766)\tf1_score 65.895 (72.235)\n",
      "Epoch: [10][50/96]\tLoss 0.5263 (0.6145)\taccuracy 81.250 (76.777)\tf1_score 76.484 (71.688)\n",
      "Epoch: [10][55/96]\tLoss 0.8270 (0.6140)\taccuracy 70.312 (76.758)\tf1_score 61.576 (71.590)\n",
      "Epoch: [10][60/96]\tLoss 0.5953 (0.6244)\taccuracy 78.125 (76.306)\tf1_score 72.167 (70.956)\n",
      "Epoch: [10][65/96]\tLoss 0.8169 (0.6251)\taccuracy 73.438 (76.255)\tf1_score 75.814 (70.965)\n",
      "Epoch: [10][70/96]\tLoss 0.6986 (0.6257)\taccuracy 70.312 (76.100)\tf1_score 63.902 (71.002)\n",
      "Epoch: [10][75/96]\tLoss 0.6836 (0.6220)\taccuracy 75.000 (76.234)\tf1_score 75.813 (71.239)\n",
      "Epoch: [10][80/96]\tLoss 0.6786 (0.6227)\taccuracy 65.625 (76.022)\tf1_score 65.563 (71.183)\n",
      "Epoch: [10][85/96]\tLoss 0.5748 (0.6270)\taccuracy 78.125 (75.908)\tf1_score 66.849 (70.986)\n",
      "Epoch: [10][90/96]\tLoss 0.6312 (0.6282)\taccuracy 81.250 (75.962)\tf1_score 78.178 (71.191)\n",
      "Epoch: [10][95/96]\tLoss 0.7496 (0.6310)\taccuracy 68.750 (75.814)\tf1_score 59.445 (70.952)\n",
      " Test: accuracy 66.797 f1_score 60.486\n",
      "Training time:  348.96415877342224 Hour:  0 Minute:  5 Second:  48 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 11\n",
      "Epoch: [11][0/96]\tLoss 0.9553 (0.9553)\taccuracy 56.250 (56.250)\tf1_score 56.033 (56.033)\n",
      "Epoch: [11][5/96]\tLoss 0.5693 (0.6481)\taccuracy 78.125 (74.219)\tf1_score 77.944 (72.474)\n",
      "Epoch: [11][10/96]\tLoss 0.4995 (0.6513)\taccuracy 81.250 (74.290)\tf1_score 77.304 (72.047)\n",
      "Epoch: [11][15/96]\tLoss 0.4010 (0.6113)\taccuracy 85.938 (75.977)\tf1_score 79.900 (73.471)\n",
      "Epoch: [11][20/96]\tLoss 0.5937 (0.6212)\taccuracy 73.438 (75.595)\tf1_score 70.660 (72.549)\n",
      "Epoch: [11][25/96]\tLoss 0.4833 (0.6142)\taccuracy 81.250 (76.442)\tf1_score 79.248 (73.364)\n",
      "Epoch: [11][30/96]\tLoss 0.6428 (0.6055)\taccuracy 78.125 (76.562)\tf1_score 74.354 (73.161)\n",
      "Epoch: [11][35/96]\tLoss 0.4616 (0.5942)\taccuracy 79.688 (77.083)\tf1_score 74.139 (73.426)\n",
      "Epoch: [11][40/96]\tLoss 0.4350 (0.5840)\taccuracy 81.250 (77.477)\tf1_score 81.147 (73.991)\n",
      "Epoch: [11][45/96]\tLoss 0.5550 (0.5724)\taccuracy 78.125 (77.921)\tf1_score 72.642 (74.395)\n",
      "Epoch: [11][50/96]\tLoss 0.6812 (0.5670)\taccuracy 78.125 (78.186)\tf1_score 65.448 (74.474)\n",
      "Epoch: [11][55/96]\tLoss 0.4825 (0.5618)\taccuracy 81.250 (78.209)\tf1_score 78.972 (74.595)\n",
      "Epoch: [11][60/96]\tLoss 0.4552 (0.5562)\taccuracy 79.688 (78.535)\tf1_score 74.706 (74.791)\n",
      "Epoch: [11][65/96]\tLoss 0.4410 (0.5584)\taccuracy 87.500 (78.362)\tf1_score 81.667 (74.459)\n",
      "Epoch: [11][70/96]\tLoss 0.5643 (0.5592)\taccuracy 82.812 (78.521)\tf1_score 82.994 (74.684)\n",
      "Epoch: [11][75/96]\tLoss 0.6809 (0.5621)\taccuracy 76.562 (78.433)\tf1_score 65.387 (74.599)\n",
      "Epoch: [11][80/96]\tLoss 0.5191 (0.5646)\taccuracy 76.562 (78.279)\tf1_score 72.628 (74.401)\n",
      "Epoch: [11][85/96]\tLoss 0.6131 (0.5653)\taccuracy 79.688 (78.252)\tf1_score 79.957 (74.529)\n",
      "Epoch: [11][90/96]\tLoss 0.3900 (0.5633)\taccuracy 87.500 (78.314)\tf1_score 82.933 (74.594)\n",
      "Epoch: [11][95/96]\tLoss 0.7379 (0.5685)\taccuracy 75.000 (78.190)\tf1_score 72.930 (74.457)\n",
      " Test: accuracy 58.724 f1_score 53.745\n",
      "Training time:  364.85475420951843 Hour:  0 Minute:  6 Second:  4 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 12\n",
      "Epoch: [12][0/96]\tLoss 0.5426 (0.5426)\taccuracy 76.562 (76.562)\tf1_score 71.062 (71.062)\n",
      "Epoch: [12][5/96]\tLoss 0.6598 (0.5892)\taccuracy 73.438 (75.260)\tf1_score 71.672 (72.374)\n",
      "Epoch: [12][10/96]\tLoss 0.7197 (0.5802)\taccuracy 81.250 (76.278)\tf1_score 78.425 (73.651)\n",
      "Epoch: [12][15/96]\tLoss 0.4168 (0.5560)\taccuracy 87.500 (77.930)\tf1_score 78.110 (74.290)\n",
      "Epoch: [12][20/96]\tLoss 0.8550 (0.5823)\taccuracy 67.188 (76.860)\tf1_score 66.385 (73.090)\n",
      "Epoch: [12][25/96]\tLoss 0.8163 (0.6000)\taccuracy 71.875 (76.202)\tf1_score 66.032 (72.581)\n",
      "Epoch: [12][30/96]\tLoss 0.8376 (0.6057)\taccuracy 71.875 (76.109)\tf1_score 67.740 (72.407)\n",
      "Epoch: [12][35/96]\tLoss 0.7857 (0.6241)\taccuracy 71.875 (75.347)\tf1_score 72.690 (71.986)\n",
      "Epoch: [12][40/96]\tLoss 0.7039 (0.6361)\taccuracy 73.438 (75.076)\tf1_score 63.856 (71.632)\n",
      "Epoch: [12][45/96]\tLoss 0.4488 (0.6370)\taccuracy 82.812 (75.136)\tf1_score 78.183 (71.485)\n",
      "Epoch: [12][50/96]\tLoss 0.3118 (0.6274)\taccuracy 93.750 (75.888)\tf1_score 88.662 (72.156)\n",
      "Epoch: [12][55/96]\tLoss 0.6487 (0.6234)\taccuracy 73.438 (75.977)\tf1_score 76.872 (72.061)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][60/96]\tLoss 0.6385 (0.6276)\taccuracy 73.438 (76.025)\tf1_score 71.552 (72.125)\n",
      "Epoch: [12][65/96]\tLoss 0.4050 (0.6215)\taccuracy 82.812 (76.207)\tf1_score 75.903 (72.235)\n",
      "Epoch: [12][70/96]\tLoss 0.6824 (0.6236)\taccuracy 76.562 (76.254)\tf1_score 69.240 (72.043)\n",
      "Epoch: [12][75/96]\tLoss 0.5030 (0.6260)\taccuracy 79.688 (76.090)\tf1_score 81.213 (71.979)\n",
      "Epoch: [12][80/96]\tLoss 0.6306 (0.6224)\taccuracy 71.875 (76.215)\tf1_score 70.759 (72.262)\n",
      "Epoch: [12][85/96]\tLoss 0.5382 (0.6221)\taccuracy 82.812 (76.235)\tf1_score 82.121 (72.332)\n",
      "Epoch: [12][90/96]\tLoss 1.0230 (0.6251)\taccuracy 59.375 (76.030)\tf1_score 52.376 (72.131)\n",
      "Epoch: [12][95/96]\tLoss 0.5776 (0.6274)\taccuracy 82.812 (76.074)\tf1_score 77.970 (72.210)\n",
      " Test: accuracy 46.810 f1_score 39.360\n",
      "Training time:  380.62104415893555 Hour:  0 Minute:  6 Second:  20 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 13\n",
      "Epoch: [13][0/96]\tLoss 0.4812 (0.4812)\taccuracy 84.375 (84.375)\tf1_score 80.218 (80.218)\n",
      "Epoch: [13][5/96]\tLoss 0.5164 (0.6585)\taccuracy 79.688 (72.656)\tf1_score 78.314 (69.036)\n",
      "Epoch: [13][10/96]\tLoss 0.5690 (0.6803)\taccuracy 79.688 (73.295)\tf1_score 81.911 (70.048)\n",
      "Epoch: [13][15/96]\tLoss 0.7739 (0.6801)\taccuracy 71.875 (74.219)\tf1_score 65.440 (70.611)\n",
      "Epoch: [13][20/96]\tLoss 0.6275 (0.6465)\taccuracy 71.875 (75.670)\tf1_score 70.873 (72.099)\n",
      "Epoch: [13][25/96]\tLoss 0.5284 (0.6211)\taccuracy 75.000 (76.683)\tf1_score 65.046 (73.275)\n",
      "Epoch: [13][30/96]\tLoss 0.4183 (0.6190)\taccuracy 81.250 (76.361)\tf1_score 78.022 (73.099)\n",
      "Epoch: [13][35/96]\tLoss 0.5256 (0.6056)\taccuracy 78.125 (76.432)\tf1_score 78.912 (73.082)\n",
      "Epoch: [13][40/96]\tLoss 0.3736 (0.6001)\taccuracy 89.062 (77.096)\tf1_score 81.965 (73.426)\n",
      "Epoch: [13][45/96]\tLoss 0.6257 (0.5868)\taccuracy 75.000 (77.582)\tf1_score 71.135 (73.732)\n",
      "Epoch: [13][50/96]\tLoss 0.6773 (0.5854)\taccuracy 70.312 (77.819)\tf1_score 67.834 (74.012)\n",
      "Epoch: [13][55/96]\tLoss 0.4002 (0.5834)\taccuracy 84.375 (77.762)\tf1_score 79.410 (74.239)\n",
      "Epoch: [13][60/96]\tLoss 0.7810 (0.5796)\taccuracy 75.000 (77.920)\tf1_score 71.389 (74.391)\n",
      "Epoch: [13][65/96]\tLoss 0.4960 (0.5782)\taccuracy 81.250 (78.196)\tf1_score 82.433 (74.654)\n",
      "Epoch: [13][70/96]\tLoss 0.4168 (0.5681)\taccuracy 82.812 (78.433)\tf1_score 77.355 (74.872)\n",
      "Epoch: [13][75/96]\tLoss 0.4563 (0.5759)\taccuracy 81.250 (78.104)\tf1_score 72.639 (74.471)\n",
      "Epoch: [13][80/96]\tLoss 0.5133 (0.5745)\taccuracy 81.250 (78.202)\tf1_score 80.361 (74.622)\n",
      "Epoch: [13][85/96]\tLoss 0.4697 (0.5716)\taccuracy 82.812 (78.252)\tf1_score 79.825 (74.667)\n",
      "Epoch: [13][90/96]\tLoss 0.6843 (0.5723)\taccuracy 73.438 (78.159)\tf1_score 70.712 (74.604)\n",
      "Epoch: [13][95/96]\tLoss 0.4598 (0.5645)\taccuracy 79.688 (78.418)\tf1_score 82.368 (74.929)\n",
      " Test: accuracy 57.552 f1_score 49.369\n",
      "Training time:  396.4765450954437 Hour:  0 Minute:  6 Second:  36 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 14\n",
      "Epoch: [14][0/96]\tLoss 0.3617 (0.3617)\taccuracy 87.500 (87.500)\tf1_score 88.904 (88.904)\n",
      "Epoch: [14][5/96]\tLoss 0.4269 (0.4817)\taccuracy 84.375 (80.729)\tf1_score 82.674 (78.433)\n",
      "Epoch: [14][10/96]\tLoss 0.6418 (0.5320)\taccuracy 78.125 (78.835)\tf1_score 78.836 (75.795)\n",
      "Epoch: [14][15/96]\tLoss 0.5918 (0.5047)\taccuracy 76.562 (79.980)\tf1_score 75.469 (77.128)\n",
      "Epoch: [14][20/96]\tLoss 0.3259 (0.4851)\taccuracy 90.625 (81.176)\tf1_score 79.772 (77.494)\n",
      "Epoch: [14][25/96]\tLoss 0.3079 (0.4984)\taccuracy 90.625 (80.529)\tf1_score 91.187 (77.421)\n",
      "Epoch: [14][30/96]\tLoss 0.4104 (0.4838)\taccuracy 78.125 (80.595)\tf1_score 78.075 (77.619)\n",
      "Epoch: [14][35/96]\tLoss 0.2972 (0.4972)\taccuracy 89.062 (80.382)\tf1_score 86.204 (77.099)\n",
      "Epoch: [14][40/96]\tLoss 0.6041 (0.5096)\taccuracy 79.688 (80.335)\tf1_score 72.741 (77.031)\n",
      "Epoch: [14][45/96]\tLoss 0.5166 (0.5106)\taccuracy 79.688 (80.231)\tf1_score 76.127 (76.809)\n",
      "Epoch: [14][50/96]\tLoss 0.4455 (0.5100)\taccuracy 85.938 (80.331)\tf1_score 88.726 (76.937)\n",
      "Epoch: [14][55/96]\tLoss 0.4068 (0.5220)\taccuracy 85.938 (79.827)\tf1_score 83.942 (76.319)\n",
      "Epoch: [14][60/96]\tLoss 0.4016 (0.5242)\taccuracy 89.062 (79.764)\tf1_score 84.822 (76.122)\n",
      "Epoch: [14][65/96]\tLoss 0.5141 (0.5223)\taccuracy 75.000 (79.782)\tf1_score 69.764 (76.207)\n",
      "Epoch: [14][70/96]\tLoss 0.5603 (0.5229)\taccuracy 76.562 (79.776)\tf1_score 70.703 (76.221)\n",
      "Epoch: [14][75/96]\tLoss 0.4064 (0.5252)\taccuracy 84.375 (79.749)\tf1_score 83.857 (76.265)\n",
      "Epoch: [14][80/96]\tLoss 0.4985 (0.5265)\taccuracy 79.688 (79.552)\tf1_score 78.239 (76.091)\n",
      "Epoch: [14][85/96]\tLoss 0.4578 (0.5249)\taccuracy 81.250 (79.560)\tf1_score 83.773 (76.137)\n",
      "Epoch: [14][90/96]\tLoss 0.3540 (0.5169)\taccuracy 89.062 (79.859)\tf1_score 86.247 (76.419)\n",
      "Epoch: [14][95/96]\tLoss 0.5274 (0.5177)\taccuracy 81.250 (79.834)\tf1_score 80.854 (76.556)\n",
      " Test: accuracy 64.388 f1_score 56.321\n",
      "Training time:  412.35926055908203 Hour:  0 Minute:  6 Second:  52 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 15\n",
      "Epoch: [15][0/96]\tLoss 0.4088 (0.4088)\taccuracy 85.938 (85.938)\tf1_score 80.094 (80.094)\n",
      "Epoch: [15][5/96]\tLoss 0.6339 (0.5351)\taccuracy 75.000 (79.167)\tf1_score 66.837 (75.152)\n",
      "Epoch: [15][10/96]\tLoss 0.2866 (0.5603)\taccuracy 87.500 (78.977)\tf1_score 83.496 (75.759)\n",
      "Epoch: [15][15/96]\tLoss 0.7037 (0.5768)\taccuracy 71.875 (78.125)\tf1_score 67.963 (74.881)\n",
      "Epoch: [15][20/96]\tLoss 0.5122 (0.5604)\taccuracy 79.688 (78.869)\tf1_score 74.146 (75.777)\n",
      "Epoch: [15][25/96]\tLoss 0.3081 (0.5405)\taccuracy 87.500 (79.387)\tf1_score 83.134 (75.929)\n",
      "Epoch: [15][30/96]\tLoss 0.3524 (0.5301)\taccuracy 81.250 (79.688)\tf1_score 78.349 (76.312)\n",
      "Epoch: [15][35/96]\tLoss 0.6824 (0.5269)\taccuracy 79.688 (79.948)\tf1_score 69.063 (76.200)\n",
      "Epoch: [15][40/96]\tLoss 0.3963 (0.5397)\taccuracy 79.688 (79.421)\tf1_score 76.844 (75.609)\n",
      "Epoch: [15][45/96]\tLoss 0.6251 (0.5366)\taccuracy 73.438 (79.518)\tf1_score 70.632 (76.000)\n",
      "Epoch: [15][50/96]\tLoss 0.6292 (0.5331)\taccuracy 76.562 (79.596)\tf1_score 75.274 (76.064)\n",
      "Epoch: [15][55/96]\tLoss 0.3416 (0.5234)\taccuracy 82.812 (79.967)\tf1_score 81.514 (76.495)\n",
      "Epoch: [15][60/96]\tLoss 0.3140 (0.5264)\taccuracy 89.062 (79.764)\tf1_score 87.828 (76.512)\n",
      "Epoch: [15][65/96]\tLoss 0.3349 (0.5238)\taccuracy 92.188 (79.806)\tf1_score 86.302 (76.458)\n",
      "Epoch: [15][70/96]\tLoss 0.5666 (0.5217)\taccuracy 76.562 (79.886)\tf1_score 75.820 (76.502)\n",
      "Epoch: [15][75/96]\tLoss 0.5299 (0.5296)\taccuracy 76.562 (79.441)\tf1_score 74.924 (75.930)\n",
      "Epoch: [15][80/96]\tLoss 0.3223 (0.5202)\taccuracy 87.500 (79.745)\tf1_score 87.262 (76.228)\n",
      "Epoch: [15][85/96]\tLoss 0.4474 (0.5186)\taccuracy 82.812 (79.778)\tf1_score 80.587 (76.231)\n",
      "Epoch: [15][90/96]\tLoss 0.3760 (0.5135)\taccuracy 82.812 (80.031)\tf1_score 75.074 (76.365)\n",
      "Epoch: [15][95/96]\tLoss 0.4059 (0.5166)\taccuracy 82.812 (79.785)\tf1_score 79.441 (76.071)\n",
      " Test: accuracy 58.138 f1_score 51.960\n",
      "Training time:  428.1394393444061 Hour:  0 Minute:  7 Second:  8 Test best accuracy: 69.59635416666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 16\n",
      "Epoch: [16][0/96]\tLoss 0.6075 (0.6075)\taccuracy 82.812 (82.812)\tf1_score 76.121 (76.121)\n",
      "Epoch: [16][5/96]\tLoss 0.4710 (0.5151)\taccuracy 81.250 (80.469)\tf1_score 75.323 (77.254)\n",
      "Epoch: [16][10/96]\tLoss 0.2984 (0.4657)\taccuracy 89.062 (82.670)\tf1_score 82.929 (77.481)\n",
      "Epoch: [16][15/96]\tLoss 0.8403 (0.4969)\taccuracy 64.062 (80.762)\tf1_score 61.942 (75.549)\n",
      "Epoch: [16][20/96]\tLoss 0.3541 (0.4931)\taccuracy 84.375 (81.101)\tf1_score 84.122 (76.187)\n",
      "Epoch: [16][25/96]\tLoss 0.4761 (0.4846)\taccuracy 79.688 (81.190)\tf1_score 75.839 (76.811)\n",
      "Epoch: [16][30/96]\tLoss 0.4882 (0.4754)\taccuracy 75.000 (81.250)\tf1_score 74.735 (77.416)\n",
      "Epoch: [16][35/96]\tLoss 0.4386 (0.4747)\taccuracy 76.562 (81.250)\tf1_score 67.606 (77.431)\n",
      "Epoch: [16][40/96]\tLoss 0.3974 (0.4767)\taccuracy 85.938 (81.555)\tf1_score 86.556 (77.747)\n",
      "Epoch: [16][45/96]\tLoss 0.3675 (0.4748)\taccuracy 84.375 (81.726)\tf1_score 75.659 (77.835)\n",
      "Epoch: [16][50/96]\tLoss 0.3890 (0.4838)\taccuracy 81.250 (81.311)\tf1_score 77.090 (77.508)\n",
      "Epoch: [16][55/96]\tLoss 0.6587 (0.4977)\taccuracy 71.875 (80.608)\tf1_score 65.881 (76.672)\n",
      "Epoch: [16][60/96]\tLoss 0.4814 (0.4988)\taccuracy 85.938 (80.482)\tf1_score 82.250 (76.464)\n",
      "Epoch: [16][65/96]\tLoss 0.6376 (0.4971)\taccuracy 73.438 (80.611)\tf1_score 69.091 (76.465)\n",
      "Epoch: [16][70/96]\tLoss 0.4591 (0.4949)\taccuracy 84.375 (80.634)\tf1_score 82.167 (76.509)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16][75/96]\tLoss 0.6782 (0.4961)\taccuracy 70.312 (80.572)\tf1_score 70.848 (76.437)\n",
      "Epoch: [16][80/96]\tLoss 0.4713 (0.4939)\taccuracy 78.125 (80.671)\tf1_score 74.482 (76.449)\n",
      "Epoch: [16][85/96]\tLoss 0.7630 (0.4909)\taccuracy 68.750 (80.759)\tf1_score 64.556 (76.541)\n",
      "Epoch: [16][90/96]\tLoss 0.8193 (0.4918)\taccuracy 70.312 (80.649)\tf1_score 67.587 (76.469)\n",
      "Epoch: [16][95/96]\tLoss 0.4194 (0.4914)\taccuracy 84.375 (80.680)\tf1_score 83.246 (76.633)\n",
      " Test: accuracy 75.456 f1_score 72.009\n",
      "Training time:  444.00796031951904 Hour:  0 Minute:  7 Second:  24 Test best accuracy: 75.45572916666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 17\n",
      "Epoch: [17][0/96]\tLoss 0.3715 (0.3715)\taccuracy 85.938 (85.938)\tf1_score 78.222 (78.222)\n",
      "Epoch: [17][5/96]\tLoss 0.6784 (0.6684)\taccuracy 79.688 (76.042)\tf1_score 61.929 (68.380)\n",
      "Epoch: [17][10/96]\tLoss 0.4120 (0.5873)\taccuracy 85.938 (77.841)\tf1_score 83.293 (71.531)\n",
      "Epoch: [17][15/96]\tLoss 0.4819 (0.5517)\taccuracy 84.375 (79.004)\tf1_score 76.814 (72.482)\n",
      "Epoch: [17][20/96]\tLoss 0.3270 (0.5371)\taccuracy 90.625 (79.762)\tf1_score 84.357 (74.004)\n",
      "Epoch: [17][25/96]\tLoss 0.4165 (0.5286)\taccuracy 81.250 (80.288)\tf1_score 75.391 (74.679)\n",
      "Epoch: [17][30/96]\tLoss 0.4837 (0.5413)\taccuracy 85.938 (80.141)\tf1_score 85.699 (75.186)\n",
      "Epoch: [17][35/96]\tLoss 0.2731 (0.5267)\taccuracy 89.062 (80.642)\tf1_score 81.295 (76.168)\n",
      "Epoch: [17][40/96]\tLoss 0.3755 (0.5183)\taccuracy 85.938 (80.907)\tf1_score 85.168 (76.586)\n",
      "Epoch: [17][45/96]\tLoss 0.5255 (0.5138)\taccuracy 78.125 (80.978)\tf1_score 69.161 (76.767)\n",
      "Epoch: [17][50/96]\tLoss 0.2947 (0.5016)\taccuracy 87.500 (81.373)\tf1_score 84.475 (77.320)\n",
      "Epoch: [17][55/96]\tLoss 0.7814 (0.4998)\taccuracy 73.438 (81.585)\tf1_score 70.617 (77.628)\n",
      "Epoch: [17][60/96]\tLoss 0.5117 (0.4939)\taccuracy 81.250 (81.685)\tf1_score 77.876 (77.577)\n",
      "Epoch: [17][65/96]\tLoss 0.4439 (0.4865)\taccuracy 84.375 (81.747)\tf1_score 78.062 (77.708)\n",
      "Epoch: [17][70/96]\tLoss 0.5958 (0.4881)\taccuracy 73.438 (81.602)\tf1_score 63.553 (77.376)\n",
      "Epoch: [17][75/96]\tLoss 0.4460 (0.4881)\taccuracy 89.062 (81.702)\tf1_score 86.772 (77.314)\n",
      "Epoch: [17][80/96]\tLoss 0.5981 (0.4934)\taccuracy 75.000 (81.501)\tf1_score 73.406 (77.044)\n",
      "Epoch: [17][85/96]\tLoss 0.4315 (0.4918)\taccuracy 79.688 (81.432)\tf1_score 70.814 (77.100)\n",
      "Epoch: [17][90/96]\tLoss 0.4585 (0.4954)\taccuracy 85.938 (81.284)\tf1_score 83.886 (77.136)\n",
      "Epoch: [17][95/96]\tLoss 0.6061 (0.4970)\taccuracy 71.875 (81.201)\tf1_score 69.928 (77.191)\n",
      " Test: accuracy 49.284 f1_score 41.209\n",
      "Training time:  459.91949129104614 Hour:  0 Minute:  7 Second:  39 Test best accuracy: 75.45572916666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 18\n",
      "Epoch: [18][0/96]\tLoss 0.4490 (0.4490)\taccuracy 82.812 (82.812)\tf1_score 80.783 (80.783)\n",
      "Epoch: [18][5/96]\tLoss 0.4023 (0.4137)\taccuracy 84.375 (85.156)\tf1_score 83.776 (80.911)\n",
      "Epoch: [18][10/96]\tLoss 0.5670 (0.4809)\taccuracy 76.562 (81.534)\tf1_score 65.657 (76.434)\n",
      "Epoch: [18][15/96]\tLoss 0.5734 (0.5423)\taccuracy 71.875 (79.297)\tf1_score 71.262 (74.633)\n",
      "Epoch: [18][20/96]\tLoss 0.6501 (0.5405)\taccuracy 73.438 (79.018)\tf1_score 72.480 (74.217)\n",
      "Epoch: [18][25/96]\tLoss 0.5791 (0.5434)\taccuracy 81.250 (78.966)\tf1_score 81.542 (74.540)\n",
      "Epoch: [18][30/96]\tLoss 0.3109 (0.5365)\taccuracy 90.625 (79.284)\tf1_score 86.829 (74.552)\n",
      "Epoch: [18][35/96]\tLoss 0.7469 (0.5331)\taccuracy 78.125 (79.861)\tf1_score 64.896 (75.174)\n",
      "Epoch: [18][40/96]\tLoss 0.5928 (0.5414)\taccuracy 79.688 (80.030)\tf1_score 79.890 (75.751)\n",
      "Epoch: [18][45/96]\tLoss 0.3507 (0.5212)\taccuracy 84.375 (80.774)\tf1_score 79.583 (76.600)\n",
      "Epoch: [18][50/96]\tLoss 0.5508 (0.5238)\taccuracy 76.562 (80.515)\tf1_score 73.425 (76.297)\n",
      "Epoch: [18][55/96]\tLoss 0.6992 (0.5198)\taccuracy 75.000 (80.441)\tf1_score 77.155 (76.246)\n",
      "Epoch: [18][60/96]\tLoss 1.0615 (0.5346)\taccuracy 62.500 (80.020)\tf1_score 59.207 (75.752)\n",
      "Epoch: [18][65/96]\tLoss 0.6495 (0.5313)\taccuracy 79.688 (80.256)\tf1_score 73.216 (76.100)\n",
      "Epoch: [18][70/96]\tLoss 0.6529 (0.5341)\taccuracy 78.125 (80.150)\tf1_score 69.616 (75.840)\n",
      "Epoch: [18][75/96]\tLoss 0.4435 (0.5325)\taccuracy 81.250 (80.222)\tf1_score 74.036 (76.002)\n",
      "Epoch: [18][80/96]\tLoss 0.9078 (0.5343)\taccuracy 65.625 (80.112)\tf1_score 56.774 (75.904)\n",
      "Epoch: [18][85/96]\tLoss 0.3139 (0.5289)\taccuracy 87.500 (80.305)\tf1_score 85.215 (76.164)\n",
      "Epoch: [18][90/96]\tLoss 0.5299 (0.5268)\taccuracy 85.938 (80.443)\tf1_score 81.968 (76.298)\n",
      "Epoch: [18][95/96]\tLoss 0.4801 (0.5231)\taccuracy 81.250 (80.469)\tf1_score 71.874 (76.236)\n",
      " Test: accuracy 79.036 f1_score 74.311\n",
      "Training time:  475.86435198783875 Hour:  0 Minute:  7 Second:  55 Test best accuracy: 79.03645833333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 19\n",
      "Epoch: [19][0/96]\tLoss 0.4299 (0.4299)\taccuracy 85.938 (85.938)\tf1_score 81.056 (81.056)\n",
      "Epoch: [19][5/96]\tLoss 0.4638 (0.3853)\taccuracy 79.688 (85.156)\tf1_score 72.086 (82.041)\n",
      "Epoch: [19][10/96]\tLoss 0.4057 (0.4108)\taccuracy 84.375 (83.807)\tf1_score 81.927 (80.204)\n",
      "Epoch: [19][15/96]\tLoss 0.4906 (0.4505)\taccuracy 79.688 (82.324)\tf1_score 71.365 (78.646)\n",
      "Epoch: [19][20/96]\tLoss 0.5772 (0.4391)\taccuracy 78.125 (82.589)\tf1_score 65.692 (78.731)\n",
      "Epoch: [19][25/96]\tLoss 0.3890 (0.4486)\taccuracy 87.500 (82.632)\tf1_score 84.912 (79.220)\n",
      "Epoch: [19][30/96]\tLoss 0.3634 (0.4395)\taccuracy 85.938 (82.863)\tf1_score 86.905 (79.713)\n",
      "Epoch: [19][35/96]\tLoss 0.3955 (0.4294)\taccuracy 82.812 (83.290)\tf1_score 83.778 (80.416)\n",
      "Epoch: [19][40/96]\tLoss 0.2950 (0.4227)\taccuracy 92.188 (83.689)\tf1_score 90.026 (80.999)\n",
      "Epoch: [19][45/96]\tLoss 0.3830 (0.4245)\taccuracy 85.938 (83.628)\tf1_score 87.349 (81.044)\n",
      "Epoch: [19][50/96]\tLoss 0.2573 (0.4194)\taccuracy 89.062 (83.824)\tf1_score 81.245 (81.014)\n",
      "Epoch: [19][55/96]\tLoss 0.4964 (0.4261)\taccuracy 79.688 (83.705)\tf1_score 84.854 (80.912)\n",
      "Epoch: [19][60/96]\tLoss 0.3007 (0.4265)\taccuracy 90.625 (83.735)\tf1_score 88.036 (80.903)\n",
      "Epoch: [19][65/96]\tLoss 0.4444 (0.4273)\taccuracy 84.375 (83.878)\tf1_score 78.776 (80.861)\n",
      "Epoch: [19][70/96]\tLoss 0.2462 (0.4257)\taccuracy 92.188 (83.979)\tf1_score 87.292 (80.898)\n",
      "Epoch: [19][75/96]\tLoss 0.3554 (0.4230)\taccuracy 87.500 (84.149)\tf1_score 85.339 (81.140)\n",
      "Epoch: [19][80/96]\tLoss 0.5331 (0.4263)\taccuracy 67.188 (83.951)\tf1_score 62.646 (80.882)\n",
      "Epoch: [19][85/96]\tLoss 0.4263 (0.4236)\taccuracy 79.688 (83.975)\tf1_score 78.237 (80.977)\n",
      "Epoch: [19][90/96]\tLoss 0.4623 (0.4256)\taccuracy 85.938 (83.860)\tf1_score 77.492 (80.861)\n",
      "Epoch: [19][95/96]\tLoss 0.5229 (0.4247)\taccuracy 79.688 (83.838)\tf1_score 72.376 (80.824)\n",
      " Test: accuracy 74.219 f1_score 70.506\n",
      "Training time:  491.76510858535767 Hour:  0 Minute:  8 Second:  11 Test best accuracy: 79.03645833333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 20\n",
      "Epoch: [20][0/96]\tLoss 0.4900 (0.4900)\taccuracy 81.250 (81.250)\tf1_score 68.859 (68.859)\n",
      "Epoch: [20][5/96]\tLoss 0.3467 (0.4444)\taccuracy 85.938 (82.031)\tf1_score 85.351 (79.333)\n",
      "Epoch: [20][10/96]\tLoss 0.4216 (0.4131)\taccuracy 79.688 (84.233)\tf1_score 77.189 (81.630)\n",
      "Epoch: [20][15/96]\tLoss 0.3704 (0.4185)\taccuracy 84.375 (83.691)\tf1_score 75.692 (80.163)\n",
      "Epoch: [20][20/96]\tLoss 0.3166 (0.4059)\taccuracy 85.938 (84.226)\tf1_score 83.176 (80.666)\n",
      "Epoch: [20][25/96]\tLoss 0.1889 (0.3856)\taccuracy 93.750 (85.156)\tf1_score 84.737 (81.748)\n",
      "Epoch: [20][30/96]\tLoss 0.4129 (0.3936)\taccuracy 78.125 (84.879)\tf1_score 76.154 (81.564)\n",
      "Epoch: [20][35/96]\tLoss 0.3822 (0.3906)\taccuracy 89.062 (84.896)\tf1_score 86.254 (81.429)\n",
      "Epoch: [20][40/96]\tLoss 0.4066 (0.4010)\taccuracy 84.375 (84.223)\tf1_score 83.941 (80.705)\n",
      "Epoch: [20][45/96]\tLoss 0.2893 (0.4150)\taccuracy 90.625 (84.069)\tf1_score 83.333 (80.584)\n",
      "Epoch: [20][50/96]\tLoss 0.3691 (0.4230)\taccuracy 82.812 (83.854)\tf1_score 70.102 (80.201)\n",
      "Epoch: [20][55/96]\tLoss 0.5624 (0.4249)\taccuracy 82.812 (83.817)\tf1_score 85.881 (80.409)\n",
      "Epoch: [20][60/96]\tLoss 0.4802 (0.4343)\taccuracy 79.688 (83.427)\tf1_score 78.503 (80.204)\n",
      "Epoch: [20][65/96]\tLoss 0.5506 (0.4332)\taccuracy 79.688 (83.499)\tf1_score 74.465 (80.186)\n",
      "Epoch: [20][70/96]\tLoss 0.2997 (0.4278)\taccuracy 87.500 (83.649)\tf1_score 84.786 (80.503)\n",
      "Epoch: [20][75/96]\tLoss 0.6503 (0.4275)\taccuracy 68.750 (83.532)\tf1_score 66.645 (80.257)\n",
      "Epoch: [20][80/96]\tLoss 0.4235 (0.4260)\taccuracy 82.812 (83.565)\tf1_score 88.935 (80.418)\n",
      "Epoch: [20][85/96]\tLoss 0.3928 (0.4236)\taccuracy 84.375 (83.521)\tf1_score 81.372 (80.212)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20][90/96]\tLoss 0.3701 (0.4214)\taccuracy 84.375 (83.585)\tf1_score 86.449 (80.453)\n",
      "Epoch: [20][95/96]\tLoss 0.2907 (0.4199)\taccuracy 90.625 (83.822)\tf1_score 92.666 (80.673)\n",
      " Test: accuracy 71.224 f1_score 66.089\n",
      "Training time:  507.63719296455383 Hour:  0 Minute:  8 Second:  27 Test best accuracy: 79.03645833333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 21\n",
      "Epoch: [21][0/96]\tLoss 0.2513 (0.2513)\taccuracy 92.188 (92.188)\tf1_score 93.246 (93.246)\n",
      "Epoch: [21][5/96]\tLoss 0.3628 (0.3566)\taccuracy 84.375 (86.198)\tf1_score 84.082 (85.787)\n",
      "Epoch: [21][10/96]\tLoss 0.1783 (0.3557)\taccuracy 92.188 (85.795)\tf1_score 91.427 (84.942)\n",
      "Epoch: [21][15/96]\tLoss 0.5295 (0.3618)\taccuracy 85.938 (86.328)\tf1_score 79.562 (85.037)\n",
      "Epoch: [21][20/96]\tLoss 0.3488 (0.3741)\taccuracy 85.938 (85.714)\tf1_score 82.175 (83.784)\n",
      "Epoch: [21][25/96]\tLoss 0.5742 (0.3853)\taccuracy 76.562 (84.916)\tf1_score 69.291 (82.503)\n",
      "Epoch: [21][30/96]\tLoss 0.4544 (0.4051)\taccuracy 82.812 (84.375)\tf1_score 83.787 (82.170)\n",
      "Epoch: [21][35/96]\tLoss 0.5367 (0.4172)\taccuracy 79.688 (84.028)\tf1_score 74.624 (81.681)\n",
      "Epoch: [21][40/96]\tLoss 0.4236 (0.4343)\taccuracy 84.375 (83.460)\tf1_score 85.302 (81.158)\n",
      "Epoch: [21][45/96]\tLoss 0.6407 (0.4483)\taccuracy 71.875 (82.711)\tf1_score 71.565 (80.415)\n",
      "Epoch: [21][50/96]\tLoss 0.5046 (0.4538)\taccuracy 81.250 (82.475)\tf1_score 72.613 (80.071)\n",
      "Epoch: [21][55/96]\tLoss 0.4951 (0.4512)\taccuracy 82.812 (82.645)\tf1_score 83.655 (80.216)\n",
      "Epoch: [21][60/96]\tLoss 0.4578 (0.4570)\taccuracy 79.688 (82.377)\tf1_score 79.817 (80.004)\n",
      "Epoch: [21][65/96]\tLoss 0.7959 (0.4650)\taccuracy 75.000 (82.173)\tf1_score 73.450 (79.761)\n",
      "Epoch: [21][70/96]\tLoss 0.4336 (0.4623)\taccuracy 81.250 (82.174)\tf1_score 74.468 (79.600)\n",
      "Epoch: [21][75/96]\tLoss 0.3633 (0.4655)\taccuracy 82.812 (81.908)\tf1_score 76.795 (79.178)\n",
      "Epoch: [21][80/96]\tLoss 0.4219 (0.4619)\taccuracy 79.688 (82.099)\tf1_score 78.269 (79.379)\n",
      "Epoch: [21][85/96]\tLoss 0.3847 (0.4596)\taccuracy 89.062 (82.249)\tf1_score 78.050 (79.276)\n",
      "Epoch: [21][90/96]\tLoss 0.6367 (0.4664)\taccuracy 76.562 (82.040)\tf1_score 72.505 (79.002)\n",
      "Epoch: [21][95/96]\tLoss 0.4139 (0.4658)\taccuracy 79.688 (81.950)\tf1_score 79.471 (78.848)\n",
      " Test: accuracy 50.326 f1_score 44.855\n",
      "Training time:  523.5409984588623 Hour:  0 Minute:  8 Second:  43 Test best accuracy: 79.03645833333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 22\n",
      "Epoch: [22][0/96]\tLoss 0.5967 (0.5967)\taccuracy 76.562 (76.562)\tf1_score 70.831 (70.831)\n",
      "Epoch: [22][5/96]\tLoss 0.5446 (0.4444)\taccuracy 75.000 (84.896)\tf1_score 67.250 (79.301)\n",
      "Epoch: [22][10/96]\tLoss 0.4507 (0.4516)\taccuracy 82.812 (84.517)\tf1_score 77.949 (80.424)\n",
      "Epoch: [22][15/96]\tLoss 0.4246 (0.4797)\taccuracy 81.250 (82.715)\tf1_score 71.088 (77.604)\n",
      "Epoch: [22][20/96]\tLoss 0.9324 (0.4846)\taccuracy 64.062 (82.068)\tf1_score 58.572 (77.065)\n",
      "Epoch: [22][25/96]\tLoss 0.3906 (0.4917)\taccuracy 85.938 (82.031)\tf1_score 76.946 (76.922)\n",
      "Epoch: [22][30/96]\tLoss 0.6156 (0.4813)\taccuracy 73.438 (82.510)\tf1_score 71.047 (77.832)\n",
      "Epoch: [22][35/96]\tLoss 0.4411 (0.4819)\taccuracy 81.250 (82.292)\tf1_score 77.506 (77.542)\n",
      "Epoch: [22][40/96]\tLoss 0.3707 (0.4867)\taccuracy 87.500 (82.279)\tf1_score 85.986 (77.858)\n",
      "Epoch: [22][45/96]\tLoss 0.5571 (0.4933)\taccuracy 79.688 (82.031)\tf1_score 77.996 (77.681)\n",
      "Epoch: [22][50/96]\tLoss 0.3019 (0.4810)\taccuracy 87.500 (82.475)\tf1_score 84.140 (78.122)\n",
      "Epoch: [22][55/96]\tLoss 0.3875 (0.4689)\taccuracy 92.188 (82.868)\tf1_score 87.932 (78.373)\n",
      "Epoch: [22][60/96]\tLoss 0.4055 (0.4677)\taccuracy 85.938 (82.864)\tf1_score 84.286 (78.281)\n",
      "Epoch: [22][65/96]\tLoss 0.4226 (0.4602)\taccuracy 85.938 (83.120)\tf1_score 82.246 (78.621)\n",
      "Epoch: [22][70/96]\tLoss 0.3642 (0.4551)\taccuracy 89.062 (83.297)\tf1_score 84.332 (78.907)\n",
      "Epoch: [22][75/96]\tLoss 0.3292 (0.4484)\taccuracy 89.062 (83.676)\tf1_score 88.571 (79.455)\n",
      "Epoch: [22][80/96]\tLoss 0.5033 (0.4471)\taccuracy 79.688 (83.603)\tf1_score 78.304 (79.442)\n",
      "Epoch: [22][85/96]\tLoss 0.3545 (0.4426)\taccuracy 84.375 (83.757)\tf1_score 87.119 (79.743)\n",
      "Epoch: [22][90/96]\tLoss 0.2689 (0.4384)\taccuracy 90.625 (83.688)\tf1_score 90.401 (79.749)\n",
      "Epoch: [22][95/96]\tLoss 0.2877 (0.4360)\taccuracy 87.500 (83.643)\tf1_score 89.737 (79.880)\n",
      " Test: accuracy 81.836 f1_score 78.811\n",
      "Training time:  539.5164241790771 Hour:  0 Minute:  8 Second:  59 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 23\n",
      "Epoch: [23][0/96]\tLoss 0.4662 (0.4662)\taccuracy 81.250 (81.250)\tf1_score 82.542 (82.542)\n",
      "Epoch: [23][5/96]\tLoss 0.3583 (0.3612)\taccuracy 84.375 (84.375)\tf1_score 80.344 (81.542)\n",
      "Epoch: [23][10/96]\tLoss 0.3204 (0.4065)\taccuracy 87.500 (83.523)\tf1_score 85.055 (81.587)\n",
      "Epoch: [23][15/96]\tLoss 0.2615 (0.3855)\taccuracy 92.188 (85.254)\tf1_score 88.508 (82.608)\n",
      "Epoch: [23][20/96]\tLoss 0.3371 (0.3994)\taccuracy 87.500 (84.003)\tf1_score 79.849 (81.197)\n",
      "Epoch: [23][25/96]\tLoss 0.3898 (0.3882)\taccuracy 84.375 (84.495)\tf1_score 80.427 (81.725)\n",
      "Epoch: [23][30/96]\tLoss 0.3158 (0.3865)\taccuracy 90.625 (84.980)\tf1_score 83.397 (82.170)\n",
      "Epoch: [23][35/96]\tLoss 0.4192 (0.3915)\taccuracy 85.938 (85.069)\tf1_score 85.295 (82.281)\n",
      "Epoch: [23][40/96]\tLoss 0.3934 (0.3876)\taccuracy 78.125 (85.023)\tf1_score 70.476 (82.047)\n",
      "Epoch: [23][45/96]\tLoss 0.3099 (0.3904)\taccuracy 84.375 (84.681)\tf1_score 82.874 (81.539)\n",
      "Epoch: [23][50/96]\tLoss 0.2574 (0.3831)\taccuracy 90.625 (85.018)\tf1_score 91.370 (82.024)\n",
      "Epoch: [23][55/96]\tLoss 0.5131 (0.3884)\taccuracy 76.562 (84.710)\tf1_score 72.869 (81.698)\n",
      "Epoch: [23][60/96]\tLoss 0.4648 (0.3856)\taccuracy 82.812 (84.734)\tf1_score 78.719 (81.750)\n",
      "Epoch: [23][65/96]\tLoss 0.3696 (0.3901)\taccuracy 82.812 (84.375)\tf1_score 81.967 (81.486)\n",
      "Epoch: [23][70/96]\tLoss 0.3136 (0.3878)\taccuracy 85.938 (84.595)\tf1_score 78.093 (81.749)\n",
      "Epoch: [23][75/96]\tLoss 0.4696 (0.3890)\taccuracy 79.688 (84.519)\tf1_score 79.569 (81.722)\n",
      "Epoch: [23][80/96]\tLoss 0.3935 (0.3888)\taccuracy 82.812 (84.529)\tf1_score 78.313 (81.730)\n",
      "Epoch: [23][85/96]\tLoss 0.7342 (0.3980)\taccuracy 76.562 (84.320)\tf1_score 74.147 (81.482)\n",
      "Epoch: [23][90/96]\tLoss 0.4244 (0.3972)\taccuracy 81.250 (84.272)\tf1_score 78.785 (81.522)\n",
      "Epoch: [23][95/96]\tLoss 0.5193 (0.3980)\taccuracy 76.562 (84.115)\tf1_score 66.131 (81.180)\n",
      " Test: accuracy 73.047 f1_score 68.569\n",
      "Training time:  555.3894598484039 Hour:  0 Minute:  9 Second:  15 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 24\n",
      "Epoch: [24][0/96]\tLoss 0.2429 (0.2429)\taccuracy 90.625 (90.625)\tf1_score 87.653 (87.653)\n",
      "Epoch: [24][5/96]\tLoss 0.6874 (0.3840)\taccuracy 75.000 (85.677)\tf1_score 65.605 (82.502)\n",
      "Epoch: [24][10/96]\tLoss 0.3171 (0.3768)\taccuracy 87.500 (86.222)\tf1_score 80.643 (81.922)\n",
      "Epoch: [24][15/96]\tLoss 0.2976 (0.3972)\taccuracy 90.625 (85.645)\tf1_score 91.145 (81.483)\n",
      "Epoch: [24][20/96]\tLoss 0.3468 (0.3927)\taccuracy 84.375 (85.417)\tf1_score 80.108 (80.341)\n",
      "Epoch: [24][25/96]\tLoss 0.2532 (0.3800)\taccuracy 89.062 (85.697)\tf1_score 82.810 (81.050)\n",
      "Epoch: [24][30/96]\tLoss 0.5101 (0.3855)\taccuracy 78.125 (85.081)\tf1_score 71.859 (80.930)\n",
      "Epoch: [24][35/96]\tLoss 0.4564 (0.3948)\taccuracy 81.250 (84.722)\tf1_score 78.549 (80.802)\n",
      "Epoch: [24][40/96]\tLoss 0.3834 (0.3930)\taccuracy 85.938 (84.947)\tf1_score 81.100 (81.343)\n",
      "Epoch: [24][45/96]\tLoss 0.5444 (0.3903)\taccuracy 84.375 (85.122)\tf1_score 84.909 (81.763)\n",
      "Epoch: [24][50/96]\tLoss 0.3072 (0.3901)\taccuracy 87.500 (85.233)\tf1_score 87.702 (82.067)\n",
      "Epoch: [24][55/96]\tLoss 0.3045 (0.3853)\taccuracy 87.500 (85.324)\tf1_score 83.705 (82.087)\n",
      "Epoch: [24][60/96]\tLoss 0.3286 (0.3879)\taccuracy 85.938 (85.118)\tf1_score 86.585 (82.003)\n",
      "Epoch: [24][65/96]\tLoss 0.2790 (0.3893)\taccuracy 92.188 (85.038)\tf1_score 89.909 (81.822)\n",
      "Epoch: [24][70/96]\tLoss 0.3685 (0.3833)\taccuracy 85.938 (85.387)\tf1_score 86.234 (82.334)\n",
      "Epoch: [24][75/96]\tLoss 0.3024 (0.3783)\taccuracy 87.500 (85.567)\tf1_score 87.718 (82.619)\n",
      "Epoch: [24][80/96]\tLoss 0.3802 (0.3839)\taccuracy 84.375 (85.455)\tf1_score 87.230 (82.637)\n",
      "Epoch: [24][85/96]\tLoss 0.4089 (0.3830)\taccuracy 82.812 (85.447)\tf1_score 80.220 (82.583)\n",
      "Epoch: [24][90/96]\tLoss 0.3253 (0.3814)\taccuracy 90.625 (85.577)\tf1_score 88.685 (82.734)\n",
      "Epoch: [24][95/96]\tLoss 0.4465 (0.3797)\taccuracy 82.812 (85.563)\tf1_score 82.035 (82.763)\n",
      " Test: accuracy 77.669 f1_score 73.947\n",
      "Training time:  571.2704148292542 Hour:  0 Minute:  9 Second:  31 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 25\n",
      "Epoch: [25][0/96]\tLoss 0.3703 (0.3703)\taccuracy 87.500 (87.500)\tf1_score 81.905 (81.905)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][5/96]\tLoss 0.3337 (0.3776)\taccuracy 87.500 (86.458)\tf1_score 85.105 (82.972)\n",
      "Epoch: [25][10/96]\tLoss 0.2989 (0.3859)\taccuracy 84.375 (85.085)\tf1_score 79.554 (81.960)\n",
      "Epoch: [25][15/96]\tLoss 0.2953 (0.3963)\taccuracy 87.500 (84.570)\tf1_score 82.970 (81.846)\n",
      "Epoch: [25][20/96]\tLoss 0.5978 (0.3972)\taccuracy 73.438 (84.598)\tf1_score 70.879 (81.047)\n",
      "Epoch: [25][25/96]\tLoss 0.3316 (0.4047)\taccuracy 93.750 (84.555)\tf1_score 94.442 (80.998)\n",
      "Epoch: [25][30/96]\tLoss 0.3439 (0.3990)\taccuracy 89.062 (84.728)\tf1_score 88.870 (81.380)\n",
      "Epoch: [25][35/96]\tLoss 0.3268 (0.3912)\taccuracy 84.375 (84.852)\tf1_score 84.800 (81.784)\n",
      "Epoch: [25][40/96]\tLoss 0.3237 (0.3961)\taccuracy 84.375 (84.642)\tf1_score 80.974 (81.217)\n",
      "Epoch: [25][45/96]\tLoss 0.7483 (0.4016)\taccuracy 75.000 (84.579)\tf1_score 75.970 (81.207)\n",
      "Epoch: [25][50/96]\tLoss 0.3562 (0.3976)\taccuracy 87.500 (84.896)\tf1_score 84.431 (81.613)\n",
      "Epoch: [25][55/96]\tLoss 0.6611 (0.3991)\taccuracy 68.750 (84.682)\tf1_score 65.582 (81.489)\n",
      "Epoch: [25][60/96]\tLoss 0.5824 (0.3994)\taccuracy 73.438 (84.631)\tf1_score 73.663 (81.365)\n",
      "Epoch: [25][65/96]\tLoss 0.4063 (0.3974)\taccuracy 87.500 (84.754)\tf1_score 87.786 (81.687)\n",
      "Epoch: [25][70/96]\tLoss 0.2906 (0.3958)\taccuracy 85.938 (84.727)\tf1_score 69.384 (81.311)\n",
      "Epoch: [25][75/96]\tLoss 0.3621 (0.3946)\taccuracy 87.500 (84.725)\tf1_score 86.251 (81.400)\n",
      "Epoch: [25][80/96]\tLoss 0.3518 (0.3933)\taccuracy 84.375 (84.799)\tf1_score 79.902 (81.601)\n",
      "Epoch: [25][85/96]\tLoss 0.3427 (0.3925)\taccuracy 90.625 (84.902)\tf1_score 80.743 (81.719)\n",
      "Epoch: [25][90/96]\tLoss 0.4602 (0.3949)\taccuracy 79.688 (84.736)\tf1_score 77.842 (81.553)\n",
      "Epoch: [25][95/96]\tLoss 0.3989 (0.3972)\taccuracy 84.375 (84.635)\tf1_score 80.006 (81.404)\n",
      " Test: accuracy 79.492 f1_score 76.265\n",
      "Training time:  587.1759881973267 Hour:  0 Minute:  9 Second:  47 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 26\n",
      "Epoch: [26][0/96]\tLoss 0.2918 (0.2918)\taccuracy 87.500 (87.500)\tf1_score 84.688 (84.688)\n",
      "Epoch: [26][5/96]\tLoss 0.2615 (0.3071)\taccuracy 87.500 (87.500)\tf1_score 84.311 (86.091)\n",
      "Epoch: [26][10/96]\tLoss 0.5206 (0.3778)\taccuracy 79.688 (85.085)\tf1_score 76.313 (83.519)\n",
      "Epoch: [26][15/96]\tLoss 0.3376 (0.3602)\taccuracy 81.250 (85.156)\tf1_score 78.743 (83.979)\n",
      "Epoch: [26][20/96]\tLoss 0.4065 (0.3894)\taccuracy 85.938 (84.226)\tf1_score 81.463 (82.219)\n",
      "Epoch: [26][25/96]\tLoss 0.5185 (0.3964)\taccuracy 75.000 (83.834)\tf1_score 70.700 (81.687)\n",
      "Epoch: [26][30/96]\tLoss 0.5561 (0.4123)\taccuracy 84.375 (83.669)\tf1_score 76.841 (81.031)\n",
      "Epoch: [26][35/96]\tLoss 0.3983 (0.4119)\taccuracy 89.062 (83.984)\tf1_score 85.286 (81.384)\n",
      "Epoch: [26][40/96]\tLoss 0.6154 (0.4194)\taccuracy 75.000 (83.651)\tf1_score 74.281 (80.837)\n",
      "Epoch: [26][45/96]\tLoss 0.3160 (0.4143)\taccuracy 87.500 (83.967)\tf1_score 84.596 (81.250)\n",
      "Epoch: [26][50/96]\tLoss 0.4358 (0.4066)\taccuracy 79.688 (84.252)\tf1_score 68.936 (81.134)\n",
      "Epoch: [26][55/96]\tLoss 0.3812 (0.4118)\taccuracy 84.375 (84.096)\tf1_score 84.607 (81.151)\n",
      "Epoch: [26][60/96]\tLoss 0.3565 (0.4103)\taccuracy 87.500 (84.221)\tf1_score 88.357 (81.370)\n",
      "Epoch: [26][65/96]\tLoss 0.2773 (0.4074)\taccuracy 89.062 (84.399)\tf1_score 87.018 (81.667)\n",
      "Epoch: [26][70/96]\tLoss 0.2209 (0.4042)\taccuracy 93.750 (84.419)\tf1_score 94.962 (81.683)\n",
      "Epoch: [26][75/96]\tLoss 0.4375 (0.4002)\taccuracy 81.250 (84.560)\tf1_score 75.280 (81.590)\n",
      "Epoch: [26][80/96]\tLoss 0.3958 (0.4037)\taccuracy 82.812 (84.414)\tf1_score 77.500 (81.256)\n",
      "Epoch: [26][85/96]\tLoss 0.5335 (0.4038)\taccuracy 71.875 (84.357)\tf1_score 66.653 (81.262)\n",
      "Epoch: [26][90/96]\tLoss 0.4288 (0.4024)\taccuracy 81.250 (84.392)\tf1_score 74.888 (81.120)\n",
      "Epoch: [26][95/96]\tLoss 0.3036 (0.3985)\taccuracy 90.625 (84.635)\tf1_score 86.857 (81.353)\n",
      " Test: accuracy 63.737 f1_score 56.890\n",
      "Training time:  603.004292011261 Hour:  0 Minute:  10 Second:  3 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 27\n",
      "Epoch: [27][0/96]\tLoss 0.5540 (0.5540)\taccuracy 78.125 (78.125)\tf1_score 77.137 (77.137)\n",
      "Epoch: [27][5/96]\tLoss 0.1467 (0.3720)\taccuracy 96.875 (85.677)\tf1_score 93.091 (81.200)\n",
      "Epoch: [27][10/96]\tLoss 0.2291 (0.3339)\taccuracy 90.625 (86.648)\tf1_score 87.831 (82.971)\n",
      "Epoch: [27][15/96]\tLoss 0.2922 (0.3357)\taccuracy 87.500 (85.840)\tf1_score 77.049 (82.604)\n",
      "Epoch: [27][20/96]\tLoss 0.3062 (0.3578)\taccuracy 85.938 (84.673)\tf1_score 77.619 (81.715)\n",
      "Epoch: [27][25/96]\tLoss 0.2631 (0.3700)\taccuracy 87.500 (84.856)\tf1_score 80.306 (81.824)\n",
      "Epoch: [27][30/96]\tLoss 0.2852 (0.3687)\taccuracy 93.750 (85.232)\tf1_score 92.222 (82.298)\n",
      "Epoch: [27][35/96]\tLoss 0.3535 (0.3878)\taccuracy 81.250 (84.245)\tf1_score 76.240 (81.197)\n",
      "Epoch: [27][40/96]\tLoss 0.5950 (0.3969)\taccuracy 81.250 (83.956)\tf1_score 71.524 (80.638)\n",
      "Epoch: [27][45/96]\tLoss 0.2605 (0.3860)\taccuracy 87.500 (84.375)\tf1_score 81.859 (81.183)\n",
      "Epoch: [27][50/96]\tLoss 0.5249 (0.3921)\taccuracy 84.375 (84.283)\tf1_score 78.772 (81.092)\n",
      "Epoch: [27][55/96]\tLoss 0.3857 (0.3874)\taccuracy 82.812 (84.375)\tf1_score 71.198 (81.022)\n",
      "Epoch: [27][60/96]\tLoss 0.6207 (0.3884)\taccuracy 76.562 (84.401)\tf1_score 75.870 (81.173)\n",
      "Epoch: [27][65/96]\tLoss 0.4381 (0.3884)\taccuracy 82.812 (84.422)\tf1_score 78.440 (81.274)\n",
      "Epoch: [27][70/96]\tLoss 0.2817 (0.3926)\taccuracy 89.062 (84.485)\tf1_score 80.741 (81.147)\n",
      "Epoch: [27][75/96]\tLoss 0.2702 (0.3929)\taccuracy 87.500 (84.560)\tf1_score 85.827 (81.218)\n",
      "Epoch: [27][80/96]\tLoss 0.3653 (0.3944)\taccuracy 84.375 (84.529)\tf1_score 81.337 (80.943)\n",
      "Epoch: [27][85/96]\tLoss 0.3535 (0.3939)\taccuracy 89.062 (84.666)\tf1_score 86.693 (81.176)\n",
      "Epoch: [27][90/96]\tLoss 0.6831 (0.4000)\taccuracy 73.438 (84.530)\tf1_score 64.373 (81.039)\n",
      "Epoch: [27][95/96]\tLoss 0.4886 (0.3976)\taccuracy 75.000 (84.473)\tf1_score 76.298 (80.948)\n",
      " Test: accuracy 63.802 f1_score 58.374\n",
      "Training time:  618.9064819812775 Hour:  0 Minute:  10 Second:  18 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 28\n",
      "Epoch: [28][0/96]\tLoss 0.5138 (0.5138)\taccuracy 82.812 (82.812)\tf1_score 78.803 (78.803)\n",
      "Epoch: [28][5/96]\tLoss 0.5372 (0.3689)\taccuracy 79.688 (85.417)\tf1_score 80.751 (81.530)\n",
      "Epoch: [28][10/96]\tLoss 0.4932 (0.3564)\taccuracy 81.250 (85.511)\tf1_score 81.000 (82.158)\n",
      "Epoch: [28][15/96]\tLoss 0.2569 (0.3503)\taccuracy 90.625 (86.230)\tf1_score 90.835 (83.125)\n",
      "Epoch: [28][20/96]\tLoss 0.3451 (0.3432)\taccuracy 85.938 (86.310)\tf1_score 83.571 (83.241)\n",
      "Epoch: [28][25/96]\tLoss 0.4443 (0.3479)\taccuracy 81.250 (86.058)\tf1_score 82.125 (83.036)\n",
      "Epoch: [28][30/96]\tLoss 0.2510 (0.3384)\taccuracy 90.625 (86.593)\tf1_score 88.333 (83.587)\n",
      "Epoch: [28][35/96]\tLoss 0.3090 (0.3381)\taccuracy 85.938 (86.372)\tf1_score 84.737 (83.300)\n",
      "Epoch: [28][40/96]\tLoss 0.2461 (0.3358)\taccuracy 90.625 (86.433)\tf1_score 87.329 (83.404)\n",
      "Epoch: [28][45/96]\tLoss 0.3259 (0.3420)\taccuracy 87.500 (86.277)\tf1_score 79.277 (83.256)\n",
      "Epoch: [28][50/96]\tLoss 0.3497 (0.3493)\taccuracy 87.500 (86.121)\tf1_score 87.286 (82.928)\n",
      "Epoch: [28][55/96]\tLoss 0.3393 (0.3495)\taccuracy 84.375 (86.217)\tf1_score 80.639 (83.090)\n",
      "Epoch: [28][60/96]\tLoss 0.2076 (0.3512)\taccuracy 92.188 (86.219)\tf1_score 91.232 (83.138)\n",
      "Epoch: [28][65/96]\tLoss 0.6960 (0.3666)\taccuracy 73.438 (85.795)\tf1_score 70.710 (82.731)\n",
      "Epoch: [28][70/96]\tLoss 0.2242 (0.3706)\taccuracy 90.625 (85.541)\tf1_score 86.385 (82.514)\n",
      "Epoch: [28][75/96]\tLoss 0.3872 (0.3664)\taccuracy 84.375 (85.650)\tf1_score 83.364 (82.741)\n",
      "Epoch: [28][80/96]\tLoss 0.6081 (0.3675)\taccuracy 73.438 (85.475)\tf1_score 73.909 (82.750)\n",
      "Epoch: [28][85/96]\tLoss 0.3268 (0.3673)\taccuracy 85.938 (85.520)\tf1_score 81.115 (82.686)\n",
      "Epoch: [28][90/96]\tLoss 0.1917 (0.3715)\taccuracy 92.188 (85.508)\tf1_score 89.227 (82.614)\n",
      "Epoch: [28][95/96]\tLoss 0.3930 (0.3727)\taccuracy 81.250 (85.417)\tf1_score 76.747 (82.457)\n",
      " Test: accuracy 50.130 f1_score 41.601\n",
      "Training time:  635.1383857727051 Hour:  0 Minute:  10 Second:  35 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 29\n",
      "Epoch: [29][0/96]\tLoss 0.4178 (0.4178)\taccuracy 85.938 (85.938)\tf1_score 83.250 (83.250)\n",
      "Epoch: [29][5/96]\tLoss 0.3848 (0.3950)\taccuracy 85.938 (84.896)\tf1_score 86.005 (82.989)\n",
      "Epoch: [29][10/96]\tLoss 0.2396 (0.4058)\taccuracy 90.625 (83.523)\tf1_score 87.750 (81.076)\n",
      "Epoch: [29][15/96]\tLoss 0.4018 (0.3764)\taccuracy 84.375 (84.277)\tf1_score 77.908 (81.935)\n",
      "Epoch: [29][20/96]\tLoss 0.1259 (0.3398)\taccuracy 96.875 (86.533)\tf1_score 96.075 (84.116)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [29][25/96]\tLoss 0.1737 (0.3438)\taccuracy 95.312 (86.659)\tf1_score 93.764 (84.129)\n",
      "Epoch: [29][30/96]\tLoss 0.3602 (0.3437)\taccuracy 84.375 (86.542)\tf1_score 85.125 (84.084)\n",
      "Epoch: [29][35/96]\tLoss 0.3608 (0.3414)\taccuracy 82.812 (86.589)\tf1_score 72.442 (83.699)\n",
      "Epoch: [29][40/96]\tLoss 0.3157 (0.3367)\taccuracy 85.938 (86.738)\tf1_score 79.123 (83.967)\n",
      "Epoch: [29][45/96]\tLoss 0.2934 (0.3391)\taccuracy 81.250 (86.447)\tf1_score 74.231 (83.450)\n",
      "Epoch: [29][50/96]\tLoss 0.3096 (0.3431)\taccuracy 90.625 (86.336)\tf1_score 88.131 (83.339)\n",
      "Epoch: [29][55/96]\tLoss 0.3618 (0.3567)\taccuracy 87.500 (85.938)\tf1_score 81.176 (82.887)\n",
      "Epoch: [29][60/96]\tLoss 0.3374 (0.3636)\taccuracy 89.062 (85.784)\tf1_score 85.254 (82.736)\n",
      "Epoch: [29][65/96]\tLoss 0.3018 (0.3717)\taccuracy 87.500 (85.488)\tf1_score 86.024 (82.322)\n",
      "Epoch: [29][70/96]\tLoss 0.4638 (0.3771)\taccuracy 81.250 (85.519)\tf1_score 79.238 (82.199)\n",
      "Epoch: [29][75/96]\tLoss 0.2808 (0.3779)\taccuracy 90.625 (85.362)\tf1_score 89.981 (82.228)\n",
      "Epoch: [29][80/96]\tLoss 0.7074 (0.3843)\taccuracy 75.000 (85.185)\tf1_score 77.718 (82.035)\n",
      "Epoch: [29][85/96]\tLoss 0.4814 (0.3816)\taccuracy 79.688 (85.320)\tf1_score 78.050 (82.298)\n",
      "Epoch: [29][90/96]\tLoss 0.3562 (0.3807)\taccuracy 85.938 (85.354)\tf1_score 81.633 (82.358)\n",
      "Epoch: [29][95/96]\tLoss 0.5654 (0.3858)\taccuracy 82.812 (85.238)\tf1_score 80.556 (82.148)\n",
      " Test: accuracy 61.263 f1_score 55.001\n",
      "Training time:  651.5879683494568 Hour:  0 Minute:  10 Second:  51 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 30\n",
      "Epoch: [30][0/96]\tLoss 0.3388 (0.3388)\taccuracy 79.688 (79.688)\tf1_score 76.714 (76.714)\n",
      "Epoch: [30][5/96]\tLoss 0.3382 (0.3902)\taccuracy 85.938 (83.333)\tf1_score 86.007 (84.179)\n",
      "Epoch: [30][10/96]\tLoss 0.4773 (0.4111)\taccuracy 85.938 (84.659)\tf1_score 76.744 (82.553)\n",
      "Epoch: [30][15/96]\tLoss 0.2994 (0.3897)\taccuracy 89.062 (85.059)\tf1_score 83.059 (82.385)\n",
      "Epoch: [30][20/96]\tLoss 0.4550 (0.3830)\taccuracy 89.062 (85.193)\tf1_score 86.778 (82.219)\n",
      "Epoch: [30][25/96]\tLoss 0.3919 (0.3745)\taccuracy 84.375 (85.517)\tf1_score 79.789 (82.389)\n",
      "Epoch: [30][30/96]\tLoss 0.4729 (0.3774)\taccuracy 81.250 (85.131)\tf1_score 78.742 (81.989)\n",
      "Epoch: [30][35/96]\tLoss 0.2278 (0.3696)\taccuracy 92.188 (85.547)\tf1_score 89.250 (82.522)\n",
      "Epoch: [30][40/96]\tLoss 0.2311 (0.3678)\taccuracy 89.062 (85.518)\tf1_score 89.072 (82.601)\n",
      "Epoch: [30][45/96]\tLoss 0.4547 (0.3686)\taccuracy 81.250 (85.394)\tf1_score 81.240 (82.557)\n",
      "Epoch: [30][50/96]\tLoss 0.3161 (0.3648)\taccuracy 87.500 (85.631)\tf1_score 79.548 (82.741)\n",
      "Epoch: [30][55/96]\tLoss 0.3647 (0.3616)\taccuracy 89.062 (85.910)\tf1_score 89.001 (83.181)\n",
      "Epoch: [30][60/96]\tLoss 0.4586 (0.3631)\taccuracy 76.562 (85.630)\tf1_score 78.112 (83.017)\n",
      "Epoch: [30][65/96]\tLoss 0.2866 (0.3643)\taccuracy 92.188 (85.440)\tf1_score 91.984 (82.797)\n",
      "Epoch: [30][70/96]\tLoss 0.5794 (0.3676)\taccuracy 75.000 (85.189)\tf1_score 74.389 (82.490)\n",
      "Epoch: [30][75/96]\tLoss 0.3854 (0.3695)\taccuracy 84.375 (85.115)\tf1_score 86.403 (82.428)\n",
      "Epoch: [30][80/96]\tLoss 0.3936 (0.3696)\taccuracy 87.500 (85.050)\tf1_score 78.286 (82.273)\n",
      "Epoch: [30][85/96]\tLoss 0.3223 (0.3683)\taccuracy 82.812 (84.956)\tf1_score 82.533 (82.233)\n",
      "Epoch: [30][90/96]\tLoss 0.2021 (0.3654)\taccuracy 93.750 (85.182)\tf1_score 92.094 (82.450)\n",
      "Epoch: [30][95/96]\tLoss 0.3219 (0.3664)\taccuracy 89.062 (85.254)\tf1_score 85.130 (82.465)\n",
      " Test: accuracy 75.716 f1_score 70.660\n",
      "Training time:  667.5630857944489 Hour:  0 Minute:  11 Second:  7 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 31\n",
      "Epoch: [31][0/96]\tLoss 0.3126 (0.3126)\taccuracy 90.625 (90.625)\tf1_score 87.317 (87.317)\n",
      "Epoch: [31][5/96]\tLoss 0.3019 (0.3578)\taccuracy 87.500 (86.719)\tf1_score 84.135 (84.129)\n",
      "Epoch: [31][10/96]\tLoss 0.2374 (0.3228)\taccuracy 93.750 (87.500)\tf1_score 90.376 (85.299)\n",
      "Epoch: [31][15/96]\tLoss 0.3321 (0.3627)\taccuracy 84.375 (85.645)\tf1_score 81.508 (83.053)\n",
      "Epoch: [31][20/96]\tLoss 0.3180 (0.3461)\taccuracy 89.062 (86.235)\tf1_score 88.526 (83.555)\n",
      "Epoch: [31][25/96]\tLoss 0.3572 (0.3382)\taccuracy 85.938 (86.538)\tf1_score 77.362 (84.061)\n",
      "Epoch: [31][30/96]\tLoss 0.2379 (0.3231)\taccuracy 92.188 (87.399)\tf1_score 91.730 (84.905)\n",
      "Epoch: [31][35/96]\tLoss 0.3192 (0.3311)\taccuracy 85.938 (87.109)\tf1_score 87.910 (84.707)\n",
      "Epoch: [31][40/96]\tLoss 0.4742 (0.3458)\taccuracy 85.938 (86.242)\tf1_score 85.167 (84.048)\n",
      "Epoch: [31][45/96]\tLoss 0.2658 (0.3391)\taccuracy 90.625 (86.651)\tf1_score 90.775 (84.579)\n",
      "Epoch: [31][50/96]\tLoss 0.2374 (0.3338)\taccuracy 90.625 (86.857)\tf1_score 87.970 (84.665)\n",
      "Epoch: [31][55/96]\tLoss 0.1881 (0.3397)\taccuracy 93.750 (86.607)\tf1_score 93.791 (84.467)\n",
      "Epoch: [31][60/96]\tLoss 0.3964 (0.3408)\taccuracy 90.625 (86.757)\tf1_score 91.079 (84.545)\n",
      "Epoch: [31][65/96]\tLoss 0.5165 (0.3459)\taccuracy 78.125 (86.506)\tf1_score 73.448 (84.247)\n",
      "Epoch: [31][70/96]\tLoss 0.3359 (0.3440)\taccuracy 87.500 (86.730)\tf1_score 89.191 (84.454)\n",
      "Epoch: [31][75/96]\tLoss 0.2886 (0.3433)\taccuracy 84.375 (86.678)\tf1_score 82.665 (84.399)\n",
      "Epoch: [31][80/96]\tLoss 0.2790 (0.3387)\taccuracy 89.062 (86.825)\tf1_score 87.971 (84.615)\n",
      "Epoch: [31][85/96]\tLoss 0.1945 (0.3363)\taccuracy 93.750 (86.900)\tf1_score 88.395 (84.637)\n",
      "Epoch: [31][90/96]\tLoss 0.3259 (0.3348)\taccuracy 85.938 (86.985)\tf1_score 84.255 (84.636)\n",
      "Epoch: [31][95/96]\tLoss 0.3332 (0.3356)\taccuracy 87.500 (86.963)\tf1_score 82.024 (84.457)\n",
      " Test: accuracy 59.961 f1_score 54.148\n",
      "Training time:  683.5543069839478 Hour:  0 Minute:  11 Second:  23 Test best accuracy: 81.8359375  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 32\n",
      "Epoch: [32][0/96]\tLoss 0.2775 (0.2775)\taccuracy 87.500 (87.500)\tf1_score 86.583 (86.583)\n",
      "Epoch: [32][5/96]\tLoss 0.1869 (0.2939)\taccuracy 93.750 (88.281)\tf1_score 93.849 (87.081)\n",
      "Epoch: [32][10/96]\tLoss 0.3933 (0.3171)\taccuracy 82.812 (86.790)\tf1_score 77.589 (84.846)\n",
      "Epoch: [32][15/96]\tLoss 0.2460 (0.3035)\taccuracy 89.062 (87.305)\tf1_score 85.397 (85.513)\n",
      "Epoch: [32][20/96]\tLoss 0.4872 (0.3089)\taccuracy 89.062 (87.202)\tf1_score 85.500 (84.900)\n",
      "Epoch: [32][25/96]\tLoss 0.2708 (0.3271)\taccuracy 89.062 (87.079)\tf1_score 89.440 (84.836)\n",
      "Epoch: [32][30/96]\tLoss 0.2553 (0.3109)\taccuracy 90.625 (87.752)\tf1_score 91.480 (85.480)\n",
      "Epoch: [32][35/96]\tLoss 0.3323 (0.3172)\taccuracy 84.375 (87.413)\tf1_score 81.096 (85.328)\n",
      "Epoch: [32][40/96]\tLoss 0.1493 (0.3277)\taccuracy 98.438 (86.966)\tf1_score 98.730 (84.957)\n",
      "Epoch: [32][45/96]\tLoss 0.4106 (0.3283)\taccuracy 87.500 (86.923)\tf1_score 85.333 (84.844)\n",
      "Epoch: [32][50/96]\tLoss 0.4386 (0.3521)\taccuracy 84.375 (86.520)\tf1_score 87.095 (84.517)\n",
      "Epoch: [32][55/96]\tLoss 0.3956 (0.3518)\taccuracy 81.250 (86.468)\tf1_score 74.929 (84.345)\n",
      "Epoch: [32][60/96]\tLoss 0.3789 (0.3517)\taccuracy 85.938 (86.552)\tf1_score 81.905 (84.115)\n",
      "Epoch: [32][65/96]\tLoss 0.4669 (0.3594)\taccuracy 85.938 (86.316)\tf1_score 87.815 (83.825)\n",
      "Epoch: [32][70/96]\tLoss 0.3791 (0.3628)\taccuracy 84.375 (86.114)\tf1_score 76.100 (83.499)\n",
      "Epoch: [32][75/96]\tLoss 0.2574 (0.3612)\taccuracy 89.062 (86.184)\tf1_score 90.998 (83.618)\n",
      "Epoch: [32][80/96]\tLoss 0.8794 (0.3636)\taccuracy 71.875 (86.130)\tf1_score 63.572 (83.472)\n",
      "Epoch: [32][85/96]\tLoss 0.3214 (0.3629)\taccuracy 87.500 (86.119)\tf1_score 84.561 (83.513)\n",
      "Epoch: [32][90/96]\tLoss 0.2942 (0.3618)\taccuracy 82.812 (86.058)\tf1_score 80.328 (83.362)\n",
      "Epoch: [32][95/96]\tLoss 0.2019 (0.3565)\taccuracy 95.312 (86.296)\tf1_score 95.302 (83.568)\n",
      " Test: accuracy 85.807 f1_score 82.172\n",
      "Training time:  699.5034475326538 Hour:  0 Minute:  11 Second:  39 Test best accuracy: 85.80729166666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 33\n",
      "Epoch: [33][0/96]\tLoss 0.2267 (0.2267)\taccuracy 92.188 (92.188)\tf1_score 92.786 (92.786)\n",
      "Epoch: [33][5/96]\tLoss 0.2627 (0.3374)\taccuracy 90.625 (88.802)\tf1_score 91.803 (88.516)\n",
      "Epoch: [33][10/96]\tLoss 0.1917 (0.2939)\taccuracy 95.312 (90.057)\tf1_score 94.278 (88.770)\n",
      "Epoch: [33][15/96]\tLoss 0.2614 (0.3002)\taccuracy 90.625 (89.746)\tf1_score 91.083 (88.632)\n",
      "Epoch: [33][20/96]\tLoss 0.2760 (0.2971)\taccuracy 89.062 (89.211)\tf1_score 81.531 (87.180)\n",
      "Epoch: [33][25/96]\tLoss 1.1484 (0.3222)\taccuracy 64.062 (88.281)\tf1_score 51.767 (85.497)\n",
      "Epoch: [33][30/96]\tLoss 0.3524 (0.3169)\taccuracy 84.375 (88.357)\tf1_score 81.085 (85.275)\n",
      "Epoch: [33][35/96]\tLoss 0.1684 (0.3049)\taccuracy 96.875 (88.715)\tf1_score 93.076 (85.569)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [33][40/96]\tLoss 0.3240 (0.3096)\taccuracy 92.188 (88.872)\tf1_score 91.194 (85.652)\n",
      "Epoch: [33][45/96]\tLoss 0.2757 (0.3123)\taccuracy 90.625 (88.757)\tf1_score 86.425 (85.720)\n",
      "Epoch: [33][50/96]\tLoss 0.3082 (0.3218)\taccuracy 89.062 (88.266)\tf1_score 87.737 (85.305)\n",
      "Epoch: [33][55/96]\tLoss 0.2678 (0.3254)\taccuracy 87.500 (88.002)\tf1_score 86.485 (84.906)\n",
      "Epoch: [33][60/96]\tLoss 0.3558 (0.3279)\taccuracy 84.375 (87.679)\tf1_score 76.527 (84.423)\n",
      "Epoch: [33][65/96]\tLoss 0.2339 (0.3305)\taccuracy 92.188 (87.547)\tf1_score 84.817 (84.198)\n",
      "Epoch: [33][70/96]\tLoss 0.2073 (0.3261)\taccuracy 92.188 (87.786)\tf1_score 91.576 (84.465)\n",
      "Epoch: [33][75/96]\tLoss 0.4886 (0.3303)\taccuracy 78.125 (87.582)\tf1_score 75.569 (84.312)\n",
      "Epoch: [33][80/96]\tLoss 0.2024 (0.3297)\taccuracy 93.750 (87.596)\tf1_score 93.202 (84.432)\n",
      "Epoch: [33][85/96]\tLoss 0.2528 (0.3267)\taccuracy 90.625 (87.718)\tf1_score 84.603 (84.677)\n",
      "Epoch: [33][90/96]\tLoss 0.7235 (0.3305)\taccuracy 76.562 (87.586)\tf1_score 68.297 (84.584)\n",
      "Epoch: [33][95/96]\tLoss 0.3374 (0.3316)\taccuracy 87.500 (87.565)\tf1_score 82.600 (84.544)\n",
      " Test: accuracy 58.073 f1_score 51.835\n",
      "Training time:  715.4590594768524 Hour:  0 Minute:  11 Second:  55 Test best accuracy: 85.80729166666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 34\n",
      "Epoch: [34][0/96]\tLoss 0.2239 (0.2239)\taccuracy 89.062 (89.062)\tf1_score 89.320 (89.320)\n",
      "Epoch: [34][5/96]\tLoss 0.2365 (0.3440)\taccuracy 95.312 (87.760)\tf1_score 93.449 (86.045)\n",
      "Epoch: [34][10/96]\tLoss 0.3963 (0.3508)\taccuracy 84.375 (86.648)\tf1_score 81.918 (83.945)\n",
      "Epoch: [34][15/96]\tLoss 0.3846 (0.3652)\taccuracy 85.938 (86.230)\tf1_score 78.428 (83.361)\n",
      "Epoch: [34][20/96]\tLoss 0.4037 (0.3896)\taccuracy 81.250 (85.268)\tf1_score 81.305 (82.595)\n",
      "Epoch: [34][25/96]\tLoss 0.3186 (0.3895)\taccuracy 85.938 (85.397)\tf1_score 81.968 (82.146)\n",
      "Epoch: [34][30/96]\tLoss 0.3922 (0.4043)\taccuracy 82.812 (84.325)\tf1_score 80.536 (81.395)\n",
      "Epoch: [34][35/96]\tLoss 0.3115 (0.3946)\taccuracy 92.188 (84.722)\tf1_score 87.250 (81.510)\n",
      "Epoch: [34][40/96]\tLoss 0.5279 (0.4056)\taccuracy 79.688 (84.070)\tf1_score 83.628 (81.239)\n",
      "Epoch: [34][45/96]\tLoss 0.4582 (0.4111)\taccuracy 82.812 (84.001)\tf1_score 79.363 (81.333)\n",
      "Epoch: [34][50/96]\tLoss 0.2542 (0.4018)\taccuracy 90.625 (84.314)\tf1_score 86.956 (81.574)\n",
      "Epoch: [34][55/96]\tLoss 0.2561 (0.3990)\taccuracy 93.750 (84.542)\tf1_score 93.469 (81.640)\n",
      "Epoch: [34][60/96]\tLoss 0.2372 (0.3989)\taccuracy 92.188 (84.606)\tf1_score 91.610 (81.482)\n",
      "Epoch: [34][65/96]\tLoss 0.4186 (0.3902)\taccuracy 84.375 (84.920)\tf1_score 82.557 (81.916)\n",
      "Epoch: [34][70/96]\tLoss 0.2202 (0.3879)\taccuracy 89.062 (85.013)\tf1_score 86.188 (82.050)\n",
      "Epoch: [34][75/96]\tLoss 0.3878 (0.3909)\taccuracy 87.500 (84.868)\tf1_score 79.024 (81.909)\n",
      "Epoch: [34][80/96]\tLoss 0.2306 (0.3844)\taccuracy 95.312 (85.204)\tf1_score 92.653 (82.327)\n",
      "Epoch: [34][85/96]\tLoss 0.4207 (0.3840)\taccuracy 87.500 (85.265)\tf1_score 79.016 (82.318)\n",
      "Epoch: [34][90/96]\tLoss 0.2921 (0.3769)\taccuracy 89.062 (85.525)\tf1_score 80.079 (82.442)\n",
      "Epoch: [34][95/96]\tLoss 0.3113 (0.3737)\taccuracy 89.062 (85.661)\tf1_score 81.950 (82.535)\n",
      " Test: accuracy 74.089 f1_score 70.410\n",
      "Training time:  731.3409616947174 Hour:  0 Minute:  12 Second:  11 Test best accuracy: 85.80729166666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 35\n",
      "Epoch: [35][0/96]\tLoss 0.2647 (0.2647)\taccuracy 90.625 (90.625)\tf1_score 86.851 (86.851)\n",
      "Epoch: [35][5/96]\tLoss 0.2084 (0.3140)\taccuracy 92.188 (88.542)\tf1_score 91.425 (84.154)\n",
      "Epoch: [35][10/96]\tLoss 0.1801 (0.3532)\taccuracy 96.875 (88.210)\tf1_score 97.016 (85.014)\n",
      "Epoch: [35][15/96]\tLoss 0.3417 (0.3544)\taccuracy 85.938 (87.500)\tf1_score 86.542 (84.630)\n",
      "Epoch: [35][20/96]\tLoss 0.5071 (0.3556)\taccuracy 84.375 (87.723)\tf1_score 78.413 (85.114)\n",
      "Epoch: [35][25/96]\tLoss 0.2470 (0.3540)\taccuracy 90.625 (87.740)\tf1_score 81.837 (84.893)\n",
      "Epoch: [35][30/96]\tLoss 0.3327 (0.3562)\taccuracy 87.500 (87.349)\tf1_score 88.452 (84.254)\n",
      "Epoch: [35][35/96]\tLoss 0.3494 (0.3513)\taccuracy 84.375 (87.370)\tf1_score 81.688 (84.482)\n",
      "Epoch: [35][40/96]\tLoss 0.3248 (0.3465)\taccuracy 89.062 (87.386)\tf1_score 84.346 (84.625)\n",
      "Epoch: [35][45/96]\tLoss 0.4498 (0.3430)\taccuracy 79.688 (87.364)\tf1_score 76.916 (84.460)\n",
      "Epoch: [35][50/96]\tLoss 0.6493 (0.3455)\taccuracy 79.688 (87.194)\tf1_score 74.626 (84.316)\n",
      "Epoch: [35][55/96]\tLoss 0.2191 (0.3373)\taccuracy 90.625 (87.528)\tf1_score 83.226 (84.652)\n",
      "Epoch: [35][60/96]\tLoss 0.2010 (0.3391)\taccuracy 93.750 (87.551)\tf1_score 93.322 (84.720)\n",
      "Epoch: [35][65/96]\tLoss 0.2938 (0.3427)\taccuracy 92.188 (87.571)\tf1_score 90.057 (84.744)\n",
      "Epoch: [35][70/96]\tLoss 0.5655 (0.3514)\taccuracy 82.812 (87.324)\tf1_score 76.248 (84.433)\n",
      "Epoch: [35][75/96]\tLoss 0.3642 (0.3510)\taccuracy 85.938 (87.233)\tf1_score 82.912 (84.443)\n",
      "Epoch: [35][80/96]\tLoss 0.4193 (0.3534)\taccuracy 82.812 (87.114)\tf1_score 78.531 (84.228)\n",
      "Epoch: [35][85/96]\tLoss 0.3374 (0.3553)\taccuracy 89.062 (87.009)\tf1_score 85.032 (84.026)\n",
      "Epoch: [35][90/96]\tLoss 0.4033 (0.3543)\taccuracy 81.250 (87.019)\tf1_score 76.542 (84.059)\n",
      "Epoch: [35][95/96]\tLoss 0.2871 (0.3539)\taccuracy 90.625 (87.061)\tf1_score 90.200 (84.148)\n",
      " Test: accuracy 86.263 f1_score 83.634\n",
      "Training time:  747.2708418369293 Hour:  0 Minute:  12 Second:  27 Test best accuracy: 86.26302083333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 36\n",
      "Epoch: [36][0/96]\tLoss 0.1797 (0.1797)\taccuracy 92.188 (92.188)\tf1_score 84.444 (84.444)\n",
      "Epoch: [36][5/96]\tLoss 0.4003 (0.4279)\taccuracy 85.938 (82.812)\tf1_score 80.480 (77.987)\n",
      "Epoch: [36][10/96]\tLoss 0.6406 (0.3890)\taccuracy 79.688 (85.227)\tf1_score 71.627 (81.011)\n",
      "Epoch: [36][15/96]\tLoss 0.3027 (0.3889)\taccuracy 87.500 (84.961)\tf1_score 86.653 (81.603)\n",
      "Epoch: [36][20/96]\tLoss 0.2989 (0.3698)\taccuracy 84.375 (85.268)\tf1_score 82.457 (82.023)\n",
      "Epoch: [36][25/96]\tLoss 0.5156 (0.3696)\taccuracy 79.688 (85.276)\tf1_score 75.553 (82.007)\n",
      "Epoch: [36][30/96]\tLoss 0.2258 (0.3631)\taccuracy 89.062 (85.484)\tf1_score 87.540 (82.280)\n",
      "Epoch: [36][35/96]\tLoss 0.4673 (0.3612)\taccuracy 85.938 (85.894)\tf1_score 86.810 (82.865)\n",
      "Epoch: [36][40/96]\tLoss 0.2838 (0.3546)\taccuracy 89.062 (86.052)\tf1_score 85.280 (83.066)\n",
      "Epoch: [36][45/96]\tLoss 0.1796 (0.3510)\taccuracy 92.188 (86.005)\tf1_score 92.420 (83.148)\n",
      "Epoch: [36][50/96]\tLoss 0.2833 (0.3457)\taccuracy 89.062 (86.213)\tf1_score 85.123 (83.441)\n",
      "Epoch: [36][55/96]\tLoss 0.5106 (0.3412)\taccuracy 81.250 (86.579)\tf1_score 73.919 (83.706)\n",
      "Epoch: [36][60/96]\tLoss 0.2273 (0.3366)\taccuracy 96.875 (86.757)\tf1_score 95.979 (83.938)\n",
      "Epoch: [36][65/96]\tLoss 0.3760 (0.3355)\taccuracy 81.250 (86.790)\tf1_score 76.232 (83.875)\n",
      "Epoch: [36][70/96]\tLoss 0.2637 (0.3415)\taccuracy 90.625 (86.752)\tf1_score 87.480 (83.725)\n",
      "Epoch: [36][75/96]\tLoss 0.2997 (0.3381)\taccuracy 85.938 (86.842)\tf1_score 80.857 (83.722)\n",
      "Epoch: [36][80/96]\tLoss 0.4117 (0.3385)\taccuracy 82.812 (86.767)\tf1_score 67.455 (83.504)\n",
      "Epoch: [36][85/96]\tLoss 0.3728 (0.3370)\taccuracy 81.250 (86.737)\tf1_score 81.111 (83.460)\n",
      "Epoch: [36][90/96]\tLoss 0.2761 (0.3425)\taccuracy 85.938 (86.538)\tf1_score 84.573 (83.336)\n",
      "Epoch: [36][95/96]\tLoss 0.4541 (0.3414)\taccuracy 81.250 (86.572)\tf1_score 78.984 (83.478)\n",
      " Test: accuracy 65.755 f1_score 59.472\n",
      "Training time:  763.2629058361053 Hour:  0 Minute:  12 Second:  43 Test best accuracy: 86.26302083333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 37\n",
      "Epoch: [37][0/96]\tLoss 0.2199 (0.2199)\taccuracy 92.188 (92.188)\tf1_score 91.078 (91.078)\n",
      "Epoch: [37][5/96]\tLoss 0.3800 (0.2807)\taccuracy 85.938 (90.104)\tf1_score 79.396 (88.542)\n",
      "Epoch: [37][10/96]\tLoss 0.4294 (0.2917)\taccuracy 81.250 (89.489)\tf1_score 78.780 (88.155)\n",
      "Epoch: [37][15/96]\tLoss 0.2299 (0.2862)\taccuracy 92.188 (89.062)\tf1_score 91.654 (87.312)\n",
      "Epoch: [37][20/96]\tLoss 0.2989 (0.2816)\taccuracy 89.062 (89.360)\tf1_score 88.286 (86.819)\n",
      "Epoch: [37][25/96]\tLoss 0.2922 (0.2802)\taccuracy 90.625 (88.942)\tf1_score 90.369 (86.581)\n",
      "Epoch: [37][30/96]\tLoss 0.3143 (0.2769)\taccuracy 84.375 (89.113)\tf1_score 80.810 (86.832)\n",
      "Epoch: [37][35/96]\tLoss 0.1504 (0.2727)\taccuracy 96.875 (89.453)\tf1_score 92.286 (87.170)\n",
      "Epoch: [37][40/96]\tLoss 0.2516 (0.2737)\taccuracy 89.062 (89.367)\tf1_score 87.680 (87.230)\n",
      "Epoch: [37][45/96]\tLoss 0.2554 (0.2715)\taccuracy 87.500 (89.470)\tf1_score 87.373 (87.552)\n",
      "Epoch: [37][50/96]\tLoss 0.3250 (0.2792)\taccuracy 87.500 (89.277)\tf1_score 87.698 (87.277)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37][55/96]\tLoss 0.5668 (0.2844)\taccuracy 81.250 (89.035)\tf1_score 73.957 (86.755)\n",
      "Epoch: [37][60/96]\tLoss 0.3117 (0.2922)\taccuracy 85.938 (88.550)\tf1_score 86.333 (86.388)\n",
      "Epoch: [37][65/96]\tLoss 0.4949 (0.2935)\taccuracy 79.688 (88.423)\tf1_score 76.425 (86.216)\n",
      "Epoch: [37][70/96]\tLoss 0.1913 (0.2917)\taccuracy 93.750 (88.512)\tf1_score 89.429 (86.238)\n",
      "Epoch: [37][75/96]\tLoss 0.3820 (0.2970)\taccuracy 85.938 (88.425)\tf1_score 84.082 (86.138)\n",
      "Epoch: [37][80/96]\tLoss 0.1956 (0.2972)\taccuracy 93.750 (88.426)\tf1_score 90.361 (86.119)\n",
      "Epoch: [37][85/96]\tLoss 0.4817 (0.2971)\taccuracy 90.625 (88.663)\tf1_score 86.404 (86.335)\n",
      "Epoch: [37][90/96]\tLoss 0.3118 (0.2958)\taccuracy 87.500 (88.736)\tf1_score 85.391 (86.368)\n",
      "Epoch: [37][95/96]\tLoss 0.1187 (0.2943)\taccuracy 96.875 (88.786)\tf1_score 96.429 (86.390)\n",
      " Test: accuracy 75.846 f1_score 70.995\n",
      "Training time:  779.2340106964111 Hour:  0 Minute:  12 Second:  59 Test best accuracy: 86.26302083333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 38\n",
      "Epoch: [38][0/96]\tLoss 0.2381 (0.2381)\taccuracy 90.625 (90.625)\tf1_score 88.851 (88.851)\n",
      "Epoch: [38][5/96]\tLoss 0.3113 (0.3220)\taccuracy 87.500 (87.500)\tf1_score 83.569 (83.307)\n",
      "Epoch: [38][10/96]\tLoss 0.2846 (0.3043)\taccuracy 87.500 (88.494)\tf1_score 82.736 (84.770)\n",
      "Epoch: [38][15/96]\tLoss 0.3151 (0.2948)\taccuracy 89.062 (88.965)\tf1_score 88.847 (85.269)\n",
      "Epoch: [38][20/96]\tLoss 0.2754 (0.2857)\taccuracy 89.062 (89.583)\tf1_score 86.780 (86.369)\n",
      "Epoch: [38][25/96]\tLoss 0.4557 (0.2893)\taccuracy 78.125 (89.123)\tf1_score 73.095 (86.199)\n",
      "Epoch: [38][30/96]\tLoss 0.2660 (0.2893)\taccuracy 90.625 (89.113)\tf1_score 86.083 (86.283)\n",
      "Epoch: [38][35/96]\tLoss 0.2081 (0.2856)\taccuracy 93.750 (89.149)\tf1_score 91.503 (86.411)\n",
      "Epoch: [38][40/96]\tLoss 0.3303 (0.2870)\taccuracy 85.938 (88.910)\tf1_score 79.135 (86.228)\n",
      "Epoch: [38][45/96]\tLoss 0.2495 (0.2793)\taccuracy 89.062 (89.198)\tf1_score 88.469 (86.667)\n",
      "Epoch: [38][50/96]\tLoss 0.2892 (0.2822)\taccuracy 92.188 (89.124)\tf1_score 92.698 (86.438)\n",
      "Epoch: [38][55/96]\tLoss 0.2313 (0.2807)\taccuracy 89.062 (88.979)\tf1_score 87.237 (86.369)\n",
      "Epoch: [38][60/96]\tLoss 0.2603 (0.2852)\taccuracy 90.625 (88.806)\tf1_score 92.220 (86.342)\n",
      "Epoch: [38][65/96]\tLoss 0.2151 (0.2839)\taccuracy 92.188 (88.873)\tf1_score 91.924 (86.500)\n",
      "Epoch: [38][70/96]\tLoss 0.3179 (0.2835)\taccuracy 85.938 (88.776)\tf1_score 82.449 (86.409)\n",
      "Epoch: [38][75/96]\tLoss 0.3291 (0.2838)\taccuracy 90.625 (88.836)\tf1_score 92.804 (86.475)\n",
      "Epoch: [38][80/96]\tLoss 0.2568 (0.2842)\taccuracy 89.062 (88.831)\tf1_score 86.917 (86.558)\n",
      "Epoch: [38][85/96]\tLoss 0.4335 (0.2842)\taccuracy 89.062 (88.826)\tf1_score 88.860 (86.562)\n",
      "Epoch: [38][90/96]\tLoss 0.2287 (0.2846)\taccuracy 93.750 (88.942)\tf1_score 92.275 (86.686)\n",
      "Epoch: [38][95/96]\tLoss 0.2863 (0.2854)\taccuracy 90.625 (88.900)\tf1_score 83.778 (86.609)\n",
      " Test: accuracy 71.745 f1_score 67.959\n",
      "Training time:  795.2059662342072 Hour:  0 Minute:  13 Second:  15 Test best accuracy: 86.26302083333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 39\n",
      "Epoch: [39][0/96]\tLoss 0.3586 (0.3586)\taccuracy 84.375 (84.375)\tf1_score 75.032 (75.032)\n",
      "Epoch: [39][5/96]\tLoss 0.3354 (0.2827)\taccuracy 85.938 (89.323)\tf1_score 83.895 (84.167)\n",
      "Epoch: [39][10/96]\tLoss 0.2521 (0.2862)\taccuracy 89.062 (89.205)\tf1_score 81.644 (85.092)\n",
      "Epoch: [39][15/96]\tLoss 0.2953 (0.2742)\taccuracy 89.062 (88.965)\tf1_score 89.129 (85.325)\n",
      "Epoch: [39][20/96]\tLoss 0.3099 (0.2650)\taccuracy 90.625 (89.062)\tf1_score 93.117 (85.839)\n",
      "Epoch: [39][25/96]\tLoss 0.3955 (0.2754)\taccuracy 84.375 (88.642)\tf1_score 79.421 (85.612)\n",
      "Epoch: [39][30/96]\tLoss 0.2923 (0.2778)\taccuracy 84.375 (88.659)\tf1_score 82.063 (85.902)\n",
      "Epoch: [39][35/96]\tLoss 0.1930 (0.2814)\taccuracy 89.062 (88.628)\tf1_score 85.970 (85.706)\n",
      "Epoch: [39][40/96]\tLoss 0.2463 (0.2787)\taccuracy 93.750 (88.910)\tf1_score 91.070 (86.049)\n",
      "Epoch: [39][45/96]\tLoss 0.2096 (0.2769)\taccuracy 90.625 (88.859)\tf1_score 88.494 (85.975)\n",
      "Epoch: [39][50/96]\tLoss 0.2351 (0.2803)\taccuracy 90.625 (88.817)\tf1_score 90.544 (85.996)\n",
      "Epoch: [39][55/96]\tLoss 0.2919 (0.2845)\taccuracy 85.938 (88.644)\tf1_score 84.193 (85.784)\n",
      "Epoch: [39][60/96]\tLoss 0.2229 (0.2849)\taccuracy 92.188 (88.832)\tf1_score 87.653 (86.044)\n",
      "Epoch: [39][65/96]\tLoss 0.3593 (0.2916)\taccuracy 85.938 (88.589)\tf1_score 86.827 (86.037)\n",
      "Epoch: [39][70/96]\tLoss 0.1570 (0.2929)\taccuracy 96.875 (88.446)\tf1_score 96.619 (85.894)\n",
      "Epoch: [39][75/96]\tLoss 0.2340 (0.2952)\taccuracy 90.625 (88.322)\tf1_score 85.455 (85.764)\n",
      "Epoch: [39][80/96]\tLoss 0.3084 (0.2971)\taccuracy 87.500 (88.214)\tf1_score 85.319 (85.636)\n",
      "Epoch: [39][85/96]\tLoss 0.3745 (0.3023)\taccuracy 84.375 (87.972)\tf1_score 85.867 (85.440)\n",
      "Epoch: [39][90/96]\tLoss 0.5360 (0.3095)\taccuracy 78.125 (87.672)\tf1_score 75.939 (85.140)\n",
      "Epoch: [39][95/96]\tLoss 0.3746 (0.3105)\taccuracy 87.500 (87.695)\tf1_score 80.585 (85.094)\n",
      " Test: accuracy 73.438 f1_score 66.978\n",
      "Training time:  811.1671323776245 Hour:  0 Minute:  13 Second:  31 Test best accuracy: 86.26302083333333  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 40\n",
      "Epoch: [40][0/96]\tLoss 0.2374 (0.2374)\taccuracy 90.625 (90.625)\tf1_score 88.751 (88.751)\n",
      "Epoch: [40][5/96]\tLoss 0.1617 (0.2480)\taccuracy 95.312 (90.104)\tf1_score 95.501 (87.813)\n",
      "Epoch: [40][10/96]\tLoss 0.3370 (0.2992)\taccuracy 84.375 (87.642)\tf1_score 86.275 (85.651)\n",
      "Epoch: [40][15/96]\tLoss 0.2365 (0.2921)\taccuracy 90.625 (88.477)\tf1_score 83.682 (85.884)\n",
      "Epoch: [40][20/96]\tLoss 0.2308 (0.2841)\taccuracy 92.188 (88.988)\tf1_score 86.937 (85.907)\n",
      "Epoch: [40][25/96]\tLoss 0.2198 (0.2918)\taccuracy 92.188 (88.401)\tf1_score 93.144 (85.798)\n",
      "Epoch: [40][30/96]\tLoss 0.3255 (0.2949)\taccuracy 89.062 (88.558)\tf1_score 89.837 (86.192)\n",
      "Epoch: [40][35/96]\tLoss 0.3542 (0.2936)\taccuracy 85.938 (88.672)\tf1_score 86.716 (86.458)\n",
      "Epoch: [40][40/96]\tLoss 0.1567 (0.2886)\taccuracy 92.188 (88.643)\tf1_score 84.786 (86.016)\n",
      "Epoch: [40][45/96]\tLoss 0.2091 (0.2845)\taccuracy 89.062 (88.689)\tf1_score 90.026 (86.298)\n",
      "Epoch: [40][50/96]\tLoss 0.3795 (0.2848)\taccuracy 84.375 (88.695)\tf1_score 80.966 (86.372)\n",
      "Epoch: [40][55/96]\tLoss 0.3688 (0.2852)\taccuracy 84.375 (88.700)\tf1_score 77.938 (86.345)\n",
      "Epoch: [40][60/96]\tLoss 0.2907 (0.2864)\taccuracy 89.062 (88.576)\tf1_score 86.746 (85.997)\n",
      "Epoch: [40][65/96]\tLoss 0.3749 (0.2914)\taccuracy 84.375 (88.565)\tf1_score 76.799 (85.859)\n",
      "Epoch: [40][70/96]\tLoss 0.2623 (0.2899)\taccuracy 89.062 (88.710)\tf1_score 88.282 (86.073)\n",
      "Epoch: [40][75/96]\tLoss 0.3085 (0.2906)\taccuracy 87.500 (88.734)\tf1_score 83.410 (86.142)\n",
      "Epoch: [40][80/96]\tLoss 0.2318 (0.2859)\taccuracy 89.062 (88.870)\tf1_score 86.032 (86.305)\n",
      "Epoch: [40][85/96]\tLoss 0.2287 (0.2827)\taccuracy 92.188 (88.953)\tf1_score 91.163 (86.463)\n",
      "Epoch: [40][90/96]\tLoss 0.2112 (0.2801)\taccuracy 93.750 (89.097)\tf1_score 94.256 (86.638)\n",
      "Epoch: [40][95/96]\tLoss 0.2882 (0.2806)\taccuracy 87.500 (89.046)\tf1_score 87.137 (86.619)\n",
      " Test: accuracy 86.719 f1_score 83.652\n",
      "Training time:  827.1082065105438 Hour:  0 Minute:  13 Second:  47 Test best accuracy: 86.71875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 41\n",
      "Epoch: [41][0/96]\tLoss 0.2230 (0.2230)\taccuracy 90.625 (90.625)\tf1_score 91.332 (91.332)\n",
      "Epoch: [41][5/96]\tLoss 0.1982 (0.2521)\taccuracy 92.188 (90.104)\tf1_score 84.233 (87.492)\n",
      "Epoch: [41][10/96]\tLoss 0.2111 (0.2464)\taccuracy 95.312 (91.051)\tf1_score 94.854 (88.437)\n",
      "Epoch: [41][15/96]\tLoss 0.2183 (0.2394)\taccuracy 90.625 (91.113)\tf1_score 88.136 (88.280)\n",
      "Epoch: [41][20/96]\tLoss 0.1381 (0.2456)\taccuracy 95.312 (91.220)\tf1_score 89.116 (87.887)\n",
      "Epoch: [41][25/96]\tLoss 0.2134 (0.2398)\taccuracy 95.312 (91.406)\tf1_score 93.730 (88.317)\n",
      "Epoch: [41][30/96]\tLoss 0.0903 (0.2283)\taccuracy 98.438 (91.784)\tf1_score 98.367 (88.896)\n",
      "Epoch: [41][35/96]\tLoss 0.2409 (0.2249)\taccuracy 90.625 (91.753)\tf1_score 89.683 (88.997)\n",
      "Epoch: [41][40/96]\tLoss 0.2108 (0.2239)\taccuracy 92.188 (91.692)\tf1_score 94.244 (88.975)\n",
      "Epoch: [41][45/96]\tLoss 0.2342 (0.2323)\taccuracy 90.625 (91.304)\tf1_score 87.143 (88.173)\n",
      "Epoch: [41][50/96]\tLoss 0.1315 (0.2329)\taccuracy 96.875 (91.268)\tf1_score 96.780 (88.305)\n",
      "Epoch: [41][55/96]\tLoss 0.2358 (0.2365)\taccuracy 89.062 (90.904)\tf1_score 87.974 (88.032)\n",
      "Epoch: [41][60/96]\tLoss 0.1624 (0.2399)\taccuracy 95.312 (90.727)\tf1_score 94.230 (87.887)\n",
      "Epoch: [41][65/96]\tLoss 0.2004 (0.2391)\taccuracy 93.750 (90.720)\tf1_score 96.056 (88.092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41][70/96]\tLoss 0.2568 (0.2416)\taccuracy 89.062 (90.559)\tf1_score 75.403 (87.741)\n",
      "Epoch: [41][75/96]\tLoss 0.3191 (0.2431)\taccuracy 87.500 (90.563)\tf1_score 92.708 (87.889)\n",
      "Epoch: [41][80/96]\tLoss 0.2812 (0.2449)\taccuracy 92.188 (90.529)\tf1_score 92.037 (87.868)\n",
      "Epoch: [41][85/96]\tLoss 0.1827 (0.2489)\taccuracy 95.312 (90.425)\tf1_score 94.962 (87.719)\n",
      "Epoch: [41][90/96]\tLoss 0.3522 (0.2506)\taccuracy 89.062 (90.367)\tf1_score 88.207 (87.715)\n",
      "Epoch: [41][95/96]\tLoss 0.2626 (0.2513)\taccuracy 90.625 (90.202)\tf1_score 89.460 (87.410)\n",
      " Test: accuracy 72.005 f1_score 67.348\n",
      "Training time:  843.0526118278503 Hour:  0 Minute:  14 Second:  3 Test best accuracy: 86.71875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 42\n",
      "Epoch: [42][0/96]\tLoss 0.1925 (0.1925)\taccuracy 93.750 (93.750)\tf1_score 92.637 (92.637)\n",
      "Epoch: [42][5/96]\tLoss 0.3230 (0.2443)\taccuracy 89.062 (90.365)\tf1_score 86.395 (90.263)\n",
      "Epoch: [42][10/96]\tLoss 0.2123 (0.2570)\taccuracy 90.625 (90.057)\tf1_score 90.936 (89.429)\n",
      "Epoch: [42][15/96]\tLoss 0.3118 (0.2552)\taccuracy 87.500 (90.137)\tf1_score 84.195 (88.946)\n",
      "Epoch: [42][20/96]\tLoss 0.1864 (0.2662)\taccuracy 95.312 (89.658)\tf1_score 91.831 (88.489)\n",
      "Epoch: [42][25/96]\tLoss 0.1649 (0.2580)\taccuracy 93.750 (89.724)\tf1_score 92.680 (88.264)\n",
      "Epoch: [42][30/96]\tLoss 0.1540 (0.2671)\taccuracy 93.750 (89.567)\tf1_score 93.707 (88.186)\n",
      "Epoch: [42][35/96]\tLoss 0.2528 (0.2652)\taccuracy 92.188 (89.583)\tf1_score 88.357 (88.266)\n",
      "Epoch: [42][40/96]\tLoss 0.2883 (0.2655)\taccuracy 89.062 (89.787)\tf1_score 80.763 (88.058)\n",
      "Epoch: [42][45/96]\tLoss 0.2877 (0.2677)\taccuracy 85.938 (89.572)\tf1_score 85.092 (87.877)\n",
      "Epoch: [42][50/96]\tLoss 0.1968 (0.2675)\taccuracy 92.188 (89.675)\tf1_score 91.697 (87.723)\n",
      "Epoch: [42][55/96]\tLoss 0.2939 (0.2659)\taccuracy 87.500 (89.844)\tf1_score 89.563 (87.917)\n",
      "Epoch: [42][60/96]\tLoss 0.2037 (0.2698)\taccuracy 93.750 (89.703)\tf1_score 91.540 (87.784)\n",
      "Epoch: [42][65/96]\tLoss 0.1763 (0.2705)\taccuracy 93.750 (89.536)\tf1_score 94.310 (87.611)\n",
      "Epoch: [42][70/96]\tLoss 0.2555 (0.2670)\taccuracy 90.625 (89.767)\tf1_score 91.349 (87.925)\n",
      "Epoch: [42][75/96]\tLoss 0.1390 (0.2616)\taccuracy 92.188 (89.967)\tf1_score 85.871 (88.020)\n",
      "Epoch: [42][80/96]\tLoss 0.2582 (0.2593)\taccuracy 90.625 (90.046)\tf1_score 85.349 (88.056)\n",
      "Epoch: [42][85/96]\tLoss 0.1724 (0.2569)\taccuracy 92.188 (90.062)\tf1_score 90.777 (88.048)\n",
      "Epoch: [42][90/96]\tLoss 0.1656 (0.2543)\taccuracy 95.312 (90.144)\tf1_score 95.145 (88.162)\n",
      "Epoch: [42][95/96]\tLoss 0.3801 (0.2566)\taccuracy 87.500 (90.055)\tf1_score 81.593 (88.050)\n",
      " Test: accuracy 44.336 f1_score 36.016\n",
      "Training time:  858.9751570224762 Hour:  0 Minute:  14 Second:  18 Test best accuracy: 86.71875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 43\n",
      "Epoch: [43][0/96]\tLoss 0.4745 (0.4745)\taccuracy 82.812 (82.812)\tf1_score 80.183 (80.183)\n",
      "Epoch: [43][5/96]\tLoss 0.3298 (0.2893)\taccuracy 87.500 (88.542)\tf1_score 88.711 (85.955)\n",
      "Epoch: [43][10/96]\tLoss 0.1894 (0.2652)\taccuracy 93.750 (90.057)\tf1_score 91.478 (88.364)\n",
      "Epoch: [43][15/96]\tLoss 0.2703 (0.2559)\taccuracy 87.500 (89.551)\tf1_score 81.407 (87.355)\n",
      "Epoch: [43][20/96]\tLoss 0.2338 (0.2600)\taccuracy 90.625 (88.914)\tf1_score 89.321 (86.574)\n",
      "Epoch: [43][25/96]\tLoss 0.2397 (0.2671)\taccuracy 90.625 (89.062)\tf1_score 89.947 (86.822)\n",
      "Epoch: [43][30/96]\tLoss 0.4299 (0.2889)\taccuracy 81.250 (88.357)\tf1_score 77.879 (86.062)\n",
      "Epoch: [43][35/96]\tLoss 0.2282 (0.2938)\taccuracy 95.312 (88.151)\tf1_score 94.346 (85.834)\n",
      "Epoch: [43][40/96]\tLoss 0.3037 (0.2942)\taccuracy 92.188 (88.224)\tf1_score 87.143 (85.898)\n",
      "Epoch: [43][45/96]\tLoss 0.2235 (0.2899)\taccuracy 90.625 (88.247)\tf1_score 88.270 (85.828)\n",
      "Epoch: [43][50/96]\tLoss 0.3967 (0.2841)\taccuracy 84.375 (88.450)\tf1_score 78.493 (85.904)\n",
      "Epoch: [43][55/96]\tLoss 0.3709 (0.2840)\taccuracy 87.500 (88.700)\tf1_score 76.992 (86.070)\n",
      "Epoch: [43][60/96]\tLoss 0.4544 (0.2860)\taccuracy 82.812 (88.704)\tf1_score 85.132 (86.292)\n",
      "Epoch: [43][65/96]\tLoss 0.2618 (0.2878)\taccuracy 89.062 (88.471)\tf1_score 83.953 (86.160)\n",
      "Epoch: [43][70/96]\tLoss 0.1679 (0.2876)\taccuracy 93.750 (88.512)\tf1_score 93.629 (86.203)\n",
      "Epoch: [43][75/96]\tLoss 0.2734 (0.2899)\taccuracy 85.938 (88.384)\tf1_score 83.656 (86.128)\n",
      "Epoch: [43][80/96]\tLoss 0.2113 (0.2859)\taccuracy 92.188 (88.619)\tf1_score 92.718 (86.281)\n",
      "Epoch: [43][85/96]\tLoss 0.2102 (0.2832)\taccuracy 92.188 (88.699)\tf1_score 88.796 (86.367)\n",
      "Epoch: [43][90/96]\tLoss 0.2673 (0.2827)\taccuracy 89.062 (88.736)\tf1_score 86.508 (86.319)\n",
      "Epoch: [43][95/96]\tLoss 0.3548 (0.2804)\taccuracy 85.938 (88.835)\tf1_score 78.165 (86.454)\n",
      " Test: accuracy 77.279 f1_score 74.015\n",
      "Training time:  874.9668219089508 Hour:  0 Minute:  14 Second:  34 Test best accuracy: 86.71875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 44\n",
      "Epoch: [44][0/96]\tLoss 0.2725 (0.2725)\taccuracy 90.625 (90.625)\tf1_score 91.782 (91.782)\n",
      "Epoch: [44][5/96]\tLoss 0.6816 (0.3275)\taccuracy 76.562 (88.802)\tf1_score 71.933 (86.339)\n",
      "Epoch: [44][10/96]\tLoss 0.3584 (0.3284)\taccuracy 81.250 (87.216)\tf1_score 80.559 (84.940)\n",
      "Epoch: [44][15/96]\tLoss 0.2616 (0.3501)\taccuracy 92.188 (87.305)\tf1_score 93.050 (85.558)\n",
      "Epoch: [44][20/96]\tLoss 0.5371 (0.3547)\taccuracy 82.812 (87.202)\tf1_score 82.120 (84.784)\n",
      "Epoch: [44][25/96]\tLoss 0.2092 (0.3357)\taccuracy 90.625 (87.981)\tf1_score 87.336 (85.600)\n",
      "Epoch: [44][30/96]\tLoss 0.2596 (0.3217)\taccuracy 92.188 (88.407)\tf1_score 91.349 (85.697)\n",
      "Epoch: [44][35/96]\tLoss 0.2691 (0.3247)\taccuracy 92.188 (88.194)\tf1_score 91.270 (85.387)\n",
      "Epoch: [44][40/96]\tLoss 0.1671 (0.3100)\taccuracy 95.312 (88.720)\tf1_score 95.952 (85.920)\n",
      "Epoch: [44][45/96]\tLoss 0.2005 (0.3045)\taccuracy 93.750 (88.825)\tf1_score 90.113 (86.122)\n",
      "Epoch: [44][50/96]\tLoss 0.2467 (0.3007)\taccuracy 92.188 (89.032)\tf1_score 92.562 (86.339)\n",
      "Epoch: [44][55/96]\tLoss 0.2628 (0.3020)\taccuracy 90.625 (88.867)\tf1_score 90.194 (86.169)\n",
      "Epoch: [44][60/96]\tLoss 0.2881 (0.3001)\taccuracy 87.500 (88.781)\tf1_score 84.492 (86.083)\n",
      "Epoch: [44][65/96]\tLoss 0.2856 (0.2966)\taccuracy 85.938 (88.778)\tf1_score 82.425 (86.196)\n",
      "Epoch: [44][70/96]\tLoss 0.2785 (0.2972)\taccuracy 92.188 (88.776)\tf1_score 79.898 (85.990)\n",
      "Epoch: [44][75/96]\tLoss 0.2380 (0.2995)\taccuracy 92.188 (88.754)\tf1_score 89.831 (85.934)\n",
      "Epoch: [44][80/96]\tLoss 0.3268 (0.3046)\taccuracy 87.500 (88.677)\tf1_score 84.816 (85.851)\n",
      "Epoch: [44][85/96]\tLoss 0.2718 (0.3043)\taccuracy 87.500 (88.626)\tf1_score 84.548 (85.898)\n",
      "Epoch: [44][90/96]\tLoss 0.3637 (0.3045)\taccuracy 85.938 (88.582)\tf1_score 77.729 (85.744)\n",
      "Epoch: [44][95/96]\tLoss 0.3098 (0.3086)\taccuracy 82.812 (88.411)\tf1_score 79.406 (85.510)\n",
      " Test: accuracy 74.089 f1_score 69.967\n",
      "Training time:  890.9250519275665 Hour:  0 Minute:  14 Second:  50 Test best accuracy: 86.71875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 45\n",
      "Epoch: [45][0/96]\tLoss 0.3658 (0.3658)\taccuracy 90.625 (90.625)\tf1_score 86.330 (86.330)\n",
      "Epoch: [45][5/96]\tLoss 0.2718 (0.2584)\taccuracy 89.062 (90.365)\tf1_score 86.982 (85.822)\n",
      "Epoch: [45][10/96]\tLoss 0.1388 (0.2749)\taccuracy 95.312 (89.489)\tf1_score 92.517 (85.931)\n",
      "Epoch: [45][15/96]\tLoss 0.2406 (0.2826)\taccuracy 89.062 (88.965)\tf1_score 87.611 (85.497)\n",
      "Epoch: [45][20/96]\tLoss 0.2714 (0.2686)\taccuracy 87.500 (89.360)\tf1_score 88.073 (86.222)\n",
      "Epoch: [45][25/96]\tLoss 0.2601 (0.2771)\taccuracy 84.375 (89.123)\tf1_score 87.627 (86.152)\n",
      "Epoch: [45][30/96]\tLoss 0.1561 (0.2743)\taccuracy 95.312 (89.365)\tf1_score 94.785 (86.849)\n",
      "Epoch: [45][35/96]\tLoss 0.1829 (0.2645)\taccuracy 92.188 (89.714)\tf1_score 88.648 (87.227)\n",
      "Epoch: [45][40/96]\tLoss 0.3427 (0.2596)\taccuracy 84.375 (89.863)\tf1_score 84.627 (87.407)\n",
      "Epoch: [45][45/96]\tLoss 0.2889 (0.2523)\taccuracy 89.062 (90.149)\tf1_score 79.511 (87.577)\n",
      "Epoch: [45][50/96]\tLoss 0.3186 (0.2507)\taccuracy 84.375 (90.288)\tf1_score 69.203 (87.571)\n",
      "Epoch: [45][55/96]\tLoss 0.2497 (0.2492)\taccuracy 85.938 (90.179)\tf1_score 87.896 (87.568)\n",
      "Epoch: [45][60/96]\tLoss 0.2157 (0.2469)\taccuracy 93.750 (90.318)\tf1_score 95.414 (87.638)\n",
      "Epoch: [45][65/96]\tLoss 0.4559 (0.2486)\taccuracy 79.688 (90.294)\tf1_score 78.086 (87.859)\n",
      "Epoch: [45][70/96]\tLoss 0.1694 (0.2464)\taccuracy 95.312 (90.493)\tf1_score 96.282 (88.055)\n",
      "Epoch: [45][75/96]\tLoss 0.1069 (0.2410)\taccuracy 98.438 (90.769)\tf1_score 97.619 (88.462)\n",
      "Epoch: [45][80/96]\tLoss 0.4582 (0.2460)\taccuracy 81.250 (90.606)\tf1_score 78.922 (88.348)\n",
      "Epoch: [45][85/96]\tLoss 0.1411 (0.2442)\taccuracy 95.312 (90.734)\tf1_score 96.164 (88.609)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45][90/96]\tLoss 0.2562 (0.2489)\taccuracy 90.625 (90.573)\tf1_score 87.544 (88.430)\n",
      "Epoch: [45][95/96]\tLoss 0.3281 (0.2522)\taccuracy 81.250 (90.381)\tf1_score 81.463 (88.260)\n",
      " Test: accuracy 72.786 f1_score 69.064\n",
      "Training time:  906.9041442871094 Hour:  0 Minute:  15 Second:  6 Test best accuracy: 86.71875  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 46\n",
      "Epoch: [46][0/96]\tLoss 0.2926 (0.2926)\taccuracy 85.938 (85.938)\tf1_score 84.210 (84.210)\n",
      "Epoch: [46][5/96]\tLoss 0.1261 (0.2424)\taccuracy 98.438 (90.885)\tf1_score 98.095 (89.070)\n",
      "Epoch: [46][10/96]\tLoss 0.1515 (0.2311)\taccuracy 93.750 (91.193)\tf1_score 91.316 (89.009)\n",
      "Epoch: [46][15/96]\tLoss 0.2187 (0.2179)\taccuracy 92.188 (91.504)\tf1_score 86.777 (89.249)\n",
      "Epoch: [46][20/96]\tLoss 0.1753 (0.2211)\taccuracy 89.062 (91.443)\tf1_score 87.732 (88.739)\n",
      "Epoch: [46][25/96]\tLoss 0.1570 (0.2220)\taccuracy 93.750 (91.406)\tf1_score 93.313 (88.867)\n",
      "Epoch: [46][30/96]\tLoss 0.3417 (0.2250)\taccuracy 84.375 (91.230)\tf1_score 82.668 (89.025)\n",
      "Epoch: [46][35/96]\tLoss 0.2252 (0.2286)\taccuracy 92.188 (91.016)\tf1_score 89.069 (88.594)\n",
      "Epoch: [46][40/96]\tLoss 0.2254 (0.2281)\taccuracy 87.500 (90.739)\tf1_score 86.956 (88.195)\n",
      "Epoch: [46][45/96]\tLoss 0.1411 (0.2298)\taccuracy 95.312 (90.761)\tf1_score 95.647 (88.337)\n",
      "Epoch: [46][50/96]\tLoss 0.3555 (0.2432)\taccuracy 85.938 (90.135)\tf1_score 83.135 (87.923)\n",
      "Epoch: [46][55/96]\tLoss 0.2149 (0.2433)\taccuracy 89.062 (90.095)\tf1_score 90.612 (88.008)\n",
      "Epoch: [46][60/96]\tLoss 0.1661 (0.2468)\taccuracy 93.750 (89.831)\tf1_score 93.605 (87.780)\n",
      "Epoch: [46][65/96]\tLoss 0.2637 (0.2463)\taccuracy 89.062 (89.796)\tf1_score 87.568 (87.715)\n",
      "Epoch: [46][70/96]\tLoss 0.1219 (0.2467)\taccuracy 95.312 (89.833)\tf1_score 94.498 (87.914)\n",
      "Epoch: [46][75/96]\tLoss 0.3108 (0.2485)\taccuracy 85.938 (89.659)\tf1_score 72.426 (87.599)\n",
      "Epoch: [46][80/96]\tLoss 0.6163 (0.2532)\taccuracy 76.562 (89.545)\tf1_score 76.806 (87.510)\n",
      "Epoch: [46][85/96]\tLoss 0.4491 (0.2561)\taccuracy 84.375 (89.390)\tf1_score 75.593 (87.228)\n",
      "Epoch: [46][90/96]\tLoss 0.2864 (0.2568)\taccuracy 89.062 (89.354)\tf1_score 92.120 (87.284)\n",
      "Epoch: [46][95/96]\tLoss 0.1754 (0.2552)\taccuracy 93.750 (89.469)\tf1_score 88.952 (87.410)\n",
      " Test: accuracy 87.956 f1_score 85.558\n",
      "Training time:  922.9202616214752 Hour:  0 Minute:  15 Second:  22 Test best accuracy: 87.95572916666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 47\n",
      "Epoch: [47][0/96]\tLoss 0.3401 (0.3401)\taccuracy 87.500 (87.500)\tf1_score 78.274 (78.274)\n",
      "Epoch: [47][5/96]\tLoss 0.2918 (0.2991)\taccuracy 85.938 (88.281)\tf1_score 82.971 (85.007)\n",
      "Epoch: [47][10/96]\tLoss 0.4668 (0.3200)\taccuracy 82.812 (87.500)\tf1_score 81.182 (84.809)\n",
      "Epoch: [47][15/96]\tLoss 0.2621 (0.2983)\taccuracy 89.062 (88.477)\tf1_score 86.295 (85.281)\n",
      "Epoch: [47][20/96]\tLoss 0.1901 (0.2803)\taccuracy 92.188 (89.360)\tf1_score 93.282 (86.575)\n",
      "Epoch: [47][25/96]\tLoss 0.1365 (0.2791)\taccuracy 96.875 (89.002)\tf1_score 96.886 (86.255)\n",
      "Epoch: [47][30/96]\tLoss 0.2185 (0.2697)\taccuracy 89.062 (89.062)\tf1_score 87.560 (86.394)\n",
      "Epoch: [47][35/96]\tLoss 0.3008 (0.2708)\taccuracy 87.500 (89.019)\tf1_score 85.165 (86.387)\n",
      "Epoch: [47][40/96]\tLoss 0.3054 (0.2702)\taccuracy 89.062 (89.139)\tf1_score 82.218 (86.369)\n",
      "Epoch: [47][45/96]\tLoss 0.2084 (0.2645)\taccuracy 89.062 (89.470)\tf1_score 81.262 (86.618)\n",
      "Epoch: [47][50/96]\tLoss 0.2343 (0.2618)\taccuracy 90.625 (89.553)\tf1_score 87.071 (86.646)\n",
      "Epoch: [47][55/96]\tLoss 0.1581 (0.2616)\taccuracy 95.312 (89.676)\tf1_score 96.091 (86.838)\n",
      "Epoch: [47][60/96]\tLoss 0.3916 (0.2642)\taccuracy 79.688 (89.575)\tf1_score 81.897 (86.815)\n",
      "Epoch: [47][65/96]\tLoss 0.2621 (0.2646)\taccuracy 89.062 (89.536)\tf1_score 87.897 (86.826)\n",
      "Epoch: [47][70/96]\tLoss 0.1930 (0.2646)\taccuracy 90.625 (89.547)\tf1_score 84.690 (86.714)\n",
      "Epoch: [47][75/96]\tLoss 0.2698 (0.2642)\taccuracy 89.062 (89.618)\tf1_score 87.997 (86.899)\n",
      "Epoch: [47][80/96]\tLoss 0.1385 (0.2639)\taccuracy 93.750 (89.622)\tf1_score 89.240 (86.982)\n",
      "Epoch: [47][85/96]\tLoss 0.3315 (0.2644)\taccuracy 90.625 (89.644)\tf1_score 91.670 (87.088)\n",
      "Epoch: [47][90/96]\tLoss 0.5552 (0.2641)\taccuracy 76.562 (89.663)\tf1_score 68.637 (86.974)\n",
      "Epoch: [47][95/96]\tLoss 0.2747 (0.2600)\taccuracy 87.500 (89.827)\tf1_score 79.105 (87.116)\n",
      " Test: accuracy 77.279 f1_score 72.856\n",
      "Training time:  938.8405797481537 Hour:  0 Minute:  15 Second:  38 Test best accuracy: 87.95572916666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 48\n",
      "Epoch: [48][0/96]\tLoss 0.1994 (0.1994)\taccuracy 95.312 (95.312)\tf1_score 93.519 (93.519)\n",
      "Epoch: [48][5/96]\tLoss 0.2110 (0.2524)\taccuracy 90.625 (91.146)\tf1_score 88.450 (86.323)\n",
      "Epoch: [48][10/96]\tLoss 0.2839 (0.2801)\taccuracy 89.062 (90.057)\tf1_score 83.965 (84.779)\n",
      "Epoch: [48][15/96]\tLoss 0.4975 (0.3088)\taccuracy 84.375 (89.551)\tf1_score 82.714 (85.569)\n",
      "Epoch: [48][20/96]\tLoss 0.2579 (0.3055)\taccuracy 93.750 (89.360)\tf1_score 89.222 (85.803)\n",
      "Epoch: [48][25/96]\tLoss 0.1768 (0.2963)\taccuracy 93.750 (89.303)\tf1_score 94.845 (85.871)\n",
      "Epoch: [48][30/96]\tLoss 0.1271 (0.2819)\taccuracy 95.312 (89.819)\tf1_score 91.901 (86.735)\n",
      "Epoch: [48][35/96]\tLoss 0.1288 (0.2811)\taccuracy 95.312 (89.670)\tf1_score 94.222 (86.948)\n",
      "Epoch: [48][40/96]\tLoss 0.2212 (0.2819)\taccuracy 93.750 (89.596)\tf1_score 86.863 (86.885)\n",
      "Epoch: [48][45/96]\tLoss 0.2683 (0.2767)\taccuracy 90.625 (89.776)\tf1_score 88.861 (87.114)\n",
      "Epoch: [48][50/96]\tLoss 0.1570 (0.2768)\taccuracy 96.875 (89.675)\tf1_score 95.619 (86.985)\n",
      "Epoch: [48][55/96]\tLoss 0.2521 (0.2832)\taccuracy 92.188 (89.509)\tf1_score 86.433 (86.581)\n",
      "Epoch: [48][60/96]\tLoss 0.1174 (0.2717)\taccuracy 93.750 (89.908)\tf1_score 88.095 (86.992)\n",
      "Epoch: [48][65/96]\tLoss 0.4393 (0.2749)\taccuracy 84.375 (89.891)\tf1_score 85.057 (87.037)\n",
      "Epoch: [48][70/96]\tLoss 0.1721 (0.2716)\taccuracy 95.312 (90.141)\tf1_score 95.778 (87.386)\n",
      "Epoch: [48][75/96]\tLoss 0.1996 (0.2750)\taccuracy 95.312 (89.926)\tf1_score 94.895 (87.344)\n",
      "Epoch: [48][80/96]\tLoss 0.1579 (0.2735)\taccuracy 93.750 (89.950)\tf1_score 91.738 (87.315)\n",
      "Epoch: [48][85/96]\tLoss 0.2607 (0.2717)\taccuracy 90.625 (90.025)\tf1_score 88.040 (87.530)\n",
      "Epoch: [48][90/96]\tLoss 0.2029 (0.2710)\taccuracy 90.625 (89.973)\tf1_score 87.052 (87.521)\n",
      "Epoch: [48][95/96]\tLoss 0.1808 (0.2673)\taccuracy 92.188 (90.088)\tf1_score 87.475 (87.672)\n",
      " Test: accuracy 87.305 f1_score 85.320\n",
      "Training time:  954.7935793399811 Hour:  0 Minute:  15 Second:  54 Test best accuracy: 87.95572916666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 49\n",
      "Epoch: [49][0/96]\tLoss 0.2045 (0.2045)\taccuracy 93.750 (93.750)\tf1_score 94.218 (94.218)\n",
      "Epoch: [49][5/96]\tLoss 0.3673 (0.2143)\taccuracy 82.812 (90.365)\tf1_score 80.429 (88.747)\n",
      "Epoch: [49][10/96]\tLoss 0.1426 (0.2396)\taccuracy 92.188 (90.767)\tf1_score 91.948 (89.290)\n",
      "Epoch: [49][15/96]\tLoss 0.2386 (0.2412)\taccuracy 87.500 (90.625)\tf1_score 87.998 (88.797)\n",
      "Epoch: [49][20/96]\tLoss 0.4094 (0.2437)\taccuracy 78.125 (90.253)\tf1_score 77.343 (88.480)\n",
      "Epoch: [49][25/96]\tLoss 0.5342 (0.2473)\taccuracy 71.875 (89.844)\tf1_score 75.051 (88.442)\n",
      "Epoch: [49][30/96]\tLoss 0.2884 (0.2463)\taccuracy 90.625 (89.919)\tf1_score 91.512 (88.497)\n",
      "Epoch: [49][35/96]\tLoss 0.1922 (0.2447)\taccuracy 90.625 (89.800)\tf1_score 86.755 (88.290)\n",
      "Epoch: [49][40/96]\tLoss 0.1705 (0.2537)\taccuracy 95.312 (89.444)\tf1_score 95.748 (88.041)\n",
      "Epoch: [49][45/96]\tLoss 0.1716 (0.2510)\taccuracy 92.188 (89.436)\tf1_score 90.962 (88.124)\n",
      "Epoch: [49][50/96]\tLoss 0.1705 (0.2555)\taccuracy 96.875 (89.308)\tf1_score 97.581 (87.944)\n",
      "Epoch: [49][55/96]\tLoss 0.4298 (0.2536)\taccuracy 82.812 (89.537)\tf1_score 83.793 (88.289)\n",
      "Epoch: [49][60/96]\tLoss 0.2180 (0.2554)\taccuracy 90.625 (89.344)\tf1_score 85.620 (87.993)\n",
      "Epoch: [49][65/96]\tLoss 0.3569 (0.2561)\taccuracy 85.938 (89.323)\tf1_score 80.777 (87.837)\n",
      "Epoch: [49][70/96]\tLoss 0.1905 (0.2548)\taccuracy 89.062 (89.327)\tf1_score 85.206 (87.807)\n",
      "Epoch: [49][75/96]\tLoss 0.2859 (0.2523)\taccuracy 89.062 (89.453)\tf1_score 83.610 (87.879)\n",
      "Epoch: [49][80/96]\tLoss 0.1868 (0.2523)\taccuracy 93.750 (89.506)\tf1_score 93.209 (87.887)\n",
      "Epoch: [49][85/96]\tLoss 0.2535 (0.2510)\taccuracy 90.625 (89.553)\tf1_score 87.336 (87.748)\n",
      "Epoch: [49][90/96]\tLoss 0.2758 (0.2508)\taccuracy 90.625 (89.629)\tf1_score 94.621 (87.859)\n",
      "Epoch: [49][95/96]\tLoss 0.2211 (0.2494)\taccuracy 92.188 (89.746)\tf1_score 90.401 (88.030)\n",
      " Test: accuracy 81.185 f1_score 76.407\n",
      "Training time:  970.7760698795319 Hour:  0 Minute:  16 Second:  10 Test best accuracy: 87.95572916666667  Test best f1 score: 0\n",
      "\n",
      "Start of epoch NO: 50\n",
      "Epoch: [50][0/96]\tLoss 0.3027 (0.3027)\taccuracy 89.062 (89.062)\tf1_score 80.975 (80.975)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][5/96]\tLoss 0.8666 (0.3984)\taccuracy 73.438 (86.458)\tf1_score 69.384 (83.622)\n",
      "Epoch: [50][10/96]\tLoss 0.3000 (0.3445)\taccuracy 89.062 (87.358)\tf1_score 88.976 (83.684)\n",
      "Epoch: [50][15/96]\tLoss 0.3953 (0.3311)\taccuracy 84.375 (87.598)\tf1_score 81.311 (84.532)\n",
      "Epoch: [50][20/96]\tLoss 0.5405 (0.3378)\taccuracy 81.250 (87.649)\tf1_score 82.459 (84.929)\n",
      "Epoch: [50][25/96]\tLoss 0.2629 (0.3426)\taccuracy 90.625 (87.800)\tf1_score 89.405 (85.042)\n",
      "Epoch: [50][30/96]\tLoss 0.2696 (0.3395)\taccuracy 92.188 (87.702)\tf1_score 90.862 (85.027)\n",
      "Epoch: [50][35/96]\tLoss 0.3043 (0.3303)\taccuracy 87.500 (87.804)\tf1_score 85.266 (85.091)\n",
      "Epoch: [50][40/96]\tLoss 0.3031 (0.3256)\taccuracy 87.500 (87.691)\tf1_score 82.154 (84.689)\n",
      "Epoch: [50][45/96]\tLoss 0.5689 (0.3256)\taccuracy 76.562 (87.704)\tf1_score 75.284 (84.747)\n",
      "Epoch: [50][50/96]\tLoss 0.2403 (0.3258)\taccuracy 87.500 (87.561)\tf1_score 83.869 (84.719)\n",
      "Epoch: [50][55/96]\tLoss 0.6363 (0.3278)\taccuracy 76.562 (87.472)\tf1_score 74.548 (84.651)\n",
      "Epoch: [50][60/96]\tLoss 0.2581 (0.3267)\taccuracy 90.625 (87.551)\tf1_score 90.646 (84.830)\n",
      "Epoch: [50][65/96]\tLoss 0.2436 (0.3212)\taccuracy 92.188 (87.784)\tf1_score 82.279 (84.922)\n",
      "Epoch: [50][70/96]\tLoss 0.4406 (0.3186)\taccuracy 82.812 (87.808)\tf1_score 76.277 (84.888)\n",
      "Epoch: [50][75/96]\tLoss 0.2510 (0.3218)\taccuracy 92.188 (87.603)\tf1_score 92.496 (84.825)\n",
      "Epoch: [50][80/96]\tLoss 0.2824 (0.3224)\taccuracy 90.625 (87.654)\tf1_score 85.556 (84.938)\n",
      "Epoch: [50][85/96]\tLoss 0.3243 (0.3239)\taccuracy 89.062 (87.555)\tf1_score 80.173 (84.829)\n",
      "Epoch: [50][90/96]\tLoss 0.3732 (0.3201)\taccuracy 84.375 (87.723)\tf1_score 75.508 (84.902)\n",
      "Epoch: [50][95/96]\tLoss 0.1610 (0.3140)\taccuracy 96.875 (87.972)\tf1_score 93.076 (85.224)\n",
      " Test: accuracy 85.547 f1_score 82.957\n",
      "Training time:  986.7756242752075 Hour:  0 Minute:  16 Second:  26 Test best accuracy: 87.95572916666667  Test best f1 score: 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch NO: %d\" % (epoch,))\n",
    "    adjust_learning_rate(optimizer, epoch, args=1)\n",
    "    train(train_loader, model, criterion,  optimizer, epoch, print_interval=5)\n",
    "    acc, f1 = validate(test_loader, model, criterion,  args=1)\n",
    "    \n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "            \n",
    "    time_interval = time.time() - start_time\n",
    "    time_split = time.gmtime(time_interval)\n",
    "    print(\"Training time: \", time_interval, \"Hour: \", time_split.tm_hour, \"Minute: \", time_split.tm_min, \"Second: \",\n",
    "              time_split.tm_sec, end='')\n",
    "    print(\" Test best accuracy:\", best_acc, \" Test best f1 score:\", best_f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff9e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb5b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399effc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
